1
00:00:04,440 --> 00:00:10,960
It is my experience that proofs involving matrices can be shortened by 50% if one throws matrices out.
-- Emil Artin

2
00:00:10,960 --> 00:00:12,020
Hey everyone!

3
00:00:12,020 --> 00:00:15,129
Where we last left off, I showed what linear
transformations look like

4
00:00:15,129 --> 00:00:18,369
and how to represent them using matrices.

5
00:00:18,369 --> 00:00:20,859
This is worth a quick recap, because it's
just really important.

6
00:00:20,859 --> 00:00:25,970
But of course, if this feels like more than
just a recap, go back and watch the full video.

7
00:00:25,970 --> 00:00:30,279
Technically speaking, linear transformations
are functions, with vectors as inputs

8
00:00:30,279 --> 00:00:31,789
and vectors as outputs.

9
00:00:31,789 --> 00:00:34,009
But I showed last time how we can think about
them visually as

10
00:00:34,009 --> 00:00:39,271
smooshing around space in such a way the gridlines
stay parallel and evenly spaced,

11
00:00:39,280 --> 00:00:41,620
and so that the origin remains fixed.

12
00:00:41,620 --> 00:00:42,899
The key take-away was that

13
00:00:42,900 --> 00:00:48,500
a linear transformation is completely determined,
by where it takes the basis vectors of the space

14
00:00:48,500 --> 00:00:51,720
which, for two dimensions, means i-hat and
j-hat.

15
00:00:51,940 --> 00:00:57,500
This is because any other vector can be described
as a linear combination of those basis vectors.

16
00:00:57,510 --> 00:00:59,789
A vector with coordinates (x, y)

17
00:00:59,789 --> 00:01:03,249
is x times i-hat + y times j-hat.

18
00:01:03,249 --> 00:01:04,959
After going through the transformation

19
00:01:04,959 --> 00:01:08,490
this property, the grid lines remain parallel
and evenly spaced,

20
00:01:08,490 --> 00:01:10,140
has a wonderful consequence.

21
00:01:10,360 --> 00:01:15,390
The place where your vector lands will be
x times the transformed version of i-hat +

22
00:01:15,390 --> 00:01:18,010
y times the transformed version of j-hat.

23
00:01:18,200 --> 00:01:21,760
This means if you keep a record of the coordinates
where i-hat lands

24
00:01:21,760 --> 00:01:23,940
and the coordinates where j-hat lands

25
00:01:23,940 --> 00:01:26,920
you can compute that a vector which starts
at (x, y),

26
00:01:26,920 --> 00:01:30,180
must land on x times the new coordinates of
i-hat

27
00:01:30,190 --> 00:01:33,610
+ y times the new coordinates of j-hat.

28
00:01:33,610 --> 00:01:37,160
The convention is to record the coordinates
of where i-hat and j-hat land

29
00:01:37,160 --> 00:01:39,300
as the columns of a matrix

30
00:01:39,300 --> 00:01:43,430
and to define this sum of the scaled versions
of those columns by x and y

31
00:01:43,430 --> 00:01:46,280
to be matrix-vector multiplication.

32
00:01:46,280 --> 00:01:47,280
In this way,

33
00:01:47,280 --> 00:01:50,140
a matrix represents a specific linear transformation

34
00:01:50,140 --> 00:01:54,200
and multiplying a matrix by a vector is, what
it means computationally,

35
00:01:54,200 --> 00:01:57,630
to apply that transformation to that vector.

36
00:01:57,970 --> 00:02:00,110
Alright, recap over.

37
00:02:00,110 --> 00:02:01,640
Onto the new stuff.

38
00:02:01,640 --> 00:02:04,520
Often-times you find yourself wanting to describe
the effect

39
00:02:04,520 --> 00:02:07,480
of applying one transformation and then another.

40
00:02:07,480 --> 00:02:08,479
For example,

41
00:02:08,479 --> 00:02:12,899
maybe you want to describe what happens when
you first rotate the plane 90° counterclockwise

42
00:02:12,900 --> 00:02:15,240
then apply a shear.

43
00:02:15,240 --> 00:02:17,780
The overall effect here, from start to finish,

44
00:02:17,780 --> 00:02:19,760
is another linear transformation,

45
00:02:19,760 --> 00:02:22,290
distinct from the rotation and the shear.

46
00:02:22,290 --> 00:02:25,630
This new linear transformation is commonly called the “composition”

47
00:02:25,630 --> 00:02:28,750
of the two separate transformations we applied.

48
00:02:28,840 --> 00:02:30,380
And like any linear transformation

49
00:02:30,380 --> 00:02:36,169
it can be described with a matrix all of its
own, by following i-hat and j-hat.

50
00:02:36,169 --> 00:02:39,160
In this example, the ultimate landing spot
for i-hat

51
00:02:39,160 --> 00:02:42,261
after both transformations is (1, 1).

52
00:02:42,261 --> 00:02:44,909
So let's make that the first column of the
matrix.

53
00:02:44,909 --> 00:02:49,209
Likewise, j-hat ultimately ends up at the
location (-1, 0),

54
00:02:49,209 --> 00:02:52,269
so we make that the second column of the matrix.

55
00:02:52,460 --> 00:02:57,682
This new matrix captures the overall effect
of applying a rotation then a sheer

56
00:02:57,682 --> 00:03:03,080
but as one single action, rather than two
successive ones.

57
00:03:03,180 --> 00:03:05,249
Here's one way to think about that new matrix:

58
00:03:05,249 --> 00:03:09,369
if you were to take some vector and pump it
through the rotation then the sheer

59
00:03:09,459 --> 00:03:11,560
the long way to compute where it ends up

60
00:03:11,560 --> 00:03:15,220
is to, first, multiply it on the left by the
rotation matrix;

61
00:03:15,220 --> 00:03:20,180
then, take whatever you get and multiply that
on the left by the sheer matrix.

62
00:03:20,180 --> 00:03:21,980
This is, numerically speaking,

63
00:03:21,980 --> 00:03:26,440
what it means to apply a rotation then a sheer
to a given vector.

64
00:03:26,530 --> 00:03:30,640
But, whatever you get should be the same as
just applying this new composition matrix

65
00:03:30,640 --> 00:03:33,020
that we just found, by
that same vector,

66
00:03:33,020 --> 00:03:34,800
no matter what vector you chose,

67
00:03:34,800 --> 00:03:38,369
since this new matrix is supposed to capture
the same overall effect

68
00:03:38,369 --> 00:03:42,310
as the rotation-then-sheer action.

69
00:03:42,310 --> 00:03:44,190
Based on how things are written down here

70
00:03:44,190 --> 00:03:48,850
I think it's reasonable to call this new matrix,
the “product” of the original two matrices.

71
00:03:48,850 --> 00:03:50,389
Don't you?

72
00:03:50,389 --> 00:03:53,891
We can think about how to compute that product
more generally in just a moment,

73
00:03:53,900 --> 00:03:56,980
but it's way too easy to get lost in the forest
of numbers.

74
00:03:56,980 --> 00:03:59,980
Always remember, the multiplying two matrices
like this

75
00:03:59,980 --> 00:04:06,051
has the geometric meaning of applying one
transformation then another.

76
00:04:06,060 --> 00:04:09,810
One thing that's kinda weird here, is that
this has reading from right to left;

77
00:04:09,810 --> 00:04:13,470
you first apply the transformation represented
by the matrix on the right.

78
00:04:13,470 --> 00:04:17,320
Then you apply the transformation represented
by the matrix on the left.

79
00:04:17,320 --> 00:04:19,329
This stems from function notation,

80
00:04:19,329 --> 00:04:21,629
since we write functions on the left of variables,

81
00:04:21,630 --> 00:04:25,840
so every time you compose two functions, you
always have to read it right to left.

82
00:04:25,840 --> 00:04:29,770
Good news for the Hebrew readers, bad news
for the rest of us.

83
00:04:29,770 --> 00:04:31,550
Let's look at another example.

84
00:04:31,550 --> 00:04:35,140
Take the matrix with columns (1, 1) and (-2, 0)

85
00:04:35,180 --> 00:04:37,840
whose transformation looks like this,

86
00:04:37,880 --> 00:04:39,530
and let's call it M1.

87
00:04:39,760 --> 00:04:43,820
Next, take the matrix with columns (0, 1)
and (2, 0)

88
00:04:43,820 --> 00:04:47,580
whose transformation looks like this,

89
00:04:47,580 --> 00:04:49,780
and let's call that guy M2.

90
00:04:49,780 --> 00:04:52,900
The total effect of applying M1 then M2

91
00:04:52,900 --> 00:04:54,460
gives us a new transformation.

92
00:04:54,460 --> 00:04:56,080
So let's find its matrix.

93
00:04:56,080 --> 00:05:00,040
But this time, let's see if we can do it without
watching the animations

94
00:05:00,040 --> 00:05:04,480
and instead, just using the numerical entries
in each matrix.

95
00:05:04,600 --> 00:05:08,000
First, we need to figure out where i-hat goes

96
00:05:08,000 --> 00:05:11,200
after applying M1 the new coordinates of i-hat,

97
00:05:11,200 --> 00:05:14,780
by definition, are given by that first column
of M1,

98
00:05:14,780 --> 00:05:16,920
namely, (1, 1)

99
00:05:16,920 --> 00:05:19,280
to see what happens after applying M2

100
00:05:19,280 --> 00:05:25,030
multiply the matrix for M2 by that vector
(1,1).

101
00:05:25,240 --> 00:05:28,120
Working it out, the way that I described last
video

102
00:05:28,120 --> 00:05:30,480
you'll get the vector (2, 1).

103
00:05:30,480 --> 00:05:33,530
This will be the first column of the composition
matrix.

104
00:05:34,240 --> 00:05:36,100
Likewise, to follow j-hat

105
00:05:36,100 --> 00:05:41,970
the second column of M1 tells us the first
lands on (-2, 0)

106
00:05:42,170 --> 00:05:48,180
then, when we apply M2 to that vector

107
00:05:48,180 --> 00:05:52,740
you can work out the matrix-vector product
to get (0, -2)

108
00:05:52,740 --> 00:05:57,060
which becomes the second column of our composition
matrix.

109
00:05:57,060 --> 00:05:59,590
Let me talk to that same process again, but
this time,

110
00:05:59,590 --> 00:06:02,060
I'll show variable entries in each matrix,

111
00:06:02,060 --> 00:06:05,620
just to show that the same line of reasoning
works for any matrices.

112
00:06:05,620 --> 00:06:08,380
This is more symbol heavy and will require
some more room,

113
00:06:08,380 --> 00:06:12,320
but it should be pretty satisfying for anyone
who has previously been taught matrix multiplication

114
00:06:12,320 --> 00:06:14,320
the more rote way.

115
00:06:14,320 --> 00:06:15,900
To follow where i-hat goes

116
00:06:15,900 --> 00:06:18,900
start by looking at the first column of the
matrix on the right,

117
00:06:18,900 --> 00:06:21,600
since this is where i-hat initially lands.

118
00:06:21,600 --> 00:06:24,540
Multiplying that column by the matrix on the
left,

119
00:06:24,540 --> 00:06:28,880
is how you can tell where the intermediate
version of i-hat ends up after applying

120
00:06:28,880 --> 00:06:30,650
the second transformation.

121
00:06:31,080 --> 00:06:34,000
So, the first column of the composition matrix

122
00:06:34,000 --> 00:06:40,720
will always equal the left matrix times the
first column of the right matrix.

123
00:06:41,820 --> 00:06:48,660
Likewise, j-hat will always initially land
on the second column of the right matrix.

124
00:06:48,660 --> 00:06:53,760
So multiplying the left matrix by this second
column will give its final location

125
00:06:53,760 --> 00:06:58,580
and hence, that's the second column of the
composition matrix.

126
00:07:00,360 --> 00:07:02,500
Notice, there's a lot of symbols here

127
00:07:02,500 --> 00:07:05,500
and it's common to be taught this formula
as something to memorize

128
00:07:05,500 --> 00:07:09,020
along with a certain algorithmic process to
kind of help remember it.

129
00:07:09,020 --> 00:07:11,920
But I really do think that before memorizing
that process

130
00:07:11,920 --> 00:07:16,660
you should get in the habit of thinking about
what matrix multiplication really represents:

131
00:07:16,660 --> 00:07:19,360
applying one transformation after another.

132
00:07:19,400 --> 00:07:22,500
Trust me, this will give you a much better
conceptual framework

133
00:07:22,500 --> 00:07:26,850
that makes the properties of matrix multiplication
much easier to understand.

134
00:07:26,850 --> 00:07:28,340
For example, here's a question:

135
00:07:28,340 --> 00:07:33,480
Does it matter what order we put the two matrices
in when we multiply them?

136
00:07:33,480 --> 00:07:36,060
Well, let's think through a simple example

137
00:07:36,060 --> 00:07:37,440
like the one from earlier:

138
00:07:37,440 --> 00:07:41,280
Take a shear which fixes i-hat and smooshes
j-hat over to the right

139
00:07:41,280 --> 00:07:43,380
and a 90° rotation.

140
00:07:43,380 --> 00:07:46,190
If you first do the shear then rotate,

141
00:07:46,190 --> 00:07:48,870
we can see that i-hat ends up at (0, 1)

142
00:07:48,870 --> 00:07:50,990
and j-hat ends up at (-1, 1)

143
00:07:50,990 --> 00:07:53,650
both are generally pointing close together.

144
00:07:53,650 --> 00:07:57,580
If you first rotate then do the shear

145
00:07:57,740 --> 00:08:00,090
i-hat ends up over at (1, 1)

146
00:08:00,090 --> 00:08:03,670
and j-hat is off on a different direction
at (-1, 0)

147
00:08:03,670 --> 00:08:06,220
and they're pointing, you know, farther apart.

148
00:08:06,220 --> 00:08:08,030
The overall effect here is clearly different

149
00:08:08,030 --> 00:08:11,310
so, evidently, order totally does matter.

150
00:08:11,510 --> 00:08:14,850
Notice, by thinking in terms of transformations

151
00:08:14,850 --> 00:08:18,070
that's the kind of thing that you can do in
your head, by visualizing.

152
00:08:18,070 --> 00:08:21,510
No matrix multiplication necessary.

153
00:08:21,560 --> 00:08:23,920
I remember when I first took linear algebra

154
00:08:23,920 --> 00:08:28,180
there's this one homework problem that asked
us to prove that matrix multiplication is

155
00:08:28,180 --> 00:08:29,420
associative.

156
00:08:29,420 --> 00:08:32,519
This means that if you have three matrices
A, B and C,

157
00:08:32,520 --> 00:08:34,320
and you multiply them all together,

158
00:08:34,320 --> 00:08:39,491
it shouldn't matter if you first compute A
times B then multiply the result by C,

159
00:08:39,500 --> 00:08:44,719
or if you first multiply B times C then multiply
that result by A on the left.

160
00:08:44,720 --> 00:08:47,931
In other words, it doesn't matter where you
put the parentheses.

161
00:08:47,940 --> 00:08:50,370
Now if you try to work through this numerically

162
00:08:50,370 --> 00:08:52,139
like I did back then,

163
00:08:52,140 --> 00:08:56,090
it's horrible, just horrible, and unenlightening
for that matter.

164
00:08:56,090 --> 00:09:01,031
But when you think about matrix multiplication
as applying one transformation after another,

165
00:09:01,040 --> 00:09:03,110
this property is just trivial.

166
00:09:03,110 --> 00:09:04,709
Can you see why?

167
00:09:04,709 --> 00:09:09,360
What it's saying is that if you first apply
C then B, then A,

168
00:09:09,360 --> 00:09:12,759
it's the same as applying C, then B then A.

169
00:09:12,840 --> 00:09:14,441
I mean, there's nothing to prove,

170
00:09:14,441 --> 00:09:19,361
you're just applying the same three things
one after the other all in the same order.

171
00:09:19,361 --> 00:09:20,670
This might feel like cheating.

172
00:09:20,670 --> 00:09:21,720
But it's not!

173
00:09:21,720 --> 00:09:26,009
This is an honest-to-goodness proof that matrix
multiplication is associative,

174
00:09:26,009 --> 00:09:30,990
and even better than that, it's a good explanation
for why that property should be true.

175
00:09:31,329 --> 00:09:34,589
I really do encourage you to play around more
with this idea

176
00:09:34,589 --> 00:09:36,810
imagining two different transformations

177
00:09:36,810 --> 00:09:39,740
thinking about what happens when you apply
one after the other

178
00:09:39,740 --> 00:09:42,020
and then working out the matrix product numerically.

179
00:09:42,020 --> 00:09:47,339
Trust me, this is the kind of play time that
really makes the idea sink in.

180
00:09:47,339 --> 00:09:51,819
In the next video I'll start talking about
extending these ideas beyond just two dimensions.

181
00:09:51,820 --> 00:09:54,120
See you then!

