1
00:00:05,390 --> 00:00:10,000
Here, we look at the math behind an animation
like this, what’s known as a “complex

2
00:00:10,000 --> 00:00:15,270
Fourier series”. Each little vector is rotating
at some constant integer frequency, and when

3
00:00:15,270 --> 00:00:21,710
you add them all together, tip to tail, they
draw out some shape over time. By tweaking

4
00:00:21,710 --> 00:00:27,430
the initial size and angle of each vector,
we can make it draw anything we want, and

5
00:00:27,430 --> 00:00:31,439
here you’ll see how.

6
00:00:31,439 --> 00:00:37,960
Before diving in, take a moment to linger
on just how striking this is. This particular

7
00:00:37,960 --> 00:00:43,469
animation has 300 rotating arrows in total.
Go full screen for this is you can, the intricacy

8
00:00:43,469 --> 00:00:55,399
is worth it. Think about this, the action
of each individual arrow is perhaps the simplest

9
00:00:55,399 --> 00:01:00,760
thing you could imagine: Rotation at a steady
rate. Yet the collection of all added together

10
00:01:00,760 --> 00:01:05,880
is anything but simple. The mind-boggling
complexity is put into even sharper focus

11
00:01:05,880 --> 00:01:11,450
the farther we zoom in, revealing the contributions
of the littlest, quickest arrows.

12
00:01:11,450 --> 00:01:17,410
Considering the chaotic frenzy you’re looking
at, and the clockwork rigidity of the underlying

13
00:01:17,410 --> 00:01:22,110
motions, it’s bizarre how the swarm acts
with a kind of coordination to trace out some

14
00:01:22,110 --> 00:01:27,549
very specific shape. Unlike much of the emergent
complexity you find elsewhere in nature, though,

15
00:01:27,549 --> 00:01:32,560
this is something we have the math to describe
and to control completely. Just by tuning

16
00:01:32,560 --> 00:01:37,270
the starting conditions, nothing more, you
can make this swarm conspire in all the right

17
00:01:37,270 --> 00:01:42,799
ways to draw anything you want, provided you
have enough little arrows. What’s even crazier,

18
00:01:42,799 --> 00:01:50,140
as you’ll see, is the ultimate formula for
all this is incredibly short.

19
00:01:50,140 --> 00:01:59,010
Often, Fourier series are described in terms
of functions of real numbers being broken

20
00:01:59,010 --> 00:02:03,590
down as a sum of sine waves. That turns out
to be a special case of this more general

21
00:02:03,590 --> 00:02:07,960
rotating vector phenomenon that we’ll build
up to, but it’s where Fourier himself started,

22
00:02:07,960 --> 00:02:11,250
and there’s good reason for us to start
the story there as well.

23
00:02:11,250 --> 00:02:15,519
Technically, this is the third video in a
sequence about the heat equation, what Fourier

24
00:02:15,519 --> 00:02:19,980
was working on when he developed his big idea.
I’d like to teach you about Fourier series

25
00:02:19,980 --> 00:02:23,760
in a way that doesn’t depend on you coming
from those chapters, but if you have at least

26
00:02:23,760 --> 00:02:27,980
a high-level idea of the problem form physics
which originally motivated this piece of math,

27
00:02:27,980 --> 00:02:33,030
it gives some indication for how unexpectedly
far-reaching Fourier series are.

28
00:02:33,030 --> 00:02:39,220
All you need to know is that we had this equation,
describing how the temperature on a rod will

29
00:02:39,220 --> 00:02:44,620
evolve over time (which incidentally also
describes many other phenomena unrelated to

30
00:02:44,620 --> 00:02:49,690
heat), and while it’s hard to directly use
it to figure out what will happen to an arbitrary

31
00:02:49,690 --> 00:02:54,659
heat distribution, there’s a simple solution
if that initial function looks like a cosine

32
00:02:54,659 --> 00:02:59,880
wave with a frequency tuned to make it flat
at each endpoint. Specifically, as you graph

33
00:02:59,880 --> 00:03:05,010
what happens over time, these waves simply
get scaled down exponentially, with higher

34
00:03:05,010 --> 00:03:10,819
frequency waves decaying faster.

35
00:03:10,819 --> 00:03:15,180
The heat equation happens to be what’s known
in the business as a “linear” equation,

36
00:03:15,180 --> 00:03:20,870
meaning if you know two solutions and you
add them up, that sum is also a new solution.

37
00:03:20,870 --> 00:03:25,360
You can even scale them each by some constant,
which gives you some dials to turn to construct

38
00:03:25,360 --> 00:03:29,319
a custom function solving the equation.

39
00:03:29,319 --> 00:03:33,121
This is a fairly straightforward property
that you can verify for yourself, but it’s

40
00:03:33,121 --> 00:03:38,239
incredibly important. It means we can take
our infinite family of solutions, these exponentially

41
00:03:38,239 --> 00:03:42,900
decaying cosine waves, scale a few of them
by some custom constants of our choosing,

42
00:03:42,900 --> 00:03:48,020
and combine them to get a solution for a new
tailor-made initial condition which is some

43
00:03:48,020 --> 00:03:50,019
combination of cosine waves.

44
00:03:50,019 --> 00:03:54,500
Something important I want you to notice about
combining the waves like this is that because

45
00:03:54,500 --> 00:04:00,379
higher frequency ones decay faster, this sum
which you construct will smooth out over time

46
00:04:00,379 --> 00:04:05,340
as the high-frequency terms quickly go to
zero, leaving only the low-frequency terms

47
00:04:05,340 --> 00:04:11,629
dominating. So in some sense, all the complexity
in the evolution that the heat equation implies

48
00:04:11,629 --> 00:04:17,100
is captured by this difference in decay rates
for the different frequency components.

49
00:04:17,100 --> 00:04:23,480
It’s at this point that Fourier gains immortality.
I think most normal people at this stage would

50
00:04:23,480 --> 00:04:27,940
say “well, I can solve the heat equation
when the initial temperature distribution

51
00:04:27,940 --> 00:04:33,230
happens to look like a wave, or a sum of waves,
but what a shame that most real-world distributions

52
00:04:33,230 --> 00:04:35,170
don’t at all look like this!”

53
00:04:35,170 --> 00:04:40,040
For example, let’s say you brought together
two rods, each at some uniform temperature,

54
00:04:40,040 --> 00:04:45,640
and you wanted to know what happens immediately
after they come into contact. To make the

55
00:04:45,640 --> 00:04:49,320
numbers simple, let’s say the temperature
of the left rod is 1 degree, and the right

56
00:04:49,320 --> 00:04:57,300
rod is -1 degree, and that the total length
L of the combined rod is 1. Our initial temperature

57
00:04:57,300 --> 00:05:02,880
distribution is a step function, which is
so obviously different from sine waves and

58
00:05:02,880 --> 00:05:07,690
sums of sine waves, don’t you think? I mean,
it’s almost entirely flat, not wavy, and

59
00:05:07,690 --> 00:05:10,070
for god’s sake, it’s even discontinuous!

60
00:05:10,070 --> 00:05:15,440
And yet, Fourier thought to ask a question
which seems absurd: How do you express this

61
00:05:15,440 --> 00:05:20,061
as a sum of sine waves? Even more boldly,
how do you express any initial temperature

62
00:05:20,061 --> 00:05:21,870
distribution as a sum of sine waves?

63
00:05:21,870 --> 00:05:25,890
And it’s more constrained than just that!
You have to restrict yourself to adding waves

64
00:05:25,890 --> 00:05:30,541
which satisfy a certain boundary condition,
which as we saw last video means working only

65
00:05:30,541 --> 00:05:35,240
with these cosine functions whose frequencies
are all some whole number multiple of a given

66
00:05:35,240 --> 00:05:36,590
base frequency.

67
00:05:36,590 --> 00:05:40,400
(And by the way, if you were working with
a different boundary condition, say that the

68
00:05:40,400 --> 00:05:44,000
endpoints must stay fixed, you’d have a
different set of waves at your disposal to

69
00:05:44,000 --> 00:05:49,000
piece together, in this case simply replacing
the cosine functions with sines)

70
00:05:49,000 --> 00:05:54,090
It’s strange how often progress in math
looks like asking a new question, rather than

71
00:05:54,090 --> 00:05:55,780
simply answering an old one.

72
00:05:55,780 --> 00:06:00,440
Fourier really does have a kind of immortality,
with his name essentially synonymous with

73
00:06:00,440 --> 00:06:06,070
the idea of breaking down functions and patterns
as combinations of simple oscillations. It’s

74
00:06:06,070 --> 00:06:10,310
really hard to overstate just how important
and far-reaching that idea turned out to be,

75
00:06:10,310 --> 00:06:16,130
well beyond anything Fourier could have imagined.
And yet, the origin of all this is in a piece

76
00:06:16,130 --> 00:06:21,321
of physics which upon first glance has nothing
to do with frequencies and oscillations. If

77
00:06:21,321 --> 00:06:25,430
nothing else this should give a hint and how
generally applicable Fourier series are.

78
00:06:25,430 --> 00:06:29,720
“Now hang on,” I hear some of you saying,
“none of these sums of sine waves being

79
00:06:29,720 --> 00:06:36,900
shown are actually the step function.” It’s
true, any finite sum of sine waves will never

80
00:06:36,900 --> 00:06:43,400
be perfectly flat (except for a constant function),
nor discontinuous. But Fourier thought more

81
00:06:43,400 --> 00:06:48,370
broadly, considering infinite sums. In the
case of our step function, it turns out to

82
00:06:48,370 --> 00:06:59,210
be equal to this infinite sum, where the coefficients
are 1, -⅓, +⅕, -1/7 and so on for all

83
00:06:59,210 --> 00:07:05,270
the odd frequencies, all rescaled by 4/pi.
I’ll explain where these numbers come from

84
00:07:05,270 --> 00:07:06,400
in a moment.

85
00:07:06,400 --> 00:07:10,750
Before that, I want to be clear about what
we mean with a phrase like “infinite sum”,

86
00:07:10,750 --> 00:07:15,851
which runs the risk of being a little vague.
Consider the simpler context of numbers, where

87
00:07:15,851 --> 00:07:22,220
you could say, for example, this infinite
sum of fractions equals pi / 4. As you keep

88
00:07:22,220 --> 00:07:27,870
adding terms one-by-one, at all times what
you have is rational; it never actually equals

89
00:07:27,870 --> 00:07:34,840
the irrational pi / 4. But this sequence of
partial sums approaches pi / 4. That is to

90
00:07:34,840 --> 00:07:40,500
say, the numbers you see, while never equal
to pi / 4, get arbitrarily close to that value,

91
00:07:40,500 --> 00:07:46,280
and stay arbitrarily close to that value.
That’s a mouthful, so instead we abbreviate

92
00:07:46,280 --> 00:07:49,430
and say the infinite sum “equals” pi / 4.

93
00:07:49,430 --> 00:07:56,190
With functions, you’re doing the same thing
but with many different values in parallel.

94
00:07:56,190 --> 00:08:01,020
Consider a specific input, and the value of
all these scaled cosine functions for that

95
00:08:01,020 --> 00:08:06,710
input. If that input is less than 0.5, as
you add more and more terms, the sum will

96
00:08:06,710 --> 00:08:14,090
approach 1. If that input is greater than
0.5, as you add more and more terms it would

97
00:08:14,090 --> 00:08:22,260
approach -1. At the input 0.5 itself, all
the cosines are 0, so the limit of the partial

98
00:08:22,260 --> 00:08:28,890
sums is 0. Somewhat awkwardly, then, for this
infinite sum to be strictly true, we do have

99
00:08:28,890 --> 00:08:36,208
to prescribe the value of the step function
at the point of discontinuity to be 0.

100
00:08:36,208 --> 00:08:41,389
Analogous to an infinite sum of rational number
being irrational, the infinite sum of wavy

101
00:08:41,390 --> 00:08:49,740
continuous functions can equal a discontinuous
flat function. Limits allow for qualitative

102
00:08:49,740 --> 00:08:53,530
changes which finite sums alone never could.

103
00:08:53,530 --> 00:08:57,440
There are multiple technical nuances I’m
sweeping under the rug here. Does the fact

104
00:08:57,440 --> 00:09:01,490
that we’re forced into a certain value for
the step function at its point of discontinuity

105
00:09:01,490 --> 00:09:05,280
make any difference for the heat flow problem?
For that matter what does it really mean to

106
00:09:05,280 --> 00:09:11,300
solve a PDE with a discontinuous initial condition?
Can we be sure the limit of solutions to the

107
00:09:11,300 --> 00:09:19,300
heat equation is also a solution? Do all functions
have a Fourier series like this? These are

108
00:09:19,300 --> 00:09:23,800
exactly the kind of question real analysis
is built to answer, but it falls a bit deeper

109
00:09:23,800 --> 00:09:28,010
in the weeds than I think we should go here,
so I’ll relegate that links in the video’s

110
00:09:28,010 --> 00:09:29,010
description.

111
00:09:29,010 --> 00:09:33,620
The upshot is that when you take the heat
equation solutions associated with these cosine

112
00:09:33,620 --> 00:09:39,420
waves and add them all up, all infinitely
many of them, you do get an exact solution

113
00:09:39,420 --> 00:09:47,550
describing how the step function will evolve
over time.

114
00:09:47,550 --> 00:09:54,730
The key challenge, of course, is to find these
coefficients? So far, we’ve been thinking

115
00:09:54,730 --> 00:09:58,830
about functions with real number outputs,
but for the computations I’d like to show

116
00:09:58,830 --> 00:10:02,880
you something more general than what Fourier
originally did, applying to functions whose

117
00:10:02,880 --> 00:10:08,200
output can be any complex number, which is
where those rotating vectors from the opening

118
00:10:08,200 --> 00:10:11,050
come back into play.

119
00:10:11,050 --> 00:10:15,850
Why the added complexity? Aside from being
more general, in my view the computations

120
00:10:15,850 --> 00:10:21,490
become cleaner and it’s easier to see why
they work. More importantly, it sets a good

121
00:10:21,490 --> 00:10:25,980
foundation for ideas that will come up again
later in the series, like the Laplace transform

122
00:10:25,980 --> 00:10:28,820
and the importance of exponential functions.
The relation between cosine decomposition

123
00:10:28,820 --> 00:10:31,520
and rotating vector decomposition
We’ll still think of functions whose input

124
00:10:31,520 --> 00:10:36,710
is some real number on a finite interval,
say the one from 0 to 1 for simplicity. But

125
00:10:36,710 --> 00:10:40,090
whereas something like a temperature function
will have an output confined to the real number

126
00:10:40,090 --> 00:10:45,180
line, we’ll broaden our view to outputs
anywhere in the two-dimensional complex plane.

127
00:10:45,180 --> 00:10:49,190
You might think of such a function as a drawing,
with a pencil tip tracing along different

128
00:10:49,190 --> 00:10:54,770
points in the complex plane as the input ranges
from 0 to 1. Instead of sine waves being the

129
00:10:54,770 --> 00:10:58,320
fundamental building block, as you saw at
the start, we’ll focus on breaking these

130
00:10:58,320 --> 00:11:05,940
functions down as a sum of little vectors,
all rotating at some constant integer frequency.

131
00:11:05,940 --> 00:11:11,060
Functions with real number outputs are essentially
really boring drawings; a 1-dimensional pencil

132
00:11:11,060 --> 00:11:15,360
sketch. You might not be used to thinking
of them like this, since usually we visualize

133
00:11:15,360 --> 00:11:20,440
such a function with a graph, but right now
the path being drawn is only in the output

134
00:11:20,440 --> 00:11:22,250
space.

135
00:11:22,250 --> 00:11:31,470
When we do the decomposition into rotating
vectors for these boring 1d drawings, what

136
00:11:31,470 --> 00:11:36,930
will happen is that all the vectors with frequency
1 and -1 will have the same length, and they’ll

137
00:11:36,930 --> 00:11:41,920
be horizontal reflections of each other. When
you just look at the sum of these two as they

138
00:11:41,920 --> 00:11:48,001
rotate, that sum stays fixed on the real number
line, and oscillates like a sine wave. This

139
00:11:48,001 --> 00:11:52,230
might be a weird way to think about a sine
wave, since we’re used to looking at its

140
00:11:52,230 --> 00:11:56,590
graph rather than the output alone wandering
on the real number line. But in the broader

141
00:11:56,590 --> 00:12:05,880
context of functions with complex number outputs,
this is what sine waves look like. Similarly,

142
00:12:05,880 --> 00:12:12,000
the pair of rotating vectors with frequency
2, -2 will add another sine wave component,

143
00:12:12,000 --> 00:12:17,170
and so on, with the sine waves we were looking
at earlier now corresponding to pairs of vectors

144
00:12:17,170 --> 00:12:19,700
rotating in opposite directions.

145
00:12:19,700 --> 00:12:24,190
So the context Fourier originally studied,
breaking down real-valued functions into sine

146
00:12:24,190 --> 00:12:28,880
wave components, is a special case of the
more general idea with 2d-drawings and rotating

147
00:12:28,880 --> 00:12:35,070
vectors.

148
00:12:35,070 --> 00:12:38,529
At this point, maybe you don’t trust me
that widening our view to complex functions

149
00:12:38,529 --> 00:12:42,840
makes things easier to understand, but bear
with me. It really is worth the added effort

150
00:12:42,840 --> 00:12:46,850
to see the fuller picture, and I think you’ll
be pleased by how clean the actual computation

151
00:12:46,850 --> 00:12:49,410
is in this broader context.

152
00:12:49,410 --> 00:12:53,200
You may also wonder why, if we’re going
to bump things up to 2-dimensions, we don’t

153
00:12:53,200 --> 00:12:57,710
we just talk about 2d vectors; What’s the
square root of -1 got to do with anything?

154
00:12:57,710 --> 00:13:04,720
Well, the heart and soul of Fourier series
is the complex exponential, e^{i * t}. As

155
00:13:04,720 --> 00:13:10,120
the value of t ticks forward with time, this
value walks around the unit circle at a rate

156
00:13:10,120 --> 00:13:12,320
of 1 unit per second.

157
00:13:12,320 --> 00:13:16,800
In the next video, you’ll see a quick intuition
for why exponentiating imaginary numbers walks

158
00:13:16,800 --> 00:13:21,290
in circles like this from the perspective
of differential equations, and beyond that,

159
00:13:21,290 --> 00:13:25,880
as the series progresses I hope to give you
some sense for why complex exponentials are

160
00:13:25,880 --> 00:13:26,880
important.

161
00:13:26,880 --> 00:13:31,340
You see, in theory, you could describe all
of this Fourier series stuff purely in terms

162
00:13:31,340 --> 00:13:37,580
of vectors and never breathe a word of i.
The formulas would become more convoluted,

163
00:13:37,580 --> 00:13:42,510
but beyond that, leaving out the function
e^x would somehow no longer authentically

164
00:13:42,510 --> 00:13:47,710
reflect why this idea turns out to be so useful
for solving differential equations. For right

165
00:13:47,710 --> 00:13:54,001
now you can think of this e^{i t} as a notational
shorthand to describe a rotating vector, but

166
00:13:54,001 --> 00:13:57,820
just keep in the back of your mind that it’s
more significant than a mere shorthand.

167
00:13:57,820 --> 00:14:02,600
I’ll be loose with language and use the
words “vector” and “complex number”

168
00:14:02,600 --> 00:14:06,990
somewhat interchangeably, in large part because
thinking of complex numbers as little arrows

169
00:14:06,990 --> 00:14:10,620
makes the idea of adding many together clearer.

170
00:14:10,620 --> 00:14:15,930
Alright, armed with the function e^{i*t},
let’s write down a formula for each of these

171
00:14:15,930 --> 00:14:20,580
rotating vectors we’re working with. For
now, think of each of them as starting pointed

172
00:14:20,580 --> 00:14:23,220
one unit to right, at the number 1.

173
00:14:23,220 --> 00:14:27,460
The easiest vector to describe is the constant
one, which just stays at the number 1, never

174
00:14:27,460 --> 00:14:34,050
moving. Or, if you prefer, it’s “rotating”
at a frequency of 0. Then there will be a

175
00:14:34,050 --> 00:14:41,150
vector rotating 1 cycle every second which
we write as e^{2pi * i * t}. The 2pi is there

176
00:14:41,150 --> 00:14:46,810
because as t goes from 0 to 1, it needs to
cover a distance of 2pi along the circle.

177
00:14:46,810 --> 00:14:50,880
In what’s being shown, it’s actually 1
cycle every 10 seconds so that things aren’t

178
00:14:50,880 --> 00:14:55,450
too dizzying, but just think of it as slowed
down by a factor of 10.

179
00:14:55,450 --> 00:15:00,180
We also have a vector rotating at 1 cycle
per second in the other direction, e^{negative

180
00:15:00,180 --> 00:15:11,500
2pi * i * t}. Similarly, the one going 2 rotations
per second is e^{2 * 2pi * i * t}, where that

181
00:15:11,500 --> 00:15:21,020
2 * 2pi in the exponent describes how much
distance is covered in 1 second. And we go

182
00:15:21,020 --> 00:15:26,240
on like this over all integers, both positive
and negative, with a general formula of e^{n

183
00:15:26,240 --> 00:15:29,390
* 2pi * i * t} for each rotating vector.

184
00:15:29,390 --> 00:15:33,870
Notice, this makes it more consistent to write
the constant vector is written as e^{0 * 2pi

185
00:15:33,870 --> 00:15:39,000
* i * t}, which feels like an awfully complicated
to write the number 1, but at least then it

186
00:15:39,000 --> 00:15:40,510
fits the pattern.

187
00:15:40,510 --> 00:15:45,000
The control we have, the set of knobs and
dials we get to turn, is the initial size

188
00:15:45,000 --> 00:15:49,830
and direction of each of these numbers. The
way we control that is by multiplying each

189
00:15:49,830 --> 00:15:54,050
one by some complex number, which I’ll call
c_n.

190
00:15:54,050 --> 00:15:58,620
For example, if we wanted that constant vector
not to be at the number 1, but to have a length

191
00:15:58,620 --> 00:16:05,190
of 0.5, we’d scale it by 0.5. If we wanted
the vector rotating at one cycle per second

192
00:16:05,190 --> 00:16:10,640
to start off at an angle of 45o, we’d multiply
it by a complex number which has the effect

193
00:16:10,640 --> 00:16:16,660
of rotating it by that much, which you might
write as e^{pi/4 * i}. If it’s initial length

194
00:16:16,660 --> 00:16:22,640
needed to be 0.3, the coefficient would be
0.3 times that amount.

195
00:16:22,640 --> 00:16:27,480
Likewise, everyone in our infinite family
of rotating vectors has some complex constant

196
00:16:27,480 --> 00:16:33,430
being multiplied into it which determines
its initial angle and magnitude. Our goal

197
00:16:33,430 --> 00:16:41,030
is to express any arbitrary function f(t),
say this one drawing an eighth note, as a

198
00:16:41,030 --> 00:16:47,670
sum of terms like this, so we need some way
to pick out these constants one-by-one given

199
00:16:47,670 --> 00:16:52,250
data of the function.

200
00:16:52,250 --> 00:16:57,670
The easiest one is the constant term. This
term represents a sort of center of mass for

201
00:16:57,670 --> 00:17:02,060
the full drawing; if you were to sample a
bunch of evenly spaced values for the input

202
00:17:02,060 --> 00:17:07,750
t as it ranges from 0 to 1, the average of
all the outputs of the function for those

203
00:17:07,750 --> 00:17:13,880
samples will be the constant term c_0. Or
more accurately, as you consider finer and

204
00:17:13,880 --> 00:17:21,189
finer samples, their average approaches c_0
in the limit. What I’m describing, finer

205
00:17:21,189 --> 00:17:27,520
and finer sums of f(t) for sample of t from
the input range, is an integral of f(t) from

206
00:17:27,520 --> 00:17:34,940
0 to 1. Normally, since I’m framing this
in terms of averages, you’d divide this

207
00:17:34,940 --> 00:17:41,350
integral by the length of the interval. But
that length is 1, so it amounts to the same

208
00:17:41,350 --> 00:17:42,350
thing.

209
00:17:42,350 --> 00:17:48,380
There’s a very nice way to think about why
this integral would pull out c0. Since we

210
00:17:48,380 --> 00:17:52,929
want to think of the function as a sum of
these rotating vectors, consider this integral

211
00:17:52,929 --> 00:17:59,750
(this continuous average) as being applied
to that sum. This average of a sum is the

212
00:17:59,750 --> 00:18:08,720
same as a sum over the averages of each part;
you can read this move as a subtle shift in

213
00:18:08,720 --> 00:18:13,300
perspective. Rather than looking at the sum
of all the vectors at each point in time,

214
00:18:13,300 --> 00:18:16,840
and taking the average value of the points
they trace out, look at the average value

215
00:18:16,840 --> 00:18:22,620
for each individual vector as t goes from
0 to 1, and add up all these averages.

216
00:18:22,620 --> 00:18:27,900
But each of these vectors makes a whole number
of rotations around 0, so its average value

217
00:18:27,900 --> 00:18:34,220
as t goes from 0 to 1 will be 0. The only
exception is that constant term; since it

218
00:18:34,220 --> 00:18:39,270
stays static and doesn’t rotate, it’s
average value is just whatever number it started

219
00:18:39,270 --> 00:18:45,410
on, which is c0. So doing this average over
the whole function is sort of a way to kill

220
00:18:45,410 --> 00:18:49,970
all terms that aren’t c0.

221
00:18:49,970 --> 00:18:54,080
But now let’s say you wanted to compute
a different term, like c_2 in front of the

222
00:18:54,080 --> 00:18:59,880
vector rotating 2 cycles per second. The trick
is to first multiply f(t) by something which

223
00:18:59,880 --> 00:19:04,240
makes that vector hold still (sort of the
mathematical equivalent of giving a smartphone

224
00:19:04,240 --> 00:19:09,800
to an overactive child). Specifically, if
you multiply the whole function by e^{negative

225
00:19:09,800 --> 00:19:18,690
2 * 2pi*i * t}, think about what happens to
each term. Since multiplying exponentials

226
00:19:18,690 --> 00:19:23,550
results in adding what’s in the exponent,
the frequency term in each of the exponents

227
00:19:23,550 --> 00:19:29,710
gets shifted down by 2.

228
00:19:29,710 --> 00:19:38,950
So now, that c_{-1} vector spins around -3
times, with an average of 0. The c_0 vector,

229
00:19:38,950 --> 00:19:45,410
previously constant, now rotates twice as
t ranges from 0 to 1, so its average is 0.

230
00:19:45,410 --> 00:19:52,360
And likewise, all vectors other than the c_2
term make some whole number of rotations,

231
00:19:52,360 --> 00:20:00,290
meaning they average out to 0. So taking the
average of this modified function, all terms

232
00:20:00,290 --> 00:20:02,990
other than the second one get killed, and
we’re left with c_2.

233
00:20:02,990 --> 00:20:06,970
Of course, there’s nothing special about
2 here. If we replace it with any other n,

234
00:20:06,970 --> 00:20:15,860
you have a formula for any other term c_n.
Again, you can read this expression as modifying

235
00:20:15,860 --> 00:20:20,961
our function, our 2d drawing, so as to make
the n-th little vector hold still, and then

236
00:20:20,961 --> 00:20:27,770
performing an average so that all other vectors
get canceled out. Isn’t that crazy? All

237
00:20:27,770 --> 00:20:34,730
the complexity of this decomposition as a
sum of many rotations is entirely captured

238
00:20:34,730 --> 00:20:36,970
in this expression.

239
00:20:36,970 --> 00:20:40,480
So when I’m rendering these animations,
that’s exactly what I’m having the computer

240
00:20:40,480 --> 00:20:46,350
do. It treats this path like a complex function,
and for a certain range of values for n, it

241
00:20:46,350 --> 00:20:52,410
computes this integral to find each coefficient
c_n. For those of you curious about where

242
00:20:52,410 --> 00:20:56,650
the data for the path itself comes from, I’m
going the easy route having the program read

243
00:20:56,650 --> 00:21:01,460
in an svg, which is a file format that defines
the image in terms of mathematical curves

244
00:21:01,460 --> 00:21:07,299
rather than with pixel values, so the mapping
f(t) from a time parameter to points in space

245
00:21:07,299 --> 00:21:10,740
basically comes predefined.

246
00:21:10,740 --> 00:21:16,110
In what’s shown right now, I’m using 101
rotating vectors, computing values of n from

247
00:21:16,110 --> 00:21:22,230
-50 up to 50. In practice, the integral is
computed numerically, basically meaning it

248
00:21:22,230 --> 00:21:27,600
chops up the unit interval into many small
pieces of size delta-t and adds up this value

249
00:21:27,600 --> 00:21:34,550
f(t)e^{-n * 2pi * i * t} * delta-t for each
one of them. There are fancier methods for

250
00:21:34,550 --> 00:21:39,350
more efficient numerical integration, but
that gives the basic idea.

251
00:21:39,350 --> 00:21:45,140
After computing these 101 values, each one
determines an initial position for the little

252
00:21:45,140 --> 00:21:49,860
vectors, and then you set them all rotating,
adding them all tip to tail, and the path

253
00:21:49,860 --> 00:21:56,030
drawn out by the final tip is some approximation
of the original path. As the number of vectors

254
00:21:56,030 --> 00:22:07,430
used approaches infinity, it gets more and
more accurate.

255
00:22:07,430 --> 00:22:16,520
Relation to step function
To bring this all back down to earth, consider

256
00:22:16,520 --> 00:22:20,890
the example we were looking at earlier of
a step function, which was useful for modeling

257
00:22:20,890 --> 00:22:26,690
the heat dissipation between two rods of different
temperatures after coming into contact.

258
00:22:26,690 --> 00:22:33,360
Like any real-valued function, and step function
is like a boring drawing confined to one-dimension.

259
00:22:33,360 --> 00:22:38,951
But this one is and especially dull drawing,
since for inputs between 0 and 0.5, the output

260
00:22:38,951 --> 00:22:43,970
just stays static at the number 1, and then
it discontinuously jumps to -1 for inputs

261
00:22:43,970 --> 00:22:50,110
between 0.5 and 1. So in the Fourier series
approximation, the vector sum stays really

262
00:22:50,110 --> 00:22:55,980
close to 1 for the first half of the cycle,
then really quickly jumps to -1 for the second

263
00:22:55,980 --> 00:23:02,590
half. Remember, each pair of vectors rotating
in opposite directions correspond to one of

264
00:23:02,590 --> 00:23:06,440
the cosine waves we were looking at earlier.

265
00:23:06,440 --> 00:23:11,020
To find the coefficients, you’d need to
compute this integral. For the ambitious viewers

266
00:23:11,020 --> 00:23:15,309
among you itching to work out some integrals
by hand, this is one where you can do the

267
00:23:15,309 --> 00:23:19,710
calculus to get an exact answer, rather than
just having a computer do it numerically for

268
00:23:19,710 --> 00:23:23,960
you. I’ll leave it as an exercise to work
this out, and to relate it back to the idea

269
00:23:23,960 --> 00:23:28,880
of cosine waves by pairing off the vectors
rotating in opposite directions.

270
00:23:28,880 --> 00:23:32,890
For the even more ambitious, I’ll also leave
another exercises up on screen on how to relate

271
00:23:32,890 --> 00:23:36,950
this more general computation with what you
might see in a textbook describing Fourier

272
00:23:36,950 --> 00:23:41,790
series only in terms of real-valued functions
with sines and cosines.

273
00:23:41,790 --> 00:23:45,910
By the way, if you’re looking for more Fourier
series content, I highly recommend the videos

274
00:23:45,910 --> 00:23:54,040
by Mathologer and The Coding Train on the
topic, and the blog post by Jezzamoon.

275
00:23:54,040 --> 00:23:58,490
So on the one hand, this concludes our discussion
of the heat equation, which was a little window

276
00:23:58,490 --> 00:24:01,370
into the study of partial differential equations.

277
00:24:01,370 --> 00:24:06,950
But on the other hand, this foray into Fourier
series is a first glimpse at a deeper idea.

278
00:24:06,950 --> 00:24:11,290
Exponential functions, including their generalization
into complex numbers and even matrices, play

279
00:24:11,290 --> 00:24:16,940
a very important role for differential equations,
especially when it comes to linear equations.

280
00:24:16,940 --> 00:24:23,700
What you just saw, breaking down a function
as a combination of these exponentials, comes

281
00:24:23,700 --> 00:24:25,970
up again in different shapes and forms.

