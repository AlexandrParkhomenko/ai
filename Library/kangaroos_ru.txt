

            Кенгуру и обучение нейронных сетей
            -------------------------------------- 

               Warren S. Sarle and Net Poohbahs
                      revised Oct 22, 1994 
               Пархоменко Александр
                      перевод Nov 13, 2020       

Обучение НС - это форма численной оптимизации, которую можно сравнить с поиском
кенгуру вершины горы Эверест. Эверест - это _глобальный оптимум_, самая высокая
гора в мире, но вершина любой другой действительно высокой горы, такой как К2
(хороший _локальный оптимум_), будет удовлетворительной. С другой стороны,
вершина небольшого холма, такого как Чапел-Хилл, Северная Каролина (плохой
локальный оптимум), неприемлема.

Эта аналогия сформулирована с точки зрения максимизации, в то время как
нейронные сети обычно обсуждаются с точки зрения минимизации меры ошибки, такой
как критерий наименьших квадратов, но если вы умножите меру ошибки на -1, она
сработает так же. Итак, в этой аналогии, чем выше высота, тем меньше ошибка.

Направления компаса представляют значения синаптических весов в сети.
Направление север-юг соответствует одному весу, а направление восток-запад -
другому весу. Большинство сетей имеют более двух весов, но для представления
дополнительных весов потребуется многомерный ландшафт, который трудно
визуализировать. Имейте в виду, что когда вы тренируете сеть с более чем двумя
весами, всё становится сложнее.

Начальные веса обычно выбираются случайным образом, что означает, что кенгуру
сбрасывается на парашюте где-то над Азией пилотом, потерявшим карту. Если вам
что-то известно о масштабах входных сигналов, вы можете дать пилоту
соответствующие инструкции, чтобы заставить кенгуру приземлиться возле Гималаев.
Однако, если вы сделаете действительно плохой выбор распределения для начальных
весов, кенгуру может упасть в Индийский океан и утонуть.

При использовании алгоритмов типа Ньютона (второго порядка) Гималаи покрыты
туманом, и кенгуру может лишь немного видеть вокруг своего местоположения. Судя
по местности, кенгуру догадывается, где находится вершина горы, предполагая, что
гора имеет красивую гладкую квадратную форму. Затем кенгуру пытается одним
прыжком прыгнуть на вершину.

Поскольку большинство гор не имеют идеальной квадратной формы, кенгуру редко
достигает вершины за один прыжок. Следовательно, кенгуру должен _iterate_, то
есть многократно прыгать, как описано ранее, пока он не найдет вершину горы. К
сожалению, нет никакой гарантии, что эта гора будет Эверестом.

В стабилизированном алгоритме Ньютона у кенгуру есть высотомер, и если прыжок
приводит его к более низкой точке, он возвращается туда, где был, и совершает
более короткий прыжок. Если используется стабилизация гребня, кенгуру также
регулирует направление своего прыжка, чтобы подняться на более крутой склон.
Если алгоритм не стабилизирован, кенгуру может по ошибке прыгнуть в Шанхай и
попасть на ужин в китайский ресторан.

На самом крутом подъеме с поиском линии туман становится очень плотным, и
кенгуру может только сказать, какое направление ведет вверх наиболее круто.
Он прыгает в этом направлении, пока местность не начнет спускаться. Затем
кенгуру снова оглядывается в поисках нового направления наискорейшего подъема и
повторяется.

Использование решателя ODE (обыкновенного дифференциального уравнения)
аналогично самому крутому восхождению, за исключением того, что кенгуру ползет
всеми пятью конечностями до вершины ближайшей горы, всегда будучи уверенным, что
будет ползать в самом крутом направлении.

Следующее описание методов сопряженных градиентов адаптировано Tony Plate.
(1993):

   Среда для поиска сопряженного градиента такая же, как и для наискорейшего 
   подъема с линейным поиском - туман густой, и кенгуру может только сказать, 
   в каком направлении ведет вверх. Разница в том, что кенгуру имеет некоторую 
   память о направлениях, в которых он прыгал раньше, а кенгуру предполагает, 
   что гребни прямые (то есть Поверхность квадратичная). Кенгуру выбирает 
   направление для прыжка вверх, если это не приводит к результату, он движется 
   вниз в тех направлениях, в которых он прыгнул. То есть он выбирает 
   направление вверх, движение по которому не отменяет работу предыдущих шагов. 
   Он прыгает вверх, пока ландшафт снова не начинает спускаться, 
   а затем выбирает другое направление.

В стандартном обратном распространении, наиболее применяемом методе обучения НС,
кенгуру слеп и должен ощупывать землю, чтобы угадать, какой путь вверх. Основная
проблема со стандартным обратным распространением заключается в том, что
расстояние, на которое кенгуру прыгает, зависит от крутизны местности. Если
кенгуру начинает свой путь на пологой равнине, а не на горном склоне, он будет
делать очень маленькие прыжки и очень медленно продвигаться. Когда она наконец
начинает подниматься на гору, ее прыжки становятся длиннее и опаснее, и она
может вообще спрыгнуть с горы. Если кенгуру когда-нибудь приблизится к пику, он
может прыгать взад и вперед по пику, даже не приземлившись на него. Если вы
используете уменьшающийся размер шага, кенгуру устает и делает все меньше и
меньше прыжков, поэтому, если он когда-нибудь приблизится к пику, у него будет
больше шансов действительно приземлиться на него до того, как Гималаи
разрушатся.

При обратном распространении с инерцией кенгуру имеет плохую тягу и не может
делать крутые повороты.

При онлайновых методах обучения, когда используется по одному примеру, случаются
частые землетрясения, а горы постоянно появляются и исчезают. Из-за этого
слепому кенгуру сложно определить, достигал ли он когда-либо вершины горы, и ему
приходится совершать небольшие прыжки, чтобы не упасть в зияющие пропасти,
которые могут открыться в любой момент.

Обратите внимание, что во всех рассмотренных до сих пор методах кенгуру в лучшем
случае может надеяться найти вершину горы рядом с тем местом, где она
начинается. Другими словами, это методы _местного восхождения_. Нет никакой
гарантии, что эта гора будет Эверестом или даже очень высокой горой. Существует
множество методов, позволяющих найти глобальный оптимум.

При имитация отжига кенгуру напивается и долго беспорядочно прыгает. Однако он
постепенно протрезвеет, и чем трезвее он, тем больше вероятность, что он прыгнет
в гору.

При случайном многозадачном методе (мультистарт) множество кенгуру сбрасывается
с парашютом в Гималаи в случайных местах. Вы надеетесь, что хотя бы один из них
найдет Эверест.

Генетический алгоритм начинается как случайный мультистарт. Однако эти кенгуру
не знают, что они должны искать вершину горы. Каждые несколько лет вы стреляете
в кенгуру на малой высоте и надеетесь, что оставшиеся будут набираться сил,
размножаться и подниматься. Текущие исследования показывают, что блохи могут
быть более эффективными, чем кенгуру в генетических алгоритмах, поскольку их
более высокая скорость размножения сильнее компенсирует их более короткие
прыжки.

Алгоритм туннелирования может применяться в сочетании с любым методом местного
восхождения, но требует божественного вмешательства и водного мотоцикла. Кенгуру
сначала находит вершину любой ближайшей горы. Затем кенгуру призывает свое
божество затопить землю до такой степени, чтобы воды достигли вершины текущей
горы. Затем она садится на свой водный мотоцикл, уходит на поиски более высокой
горы и повторяет процесс до тех пор, пока более высокие горы не будут найдены.

Reference:

   Plate, T. (1993), "Re: Kangaroos (Was Re: BackProp without Calculus?),
   Usenet article <93Sep8.162519edt.997@neuron.ai.toronto.edu> in
   comp.ai.neural-nets.

______________________________________________________________________

From: sef@sef-pmax.slisp.cs.cmu.edu
Subject: Re: Kangaroos (Was Re: BackProp without Calculus?)
Message-ID: <CCpILM.F8s.1@cs.cmu.edu>
Organization: School of Computer Science, Carnegie Mellon
Date: Wed, 1 Sep 93 23:20:07 EDT

    From: saswss@hotellng.unx.sas.com (Warren Sarle)

    Обучение сети - это форма численной оптимизации, которую можно сравнить 
    с поиском кенгуру вершины горы Эверест. 

Отличный пост! Конечно, если вы хотите, чтобы кенгуру хорошо себя показали, вам 
сначала нужно научить их считать. 

    Мне не удалось придумать аналогию с кенгуру для каскадной корреляции. 
    Есть идеи, Скотт?

Никогда не отказывайся от глупого вызова, когда мне нужно проводить 
исследования... 

Реальная история всех этих алгоритмов заключается в том, что у нас есть большой
континент с неизвестным количеством гор (компонентов ошибки). Ваша задача -
посадить по одному кенгуру на каждую гору одновременно. Если вам удастся это
сделать, не выпуская слишком много дополнительных кенгуру, вы выиграете.
Избыточные кенгуру, как правило, пробираются на армейские базы и атакуют
генералов, оставляя армию с плохим обобщением. (Прости за это!)

В отличие от Гималаев, это РЕЗИНОВЫЕ горы, поэтому, когда кенгуру оказывается на
вершине горы, он прижимается к земле. Так что хорошее решение - это то, в
котором все горы сдавлены сразу. Проблема в том, что это кенгуру «скрытого
отряда», и поэтому они невидимы друг для друга (и для генералов). Это лишает их
возможности координировать свою деятельность, что очень жаль, поскольку мы
хотим, чтобы они были на ОТЛИЧНЫХ горах. Однако они могут видеть местность с
некоторого расстояния и видеть, какие горы сглаживаются в любой момент времени.
Эти кенгуру хотят подниматься в гору, но у них плохая память, поэтому они
склонны реагировать на любую местность, которую они видят в любой момент.

Теперь, при обратном распространении, вы угадываете, сколько кенгуру вам
понадобится, и выпускаете их всех одновременно в случайные места. Каждый кенгуру
оглядывается, замечает любую далекую гору, которая кажется самой большой, и
направляется к ней. Если эта гора внезапно становится плоской, он оглядывается и
находит другую гору - что-то вроде сумчатого, эластичного, альпийского варианта
музыкальных стульев. Проблема в том, что когда кенгуру стоит на вершине горы,
даже если это Эверест, эта гора становится плоской, и этот кенгуру может вместо
этого прыгнуть, чтобы занять другую гору.

Как вы можете себе представить, в такой хаотической ситуации требуется много
времени, чтобы сравнять все горы сразу, даже если вы правильно угадали насчет
количества кенгуру, а это непростая задача без подробной карты.

В алгоритме каскадной корреляции Cascor вы выпускаете по одному кенгуру за раз.
Он оглядывается, замечает самую высокую гору в поле зрения и направляется прямо
к ней. Когда он достигает вершины, он останавливается. Затем мы прибиваем его к
земле, чтобы он не уходил, и выпускаем следующего кенгуру, который уходит искать
другую гору. Несмотря на то, что мы отказались от некоторого количества
параллельного поиска, этот упорядоченный процесс все же быстрее, чем полный хаос
обратного распространения данных с несколькими кенгуру. Когда все горы станут
плоскими, вы перестанете выпускать кенгуру, пока в армии еще много генералов.

На самом деле Cascor немного сложнее, потому что кенгуру могут стоять друг на
друге и, таким образом, достигают более высоких и сложных мест, чем они могли бы
достичь другим способом. (Кенгуру ненавидят, когда вы пригвоздите тех, кто стоит
им на голове.)

Есть что-то в том, чтобы предоставить право владения наиболее успешным кенгуру и
убить других, но я думаю, что мне лучше остановиться сейчас.

-- Скотт 

===========================================================================
Scott E. Fahlman                        Internet:  sef+@cs.cmu.edu
Senior Research Scientist               Phone:     412 268-2575
School of Computer Science              Fax:       412 681-5739
Carnegie Mellon University              Latitude:  40:26:33 N
5000 Forbes Avenue                      Longitude: 79:56:48 W
Pittsburgh, PA 15213
===========================================================================
______________________________________________________________________

From: rrdjro@minyos.xx.rmit.OZ.AU (Jonathan O'Donnell)
Newsgroups: comp.ai.neural-nets
Subject: Re: Kangaroos (Was Re: BackProp without Calculus?)
Date: Sun, 19 Sep 93 10:21:20 EDT
Organization: Royal Melbourne Institute of Technology, Melbourne, Australia.
Message-ID: <27hpt0$2l7@aggedor.rmit.OZ.AU>

[... Замечательные описания удалены ...] 

Вероятно, поэтому Австралия такая плоская. 

Извини, я не удержался.
        Jonathan@RMIT.edu.au
______________________________________________________________________

From: prechelt@i41s18.ira.uka.de (Lutz Prechelt)
Newsgroups: comp.ai.neural-nets
Subject: Re: Kangaroos (Was Re: BackProp without Calculus?)
Date: Thu, 2 Sep 93 12:31:45 EDT
Organization: University of Karlsruhe, FRG
Message-ID: <26575hINN1km@iraun1.ira.uka.de>

В статье <CCp2M8.uL@unx.sas.com>, saswss@hotellng.unx.sas.com (Warren Sarle) 
пишет:
|>
|> Обучение НС - это форма численной оптимизации, которую можно сравнить 
|> с поиском кенгуру вершины горы Эверест.
...
|> Начальные веса обычно выбираются случайным образом, а это значит, 
|> что кенгуру может появиться где угодно в Азии.

Чтобы пролить свет на то, что эта замечательная статья означает по отношению к
исходному вопросу (как понять алгоритм обратного распространения ошибки без
исчисления), вот несколько дополнительных замечаний:

1. Аналогия только объясняет, ЧТО делает алгоритм, но не КАК он выполняет
наиболее сложную часть: выбор направления следующего прыжка.

   По сути, кенгуру делает следующее: где бы он ни стоял, он вырубает 2 канавы,
   стены которых встречаются таким образом, чтобы образовать V-образную форму; 
   один ров с севера на юг и один с востока на запад. Он покрывает стены этих 
   канав сначала сталью, а затем тефлоном, чтобы уменьшить трение (большинство, 
   но не все варианты обратного распространения фактически сводят трение к нулю) 
   и чтобы все небольшие впадины или холмы, которые могли быть в канаве, были
   усреднены.

   Затем кенгуру достает шар для боулинга из сумки, кладет его в канаву с севера
   на юг и измеряет, как далеко он катится за определенное время и в каком 
   направлении катится по канаве. 
   Эта процедура повторяется для траншеи восток-запад.
   Предположим, что мяч катился на 8 сантиметров в северном направлении в первой
   канаве и 14 сантиметров на восток во второй канаве. Затем кенгуру, который
   использует скорость обучения 50, прыгнет в точку, расположенную на 4 метра к
   северу и 7 метров к востоку от того места, где он был раньше.

   Для алгоритма не важно, использует ли кенгуру один и тот же шар для боулинга
   снова и снова или выбрасывает его после каждого измерения и в следующий раз
   вынимает новый из мешочка. Это потому, что в мире обратного распространения 
   шары для боулинга разлагаются за нулевое время.

2. Как и все приятные упрощения, у этого тоже есть небольшой недостаток. В этом
случае ограничение состоит в том, что аналогия объясняет только случай сети с
двумя весами (что меньше *любой* полезной сети обратного распространения). Эти
два веса представлены двумя ортогональными направлениями поиска кенгуру
(север-юг и восток-запад).

   Чтобы обобщить пример, скажем, на полносвязную сеть с тремя уровнями, 
   содержащими 10 входных узлов, 5 скрытых узлов и 8 выходных узлов 
   (имеющих 10x5 + 5x8 = 50 + 40 = 90 весов), вы должны представить ту же 
   ситуацию в мире, существующем в 91-мерном пространстве вместо нашего 
   3-х мерного.

   Уверяю вас, что визуализировать это обобщение для человека, не занимающегося 
   математикой, так же легко, как и для любого профессора математического 
   анализа. 

 3. Ах да, еще один очень важный вопрос: почему-то Гималаи выглядят именно так? 
 Ответ: нет. 

   Горы, по которым прыгает кенгуру, "вызваны" данными ваших тренировок. 
   Каждый пример предлагает определенные холмы или горы в определенных точках 
   на поверхности (в остальном абсолютно плоской) земли. Если кенгуру выполняет 
   "пакетный" поиск, мир выглядит как среднее арифметическое из того, 
   что предлагают примеры обучения. Если кенгуру выполняет поиск в онлайн, 
   ситуация усложняется: для каждого примера обучения существует один мир; 
   Каждый из этих миров выглядит в точности так, как предполагает один 
   тренировочный пример, из которого он был сделан. Кенгуру совершает 
   один прыжок в первый мир в соответствии с описанным выше методом, 
   а затем волшебным образом переносится в эквивалентную точку в следующем мире,
    то есть в точку с той же долготой и широтой, э-э, с теми же координатами 
    x и y ( поскольку миры должны быть прямоугольными для обратного 
    распространения, а не сферическими). В каждом из миров применяется одна и та
     же процедура, а затем прыжки кенгуру снова продолжаются в первом мире.

   Достаточно интересно, что магический переход между мирами настолько 
   вдохновляет кенгуру, что он может совершить один прыжок во всех «онлайн» 
   мирах (независимо от того, сколько их) примерно за одно и то же время, 
   необходимое для всего двух прыжков в "пакетный" мир. Это причина, по которой 
   кенгуру «онлайн» часто находят точку, обеспечивающую наилучший компромисс 
   между высотой во всех мирах, намного быстрее, чем «групповые» кенгуру находят
   вершину самой высокой горы в своем единственном мире. Иногда, однако, 
   межмирные перемещения настолько сбивают с толку «онлайн» кенгуру, что он 
   никогда (или очень медленно) находит оптимальную точку. 

   Существует множество эвристических методов для дальнейшего повышения скорости
   и/или точности поиска кенгуру. Однако для большинства из них требуется 
   карманный калькулятор, много бумаги для заметок или и то, и другое.

Из всего этого можно сделать вывод, что лучшие методы поиска Эвереста 
(по порядку):

1. знать, где это 
2. иметь карту, на которой вы можете найти это 
3. знать кого-то, кто знает, или у кого есть карта 
4. послать кенгуру на поиски 

и даже если вам нужно послать кенгуру, полезно, если вы знаете хотя бы

1. где находится горный хребет, в котором может быть гора Эверест и 
2. как доставить кенгуру к горному хребту. 

  Lutz

P.S.: Последние результаты исследований в области нейронных сетей показывают, 
что обратное распространение также работает с лягушками, если вы замените шар 
для боулинга чем-то подходящим (например, электромеханическим 3-битным крутым 
O-метром на солнечной энергии).

--
Lutz Prechelt   (email: prechelt@ira.uka.de)            | Whenever you
Institut fuer Programmstrukturen und Datenorganisation  | complicate things,
Universitaet Karlsruhe;  76128 Karlsruhe;  Germany      | they get
(Voice: ++49/721/608-4068, FAX: ++49/721/694092)        | less simple.

