1
00:00:04,010 --> 00:00:07,575
Welcome everyone, uh, back to the class.

2
00:00:07,575 --> 00:00:09,540
Uh, super excited to,

3
00:00:09,540 --> 00:00:10,770
uh, talk to you all today.

4
00:00:10,770 --> 00:00:13,215
Um, we are going to discuss,

5
00:00:13,215 --> 00:00:16,105
um, several very interesting topics.

6
00:00:16,105 --> 00:00:18,215
Uh, first, we are going to finish,

7
00:00:18,215 --> 00:00:19,850
uh, some of the parts, uh,

8
00:00:19,850 --> 00:00:23,000
that are left unfinished from the last lecture,

9
00:00:23,000 --> 00:00:26,640
and then we are going to dig into the theory of,

10
00:00:26,640 --> 00:00:28,935
uh, graph neural networks.

11
00:00:28,935 --> 00:00:30,960
So let's first talk about,

12
00:00:30,960 --> 00:00:33,480
uh, where we ended last time, right?

13
00:00:33,480 --> 00:00:37,515
So last time we talked about how do you design graph neural networks?

14
00:00:37,515 --> 00:00:39,690
What kind of, um, uh,

15
00:00:39,690 --> 00:00:42,495
design choices do you make and, eh,

16
00:00:42,495 --> 00:00:44,465
how do you set up the entire,

17
00:00:44,465 --> 00:00:46,805
let's call it training inference pipeline.

18
00:00:46,805 --> 00:00:49,755
And we talked about how do you setup the input graph?

19
00:00:49,755 --> 00:00:52,970
How do you define the graph neural network architecture?

20
00:00:52,970 --> 00:00:55,705
How do you then use it to create node embeddings?

21
00:00:55,705 --> 00:00:58,220
And then we also talked about how do you get from

22
00:00:58,220 --> 00:01:01,070
node embeddings to the prediction- prediction head.

23
00:01:01,070 --> 00:01:04,160
And we talked about the different prediction heads, uh,

24
00:01:04,160 --> 00:01:06,230
based on node classification, uh,

25
00:01:06,230 --> 00:01:10,010
link, uh, prediction as well as graph classification.

26
00:01:10,010 --> 00:01:12,920
We talked about how do you then make predictions?

27
00:01:12,920 --> 00:01:17,020
How do you compare those predictions with ground truth labels, uh,

28
00:01:17,020 --> 00:01:19,580
to optimize the loss function and be able to do

29
00:01:19,580 --> 00:01:23,750
back-propagation all the way down to the graph neural network structure?

30
00:01:23,750 --> 00:01:26,180
And then we also talked about various kinds of, uh,

31
00:01:26,180 --> 00:01:28,265
evaluation metrics you can use, uh,

32
00:01:28,265 --> 00:01:30,045
to assess, estimate, uh,

33
00:01:30,045 --> 00:01:31,670
the performance of your model.

34
00:01:31,670 --> 00:01:33,480
One thing that still remains, uh,

35
00:01:33,480 --> 00:01:36,510
unanswered is, uh, how do we set up the tasks?

36
00:01:36,510 --> 00:01:39,765
How do we properly split into the training,

37
00:01:39,765 --> 00:01:41,940
validation, uh, and test set?

38
00:01:41,940 --> 00:01:43,245
And what I wanna talk, uh,

39
00:01:43,245 --> 00:01:44,670
in this part of the lecture,

40
00:01:44,670 --> 00:01:46,020
is address this question,

41
00:01:46,020 --> 00:01:51,775
how do we split our datasets- our graph dataset into train, validation, and test sets?

42
00:01:51,775 --> 00:01:54,780
So, um, we have two options,

43
00:01:54,780 --> 00:01:56,925
um, when we are splitting a dataset.

44
00:01:56,925 --> 00:02:02,690
We can, uh, split our dataset at once and call this a fixed split, where basically,

45
00:02:02,690 --> 00:02:08,479
we want to take a dataset and split it into three disjoint independent pieces.

46
00:02:08,479 --> 00:02:14,620
We wanna have a training set that we are going to use to optimize GNN model parameters.

47
00:02:14,620 --> 00:02:19,370
We are going to use a validation set which we- we can use to

48
00:02:19,370 --> 00:02:25,010
tune hyperparameters and various kinds of con- constants and decision choices,

49
00:02:25,010 --> 00:02:27,155
uh, in terms of,

50
00:02:27,155 --> 00:02:29,050
uh, the modeling architecture.

51
00:02:29,050 --> 00:02:33,420
And once basically using the training set and the validation set,

52
00:02:33,420 --> 00:02:35,360
we finalize our final model,

53
00:02:35,360 --> 00:02:38,150
final- final values of hyper-parameters,

54
00:02:38,150 --> 00:02:41,100
final values of different design dimensions.

55
00:02:41,100 --> 00:02:43,950
Uh, we are then going to apply our model to

56
00:02:43,950 --> 00:02:49,410
this new independent test set that was held out all the time,

57
00:02:49,410 --> 00:02:52,955
and we only use it to report final, uh, performance.

58
00:02:52,955 --> 00:02:55,670
And this is a fair way to evaluate because we

59
00:02:55,670 --> 00:02:59,455
used training and validation to build the model,

60
00:02:59,455 --> 00:03:04,190
then we fix the model and we apply it to this, uh, independent,

61
00:03:04,190 --> 00:03:08,300
unseen never touched before test set and we pre- uh,

62
00:03:08,300 --> 00:03:10,655
we report, uh, our performance.

63
00:03:10,655 --> 00:03:14,470
Um, what is interesting in graphs, is that, uh,

64
00:03:14,470 --> 00:03:18,770
sometimes we cannot guarantee that the test set will really be held out,

65
00:03:18,770 --> 00:03:21,545
meaning that there will be no information leakage

66
00:03:21,545 --> 00:03:24,680
from training and validation sets into the test set.

67
00:03:24,680 --> 00:03:27,685
And this is why, uh, this becomes interesting.

68
00:03:27,685 --> 00:03:29,870
So that's that's in terms of a fixed split.

69
00:03:29,870 --> 00:03:32,270
Once we have created the fixed split,

70
00:03:32,270 --> 00:03:35,150
we could actually make it such that it is a random.

71
00:03:35,150 --> 00:03:39,110
And what this would mean, is that we could randomly split our data into training,

72
00:03:39,110 --> 00:03:40,370
validation, and test set,

73
00:03:40,370 --> 00:03:43,955
and then we could kind of report- rather than on a single split,

74
00:03:43,955 --> 00:03:47,615
we could report average performance over different,

75
00:03:47,615 --> 00:03:49,880
uh, uh, let's call them, uh, random splits.

76
00:03:49,880 --> 00:03:53,470
So one is just to create the split and work with it forever.

77
00:03:53,470 --> 00:03:55,835
The other one is to kind of create the split,

78
00:03:55,835 --> 00:04:00,290
but one component of that split is that there is some randomness and we can

79
00:04:00,290 --> 00:04:05,285
then try out many different instantiation of the split and report the average,

80
00:04:05,285 --> 00:04:07,385
uh, to provide even more,

81
00:04:07,385 --> 00:04:09,565
uh, robust, uh, results.

82
00:04:09,565 --> 00:04:11,610
So, um, you know,

83
00:04:11,610 --> 00:04:14,355
why is splitting graphs special?

84
00:04:14,355 --> 00:04:18,875
Uh, imagine if you have an image dataset or a document dataset.

85
00:04:18,875 --> 00:04:20,495
Then in such datasets,

86
00:04:20,495 --> 00:04:22,010
you assume that, uh,

87
00:04:22,010 --> 00:04:25,565
uh, data points are independent from, uh, each other.

88
00:04:25,565 --> 00:04:27,165
So this means that, uh,

89
00:04:27,165 --> 00:04:30,375
each data point here is an image, and, uh,

90
00:04:30,375 --> 00:04:32,255
because they are independent from each other,

91
00:04:32,255 --> 00:04:34,970
it is easy to split them into training, test,

92
00:04:34,970 --> 00:04:37,285
uh, and validation, uh, set.

93
00:04:37,285 --> 00:04:43,370
Um, and there is no leakage because each image is a data- data point, uh, by its own.

94
00:04:43,370 --> 00:04:46,480
Uh, splitting a graph is different.

95
00:04:46,480 --> 00:04:50,755
Um, the problem with the graph is that nodes are connected with each other.

96
00:04:50,755 --> 00:04:52,985
So for example, in node classification,

97
00:04:52,985 --> 00:04:55,280
each data point is a node now, um,

98
00:04:55,280 --> 00:04:58,080
but these nodes are not independent from each other.

99
00:04:58,080 --> 00:05:00,800
The nodes are actually connected, uh,

100
00:05:00,800 --> 00:05:02,240
with each other, meaning that,

101
00:05:02,240 --> 00:05:03,920
you know, for example, in this case,

102
00:05:03,920 --> 00:05:07,760
if I look at node 5, in order to predict node 5, it will,

103
00:05:07,760 --> 00:05:11,300
in terms of a graph neural network also collect information from nodes,

104
00:05:11,300 --> 00:05:12,545
uh, 1 and 2.

105
00:05:12,545 --> 00:05:13,640
So this means that, uh,

106
00:05:13,640 --> 00:05:16,410
nodes, um, 1 and, um, uh,

107
00:05:16,410 --> 00:05:18,540
2, um, will affect,

108
00:05:18,540 --> 00:05:20,820
uh, the prediction on- on- of node 5.

109
00:05:20,820 --> 00:05:25,070
So if 1 and 2 are the training dataset and 5 is the test dataset,

110
00:05:25,070 --> 00:05:27,065
then clearly we have some,

111
00:05:27,065 --> 00:05:29,165
um, information, uh, leakage.

112
00:05:29,165 --> 00:05:32,315
So, uh, this is why this is interesting.

113
00:05:32,315 --> 00:05:33,815
So then the question is,

114
00:05:33,815 --> 00:05:35,675
um, what are our options?

115
00:05:35,675 --> 00:05:38,590
What can we- uh, what can we do?

116
00:05:38,590 --> 00:05:41,265
Um, we can do the following.

117
00:05:41,265 --> 00:05:44,745
Um, the first solution is to do what we call,

118
00:05:44,745 --> 00:05:46,675
um, a transductive setting,

119
00:05:46,675 --> 00:05:51,830
where the input graph can be observed over, for all the dataset splits.

120
00:05:51,830 --> 00:05:55,580
So basically we- we will work with the same graph structure for training,

121
00:05:55,580 --> 00:05:57,775
validation, and, uh, test set.

122
00:05:57,775 --> 00:06:01,100
And we will only split the node- the node labels,

123
00:06:01,100 --> 00:06:03,590
meaning we'll keep the graph structure as is,

124
00:06:03,590 --> 00:06:06,275
but we're going to put some nodes into the training,

125
00:06:06,275 --> 00:06:09,065
test and, uh, validation, uh, set.

126
00:06:09,065 --> 00:06:11,930
So we are only splitting, uh, node labels.

127
00:06:11,930 --> 00:06:13,835
This means that at the training time,

128
00:06:13,835 --> 00:06:16,145
we compute embeddings of nodes,

129
00:06:16,145 --> 00:06:19,330
let's say 1 and 2 because they are our training set, uh,

130
00:06:19,330 --> 00:06:20,795
using the entire graph,

131
00:06:20,795 --> 00:06:22,780
but only labels of 1 and 2.

132
00:06:22,780 --> 00:06:26,140
And at validation time we compute embeddings of the, uh,

133
00:06:26,140 --> 00:06:30,035
entire graph and only evaluate on, uh, uh, uh,

134
00:06:30,035 --> 00:06:34,705
labels of nodes 3 and 4 because we have the data, uh, for them.

135
00:06:34,705 --> 00:06:36,975
So this would be one possible,

136
00:06:36,975 --> 00:06:39,270
uh, approach, uh, to do this.

137
00:06:39,270 --> 00:06:42,050
Another approach is what we call,

138
00:06:42,050 --> 00:06:44,825
uh, an inductive setting, where we, uh,

139
00:06:44,825 --> 00:06:48,080
break the edges between the splits into, uh,

140
00:06:48,080 --> 00:06:52,850
multiple graphs or multiple independent graphs, multiple independent components.

141
00:06:52,850 --> 00:06:54,500
So now we have, uh,

142
00:06:54,500 --> 00:06:56,210
three graphs that are independent.

143
00:06:56,210 --> 00:07:01,770
Um, and in our case that would mean is that we would just drop these , uh, dotted edges.

144
00:07:01,770 --> 00:07:05,630
So now we have three different graphs and we can call one a training graph,

145
00:07:05,630 --> 00:07:08,335
a validation graph, um, and a test graph.

146
00:07:08,335 --> 00:07:11,210
Um, so this means that when now we are making,

147
00:07:11,210 --> 00:07:12,590
let's say a prediction, uh,

148
00:07:12,590 --> 00:07:14,585
in the test set about node five,

149
00:07:14,585 --> 00:07:15,950
we are not affected, uh,

150
00:07:15,950 --> 00:07:18,485
by the, uh, prediction of- uh,

151
00:07:18,485 --> 00:07:22,745
by the label or the structure from- information from node 1 anymore.

152
00:07:22,745 --> 00:07:25,760
So this means that at the training time we compute embeddings

153
00:07:25,760 --> 00:07:28,790
only over the graph that includes nodes 1 and 2,

154
00:07:28,790 --> 00:07:30,470
um, and only, uh,

155
00:07:30,470 --> 00:07:32,300
in using the labels of 1 and 2.

156
00:07:32,300 --> 00:07:33,740
And at validation time,

157
00:07:33,740 --> 00:07:36,450
we compute the embedding using the graph, uh,

158
00:07:36,450 --> 00:07:38,190
over nodes 3 and 4, uh,

159
00:07:38,190 --> 00:07:40,805
and evaluate based on the nodes, uh, 3 and 4.

160
00:07:40,805 --> 00:07:43,100
Of course, the problem with this- with this approach,

161
00:07:43,100 --> 00:07:46,340
is that now I have- I have thrown away quite a few edges,

162
00:07:46,340 --> 00:07:48,305
quite a bit of graph information,

163
00:07:48,305 --> 00:07:49,970
and if my graphs are small,

164
00:07:49,970 --> 00:07:51,775
this is not, uh, preferred.

165
00:07:51,775 --> 00:07:57,410
So kind of the trade-off is either I have some leakage of structured information between,

166
00:07:57,410 --> 00:07:59,540
uh, training, validation and test set,

167
00:07:59,540 --> 00:08:01,880
but at least the labels are independent in

168
00:08:01,880 --> 00:08:04,895
the transductive setting or in an inductive setting,

169
00:08:04,895 --> 00:08:08,285
I actually have to throw away the edges so that I chop

170
00:08:08,285 --> 00:08:12,065
the graph in two different independent pieces and then,

171
00:08:12,065 --> 00:08:16,120
uh, run or evaluate over those pieces.

172
00:08:16,120 --> 00:08:21,275
So in- the solution in that transactive setting is that the in- input graph, uh,

173
00:08:21,275 --> 00:08:23,540
can be, uh, observed, uh,

174
00:08:23,540 --> 00:08:25,640
for all, uh, dataset splits,

175
00:08:25,640 --> 00:08:27,250
training, validation, and test.

176
00:08:27,250 --> 00:08:31,780
Um, and this is- this is interesting because, um,

177
00:08:31,780 --> 00:08:35,179
it allows us to basically operate in this what you could also think of

178
00:08:35,179 --> 00:08:38,929
as semi-supervised setting where the graph is given, uh,

179
00:08:38,929 --> 00:08:41,559
the- the edges of all the nodes are given,

180
00:08:41,559 --> 00:08:43,714
uh, the features of all the nodes are given,

181
00:08:43,715 --> 00:08:46,905
but the lab- but the labels of nodes are only,

182
00:08:46,905 --> 00:08:50,405
uh, only a subset of node labels, uh, is observed.

183
00:08:50,405 --> 00:08:52,595
So, uh, to summarize,

184
00:08:52,595 --> 00:08:54,080
in the transactive setting,

185
00:08:54,080 --> 00:08:55,160
we have training, test,

186
00:08:55,160 --> 00:08:56,840
and validation split, uh,

187
00:08:56,840 --> 00:08:58,340
all on the same graph.

188
00:08:58,340 --> 00:09:01,175
Where data consists of one connected graph.

189
00:09:01,175 --> 00:09:03,409
The entire graph can be observed,

190
00:09:03,409 --> 00:09:05,360
uh, uh, in all the data splits.

191
00:09:05,360 --> 00:09:06,875
So it means all the nodes,

192
00:09:06,875 --> 00:09:09,110
all the edges and all the node features,

193
00:09:09,110 --> 00:09:10,790
uh, but we only split the,

194
00:09:10,790 --> 00:09:13,015
uh, the labels, meaning, uh,

195
00:09:13,015 --> 00:09:14,360
some labels are observed,

196
00:09:14,360 --> 00:09:17,015
other labels- labels are unobserved.

197
00:09:17,015 --> 00:09:20,750
And this, uh, setting is applicable both to node prediction,

198
00:09:20,750 --> 00:09:24,265
uh, as well as edge class- edge prediction tasks.

199
00:09:24,265 --> 00:09:26,660
The inductive setting, which is the training,

200
00:09:26,660 --> 00:09:28,175
validation, and test sets,

201
00:09:28,175 --> 00:09:29,755
are on different graphs.

202
00:09:29,755 --> 00:09:34,700
Uh, the dataset here consists of multiple graphs that are independent from each other.

203
00:09:34,700 --> 00:09:39,260
We only observe the graph structure- note features as well as,

204
00:09:39,260 --> 00:09:40,850
ah, let say node labels,

205
00:09:40,850 --> 00:09:42,415
uh, within the split.

206
00:09:42,415 --> 00:09:46,555
Um, and this allows us to really test how can we generalize to  unseen graphs.

207
00:09:46,555 --> 00:09:49,610
The- the drawback of this approach is that we

208
00:09:49,610 --> 00:09:52,985
have to take the original graph and chop it into many,

209
00:09:52,985 --> 00:09:55,550
uh, different, uh, small, uh, pieces.

210
00:09:55,550 --> 00:09:59,775
Uh, and this way we throw away some, uh, graph formation.

211
00:09:59,775 --> 00:10:03,175
This was now in terms of node classification.

212
00:10:03,175 --> 00:10:06,670
Here I give you an example in terms of transductive classification,

213
00:10:06,670 --> 00:10:09,310
you simply split, uh, nodes into training,

214
00:10:09,310 --> 00:10:11,425
uh, validation, and test sets.

215
00:10:11,425 --> 00:10:13,765
Um, in the inductive setting, uh,

216
00:10:13,765 --> 00:10:18,580
we basically- we can assume we have multiple different, uh, graphs, um,

217
00:10:18,580 --> 00:10:22,030
uh, given and we can, um, uh,

218
00:10:22,030 --> 00:10:24,070
take some graphs into the training set,

219
00:10:24,070 --> 00:10:26,155
others in the validation and test set.

220
00:10:26,155 --> 00:10:28,060
If we don't have multiple graphs,

221
00:10:28,060 --> 00:10:31,630
we have to create multiple graphs by basically dropping the edges

222
00:10:31,630 --> 00:10:35,605
or cutting the edges between them so that we get to these different,

223
00:10:35,605 --> 00:10:39,070
uh, connected components and then put them in the training, test,

224
00:10:39,070 --> 00:10:41,650
uh, and validation, uh, set.

225
00:10:41,650 --> 00:10:46,075
So now that we have talked about node classification,

226
00:10:46,075 --> 00:10:48,520
let's switch and let's go to the next, uh,

227
00:10:48,520 --> 00:10:51,370
classification task, which is graph classification.

228
00:10:51,370 --> 00:10:53,560
In graph classification, uh,

229
00:10:53,560 --> 00:10:57,610
induc- inductive setting is well defined because we have independent graphs,

230
00:10:57,610 --> 00:11:01,660
um, and we can simply split them into the training, validation, and test sets.

231
00:11:01,660 --> 00:11:04,375
So basically, we put some graphs into the training set,

232
00:11:04,375 --> 00:11:05,710
some in the validation set,

233
00:11:05,710 --> 00:11:06,820
and some in the test set.

234
00:11:06,820 --> 00:11:09,535
Se here, we basically have independent, uh, graphs.

235
00:11:09,535 --> 00:11:10,780
It's easy to split them,

236
00:11:10,780 --> 00:11:11,994
there is no crosstalk,

237
00:11:11,994 --> 00:11:13,915
there is no information leakage,

238
00:11:13,915 --> 00:11:16,055
um, and this can be done.

239
00:11:16,055 --> 00:11:21,180
Perhaps, um, the trickiest of all the settings,

240
00:11:21,180 --> 00:11:24,285
uh, for machine learning with graphs is link prediction.

241
00:11:24,285 --> 00:11:28,535
Um, and the goal of link prediction is to predict missing edges.

242
00:11:28,535 --> 00:11:32,485
And setting up link prediction requires a bit of thought and it

243
00:11:32,485 --> 00:11:36,820
can be tricky because link prediction is an unsupervised,

244
00:11:36,820 --> 00:11:38,935
uh, or self-supervised task.

245
00:11:38,935 --> 00:11:42,115
We need to create labels and the data splits,

246
00:11:42,115 --> 00:11:43,435
uh, on our own.

247
00:11:43,435 --> 00:11:46,900
So this means that we need to hide some of the edges from

248
00:11:46,900 --> 00:11:51,475
the GNN and let the GNN predict the existing edges.

249
00:11:51,475 --> 00:11:53,170
So the idea is, for example,

250
00:11:53,170 --> 00:11:54,865
if I have the original graph,

251
00:11:54,865 --> 00:11:57,055
I have to hide a couple of edges,

252
00:11:57,055 --> 00:11:58,660
for example, these two red edges,

253
00:11:58,660 --> 00:12:03,880
so that I say this is the input and I want my- my GNN to be able to predict these two,

254
00:12:03,880 --> 00:12:06,070
uh, output, uh, edges, right?

255
00:12:06,070 --> 00:12:08,830
So in some sense, we'll have to take some edges out,

256
00:12:08,830 --> 00:12:12,595
hide them from ourselves and try to, uh, predict them.

257
00:12:12,595 --> 00:12:18,430
So, uh, this is interesting and it creates a bit more complexity because,

258
00:12:18,430 --> 00:12:19,840
um, in a GNN,

259
00:12:19,840 --> 00:12:21,340
we have two types of edges.

260
00:12:21,340 --> 00:12:23,785
We will have the message-passing edges,

261
00:12:23,785 --> 00:12:26,620
so edges that the GNN can use to create the embedding,

262
00:12:26,620 --> 00:12:29,455
and then we'll have these what we'll call supervision edges,

263
00:12:29,455 --> 00:12:31,360
which are the edges that are part of,

264
00:12:31,360 --> 00:12:33,790
let's say, our training, uh, dataset.

265
00:12:33,790 --> 00:12:36,430
So for, uh, link prediction,

266
00:12:36,430 --> 00:12:38,200
we need to split edges twice.

267
00:12:38,200 --> 00:12:42,310
In first step, we assign two types of edges to the original graph.

268
00:12:42,310 --> 00:12:45,550
As I said, some edges we'll call message passing edges.

269
00:12:45,550 --> 00:12:49,045
They are edges used for the GNN to operate over.

270
00:12:49,045 --> 00:12:53,350
And then we'll also call- what we'll call supervision edges.

271
00:12:53,350 --> 00:12:56,410
These are the edges for us to compute the objective function,

272
00:12:56,410 --> 00:12:59,650
loss function, performance of the model, and so on.

273
00:12:59,650 --> 00:13:02,665
Um, and after the step 1, um,

274
00:13:02,665 --> 00:13:07,840
only message edges will remain in the graph and supervision edges are the,

275
00:13:07,840 --> 00:13:11,650
uh, edges that are used for supervision of, uh, edge prediction,

276
00:13:11,650 --> 00:13:16,090
uh, made by the model and will not be used, uh, by the GNN.

277
00:13:16,090 --> 00:13:18,835
Um, so this- this is the first step.

278
00:13:18,835 --> 00:13:21,355
And then in the second step, we split, uh,

279
00:13:21,355 --> 00:13:24,565
edges into train, test, and validation set.

280
00:13:24,565 --> 00:13:26,155
Um, and we have two options.

281
00:13:26,155 --> 00:13:30,520
One is to do what is called inductive link prediction split, where, you know,

282
00:13:30,520 --> 00:13:35,560
we- let's say we have a dataset with three graphs and each split will be,

283
00:13:35,560 --> 00:13:37,750
uh, indepe- will be an independent graph.

284
00:13:37,750 --> 00:13:39,205
So we'll have a training set,

285
00:13:39,205 --> 00:13:42,550
we'll have our validation set and a test set, three different graphs,

286
00:13:42,550 --> 00:13:46,000
and each graph will have a different, um, uh,

287
00:13:46,000 --> 00:13:47,980
split in terms of training,

288
00:13:47,980 --> 00:13:49,720
validation, and test edges, right?

289
00:13:49,720 --> 00:13:53,320
So here this would be the message-passing edges and the supervision edges.

290
00:13:53,320 --> 00:13:55,750
In the second validation graph,

291
00:13:55,750 --> 00:13:58,045
y- you know, we'll have different, um, uh,

292
00:13:58,045 --> 00:14:01,585
supervision edges and different message-passing edges,

293
00:14:01,585 --> 00:14:04,270
and then, in the test set, uh, the same.

294
00:14:04,270 --> 00:14:05,770
So this is, uh,

295
00:14:05,770 --> 00:14:08,275
one way, um, uh, to do this.

296
00:14:08,275 --> 00:14:10,990
Another way to do this is to do this in,

297
00:14:10,990 --> 00:14:12,805
uh, the transductive setting.

298
00:14:12,805 --> 00:14:15,640
And if we do transductive link prediction split, um,

299
00:14:15,640 --> 00:14:19,885
this is generally the default when people talk about link prediction.

300
00:14:19,885 --> 00:14:22,630
And suppose we only have one- one input graph.

301
00:14:22,630 --> 00:14:25,090
What we have to do in this, uh, one,

302
00:14:25,090 --> 00:14:27,519
um, input graph, by definition,

303
00:14:27,519 --> 00:14:29,470
the transductive- of the- uh,

304
00:14:29,470 --> 00:14:31,420
what we mean by transductive learning,

305
00:14:31,420 --> 00:14:33,580
the entire graph can be observed,

306
00:14:33,580 --> 00:14:35,725
uh, for all the datasets' splits.

307
00:14:35,725 --> 00:14:37,870
But since edges are both, uh,

308
00:14:37,870 --> 00:14:40,375
part of the graph structure and the supervision,

309
00:14:40,375 --> 00:14:42,085
we need to hold out, uh,

310
00:14:42,085 --> 00:14:44,005
validation and test edges.

311
00:14:44,005 --> 00:14:46,180
Um, and then to train the training set,

312
00:14:46,180 --> 00:14:47,845
we need to further hold out, uh,

313
00:14:47,845 --> 00:14:50,605
the supervision edges, uh, on the training set.

314
00:14:50,605 --> 00:14:51,850
So let me now, uh,

315
00:14:51,850 --> 00:14:54,235
show you how exactly to do this.

316
00:14:54,235 --> 00:14:59,020
So, uh, for transductive link predict- um, link prediction,

317
00:14:59,020 --> 00:15:02,200
we will take the original graph and we are going to create

318
00:15:02,200 --> 00:15:05,665
a training dataset where we'll have a couple of training edges,

319
00:15:05,665 --> 00:15:09,715
um, er, for message-passing as well as the supervision edges.

320
00:15:09,715 --> 00:15:14,290
At validation time, we are going to use the training edges and the, uh,

321
00:15:14,290 --> 00:15:17,665
training message-passing edges and training supervision edges,

322
00:15:17,665 --> 00:15:20,820
uh, to be able to predict the validation edges.

323
00:15:20,820 --> 00:15:22,470
And then at the test time,

324
00:15:22,470 --> 00:15:24,915
we are going to use the training message edges,

325
00:15:24,915 --> 00:15:30,195
training supervision edges, as well as validation edges to predict the test edges.

326
00:15:30,195 --> 00:15:31,785
So now you can see how, uh,

327
00:15:31,785 --> 00:15:34,169
at training time the graph is sparser,

328
00:15:34,169 --> 00:15:35,640
at the validation time,

329
00:15:35,640 --> 00:15:38,435
we need- we get to see the supervision edges,

330
00:15:38,435 --> 00:15:40,870
but we have to predict the validation edges,

331
00:15:40,870 --> 00:15:42,925
and at the final test time,

332
00:15:42,925 --> 00:15:45,955
we get to see all the edges but the test edges,

333
00:15:45,955 --> 00:15:47,230
and we need to predict,

334
00:15:47,230 --> 00:15:48,460
uh, the test edges.

335
00:15:48,460 --> 00:15:50,470
So here you see how, uh, basically, these,

336
00:15:50,470 --> 00:15:52,900
uh, sets are nested in one another.

337
00:15:52,900 --> 00:15:56,395
So, um, why do we use a growing number of edges?

338
00:15:56,395 --> 00:16:00,670
Because one way to think of this if- is if the graph is evolving over time,

339
00:16:00,670 --> 00:16:02,440
then you could say at some early time,

340
00:16:02,440 --> 00:16:05,680
this was the graph, then it grew by adding this edge.

341
00:16:05,680 --> 00:16:08,170
So that was the graph and it added another edge,

342
00:16:08,170 --> 00:16:09,370
and so on and so forth.

343
00:16:09,370 --> 00:16:12,835
So you can think of this almost like as splitting it along, uh, uh,

344
00:16:12,835 --> 00:16:15,730
uh, three- into thee- three different,

345
00:16:15,730 --> 00:16:17,800
um, time, uh, intervals.

346
00:16:17,800 --> 00:16:20,665
And that's perhaps the best way to define,

347
00:16:20,665 --> 00:16:23,065
uh, link prediction, uh, on a graph.

348
00:16:23,065 --> 00:16:27,550
So to summarize, transductive link prediction split is a bit, um, um,

349
00:16:27,550 --> 00:16:30,490
uh, tricky because we need to take

350
00:16:30,490 --> 00:16:33,985
the original graph and s- and basically have four types of edges.

351
00:16:33,985 --> 00:16:37,615
Training message-passing edges, training supervision edges,

352
00:16:37,615 --> 00:16:39,595
validation edges, as well as,

353
00:16:39,595 --> 00:16:41,125
uh, test edges.

354
00:16:41,125 --> 00:16:42,685
Um, and we have nice,

355
00:16:42,685 --> 00:16:43,930
uh, even though this, you know,

356
00:16:43,930 --> 00:16:46,375
might be a bit cumbersome, uh, to split, uh,

357
00:16:46,375 --> 00:16:49,210
around, uh, this allows us, uh,

358
00:16:49,210 --> 00:16:53,275
to do- uh, to do the- to do things well because we have, uh, good tools,

359
00:16:53,275 --> 00:16:55,975
meaning DeepSNAP and GraphGym that allow us,

360
00:16:55,975 --> 00:16:58,780
uh, to do this, uh, for free, uh, for us.

361
00:16:58,780 --> 00:17:01,525
So, uh, to summarize, uh,

362
00:17:01,525 --> 00:17:06,790
we- we talked about the entire GNN training pipeline from evaluation metrics,

363
00:17:06,790 --> 00:17:10,435
loss functions, labels, as well as, uh, the predictions.

364
00:17:10,435 --> 00:17:12,130
And these are some of the tools, uh,

365
00:17:12,130 --> 00:17:17,425
you can use that allow you to kind of manage these in an end-to-end, uh, fashion.

366
00:17:17,425 --> 00:17:19,690
So to summarize, uh,

367
00:17:19,690 --> 00:17:21,520
we talked about, um, uh,

368
00:17:21,520 --> 00:17:24,250
the GNN layer and how do we define it,

369
00:17:24,250 --> 00:17:28,015
we talked about how to stack different GNN layers together,

370
00:17:28,015 --> 00:17:31,030
and then we also talked about graph augmentation in

371
00:17:31,030 --> 00:17:34,615
terms of feature augmentation and graph structure augmentation,

372
00:17:34,615 --> 00:17:35,830
and what I talked, uh,

373
00:17:35,830 --> 00:17:37,930
now was about learning, uh,

374
00:17:37,930 --> 00:17:40,510
objectives and, uh, how do we,

375
00:17:40,510 --> 00:17:43,850
uh, set up different, uh, tasks.

