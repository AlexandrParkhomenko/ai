1
00:00:04,070 --> 00:00:10,005
We continue with our investigation of traditional machine learning approaches uh,

2
00:00:10,005 --> 00:00:12,375
to uh, graph level predictions.

3
00:00:12,375 --> 00:00:15,855
And now we have- we are going to focus on

4
00:00:15,855 --> 00:00:19,605
link pre- prediction tasks and features that capture,

5
00:00:19,605 --> 00:00:21,450
uh, structure of links,

6
00:00:21,450 --> 00:00:23,790
uh, in a given, uh, network.

7
00:00:23,790 --> 00:00:28,815
So the link le- level prediction tasks is the following.

8
00:00:28,815 --> 00:00:33,350
The task is to predict new links based on the existing links in the network.

9
00:00:33,350 --> 00:00:35,445
So this means at test time,

10
00:00:35,445 --> 00:00:39,555
we have to evaluate all node pairs that are not yet linked,

11
00:00:39,555 --> 00:00:41,535
uh, rank them, and then, uh,

12
00:00:41,535 --> 00:00:45,160
proclaim that the top k note pairs, as, um,

13
00:00:45,160 --> 00:00:47,494
predicted by our algorithm,

14
00:00:47,494 --> 00:00:49,400
are the links that are going to occur,

15
00:00:49,400 --> 00:00:50,660
uh, in the network.

16
00:00:50,660 --> 00:00:54,965
And the key here is to design features for a pair of nodes.

17
00:00:54,965 --> 00:00:57,650
And of course, what we can do, um, uh,

18
00:00:57,650 --> 00:01:00,050
as we have seen in the node level, uh,

19
00:01:00,050 --> 00:01:02,360
tasks, we could go and, uh,

20
00:01:02,360 --> 00:01:04,280
let say concatenate, uh,

21
00:01:04,280 --> 00:01:07,130
uh, the features of node number 1,

22
00:01:07,130 --> 00:01:08,720
features of the node number 2,

23
00:01:08,720 --> 00:01:12,380
and train a model on that type of, uh, representation.

24
00:01:12,380 --> 00:01:14,540
However, that would be very, um,

25
00:01:14,540 --> 00:01:18,245
unsatisfactory, because, uh, many times this would, uh,

26
00:01:18,245 --> 00:01:23,380
lose, uh, much of important information about the relationship between the two nodes,

27
00:01:23,380 --> 00:01:24,545
uh, in the network.

28
00:01:24,545 --> 00:01:29,465
So the way we will think of this link prediction task is two-way.

29
00:01:29,465 --> 00:01:31,625
We can formulate it in two different ways.

30
00:01:31,625 --> 00:01:34,100
One way we can formulate it is simply to say,

31
00:01:34,100 --> 00:01:35,390
links in the network are,

32
00:01:35,390 --> 00:01:37,010
let say missing at random,

33
00:01:37,010 --> 00:01:38,870
so we are given a network,

34
00:01:38,870 --> 00:01:40,470
we are going to remove, uh,

35
00:01:40,470 --> 00:01:43,890
at random some number of links and then trying to predict,

36
00:01:43,890 --> 00:01:46,380
uh, back, uh, those links using our,

37
00:01:46,380 --> 00:01:47,700
uh, machine learning algorithm.

38
00:01:47,700 --> 00:01:49,710
That's one type of a formulation.

39
00:01:49,710 --> 00:01:55,190
And then the other type of a formulation is that we are going to predict links over time.

40
00:01:55,190 --> 00:01:59,480
This means that if we have a network that naturally evolves over time, for example,

41
00:01:59,480 --> 00:02:01,880
our citation network, our social network,

42
00:02:01,880 --> 00:02:03,725
or our collaboration network,

43
00:02:03,725 --> 00:02:05,180
then we can say, ah,

44
00:02:05,180 --> 00:02:09,449
we are going to look at a graph between time zero and time zero,

45
00:02:09,449 --> 00:02:13,310
uh, prime, and based on the edges and the structure up to this uh,

46
00:02:13,310 --> 00:02:15,305
the time t 0 prime, uh,

47
00:02:15,305 --> 00:02:18,710
we are going then to output a ranked list L of

48
00:02:18,710 --> 00:02:22,100
links that we predict are going to occur in the future.

49
00:02:22,100 --> 00:02:26,215
Let's say that are going to appear between times T1 and T1 prime.

50
00:02:26,215 --> 00:02:30,830
And the way, uh, we can then evaluate this type of approach is to say ah,

51
00:02:30,830 --> 00:02:32,810
we know that in the future, um,

52
00:02:32,810 --> 00:02:35,720
n new links will appear, let's, uh,

53
00:02:35,720 --> 00:02:39,440
let's rank, uh, the- the potential edges outputed by

54
00:02:39,440 --> 00:02:42,320
our algorithm and let's compare it to the edges

55
00:02:42,320 --> 00:02:45,470
that actually really appeared, uh, in the future.

56
00:02:45,470 --> 00:02:49,010
Uh, this type of formulation is useful or natural

57
00:02:49,010 --> 00:02:52,745
for networks that evolve over time like transaction networks,

58
00:02:52,745 --> 00:02:55,985
like social networks, well, edges, uh, keep,

59
00:02:55,985 --> 00:02:58,685
um- keep adding, while for example,

60
00:02:58,685 --> 00:03:03,440
the links missing at random type formulation is more useful, for example,

61
00:03:03,440 --> 00:03:07,400
for static networks like protein- protein interaction networks,

62
00:03:07,400 --> 00:03:09,259
where we can assume,

63
00:03:09,259 --> 00:03:12,590
even though this assumption is actually heavily violated, that, you know,

64
00:03:12,590 --> 00:03:17,510
biologists are testing kind of at random connections between proteins,

65
00:03:17,510 --> 00:03:21,125
um, and we'd like to infer what other connections in the future, uh,

66
00:03:21,125 --> 00:03:25,610
are going for- for biologists are going to discover, uh, in the future,

67
00:03:25,610 --> 00:03:28,380
or which links should they probe with the,

68
00:03:28,380 --> 00:03:30,375
uh- that lab, uh, experiments.

69
00:03:30,375 --> 00:03:31,984
Of course, in reality,

70
00:03:31,984 --> 00:03:34,790
biologists are not exploring the physical, uh,

71
00:03:34,790 --> 00:03:38,690
protein-protein interaction network, uh, um, at random.

72
00:03:38,690 --> 00:03:42,785
Um, you know, they are heavily influenced by positive results of one another.

73
00:03:42,785 --> 00:03:46,280
So essentially some parts of this network suddenly well explored,

74
00:03:46,280 --> 00:03:49,540
while others are very much, uh, under explored.

75
00:03:49,540 --> 00:03:52,515
So with these two formulations, uh,

76
00:03:52,515 --> 00:03:55,260
let's now start thinking about, um,

77
00:03:55,260 --> 00:03:57,060
how are we going to, uh,

78
00:03:57,060 --> 00:03:59,295
provide a feature descriptor,

79
00:03:59,295 --> 00:04:01,395
uh, for a given, uh, pair of nodes?

80
00:04:01,395 --> 00:04:04,160
So the idea is that for a pair of nodes x, y,

81
00:04:04,160 --> 00:04:06,279
we are going to compute some score,

82
00:04:06,279 --> 00:04:08,550
um, uh, c, uh, x, y.

83
00:04:08,550 --> 00:04:10,155
For example, a score, uh,

84
00:04:10,155 --> 00:04:14,735
could be the number of common neighbors between nodes, uh, X and Y.

85
00:04:14,735 --> 00:04:17,630
And then we are going to sort all pairs x,

86
00:04:17,630 --> 00:04:19,970
y according to the decreasing, uh,

87
00:04:19,970 --> 00:04:25,490
score C, um, and we will predict top end pairs as the new links that are going to appear,

88
00:04:25,490 --> 00:04:26,725
uh, in the network.

89
00:04:26,725 --> 00:04:28,950
And then we can end, uh, the test-time, right,

90
00:04:28,950 --> 00:04:33,080
we can actually go and observe which links actually appear and compare these two lists,

91
00:04:33,080 --> 00:04:35,705
and this way determine how well our approach,

92
00:04:35,705 --> 00:04:37,775
our algorithm, um, is working.

93
00:04:37,775 --> 00:04:39,455
We are going to review, uh,

94
00:04:39,455 --> 00:04:42,350
three different ways how to, uh,

95
00:04:42,350 --> 00:04:47,130
featurize or create a descriptor of the relationship between two nodes in the network.

96
00:04:47,130 --> 00:04:49,730
We are going to talk about distance-based features,

97
00:04:49,730 --> 00:04:51,785
local neighborhood overlap features,

98
00:04:51,785 --> 00:04:55,385
as well as global neighbor- neighborhood overlap, uh, features.

99
00:04:55,385 --> 00:04:57,650
And the goal is that for a given pair of nodes,

100
00:04:57,650 --> 00:05:00,630
we are going to describe the relationship, um,

101
00:05:00,630 --> 00:05:02,250
between the two nodes, uh,

102
00:05:02,250 --> 00:05:04,850
so that from this relationship we can then predict or

103
00:05:04,850 --> 00:05:08,810
learn whether there exists a link between them or not.

104
00:05:08,810 --> 00:05:13,040
So first, uh, we talk about distance-based feature.

105
00:05:13,040 --> 00:05:14,510
Uh, this is very natural.

106
00:05:14,510 --> 00:05:15,740
We can think about

107
00:05:15,740 --> 00:05:19,200
the shortest path distance between the two nodes and characterize it in this way.

108
00:05:19,200 --> 00:05:22,070
So for example, if we have nodes B and H,

109
00:05:22,070 --> 00:05:25,415
then the shortest path length between them, uh, equals two.

110
00:05:25,415 --> 00:05:27,950
So the value of this feature would be equal to two.

111
00:05:27,950 --> 00:05:30,390
However, if you look at this, uh, this does,

112
00:05:30,390 --> 00:05:33,675
uh- what this- what this metric does not capture it, it captures the distance,

113
00:05:33,675 --> 00:05:35,385
but it doesn't measure,

114
00:05:35,385 --> 00:05:40,250
kind of capture the degree of neighborhood overlap or the strength of connection.

115
00:05:40,250 --> 00:05:42,680
Because for example, you can look in this network

116
00:05:42,680 --> 00:05:45,560
nodes B and H actually have two friends in common.

117
00:05:45,560 --> 00:05:49,580
So the- the connection here in some sense is stronger between them.

118
00:05:49,580 --> 00:05:51,995
Then for example, the connection between, uh,

119
00:05:51,995 --> 00:05:54,515
node D and, uh, node, uh,

120
00:05:54,515 --> 00:05:57,350
F, um, because they only have kind of- there is

121
00:05:57,350 --> 00:06:00,395
only one path while here there are two different paths.

122
00:06:00,395 --> 00:06:02,360
So the way we can, um,

123
00:06:02,360 --> 00:06:05,870
try to capture the strength of connection between two nodes would be to ask, okay,

124
00:06:05,870 --> 00:06:07,820
how many neighbors, uh,

125
00:06:07,820 --> 00:06:09,635
do you have in common, right?

126
00:06:09,635 --> 00:06:12,785
What is the number of common friends between a pair of nodes?

127
00:06:12,785 --> 00:06:16,745
And this is captured by the notion of local neighborhood overlap,

128
00:06:16,745 --> 00:06:21,020
which captures the number of neighboring nodes shared between two nodes,

129
00:06:21,020 --> 00:06:23,380
v and, uh- v1 and v2.

130
00:06:23,380 --> 00:06:26,055
Uh, one way to capture this is you simply say,

131
00:06:26,055 --> 00:06:28,460
what is the- what is the number of common neighbors, right?

132
00:06:28,460 --> 00:06:31,205
We take the neighbors of node V1,

133
00:06:31,205 --> 00:06:32,960
take the neighbors of node V2,

134
00:06:32,960 --> 00:06:36,355
and take the intersection of these two sets.

135
00:06:36,355 --> 00:06:39,795
Um, a normalized version of this, uh,

136
00:06:39,795 --> 00:06:42,180
same idea is Jaccard coefficient,

137
00:06:42,180 --> 00:06:44,265
where we take the intersection-

138
00:06:44,265 --> 00:06:47,360
the size of the intersection divided by the size of the union.

139
00:06:47,360 --> 00:06:49,760
The issue with common neighbors is that, of course,

140
00:06:49,760 --> 00:06:53,840
nodes that have higher degree are more likely to have neighbors with others.

141
00:06:53,840 --> 00:06:56,600
While here in the Jaccard coefficient, in some sense,

142
00:06:56,600 --> 00:07:00,065
we are norma- we are trying to normalize, um,

143
00:07:00,065 --> 00:07:02,150
by the degree, uh,

144
00:07:02,150 --> 00:07:05,450
to some degree by saying what is the union of the number of,

145
00:07:05,450 --> 00:07:07,330
um, neighbors of the two nodes.

146
00:07:07,330 --> 00:07:08,775
Uh, and then, uh,

147
00:07:08,775 --> 00:07:10,650
the other type of, uh,

148
00:07:10,650 --> 00:07:12,585
uh, local neighborhood overlap, uh,

149
00:07:12,585 --> 00:07:16,235
metric that is- that actually works quite well in practice is called,

150
00:07:16,235 --> 00:07:17,930
uh, Adamic- Adar index.

151
00:07:17,930 --> 00:07:19,610
And simply what this is saying is,

152
00:07:19,610 --> 00:07:20,900
let's go over the,

153
00:07:20,900 --> 00:07:26,120
um- let's sum over the neighbors that nodes v1 and v2 have in common,

154
00:07:26,120 --> 00:07:29,810
and let's take one over the log, uh, their degree.

155
00:07:29,810 --> 00:07:33,520
So basically, the idea here is that we count how many neighbors,

156
00:07:33,520 --> 00:07:35,295
um, the two nodes have in common,

157
00:07:35,295 --> 00:07:37,955
but the importance of uneven neighbor is,

158
00:07:37,955 --> 00:07:42,650
uh- is low, uh- decreases, uh, with these degrees.

159
00:07:42,650 --> 00:07:43,670
So if you have a lot of,

160
00:07:43,670 --> 00:07:47,315
um, neighbors in common that have low degree,

161
00:07:47,315 --> 00:07:50,780
that is better than if you have a lot of high-

162
00:07:50,780 --> 00:07:54,260
highly connected celebrities as a set of common neighbors.

163
00:07:54,260 --> 00:07:59,335
So this is a- a net- a feature that works really well in a social network.

164
00:07:59,335 --> 00:08:02,950
Of course, the problem with, uh, local, um,

165
00:08:02,950 --> 00:08:07,805
network neighborhood overlap is the limitation is that this, uh,

166
00:08:07,805 --> 00:08:13,145
metric always returns zero if two- two nodes are not- do not have any,

167
00:08:13,145 --> 00:08:14,525
uh, neighbors in common.

168
00:08:14,525 --> 00:08:16,265
So for example, in this case,

169
00:08:16,265 --> 00:08:20,315
if we would want to say what is the neighborhood overlap between nodes A and E,

170
00:08:20,315 --> 00:08:22,230
because they have no neighbors in common,

171
00:08:22,230 --> 00:08:24,170
they are more than, um,

172
00:08:24,170 --> 00:08:26,040
uh, two hops away from each other.

173
00:08:26,040 --> 00:08:28,185
Then the- if only in such cases,

174
00:08:28,185 --> 00:08:33,500
the return- the value of that it will be returned to will always be, zero.

175
00:08:33,500 --> 00:08:38,240
However, in reality, these two nodes may still potentially be connected in the future.

176
00:08:38,240 --> 00:08:40,625
So to fix this problem,

177
00:08:40,625 --> 00:08:44,020
we then define global neighborhood overlap matrix.

178
00:08:44,020 --> 00:08:47,450
That is all of this limitation by only, uh,

179
00:08:47,450 --> 00:08:50,330
focusing on a hop- two hop distances and

180
00:08:50,330 --> 00:08:54,085
two-hop paths between a pairs- pair of nodes and consider,

181
00:08:54,085 --> 00:08:57,895
um, all other distances or the entire graph as well.

182
00:08:57,895 --> 00:09:03,465
So let's now look at global neigh- neighborhood overlap type, uh, metrics.

183
00:09:03,465 --> 00:09:07,960
And the metric we are going to talk about is called Katz index,

184
00:09:07,960 --> 00:09:10,955
and it counts the number of all paths, uh,

185
00:09:10,955 --> 00:09:15,510
of all different lengths between a given pair of nodes.

186
00:09:15,510 --> 00:09:18,325
So now we need to figure out two things here.

187
00:09:18,325 --> 00:09:22,495
First is, how do we compute number of paths of a given length,

188
00:09:22,495 --> 00:09:25,485
uh, between, uh, two, uh, nodes?

189
00:09:25,485 --> 00:09:28,850
This can actually be very elegantly computed by

190
00:09:28,850 --> 00:09:31,700
using powers of the graph adjacency matrix.

191
00:09:31,700 --> 00:09:36,260
So let me give you a quick illustration or a quick proof why this is true.

192
00:09:36,260 --> 00:09:38,135
So the uh, first,

193
00:09:38,135 --> 00:09:41,990
I wanna give you the intuition around the powers of adjacency matrix, right?

194
00:09:41,990 --> 00:09:44,450
The point is that what we are going to show is

195
00:09:44,450 --> 00:09:48,800
that computing number of paths between uh, two nodes um,

196
00:09:48,800 --> 00:09:52,730
reduces down to computing powers of the graph adjacency matrix or

197
00:09:52,730 --> 00:09:57,335
essentially taking the graph adjacency matrix and multiplying it with itself.

198
00:09:57,335 --> 00:10:00,500
So first graph adjacency matrix recall,

199
00:10:00,500 --> 00:10:07,760
it has a value 1 at every entry uv if- if nodes u and v are connected.

200
00:10:07,760 --> 00:10:09,665
Then let's say that p,

201
00:10:09,665 --> 00:10:14,780
uv uh superscript capital K counts the number of paths of

202
00:10:14,780 --> 00:10:20,000
length K between nodes u and v. And our goal is to show that uh,

203
00:10:20,000 --> 00:10:22,950
uh, if we are interested in the number of paths uh,

204
00:10:22,950 --> 00:10:25,145
uh, of length K,

205
00:10:25,145 --> 00:10:26,765
then we have to uh,

206
00:10:26,765 --> 00:10:32,615
compute A to the power of k and that entry uv will tell us the number of pets.

207
00:10:32,615 --> 00:10:35,960
The capital K here is the same as uh,

208
00:10:35,960 --> 00:10:37,190
uh, a small case,

209
00:10:37,190 --> 00:10:42,875
so the Kth power of A measures the number of paths of a given length.

210
00:10:42,875 --> 00:10:44,810
And if you think about it right,

211
00:10:44,810 --> 00:10:47,630
how many paths of length 1 are there between a pair of

212
00:10:47,630 --> 00:10:51,230
nodes that is exactly captured by the graph adjacency matrix, right?

213
00:10:51,230 --> 00:10:53,120
If a pair of nodes is connected,

214
00:10:53,120 --> 00:10:54,755
then there is a value 1,

215
00:10:54,755 --> 00:10:57,215
and if a pair of nodes is not connected,

216
00:10:57,215 --> 00:10:59,855
then there is the value 0.

217
00:10:59,855 --> 00:11:03,590
Now that we know how to compute um,

218
00:11:03,590 --> 00:11:07,505
the number of paths of length 1 between a pair of nodes.

219
00:11:07,505 --> 00:11:10,100
Now we can ask how many- how do we compute

220
00:11:10,100 --> 00:11:13,040
the number of paths of length 2 between a pair of nodes u.

221
00:11:13,040 --> 00:11:16,460
And we are going to do this via the two- two-step procedure.

222
00:11:16,460 --> 00:11:20,810
Uh, and we are going to do this by decompose the path of

223
00:11:20,810 --> 00:11:25,430
length 2 into a path of length 1 plus another path of length 1.

224
00:11:25,430 --> 00:11:29,555
So the idea is that we compute the number of paths of length 1

225
00:11:29,555 --> 00:11:33,995
between each of u's neighbors and v,

226
00:11:33,995 --> 00:11:36,650
and then um, add one to that.

227
00:11:36,650 --> 00:11:38,660
So the idea is the following,

228
00:11:38,660 --> 00:11:43,850
the number of paths between nodes u and v of length 1- of length 2 is

229
00:11:43,850 --> 00:11:49,335
simply a summation over the nodes i that are the neighbors of the starting node u,

230
00:11:49,335 --> 00:11:52,270
um, times the number of paths now from

231
00:11:52,270 --> 00:11:56,320
this neighbor i to the target node v. And this will

232
00:11:56,320 --> 00:12:03,680
now give us the number of paths of length 2 between u and v. And now what you can see,

233
00:12:03,680 --> 00:12:07,190
you can see a substitute here back, the adjacency matrix.

234
00:12:07,190 --> 00:12:09,155
So all these is a sum over i,

235
00:12:09,155 --> 00:12:13,790
u- A _ui times A_iv.

236
00:12:13,790 --> 00:12:16,505
So if you see this,

237
00:12:16,505 --> 00:12:19,580
this is simply the product of matrices uh,

238
00:12:19,580 --> 00:12:23,090
of made- of adjacency matrix A_ iu itself.

239
00:12:23,090 --> 00:12:24,455
So this is now uh,

240
00:12:24,455 --> 00:12:29,420
the entry uv of the adjacency matrix A uh, squared.

241
00:12:29,420 --> 00:12:31,370
Um, this is uh,

242
00:12:31,370 --> 00:12:32,900
now by basically by induction,

243
00:12:32,900 --> 00:12:41,090
we can keep repeating this and get a higher powers that count paths of longer lengths um,

244
00:12:41,090 --> 00:12:43,700
as- as this is uh, increasing.

245
00:12:43,700 --> 00:12:45,950
Another way to look at this,

246
00:12:45,950 --> 00:12:47,960
here is a visual proof is that uh,

247
00:12:47,960 --> 00:12:49,220
what is A squared?

248
00:12:49,220 --> 00:12:52,460
A squared is A multiplied by itself,

249
00:12:52,460 --> 00:12:55,040
so when we are interested in a given,

250
00:12:55,040 --> 00:12:57,740
let's say entry, here these are entry,

251
00:12:57,740 --> 00:12:59,990
these are neighbors of Node 1.

252
00:12:59,990 --> 00:13:02,735
These are um, now the,

253
00:13:02,735 --> 00:13:08,960
the number of paths of length 1 between one- one's neighbors and node number 2.

254
00:13:08,960 --> 00:13:11,090
So after the multiplication,

255
00:13:11,090 --> 00:13:12,530
the value here will be 1,

256
00:13:12,530 --> 00:13:19,565
which we mean that there is one path of length 2 between node 1 uh, and Node 2.

257
00:13:19,565 --> 00:13:23,420
So this is how powers of adjacency matrix give

258
00:13:23,420 --> 00:13:29,090
account paths of length K between a pair of nodes uh, in the network.

259
00:13:29,090 --> 00:13:34,400
What this means is that now we can define the- we have developed

260
00:13:34,400 --> 00:13:39,650
the first component that will allow us to count- to compute the cuts index,

261
00:13:39,650 --> 00:13:45,275
because it allows us to count the number of paths between a pair of nodes for a given K.

262
00:13:45,275 --> 00:13:51,560
But what we still need to decide is how do we do this for all the path lengths,

263
00:13:51,560 --> 00:13:53,285
from one to infinity.

264
00:13:53,285 --> 00:13:55,760
So to compute the pets, as we said,

265
00:13:55,760 --> 00:13:58,880
we are going to use powers of the adjacency matrix uh,

266
00:13:58,880 --> 00:14:03,545
you know, uh, the adjacency matrix itself tells us powers of length 1,

267
00:14:03,545 --> 00:14:05,300
square of it tells us power of,

268
00:14:05,300 --> 00:14:09,005
uh squared tells us paths of length 2,

269
00:14:09,005 --> 00:14:12,470
and the adjacency matrix raised to

270
00:14:12,470 --> 00:14:17,840
the power l counts the number of paths of length l between a pair of nodes.

271
00:14:17,840 --> 00:14:24,050
NOW, the Katz index goes over from 1 path lengths all the way to infinity.

272
00:14:24,050 --> 00:14:27,215
So the- the Katz index uh,

273
00:14:27,215 --> 00:14:30,230
global neighborhood overlap between nodes v1 and

274
00:14:30,230 --> 00:14:34,535
v2 is simply a summation of l from one to infinity.

275
00:14:34,535 --> 00:14:37,850
We have this Beta raised to the power of l by basically

276
00:14:37,850 --> 00:14:42,650
a disc- discount factor that gives lower- lower importance

277
00:14:42,650 --> 00:14:46,670
to paths of longer lengths and A to b_l counts

278
00:14:46,670 --> 00:14:51,440
the number of paths of length l between nodes of v1 and v2.

279
00:14:51,440 --> 00:14:56,120
And now what is interesting about Katz index is that, um,

280
00:14:56,120 --> 00:15:01,205
um,uh, we can actually compute this particular expression in a closed-form.

281
00:15:01,205 --> 00:15:05,180
And here is- here is the- the formula for the Katz index again,

282
00:15:05,180 --> 00:15:06,635
and basically what uh,

283
00:15:06,635 --> 00:15:10,805
here is a closed form expression that will exactly compute the sum,

284
00:15:10,805 --> 00:15:12,275
and the reason um,

285
00:15:12,275 --> 00:15:15,095
why this is true or y there is inequality is this.

286
00:15:15,095 --> 00:15:16,775
We notice that this is simply uh,

287
00:15:16,775 --> 00:15:19,654
geometric series uh, for matrices,

288
00:15:19,654 --> 00:15:21,350
and for that there exists

289
00:15:21,350 --> 00:15:26,180
a closed form expression that all that it requires us is take the identity matrix

290
00:15:26,180 --> 00:15:29,510
minus Beta times adjacency matrix inverted that and

291
00:15:29,510 --> 00:15:33,020
then again then subtract the identity matrix again.

292
00:15:33,020 --> 00:15:37,895
And the entries of this matrix S will give us

293
00:15:37,895 --> 00:15:44,000
the Katz neighborhood overlap scores for any pair uh, of nodes.

294
00:15:44,000 --> 00:15:47,795
So to summarize, uh, link level features.

295
00:15:47,795 --> 00:15:50,450
Uh, we- we described three types of them.

296
00:15:50,450 --> 00:15:53,990
We talked about distance-based features that users, for example,

297
00:15:53,990 --> 00:15:58,535
shortest path between a pair of nodes and does not capture neighborhood overlaps.

298
00:15:58,535 --> 00:16:03,560
Then we talked about this neighborhood overlap metrics like common neighbors, Jaccard,

299
00:16:03,560 --> 00:16:08,225
and the Dmitry data that captures find- in a fine-grained wait,

300
00:16:08,225 --> 00:16:12,455
how many neighbors does a pair of nodes have in common?

301
00:16:12,455 --> 00:16:15,815
But the problem with this is that nodes that are more than two hops apart,

302
00:16:15,815 --> 00:16:17,855
nodes that have no neighbors in common,

303
00:16:17,855 --> 00:16:20,345
the metric will return value 0.

304
00:16:20,345 --> 00:16:23,360
So the global neighborhood overlap type metrics,

305
00:16:23,360 --> 00:16:25,775
for example, like Katz, uh,

306
00:16:25,775 --> 00:16:31,910
uses global graph structure to give us a score for a pair of nodes and Katz index counts

307
00:16:31,910 --> 00:16:35,000
the number of pets of all lands between a pair of

308
00:16:35,000 --> 00:16:38,600
nodes where these paths are discounted um,

309
00:16:38,600 --> 00:16:42,480
exponentially with their length.

