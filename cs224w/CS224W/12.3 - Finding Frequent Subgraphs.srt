1
00:00:00,000 --> 00:00:04,950


2
00:00:04,950 --> 00:00:08,790
So far, we have been
talking about the problem

3
00:00:08,790 --> 00:00:11,790
where we are given
a query graph and we

4
00:00:11,790 --> 00:00:14,250
want to predict
or identify a way

5
00:00:14,250 --> 00:00:18,900
that a given query graph is
a subgraph in a larger target

6
00:00:18,900 --> 00:00:20,220
graph.

7
00:00:20,220 --> 00:00:23,550
Now, we are going to generalize
this approach we just

8
00:00:23,550 --> 00:00:27,690
talked about to the problem
of finding frequent subgraphs.

9
00:00:27,690 --> 00:00:32,540
So let me tell you
what this problem is.

10
00:00:32,540 --> 00:00:36,030
What we would like to do is to
talk about frequent subgraph

11
00:00:36,030 --> 00:00:36,530
mining.

12
00:00:36,530 --> 00:00:39,860
So first, we discussed
in the previous lecture

13
00:00:39,860 --> 00:00:42,530
about subgraphs and motifs
and we defined them.

14
00:00:42,530 --> 00:00:47,030
And then we talked about the
problem of a neural subgraph

15
00:00:47,030 --> 00:00:50,360
representation and be
able to quickly say

16
00:00:50,360 --> 00:00:54,860
whether a given query graph is
a subgraph in a bigger target

17
00:00:54,860 --> 00:00:55,550
graph.

18
00:00:55,550 --> 00:00:57,590
Now, we are going to
further expand this

19
00:00:57,590 --> 00:01:00,260
to frequent subgraph mining.

20
00:01:00,260 --> 00:01:05,209
So here is the problem, the
idea is that given a large graph

21
00:01:05,209 --> 00:01:09,180
we would like to identify
what are the building blocks?

22
00:01:09,180 --> 00:01:11,840
What are the
frequently occurring

23
00:01:11,840 --> 00:01:17,030
subgraphs that are part of
this bigger target graph?

24
00:01:17,030 --> 00:01:19,850
And this is called the
frequent subgraph mining

25
00:01:19,850 --> 00:01:21,320
where basically we
want to identify

26
00:01:21,320 --> 00:01:25,160
these frequently occurring
building blocks of a big graph.

27
00:01:25,160 --> 00:01:29,030
And generally, using
combinatorial approaches

28
00:01:29,030 --> 00:01:33,110
the way you would approach this
problem is that, by the finding

29
00:01:33,110 --> 00:01:37,640
most frequent size-k
subgraphs requires

30
00:01:37,640 --> 00:01:39,350
solving two challenges.

31
00:01:39,350 --> 00:01:42,440
First is that, we want
to enumerate or consider

32
00:01:42,440 --> 00:01:45,950
all size-k connected
subgraphs, right, and then

33
00:01:45,950 --> 00:01:49,610
each of these connected
subgraphs of size-k acts

34
00:01:49,610 --> 00:01:55,340
like a query which we then want
to identify in the target graph

35
00:01:55,340 --> 00:01:57,120
to count its occurrence.

36
00:01:57,120 --> 00:01:59,060
So basically this
means that, in order

37
00:01:59,060 --> 00:02:03,050
to identify frequent subgraphs
of a given size we first

38
00:02:03,050 --> 00:02:06,290
have to identify what is
the universe of subgraphs

39
00:02:06,290 --> 00:02:07,430
of a given size.

40
00:02:07,430 --> 00:02:09,440
And then for each
of these subgraphs

41
00:02:09,440 --> 00:02:12,650
find its frequency in
the given target graph.

42
00:02:12,650 --> 00:02:16,140
So this is how traditional
approaches to this would work.

43
00:02:16,140 --> 00:02:18,320
So for example,
if I'm interested

44
00:02:18,320 --> 00:02:23,150
in connected subgraphs
undirected of size-3

45
00:02:23,150 --> 00:02:28,350
then there are two possible such
subgraphs that are shown here.

46
00:02:28,350 --> 00:02:32,180
I generated them so this is step
1, and then for each of them

47
00:02:32,180 --> 00:02:36,080
I would want to ask, what is the
frequency of them in the larger

48
00:02:36,080 --> 00:02:37,550
target graph?

49
00:02:37,550 --> 00:02:39,880
And here basically I
would need to count them.

50
00:02:39,880 --> 00:02:44,480
So for example, for this let's
say motif subgraphs of size-3

51
00:02:44,480 --> 00:02:47,900
here these different
green polygons

52
00:02:47,900 --> 00:02:50,220
show the instances
of this given motif,

53
00:02:50,220 --> 00:02:52,910
so its frequency equals to 3.

54
00:02:52,910 --> 00:02:56,630
So this is a hard
combinatorial problem

55
00:02:56,630 --> 00:03:00,410
because just knowing if
a certain subgraph exists

56
00:03:00,410 --> 00:03:03,820
in a given larger graph is a
hard computational problem,

57
00:03:03,820 --> 00:03:04,320
right?

58
00:03:04,320 --> 00:03:07,970
This is essentially a
subgraph isomorphism problem.

59
00:03:07,970 --> 00:03:11,240
The frequent subgraph
counting is even bigger,

60
00:03:11,240 --> 00:03:14,090
it's kind of even a harder
problem because first we

61
00:03:14,090 --> 00:03:17,600
want to know the frequency
of a given subgraph

62
00:03:17,600 --> 00:03:20,030
and then we want to
find the subgraphs that

63
00:03:20,030 --> 00:03:24,230
are the most frequent out of all
possible subgraphs of a given

64
00:03:24,230 --> 00:03:25,110
size.

65
00:03:25,110 --> 00:03:28,040
So because the number of
subgraphs of a given size

66
00:03:28,040 --> 00:03:30,120
increases
super-exponentially, you

67
00:03:30,120 --> 00:03:35,750
are basically battling two
exponential algorithms.

68
00:03:35,750 --> 00:03:38,270
First is the counting
and the second one

69
00:03:38,270 --> 00:03:41,820
is the number of possible
things you have to count, right?

70
00:03:41,820 --> 00:03:46,130
We saw how the number of motifs
or how the number of subgraphs

71
00:03:46,130 --> 00:03:50,090
increases super-exponentially
with their size.

72
00:03:50,090 --> 00:03:52,970
So traditional
combinatorial approaches

73
00:03:52,970 --> 00:03:57,320
can only handle subgraphs
between size, let's say 3,

74
00:03:57,320 --> 00:03:59,810
to 5, 6, maybe 7.

75
00:03:59,810 --> 00:04:02,630
Because the number of them
increases so drastically

76
00:04:02,630 --> 00:04:05,390
and then just counting
each one of them

77
00:04:05,390 --> 00:04:08,450
to determine their
frequency is computationally

78
00:04:08,450 --> 00:04:10,410
expensive as well.

79
00:04:10,410 --> 00:04:13,820
So what we are going to
do in this lecture is

80
00:04:13,820 --> 00:04:16,850
we are going to talk about
how can we use representation

81
00:04:16,850 --> 00:04:19,610
learning and graph
neural networks to solve

82
00:04:19,610 --> 00:04:22,670
this hard combinatorial problem?

83
00:04:22,670 --> 00:04:25,400
As I said finding
frequent subgraphs

84
00:04:25,400 --> 00:04:29,060
is computationally hard because
there are two problems that

85
00:04:29,060 --> 00:04:30,410
are both exponential.

86
00:04:30,410 --> 00:04:33,530
First is you get a
combinatorial explosion

87
00:04:33,530 --> 00:04:35,660
in the number of
possible patterns,

88
00:04:35,660 --> 00:04:38,150
possible subgraphs
of a given size.

89
00:04:38,150 --> 00:04:42,050
And then given one of
these possible subgraphs

90
00:04:42,050 --> 00:04:44,870
you have to count it, you
have to find its frequency

91
00:04:44,870 --> 00:04:47,700
in the big target graph
so that then you can say,

92
00:04:47,700 --> 00:04:50,143
here are the let's say
10 most frequent when

93
00:04:50,143 --> 00:04:52,310
you kind of sort them by
their decreasing frequency.

94
00:04:52,310 --> 00:04:56,120
So both of these by
themselves are hard.

95
00:04:56,120 --> 00:05:00,310
So we are going to
elegantly sidestep

96
00:05:00,310 --> 00:05:02,540
these hard
combinatorial problems

97
00:05:02,540 --> 00:05:05,240
by using representation
learning and show how

98
00:05:05,240 --> 00:05:07,130
we can tackle these challenges.

99
00:05:07,130 --> 00:05:11,780
The combinatorial explosion
will be of possible subgraphs

100
00:05:11,780 --> 00:05:16,640
will be attained by organizing
the search space cleverly.

101
00:05:16,640 --> 00:05:20,420
And then the problem of subgraph
isomorphism and subgraph

102
00:05:20,420 --> 00:05:24,280
counting will be tackled
by graph neural networks.

103
00:05:24,280 --> 00:05:27,140
So let me give you a bit
more details about how

104
00:05:27,140 --> 00:05:29,730
we are going to do this.

105
00:05:29,730 --> 00:05:34,370
So for counting, we are actually
using the graph neural network

106
00:05:34,370 --> 00:05:37,220
to predict a frequency
of a given subgraph.

107
00:05:37,220 --> 00:05:39,230
So basically what
we are going to do

108
00:05:39,230 --> 00:05:42,740
is we are going to take a big
target graph and embed it.

109
00:05:42,740 --> 00:05:46,040
And then when a small
query graph comes

110
00:05:46,040 --> 00:05:48,660
we are going to
predict its frequency.

111
00:05:48,660 --> 00:05:51,410
So that rather than
directly counting it

112
00:05:51,410 --> 00:05:53,550
we are just going to
predict its frequency.

113
00:05:53,550 --> 00:05:55,310
So that will be the
first innovation.

114
00:05:55,310 --> 00:05:57,530
And then the second
innovation, now,

115
00:05:57,530 --> 00:06:01,340
rather than predicting the
frequency of all size scale

116
00:06:01,340 --> 00:06:05,930
let's say k's 5, 10,
20, connected subgraphs

117
00:06:05,930 --> 00:06:08,810
because there is super
exponentially many of them,

118
00:06:08,810 --> 00:06:12,080
we are actually going to
develop a search procedure that

119
00:06:12,080 --> 00:06:15,860
will start with a
small subgraph and grow

120
00:06:15,860 --> 00:06:20,960
it node by node until it
reaches a desirable size,

121
00:06:20,960 --> 00:06:25,160
and this way we will also
try to grow it in such a way

122
00:06:25,160 --> 00:06:27,930
that its frequency
will be higher.

123
00:06:27,930 --> 00:06:29,540
The important point
here is because we

124
00:06:29,540 --> 00:06:31,760
are talking about
frequency subgraph mining,

125
00:06:31,760 --> 00:06:34,610
we are only interested in
the most frequent subgraphs

126
00:06:34,610 --> 00:06:36,710
and the most frequent
motifs and not

127
00:06:36,710 --> 00:06:39,060
the frequency of all the motifs.

128
00:06:39,060 --> 00:06:42,900
So that's why the search
procedure will be useful.

129
00:06:42,900 --> 00:06:46,140
So let's look into
this problem more,

130
00:06:46,140 --> 00:06:48,390
let's try to
understand it better.

131
00:06:48,390 --> 00:06:51,950
So the problem set up for
the frequent motif mining

132
00:06:51,950 --> 00:06:53,280
is the following.

133
00:06:53,280 --> 00:06:55,535
We are given a
large target graph

134
00:06:55,535 --> 00:07:01,010
G sub T and a subgraph
size parameter k,

135
00:07:01,010 --> 00:07:05,480
as well as the number
of desired results r.

136
00:07:05,480 --> 00:07:10,160
And the goal is to identify
among all possible graphs

137
00:07:10,160 --> 00:07:14,980
on k node out of them that have
the highest frequency in G sub

138
00:07:14,980 --> 00:07:15,780
T, right?

139
00:07:15,780 --> 00:07:22,730
So I want to find r most
frequent subgraphs on k nodes

140
00:07:22,730 --> 00:07:27,020
in a given target graph G sub T.

141
00:07:27,020 --> 00:07:29,930
And here for the
frequency definition

142
00:07:29,930 --> 00:07:33,590
we are going to use what we
call the node level frequency

143
00:07:33,590 --> 00:07:39,350
definition, where this is the
number of nodes u in target

144
00:07:39,350 --> 00:07:44,660
graph T, G sub T for which
some subgraph of G sub T

145
00:07:44,660 --> 00:07:49,400
is isomorphic to our query and
the isomorphism maps node u

146
00:07:49,400 --> 00:07:50,570
to node v.

147
00:07:50,570 --> 00:07:53,630
And perhaps the best way
to understand this is,

148
00:07:53,630 --> 00:07:56,970
imagine I have my
target graph, it's

149
00:07:56,970 --> 00:08:00,710
a kind of a star with
100 spokes and imagine

150
00:08:00,710 --> 00:08:05,460
I have a query graph that
is a star on 6 spokes.

151
00:08:05,460 --> 00:08:09,500
And imagine that I say this
is the anchor I care about,

152
00:08:09,500 --> 00:08:14,420
then the frequency of this
given query in the target graph

153
00:08:14,420 --> 00:08:17,720
will be exactly 1 because
the anchor is going

154
00:08:17,720 --> 00:08:20,780
to map to the center node
and that's the only way how

155
00:08:20,780 --> 00:08:25,160
to map this query graph
to the target graph

156
00:08:25,160 --> 00:08:28,293
while also mapping
the anchor node to one

157
00:08:28,293 --> 00:08:29,960
of the nodes in the
target graph, right?

158
00:08:29,960 --> 00:08:38,630
So rather here having G
sub Q frequency of 100 to 6

159
00:08:38,630 --> 00:08:40,820
it will have just frequency
of 1 because there

160
00:08:40,820 --> 00:08:46,340
is only one way to map this
anchor node to the underlying G

161
00:08:46,340 --> 00:08:48,500
sub T. So this
frequency definition

162
00:08:48,500 --> 00:08:52,310
is more robust to this
combinatorial explosion

163
00:08:52,310 --> 00:08:55,130
when like I try to
illustrate here.

164
00:08:55,130 --> 00:08:58,470
So that's the frequency
definition we care about.

165
00:08:58,470 --> 00:09:02,780
So now the method that
we talk about is SPMiner

166
00:09:02,780 --> 00:09:07,100
and it's a neural network model
to identify frequent motifs.

167
00:09:07,100 --> 00:09:09,990
And the way this is going
to work is the following.

168
00:09:09,990 --> 00:09:13,010
We are going to give
an input graph G sub T

169
00:09:13,010 --> 00:09:15,110
and we are going to
decompose it into

170
00:09:15,110 --> 00:09:17,540
node anchored neighborhoods.

171
00:09:17,540 --> 00:09:20,450
And then we are going to use a
graph neural network to embed

172
00:09:20,450 --> 00:09:22,440
each of these neighborhoods.

173
00:09:22,440 --> 00:09:28,860
And this is exactly what we have
been talking in lecture 12.2,

174
00:09:28,860 --> 00:09:31,250
right, where we talked
about how do you basically

175
00:09:31,250 --> 00:09:35,450
take the graph, decompose
it into node overlapping

176
00:09:35,450 --> 00:09:38,630
node anchored neighborhoods--
and then use the encoder,

177
00:09:38,630 --> 00:09:42,500
use the graph neural network to
basically embed every dot here

178
00:09:42,500 --> 00:09:45,020
as a different neighborhood
and you embed it

179
00:09:45,020 --> 00:09:48,290
in the embedding space.

180
00:09:48,290 --> 00:09:50,660
So this will be
the encoder part.

181
00:09:50,660 --> 00:09:52,580
What is new in this
part of the lecture

182
00:09:52,580 --> 00:09:54,320
is the last part
where we will have

183
00:09:54,320 --> 00:09:57,950
what we call a search procedure
to find frequent subgraphs

184
00:09:57,950 --> 00:10:00,860
by growing our motif.

185
00:10:00,860 --> 00:10:04,460
So we are going to start
with a trivial motif of two

186
00:10:04,460 --> 00:10:06,230
nodes and an edge
and then we are

187
00:10:06,230 --> 00:10:09,020
going to iteratively
grow it while trying

188
00:10:09,020 --> 00:10:11,210
to preserve its frequency.

189
00:10:11,210 --> 00:10:14,360
We are going to say, how
do I grow this motif so

190
00:10:14,360 --> 00:10:16,670
that its frequency remains high?

191
00:10:16,670 --> 00:10:20,180
And when I reach the
desired size of the motif,

192
00:10:20,180 --> 00:10:24,320
the size-k I'm going to stop
and say, here is the motif,

193
00:10:24,320 --> 00:10:26,750
this is its predicted frequency.

194
00:10:26,750 --> 00:10:29,330
So the point is that,
rather than trying out

195
00:10:29,330 --> 00:10:32,810
let's say all possible
graphs on 10 nodes,

196
00:10:32,810 --> 00:10:35,600
we are going to grow
a graph on 10 nodes

197
00:10:35,600 --> 00:10:40,040
iteratively while trying
to maximize its frequency.

198
00:10:40,040 --> 00:10:43,230
That is the idea,
this is the overview.

199
00:10:43,230 --> 00:10:48,370
So now let's dive deeper
into this lecture.

200
00:10:48,370 --> 00:10:52,830
So the key idea of SPMiner is
to decompose the input graft

201
00:10:52,830 --> 00:10:55,740
Gt into a lot of
small neighborhoods.

202
00:10:55,740 --> 00:10:59,820
And we are going to embed these
neighborhoods into an order

203
00:10:59,820 --> 00:11:01,440
embedding space.

204
00:11:01,440 --> 00:11:04,110
And the key benefit of
order embedding space

205
00:11:04,110 --> 00:11:06,570
will be that we'll be
able to quickly predict

206
00:11:06,570 --> 00:11:10,920
the frequency of a
given subgraph G sub Q.

207
00:11:10,920 --> 00:11:13,380
So essentially rather
than taking G sub Q

208
00:11:13,380 --> 00:11:17,477
and trying to match it in many
different places in the G sub

209
00:11:17,477 --> 00:11:20,850
T, we are just going
to encode G sub Q

210
00:11:20,850 --> 00:11:23,910
and then predict its
frequency in the G sub T.

211
00:11:23,910 --> 00:11:25,890
That's the kind of
the idea is that we

212
00:11:25,890 --> 00:11:29,580
have a very fast
frequency predictor that

213
00:11:29,580 --> 00:11:31,600
will use graph neural networks.

214
00:11:31,600 --> 00:11:34,770
So here is how we are
going to do this frequency

215
00:11:34,770 --> 00:11:35,910
prediction, right?

216
00:11:35,910 --> 00:11:40,380
So the idea is that we take
a set of subgraphs, these

217
00:11:40,380 --> 00:11:43,830
are our node anchored
neighborhoods G sub

218
00:11:43,830 --> 00:11:48,800
N of big target graph G sub T.

219
00:11:48,800 --> 00:11:51,230
And the idea will be that
we are going to estimate now

220
00:11:51,230 --> 00:11:55,380
the frequency of our given
subgraph of a given target

221
00:11:55,380 --> 00:12:00,020
graph G sub Q by counting
the number of neighborhoods

222
00:12:00,020 --> 00:12:04,190
such that their embedding
satisfies the order embedding

223
00:12:04,190 --> 00:12:05,300
property.

224
00:12:05,300 --> 00:12:09,800
So basically we are going to
say, for a given graph G sub Q

225
00:12:09,800 --> 00:12:12,710
we are going to embed it into
some point in the embedding

226
00:12:12,710 --> 00:12:17,572
space, and we are going to ask
how many neighborhoods of G sub

227
00:12:17,572 --> 00:12:21,680
T are to the upper
right of it, right?

228
00:12:21,680 --> 00:12:23,450
Basically with
this notation I try

229
00:12:23,450 --> 00:12:27,830
to say how many
neighborhoods N sub

230
00:12:27,830 --> 00:12:31,100
I are there whose
individual coordinates are

231
00:12:31,100 --> 00:12:37,400
all greater than the embedding
coordinates of my query graph

232
00:12:37,400 --> 00:12:38,490
Q.

233
00:12:38,490 --> 00:12:40,280
And this is exactly
a consequence

234
00:12:40,280 --> 00:12:43,040
of order embedding
space property

235
00:12:43,040 --> 00:12:44,690
that we have discussed, right?

236
00:12:44,690 --> 00:12:50,390
So intuitively when my G sub Q
arrives, I'm going to embed it

237
00:12:50,390 --> 00:12:53,720
and I'm going to say
its frequency is simply

238
00:12:53,720 --> 00:12:56,090
the number of node
anchored neighborhoods

239
00:12:56,090 --> 00:12:59,990
that are embedded into the
top right of it, right?

240
00:12:59,990 --> 00:13:05,540
So number of node anchor
neighborhoods whose embedding

241
00:13:05,540 --> 00:13:09,320
coordinates are greater
than the embedding

242
00:13:09,320 --> 00:13:12,920
coordinates of my query point.

243
00:13:12,920 --> 00:13:16,280
So basically there is this
what we call a super graph

244
00:13:16,280 --> 00:13:20,030
region, where basically all the
points, all the neighborhoods

245
00:13:20,030 --> 00:13:23,120
in the red shaded region
corresponds to neighborhoods

246
00:13:23,120 --> 00:13:27,980
in G sub T that contain G
sub Q as a subgraph, right?

247
00:13:27,980 --> 00:13:31,970
So basically this will be
now our frequency estimation

248
00:13:31,970 --> 00:13:33,560
and the benefit
will be that now we

249
00:13:33,560 --> 00:13:38,090
have a super fast subgraph
counting frequency estimation

250
00:13:38,090 --> 00:13:42,770
method because when a new
motif arrives we just embed

251
00:13:42,770 --> 00:13:45,110
it and then determine
how many points

252
00:13:45,110 --> 00:13:50,220
fall to the top right of it and
this can be done super fast.

253
00:13:50,220 --> 00:13:54,650
So now that we know how
to estimate the frequency,

254
00:13:54,650 --> 00:13:57,260
now let's talk about
the search procedure

255
00:13:57,260 --> 00:14:00,290
that is actually going
to find the motif.

256
00:14:00,290 --> 00:14:04,800
So the way we are going to
do this is the following.

257
00:14:04,800 --> 00:14:09,170
We are going to randomly pick
a starting node u in the target

258
00:14:09,170 --> 00:14:13,400
graph G sub T and then we
are going to basically expand

259
00:14:13,400 --> 00:14:17,030
the neighborhood around this
target node u in the G sub T

260
00:14:17,030 --> 00:14:19,688
to get the query
graph, and we are

261
00:14:19,688 --> 00:14:21,230
going to use the
graph neural network

262
00:14:21,230 --> 00:14:22,760
to estimate its frequency.

263
00:14:22,760 --> 00:14:26,030
And we are going to
grow it in G sub T

264
00:14:26,030 --> 00:14:29,800
while trying to keep the
frequency as high as possible.

265
00:14:29,800 --> 00:14:31,550
And the way you can
think of this as that,

266
00:14:31,550 --> 00:14:34,010
we are going to start
with an individual node u

267
00:14:34,010 --> 00:14:38,000
and its embedding will
be somewhere all the way

268
00:14:38,000 --> 00:14:41,570
to the lower level because an
individual node is a subgraph

269
00:14:41,570 --> 00:14:44,540
of all neighborhoods, right?

270
00:14:44,540 --> 00:14:47,180
Because the neighborhoods
are composed of nodes

271
00:14:47,180 --> 00:14:50,075
so this individual node is a
subgraph in all neighborhoods,

272
00:14:50,075 --> 00:14:50,990
right?

273
00:14:50,990 --> 00:14:54,800
So here the point is
that each dot here

274
00:14:54,800 --> 00:14:57,890
represents a neighborhood
in the target graph

275
00:14:57,890 --> 00:15:01,250
that contains the
motif pattern, right?

276
00:15:01,250 --> 00:15:04,050
And whatever is in the
red shaded three regions.

277
00:15:04,050 --> 00:15:07,520
These are the neighborhoods
that contain that motif.

278
00:15:07,520 --> 00:15:10,310
And of course, initially
all neighborhoods

279
00:15:10,310 --> 00:15:15,450
contain the motif because
the motif is a single node.

280
00:15:15,450 --> 00:15:20,480
So now that we have a
partially built motif S

281
00:15:20,480 --> 00:15:22,880
we want to grow it
until it reaches

282
00:15:22,880 --> 00:15:27,530
size-k such that its
frequency of this size-k motif

283
00:15:27,530 --> 00:15:29,640
will be as large as possible.

284
00:15:29,640 --> 00:15:31,550
So the way we are
going to do this is we

285
00:15:31,550 --> 00:15:36,050
are going to do it through
an iterative procedure that

286
00:15:36,050 --> 00:15:38,810
is going to grow the motif
iteratively meaning node

287
00:15:38,810 --> 00:15:43,160
by node and edge by edge,
by basically traversing

288
00:15:43,160 --> 00:15:46,400
the neighborhood of this
chosen node u in G sub T

289
00:15:46,400 --> 00:15:50,030
and adding neighbors
of that node.

290
00:15:50,030 --> 00:15:53,690
The neighbors of neighbors
to S and at the same time

291
00:15:53,690 --> 00:15:56,720
we are going to use the order
embedding space to now take

292
00:15:56,720 --> 00:16:02,810
S, embed it, and ask what is
the frequency of that bigger

293
00:16:02,810 --> 00:16:03,660
subgraph, right?

294
00:16:03,660 --> 00:16:05,150
So the way you
can think of it is

295
00:16:05,150 --> 00:16:08,460
we are going to start
with the individual node

296
00:16:08,460 --> 00:16:11,690
and we are going now to say,
an individual node and that's

297
00:16:11,690 --> 00:16:15,650
our S, and then we are going
to add one neighbor of it to S,

298
00:16:15,650 --> 00:16:17,180
so now S will be bigger.

299
00:16:17,180 --> 00:16:21,260
And for every possible way
to add this new node or this

300
00:16:21,260 --> 00:16:26,870
to the S we are going to ask,
what is the best node to add

301
00:16:26,870 --> 00:16:31,070
to the S so that the frequency
remains as high as possible?

302
00:16:31,070 --> 00:16:34,400
And we can use this kind of
gritty search procedure that

303
00:16:34,400 --> 00:16:38,540
is going to grow our motif
node by node until it

304
00:16:38,540 --> 00:16:41,720
reaches the desirable size.

305
00:16:41,720 --> 00:16:44,000
And now of course,
what we need to decide

306
00:16:44,000 --> 00:16:49,090
is how do we decide what
node to include next, right?

307
00:16:49,090 --> 00:16:56,350
How precisely do we grow this
underlying motif, node by node?

308
00:16:56,350 --> 00:16:58,180
And the way we are
going to do this

309
00:16:58,180 --> 00:17:00,460
is that, we are going
to grow it with the goal

310
00:17:00,460 --> 00:17:03,610
to maximize the number
of neighborhoods

311
00:17:03,610 --> 00:17:07,390
that are in the red shaded
region after the k steps,

312
00:17:07,390 --> 00:17:08,060
right?

313
00:17:08,060 --> 00:17:10,750
So basically in the end,
we want to reach out

314
00:17:10,750 --> 00:17:16,750
some point which that
describes a graph of a given

315
00:17:16,750 --> 00:17:19,540
size-k such that the
number of neighborhoods

316
00:17:19,540 --> 00:17:21,368
that are to the top
right of it, meaning

317
00:17:21,368 --> 00:17:24,818
that are in these red-shaded
regions is as high as possible.

318
00:17:24,819 --> 00:17:26,618
Because whatever are
the neighborhoods

319
00:17:26,618 --> 00:17:28,900
to the top right of it,
these are the neighborhoods

320
00:17:28,900 --> 00:17:31,930
that our red dot
is a subgraph of,

321
00:17:31,930 --> 00:17:35,710
that's the order
embedding property that we

322
00:17:35,710 --> 00:17:40,780
have worked so hard to establish
in the previous lecture.

323
00:17:40,780 --> 00:17:42,970
So that's the idea.

324
00:17:42,970 --> 00:17:46,630
So right then we'll be growing
this motif node by node

325
00:17:46,630 --> 00:17:49,690
until it reaches the
desired motif size,

326
00:17:49,690 --> 00:17:51,550
until it reaches size-k.

327
00:17:51,550 --> 00:17:54,610
And then we are
going to terminate,

328
00:17:54,610 --> 00:17:58,510
and what we are
going to return, we

329
00:17:58,510 --> 00:18:02,080
are going to return whatever is
the motif we terminated and we

330
00:18:02,080 --> 00:18:04,690
are going to return its
predicted frequency, which

331
00:18:04,690 --> 00:18:09,260
is the number of neighborhoods
in this red shaded region.

332
00:18:09,260 --> 00:18:11,500
The reason why we are--

333
00:18:11,500 --> 00:18:14,650
just kind of
noticed that, we are

334
00:18:14,650 --> 00:18:17,320
only interested in
the subgraph's motifs

335
00:18:17,320 --> 00:18:18,670
that have high frequency.

336
00:18:18,670 --> 00:18:22,570
So as we are building it we
are kind of greedily deciding

337
00:18:22,570 --> 00:18:28,450
how to grow that motif so that
its frequency will remain high.

338
00:18:28,450 --> 00:18:32,080
So to now answer the most
important question, which

339
00:18:32,080 --> 00:18:36,760
is how do I decide which
node to pick and add

340
00:18:36,760 --> 00:18:41,992
to my current subgraph motif S?

341
00:18:41,992 --> 00:18:43,450
And the way we are
going to do this

342
00:18:43,450 --> 00:18:46,990
is, we are going to define
the notion of total violation

343
00:18:46,990 --> 00:18:49,840
of a subgraph, let's
call it G which

344
00:18:49,840 --> 00:18:51,820
is the number of
neighborhoods that

345
00:18:51,820 --> 00:18:56,050
do not contain this subgraph G.

346
00:18:56,050 --> 00:18:58,630
So this is the number
of neighborhoods

347
00:18:58,630 --> 00:19:04,120
that do not satisfy my
order embedding property.

348
00:19:04,120 --> 00:19:06,790
Which basically it would be the
number of neighborhoods where

349
00:19:06,790 --> 00:19:09,460
at least one of the
coordinates in the embedding

350
00:19:09,460 --> 00:19:13,360
space of the neighborhood
is less than the embedding

351
00:19:13,360 --> 00:19:19,180
coordinate of my graph G.
So this is the same thing,

352
00:19:19,180 --> 00:19:21,290
this G is this cubed.

353
00:19:21,290 --> 00:19:23,890
And this means that basically
minimizing the total violation,

354
00:19:23,890 --> 00:19:26,500
means maximizing the frequency.

355
00:19:26,500 --> 00:19:29,800
And you can then use many
different search heuristics

356
00:19:29,800 --> 00:19:33,320
but one possible such
heuristic is greedy, right?

357
00:19:33,320 --> 00:19:35,080
Basically, at
every step you want

358
00:19:35,080 --> 00:19:40,120
to add a node to the subgraph
S that results in the smallest

359
00:19:40,120 --> 00:19:41,000
total violation.

360
00:19:41,000 --> 00:19:43,240
Basically, you want
to add a node that

361
00:19:43,240 --> 00:19:46,810
will keep the number
of neighborhoods

362
00:19:46,810 --> 00:19:50,170
to the top right
of that subgraph S

363
00:19:50,170 --> 00:19:51,725
to be as high as possible.

364
00:19:51,725 --> 00:19:54,100
And you can think of this,
right, we start with one node,

365
00:19:54,100 --> 00:19:56,230
we add the second node,
we add the third one,

366
00:19:56,230 --> 00:19:59,920
we add the fourth one, and
you are kind of dancing,

367
00:19:59,920 --> 00:20:02,830
as you are building the motif
you are kind of moving up.

368
00:20:02,830 --> 00:20:08,560
And the goal is to reach a
motif of a given size that

369
00:20:08,560 --> 00:20:11,230
has the largest number
of neighborhoods

370
00:20:11,230 --> 00:20:14,020
in the red shaded region,
so in the region that

371
00:20:14,020 --> 00:20:16,360
is up and above from it.

372
00:20:16,360 --> 00:20:20,260
And that's essentially the idea.

373
00:20:20,260 --> 00:20:23,260
I can show you some
experimental results

374
00:20:23,260 --> 00:20:27,640
to show that this really
works quite remarkably well.

375
00:20:27,640 --> 00:20:30,790
Where for example, we can
say let the ground truth

376
00:20:30,790 --> 00:20:35,710
be the most frequent top
10 most frequent motifs

377
00:20:35,710 --> 00:20:38,050
in a given target graph.

378
00:20:38,050 --> 00:20:42,550
And we are going to do these
four motifs of size 5 and 6

379
00:20:42,550 --> 00:20:44,710
because this is what
kind of this brute force

380
00:20:44,710 --> 00:20:48,785
exact enumeration counting is
able to do in a couple of days,

381
00:20:48,785 --> 00:20:50,260
right?

382
00:20:50,260 --> 00:20:56,020
So then we can ask is, what
are the frequency of the top 10

383
00:20:56,020 --> 00:20:58,210
most frequent motifs
that this search

384
00:20:58,210 --> 00:20:59,840
procedure is able to identify?

385
00:20:59,840 --> 00:21:05,920
Where basically we pick a random
node u in the target graph G,

386
00:21:05,920 --> 00:21:09,520
we kind of grow the motif
around it and at the same time

387
00:21:09,520 --> 00:21:11,260
as we are of growing
that motif we

388
00:21:11,260 --> 00:21:15,190
ask what its frequency as
predicted with the order

389
00:21:15,190 --> 00:21:16,870
embedding space?

390
00:21:16,870 --> 00:21:19,240
And then this graph
tries to illustrate this,

391
00:21:19,240 --> 00:21:22,630
these are the top 10
most frequent motifs

392
00:21:22,630 --> 00:21:27,460
just rank ordered, and the
y-axis is their frequency.

393
00:21:27,460 --> 00:21:29,980
And exact is the
ground truth, right,

394
00:21:29,980 --> 00:21:32,770
so this would be the frequency
of the most frequent motif,

395
00:21:32,770 --> 00:21:35,980
the second most frequent, third
most frequent, fourth, fifth,

396
00:21:35,980 --> 00:21:37,860
all the way down to tenth.

397
00:21:37,860 --> 00:21:41,350
Now, what we also
did in our case,

398
00:21:41,350 --> 00:21:44,890
is we use this neural
network order embedding

399
00:21:44,890 --> 00:21:50,600
space based method to identify
top 10 most frequent motifs

400
00:21:50,600 --> 00:21:52,910
that it finds.

401
00:21:52,910 --> 00:21:56,950
And let's compare
their frequency

402
00:21:56,950 --> 00:21:59,320
to what the exact
counting finds.

403
00:21:59,320 --> 00:22:06,070
And of course, the frequencies
drop as the rank of the motif

404
00:22:06,070 --> 00:22:07,840
gets higher, that's okay.

405
00:22:07,840 --> 00:22:11,470
But you notice, for example
that SPMiner is basically able

406
00:22:11,470 --> 00:22:16,330
to identify the top in this
case, top eight motifs perfect

407
00:22:16,330 --> 00:22:17,560
out of the top ten.

408
00:22:17,560 --> 00:22:20,590
And then the other two
are their frequency

409
00:22:20,590 --> 00:22:24,878
are just a bit lower so these
two were not exactly identified

410
00:22:24,878 --> 00:22:26,170
so their frequencies are lower.

411
00:22:26,170 --> 00:22:30,760
Here is top eight are
perfectly identified here,

412
00:22:30,760 --> 00:22:32,650
for size 6 it's
actually top nine that

413
00:22:32,650 --> 00:22:34,090
are perfectly identified.

414
00:22:34,090 --> 00:22:39,250
And these are some traditional
approximate searching methods.

415
00:22:39,250 --> 00:22:42,440
You see that they fail
much, much, much worse.

416
00:22:42,440 --> 00:22:47,800
And perhaps, if
the mfinder method

417
00:22:47,800 --> 00:22:52,390
finds the top 10th,
the motif at rank 10,

418
00:22:52,390 --> 00:23:00,490
its frequency is only 5,
raised to the times 1,000.

419
00:23:00,490 --> 00:23:04,150
Our SPMiner is able to
find the tenth motif that

420
00:23:04,150 --> 00:23:07,030
has the frequency of around
let's say, 15,000, right?

421
00:23:07,030 --> 00:23:09,260
So much, much more accurate.

422
00:23:09,260 --> 00:23:11,770
So this is for small
motifs, you can also

423
00:23:11,770 --> 00:23:14,530
do this for very large motifs
because the search procedure

424
00:23:14,530 --> 00:23:15,680
is very cheap.

425
00:23:15,680 --> 00:23:22,750
So you can identify large motifs
for example, motifs of size 14,

426
00:23:22,750 --> 00:23:27,920
17, 20, that still have
very high frequencies.

427
00:23:27,920 --> 00:23:31,390
And you can do this in two
different real world networks

428
00:23:31,390 --> 00:23:36,250
and really find large
motifs with high frequencies

429
00:23:36,250 --> 00:23:39,610
computationally
very, very cheaply.

430
00:23:39,610 --> 00:23:41,920
And the motifs you find
tend to be much, much

431
00:23:41,920 --> 00:23:45,160
more frequent than what
kind of random search

432
00:23:45,160 --> 00:23:48,370
traditional kind of
heuristic-based baselines

433
00:23:48,370 --> 00:23:49,970
can do.

434
00:23:49,970 --> 00:23:53,810
So to summarize this
lecture, here we

435
00:23:53,810 --> 00:23:57,260
talked about
subgraphs and motifs

436
00:23:57,260 --> 00:24:00,710
that are important concepts
that provide insights

437
00:24:00,710 --> 00:24:03,650
into the structure of
large graphs, right?

438
00:24:03,650 --> 00:24:06,770
And the frequency of
these subgraphs or motifs

439
00:24:06,770 --> 00:24:11,150
can be used as features
of nodes or graphs.

440
00:24:11,150 --> 00:24:12,890
And they can kind
of also tell us

441
00:24:12,890 --> 00:24:15,950
what is the organization of
networks, what are the building

442
00:24:15,950 --> 00:24:19,140
blocks of a given graph?

443
00:24:19,140 --> 00:24:24,080
And I talked to you about how
it is computationally hard

444
00:24:24,080 --> 00:24:27,590
combinatorially to
identify frequently

445
00:24:27,590 --> 00:24:31,580
occurring subgraphs of a given
size in a big target graph.

446
00:24:31,580 --> 00:24:34,700
And we covered neural
approaches for prediction

447
00:24:34,700 --> 00:24:38,060
of subgraph isomorphism
relationship.

448
00:24:38,060 --> 00:24:41,900
We developed this notion
of an order embedding space

449
00:24:41,900 --> 00:24:45,980
that has a desirable property
and allows us to quickly say

450
00:24:45,980 --> 00:24:49,370
whether a given graph is a
subgraph of a bigger graph,

451
00:24:49,370 --> 00:24:52,700
or it allows us to
quickly say, what

452
00:24:52,700 --> 00:24:56,820
is the frequency of a given
subgraph in a bigger target

453
00:24:56,820 --> 00:24:57,320
graph.

454
00:24:57,320 --> 00:25:02,950
So that prediction happens
super quickly and is accurate.

455
00:25:02,950 --> 00:25:05,290
And then the last
thing we did was

456
00:25:05,290 --> 00:25:09,490
we talked about this neural
embedding guided search that

457
00:25:09,490 --> 00:25:12,100
starts with a small
motif, iteratively

458
00:25:12,100 --> 00:25:15,490
grows it n node by
node such that it

459
00:25:15,490 --> 00:25:19,750
allows us to identify
a large motif that

460
00:25:19,750 --> 00:25:22,150
also has a high frequency.

461
00:25:22,150 --> 00:25:26,650
And we saw that these methods
are extremely practical,

462
00:25:26,650 --> 00:25:30,430
they are extremely fast
and lead to high accuracy

463
00:25:30,430 --> 00:25:35,530
of identified motifs and
identified subgraphs.

464
00:25:35,530 --> 00:25:39,160
So with this we have
finished the treatment

465
00:25:39,160 --> 00:25:43,360
of subgraph identification,
subgraph counting,

466
00:25:43,360 --> 00:25:46,630
and frequent subgraph mining.

467
00:25:46,630 --> 00:25:48,720
Thank you very much.

468
00:25:48,720 --> 00:25:53,000


