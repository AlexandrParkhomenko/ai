1
00:00:04,160 --> 00:00:07,380
So now that we have defined the notion of

2
00:00:07,380 --> 00:00:10,900
a network motif and a notion of a subnet network subgraph,

3
00:00:10,900 --> 00:00:15,780
and I'm really kind of using these two terms interchangeably, now we need to- um,

4
00:00:15,780 --> 00:00:18,210
and then we also defined what is a frequency of

5
00:00:18,210 --> 00:00:22,055
a given motif or a frequency of a given subgraph in a given graph.

6
00:00:22,055 --> 00:00:26,010
Now, we wanna basically develop

7
00:00:26,010 --> 00:00:31,040
a neural network approach that will allow us to quickly determine whether a given,

8
00:00:31,040 --> 00:00:34,230
uh, graph is a subgraph in a bigger graph.

9
00:00:34,230 --> 00:00:36,945
Um, so to give you- um, the next,

10
00:00:36,945 --> 00:00:41,490
we are going to talk about neural subgraph, uh, representations.

11
00:00:41,490 --> 00:00:43,415
So, what's the problem?

12
00:00:43,415 --> 00:00:45,845
The problem is called subgraph matching.

13
00:00:45,845 --> 00:00:47,930
I'm given a large target graph,

14
00:00:47,930 --> 00:00:50,800
and I'm given a small, uh, query graph.

15
00:00:50,800 --> 00:00:56,180
And what I have to decide whether a query is a subgraph into- in the target graph.

16
00:00:56,180 --> 00:00:57,395
Right? So for example,

17
00:00:57,395 --> 00:01:00,020
here's my query, here's my target graph.

18
00:01:00,020 --> 00:01:03,860
In this case, the answer should be yes because this particular set of

19
00:01:03,860 --> 00:01:07,850
four nodes can map to this particular set of four nodes,

20
00:01:07,850 --> 00:01:09,395
and edges are preserved.

21
00:01:09,395 --> 00:01:12,230
Here, I use different colors to deter- to denote,

22
00:01:12,230 --> 00:01:14,820
you know, that this node can map to that node.

23
00:01:14,820 --> 00:01:18,470
You know, this node maps to this node and so on and so forth.

24
00:01:18,470 --> 00:01:22,450
So query Q, is included in the target, uh, graph.

25
00:01:22,450 --> 00:01:23,925
Um, so that's the, uh,

26
00:01:23,925 --> 00:01:25,410
that's the first- uh,

27
00:01:25,410 --> 00:01:26,835
that's the problem you want to do.

28
00:01:26,835 --> 00:01:28,815
We just wanna say yes, no.

29
00:01:28,815 --> 00:01:31,395
Right? It's not about the co- the number yet.

30
00:01:31,395 --> 00:01:35,025
You just wanna say is query in- included?

31
00:01:35,025 --> 00:01:37,665
Is it a subgraph of the target graph?

32
00:01:37,665 --> 00:01:40,395
Um, how are we going to do this?

33
00:01:40,395 --> 00:01:42,860
Rather than doing this as a kind of

34
00:01:42,860 --> 00:01:46,685
combinatorial matching and trying to check edge by edge if,

35
00:01:46,685 --> 00:01:49,435
uh, query is in- included in the target,

36
00:01:49,435 --> 00:01:52,110
we're going to develop a machine learning approach to it.

37
00:01:52,110 --> 00:01:55,450
So basically we're going to formulate this as a prediction task.

38
00:01:55,450 --> 00:01:58,680
And our intuition will be that we're going to exploit

39
00:01:58,680 --> 00:02:05,290
the sh- geometric shape of the embedding space to capture the subgraph relationship.

40
00:02:05,290 --> 00:02:08,520
Let me, uh, now kind of, uh,

41
00:02:08,520 --> 00:02:12,285
er, unpack what do I mean, er, by that.

42
00:02:12,285 --> 00:02:17,405
So the task is that I wanna do a binary prediction to return

43
00:02:17,405 --> 00:02:22,235
true if query is isomorphic to a subgraph of the target graph,

44
00:02:22,235 --> 00:02:24,505
and otherwise I return false.

45
00:02:24,505 --> 00:02:26,090
So again, in this case,

46
00:02:26,090 --> 00:02:27,995
I give you the query, the target,

47
00:02:27,995 --> 00:02:29,420
and the dashed, uh,

48
00:02:29,420 --> 00:02:33,640
edges repres- lines, represent the node correspondences.

49
00:02:33,640 --> 00:02:35,720
So in this case, just note,

50
00:02:35,720 --> 00:02:38,300
we won't be interested in actually finding

51
00:02:38,300 --> 00:02:42,050
correspondences because that's another challenging problem.

52
00:02:42,050 --> 00:02:44,690
What- uh, and we're not going to talk about it.

53
00:02:44,690 --> 00:02:46,970
All we want is just true, false.

54
00:02:46,970 --> 00:02:48,830
Right? Given query, given target,

55
00:02:48,830 --> 00:02:54,240
return true if query appears as a subgraph of the target, otherwise, return false.

56
00:02:54,240 --> 00:02:58,705
We're just interested in the decision problem in the binary task.

57
00:02:58,705 --> 00:03:02,990
So how are we going to approach this is, er, the following.

58
00:03:02,990 --> 00:03:05,180
This is kind of the high level overview of the approach.

59
00:03:05,180 --> 00:03:07,835
We'll take a big input graph, the target graph,

60
00:03:07,835 --> 00:03:11,040
and we're going to decompose it in a set of- uh,

61
00:03:11,040 --> 00:03:12,739
in- in a set of neighborhoods.

62
00:03:12,739 --> 00:03:13,790
And these neighborhoods will be,

63
00:03:13,790 --> 00:03:15,565
let's say, relatively small.

64
00:03:15,565 --> 00:03:19,025
Um, so we are going to decompose it into a set of neighborhoods.

65
00:03:19,025 --> 00:03:24,035
And then we are going to use a graph neural network to embed, uh, each neighborhood.

66
00:03:24,035 --> 00:03:25,220
We are going to basically apply

67
00:03:25,220 --> 00:03:28,430
graph embedding to create an embedding for each neighborhood.

68
00:03:28,430 --> 00:03:30,315
Then at the query time,

69
00:03:30,315 --> 00:03:34,805
we'll also take the query and we are going to embed the query.

70
00:03:34,805 --> 00:03:38,840
And then what we are going to do is we're going to build a predictor that will say,

71
00:03:38,840 --> 00:03:42,155
given the embedding of the query and embedding of a neighborhood,

72
00:03:42,155 --> 00:03:45,090
you know, predi- predict yes or no.

73
00:03:45,090 --> 00:03:46,890
Yes would mean a given,

74
00:03:46,890 --> 00:03:48,150
um- a given, uh,

75
00:03:48,150 --> 00:03:51,545
um, er, a given query is included,

76
00:03:51,545 --> 00:03:53,180
is a subgraph, um,

77
00:03:53,180 --> 00:03:55,130
of a given, uh, uh, er,

78
00:03:55,130 --> 00:03:57,680
neighborhood versus, uh, uh,

79
00:03:57,680 --> 00:04:00,760
that given query not being a subgraph of a given neighborhood.

80
00:04:00,760 --> 00:04:03,590
So for example, for this query and this neighborhood,

81
00:04:03,590 --> 00:04:05,220
we should predict, uh, no.

82
00:04:05,220 --> 00:04:08,550
For this neighborhood in the query we predict yes.

83
00:04:08,550 --> 00:04:11,235
Here, we also predict yes because it's an, uh,

84
00:04:11,235 --> 00:04:12,445
triangle and an edge,

85
00:04:12,445 --> 00:04:14,100
a triangle and an edge and, you know,

86
00:04:14,100 --> 00:04:15,660
our query is a triangle and an edge, right?

87
00:04:15,660 --> 00:04:17,550
So basically, based on the embeddings,

88
00:04:17,550 --> 00:04:19,050
we wanna make these predictions.

89
00:04:19,050 --> 00:04:21,860
And this can be super fast because as I'm giving a query,

90
00:04:21,860 --> 00:04:25,370
I just kind of run through these neighborhoods and make predictions.

91
00:04:25,370 --> 00:04:26,770
Yes, no, yes, no, yes, no.

92
00:04:26,770 --> 00:04:29,040
That's essentially the idea.

93
00:04:29,040 --> 00:04:31,290
How are we going to do this?

94
00:04:31,290 --> 00:04:32,540
Let's give a bit more detail.

95
00:04:32,540 --> 00:04:36,245
We're going to work with node-anchored definitions, right?

96
00:04:36,245 --> 00:04:40,250
Meaning we are going to have a notion of an anchor and we are trying to

97
00:04:40,250 --> 00:04:44,710
predict whether a given node anch- node anchored query,

98
00:04:44,710 --> 00:04:47,150
um, is a subgraph of a, again,

99
00:04:47,150 --> 00:04:49,790
a given anchor into the target, uh, graph.

100
00:04:49,790 --> 00:04:52,205
So we are working with, uh, anchored, uh,

101
00:04:52,205 --> 00:04:54,810
definitions where we- what means- what

102
00:04:54,810 --> 00:04:57,610
has to do is one anchor has to map to another anchor,

103
00:04:57,610 --> 00:05:00,390
and then all the edges and all the other nodes,

104
00:05:00,390 --> 00:05:02,055
uh, have to map as well.

105
00:05:02,055 --> 00:05:03,455
So that's the first important point,

106
00:05:03,455 --> 00:05:05,650
is we have a notion of the anchor.

107
00:05:05,650 --> 00:05:09,220
Um, the second, um, impor- important, uh,

108
00:05:09,220 --> 00:05:15,555
notion is that we are going to decompose the target graph into a set of neighborhoods.

109
00:05:15,555 --> 00:05:18,065
So in these neighborhoods will be node-anchored.

110
00:05:18,065 --> 00:05:20,290
And what does this mean is essentially we'll pick

111
00:05:20,290 --> 00:05:23,490
a node and then we'll take a k-hop neighborhood around it.

112
00:05:23,490 --> 00:05:25,545
But let's say one hop, two hop.

113
00:05:25,545 --> 00:05:30,165
Um, and then this will create a neighborhood and we are going to embed this neighborhood.

114
00:05:30,165 --> 00:05:34,960
So we'll take the target graph and we are going to create many neighborhoods,

115
00:05:34,960 --> 00:05:36,620
uh, and embed them.

116
00:05:36,620 --> 00:05:38,405
And then for a given query,

117
00:05:38,405 --> 00:05:40,130
the task will be given the query, uh,

118
00:05:40,130 --> 00:05:45,520
in that neighborhood, predict whether query is a subgraph of the neighborhood.

119
00:05:45,520 --> 00:05:48,975
So the entire approach is the following.

120
00:05:48,975 --> 00:05:51,440
As I said, we create a query,

121
00:05:51,440 --> 00:05:53,270
pick an anchored node, um,

122
00:05:53,270 --> 00:05:55,205
uh, and, uh, embed it.

123
00:05:55,205 --> 00:05:56,780
We take the target graph,

124
00:05:56,780 --> 00:05:58,610
decompose it into many, uh,

125
00:05:58,610 --> 00:06:02,100
neighborhoods and embed those neighborhoods.

126
00:06:02,100 --> 00:06:05,810
And now given the embedding of the query and embedding of the neighborhood,

127
00:06:05,810 --> 00:06:08,785
we wanna predict return true or false.

128
00:06:08,785 --> 00:06:12,045
True if, uh, this query, uh,

129
00:06:12,045 --> 00:06:15,695
is a, uh, node-anchored subgraph of the neighborhood,

130
00:06:15,695 --> 00:06:18,535
and return false if, um,

131
00:06:18,535 --> 00:06:25,005
these node-anchored query is not a subgraph of the node-anchored, uh, neighborhood.

132
00:06:25,005 --> 00:06:27,225
So that's, uh, how,

133
00:06:27,225 --> 00:06:29,115
uh, we are going to do this.

134
00:06:29,115 --> 00:06:31,550
Um, so now, of course, the question is,

135
00:06:31,550 --> 00:06:33,920
how do we use embeddings to make predictions?

136
00:06:33,920 --> 00:06:36,810
Right? In terms of the, uh, uh,

137
00:06:36,810 --> 00:06:39,125
creating the embedding of the neighborhood,

138
00:06:39,125 --> 00:06:42,020
we believe- we can use our standard graph neural networks.

139
00:06:42,020 --> 00:06:43,730
So kind of not too much,

140
00:06:43,730 --> 00:06:46,350
um, uh, uh, importance there.

141
00:06:46,350 --> 00:06:48,180
I'm kind of going to skip that detail.

142
00:06:48,180 --> 00:06:51,065
There are some interesting kind of architectural details,

143
00:06:51,065 --> 00:06:54,800
but just a standard graph neural network for embedding graphs,

144
00:06:54,800 --> 00:06:56,650
uh, would already be good.

145
00:06:56,650 --> 00:07:00,355
So now we need to decide and kind of r- I

146
00:07:00,355 --> 00:07:03,830
wanna talk a bit about why do we pick anchored neighborhoods?

147
00:07:03,830 --> 00:07:06,190
Why not non-anchored?

148
00:07:06,190 --> 00:07:09,890
Um, you know, recall that the node level frequency definition says,

149
00:07:09,890 --> 00:07:11,390
you know, the number of, uh,

150
00:07:11,390 --> 00:07:15,485
nodes u in G_T for which some subgraph of G_T is

151
00:07:15,485 --> 00:07:21,690
isomorphic to the query and the- and the isomorphism maps node u,

152
00:07:21,690 --> 00:07:24,720
uh, in G_T to node v in the queue.

153
00:07:24,720 --> 00:07:29,105
Right? So basically the anchors have to map plus all the edges,

154
00:07:29,105 --> 00:07:31,945
uh, and the remaining nodes can also map.

155
00:07:31,945 --> 00:07:34,460
Um, the point is that we are going to, uh,

156
00:07:34,460 --> 00:07:36,500
create this anchor, the embeddings,

157
00:07:36,500 --> 00:07:39,665
because we can then create basically a graph neural network,

158
00:07:39,665 --> 00:07:43,055
um, for- um, around each node, uh,

159
00:07:43,055 --> 00:07:47,780
u and each node v. And this way basically create embeddings of the neighborhoods.

160
00:07:47,780 --> 00:07:49,030
So that's the reason why.

161
00:07:49,030 --> 00:07:53,240
So we will use these embeddings to decide if neighborhood of u is

162
00:07:53,240 --> 00:07:58,110
isomorphic to subgraph of neighborhood of v. And, um,

163
00:07:58,110 --> 00:08:00,740
we not only predict if there exists a mapping,

164
00:08:00,740 --> 00:08:02,405
but we can also, um,

165
00:08:02,405 --> 00:08:04,970
in some cases be able to corres- to identify

166
00:08:04,970 --> 00:08:08,060
corresponding nodes because we know that u corresponds,

167
00:08:08,060 --> 00:08:13,895
uh, to v. So we'll also find the correspondence of, uh, anchors.

168
00:08:13,895 --> 00:08:18,775
So how are we going to decompose G_T into neighborhoods?

169
00:08:18,775 --> 00:08:22,360
Basically, for every node in the target graph,

170
00:08:22,360 --> 00:08:25,810
we are going to obtain a k-hop neighborhood around the anchor.

171
00:08:25,810 --> 00:08:30,175
We can simply pre- do this with- using breadth-first search.

172
00:08:30,175 --> 00:08:32,380
Usually, you know, our parameter,

173
00:08:32,380 --> 00:08:33,865
k, will be around,

174
00:08:33,865 --> 00:08:35,440
you know, maybe three, maybe four.

175
00:08:35,440 --> 00:08:37,090
So basically, we go three hops out,

176
00:08:37,090 --> 00:08:38,620
we go four hops out.

177
00:08:38,620 --> 00:08:41,049
And we can- and this way, we can, um,

178
00:08:41,049 --> 00:08:46,090
decompose G_T, the target graphing to a lot of different neighborhoods.

179
00:08:46,090 --> 00:08:49,345
And now, as we have created the neighborhood,

180
00:08:49,345 --> 00:08:55,045
we simply apply our graph neural network embedding of the- of the anchor node,

181
00:08:55,045 --> 00:08:59,455
um, v, to map that anchor node into the embedding space.

182
00:08:59,455 --> 00:09:03,475
And then we can also do the same procedure,

183
00:09:03,475 --> 00:09:07,045
uh, to the query to obtain neighborhoods in the query graph.

184
00:09:07,045 --> 00:09:10,705
Um, and then we are going to embed these neighborhoods, as I said,

185
00:09:10,705 --> 00:09:15,520
using a GNN by computing simply the node embedding for every anchor,

186
00:09:15,520 --> 00:09:19,570
um, in its corresponding neighborhood.

187
00:09:19,570 --> 00:09:23,890
Now, what is the- the cool part and actually,

188
00:09:23,890 --> 00:09:27,460
the most important part of this lecture is this notion of

189
00:09:27,460 --> 00:09:29,665
an order embedding space.

190
00:09:29,665 --> 00:09:32,695
So, you know, what we talked so far was kind of

191
00:09:32,695 --> 00:09:35,890
clear and you have perhaps- perhaps heard about it,

192
00:09:35,890 --> 00:09:38,185
but you haven't heard about this topic.

193
00:09:38,185 --> 00:09:39,565
This is now super cool.

194
00:09:39,565 --> 00:09:42,190
So order embedding space.

195
00:09:42,190 --> 00:09:44,380
Let me explain what we mean by this, right?

196
00:09:44,380 --> 00:09:46,660
So, um, we map graph,

197
00:09:46,660 --> 00:09:50,320
let's say A to point Z_A in a high-dimensional space,

198
00:09:50,320 --> 00:09:52,570
let's say 64-dimensional embedding.

199
00:09:52,570 --> 00:09:56,860
Um, and we are going to assume that the embedding space is non-negative,

200
00:09:56,860 --> 00:10:00,880
so all coordinates are either 0or, uh, positive.

201
00:10:00,880 --> 00:10:04,720
And then what we would like to do is we'd like to capture

202
00:10:04,720 --> 00:10:09,340
partial ordering transitivity in the embedding space, right?

203
00:10:09,340 --> 00:10:13,510
Then we are going to use this notation to say that,

204
00:10:13,510 --> 00:10:18,430
you know, the- the left node is- is- is less than,

205
00:10:18,430 --> 00:10:20,230
equal than the right node, um,

206
00:10:20,230 --> 00:10:23,260
if all coordinates of the blue node- of

207
00:10:23,260 --> 00:10:28,070
the left node are less or equal to the- all the coordinates of the right node.

208
00:10:28,070 --> 00:10:31,665
So for example, in our- in this- in this case,

209
00:10:31,665 --> 00:10:34,890
what this means is we have this transitive, uh, relation.

210
00:10:34,890 --> 00:10:38,145
Because intuitively, when I say all the coordinates to be less,

211
00:10:38,145 --> 00:10:39,630
it really means, um,

212
00:10:39,630 --> 00:10:44,500
a given point has to be to the low- lower left of some other point, right?

213
00:10:44,500 --> 00:10:47,995
So if- if this point is lower left

214
00:10:47,995 --> 00:10:51,975
of that point and that same point is lower left of another point,

215
00:10:51,975 --> 00:10:54,600
then also the first point is to the lower left,

216
00:10:54,600 --> 00:10:56,880
uh, of the, uh, third point, right?

217
00:10:56,880 --> 00:10:59,170
So here, you know, um,

218
00:10:59,170 --> 00:11:01,540
this particular point is to the le- lower left,

219
00:11:01,540 --> 00:11:04,360
uh, of, uh, that particular point, right?

220
00:11:04,360 --> 00:11:06,685
So basically, what we want is we wanna, uh,

221
00:11:06,685 --> 00:11:11,860
have these relationships of being to the lower- to the lower left,

222
00:11:11,860 --> 00:11:16,150
which means in any- any part of the- of the space, right?

223
00:11:16,150 --> 00:11:19,000
Basically, all the coordinates have to be less or equal,

224
00:11:19,000 --> 00:11:23,230
which means you have to be embedded to the lower left of something else.

225
00:11:23,230 --> 00:11:26,410
So- and this is called order embedding because

226
00:11:26,410 --> 00:11:29,365
this partial ordering, this transitivity, uh,

227
00:11:29,365 --> 00:11:31,645
is captured by this relation,

228
00:11:31,645 --> 00:11:35,500
are you embedded lower left of something else.

229
00:11:35,500 --> 00:11:38,755
So, you know, why- why- why should you care, right?

230
00:11:38,755 --> 00:11:42,925
Why is lower left so cool and so important?

231
00:11:42,925 --> 00:11:45,040
The point is that, uh,

232
00:11:45,040 --> 00:11:50,995
lower left is so important is because it captures subgraph, uh, relations, right?

233
00:11:50,995 --> 00:11:52,885
Imagine, uh, for example,

234
00:11:52,885 --> 00:11:54,985
uh, the case here is that I have, uh,

235
00:11:54,985 --> 00:11:57,235
the target graph, I have the neighborhood,

236
00:11:57,235 --> 00:12:00,580
and I have different- different queries, right?

237
00:12:00,580 --> 00:12:03,025
Then in my case, imagine that this is, uh,

238
00:12:03,025 --> 00:12:04,765
the node anchored, uh,

239
00:12:04,765 --> 00:12:07,090
neighborhood that I embedded here.

240
00:12:07,090 --> 00:12:09,280
And I have two- two anchored queries,

241
00:12:09,280 --> 00:12:10,735
Query 1 and Query 2.

242
00:12:10,735 --> 00:12:13,660
And now, because basically the point is the following,

243
00:12:13,660 --> 00:12:17,200
because Query 1 is a subgraph of the neighborhood,

244
00:12:17,200 --> 00:12:22,750
Query 1 should be embedded to the lower left of the neighborhood,

245
00:12:22,750 --> 00:12:25,735
while Query 2 is not a subgraph,

246
00:12:25,735 --> 00:12:28,930
so it should not be embedded to the lower left, right?

247
00:12:28,930 --> 00:12:32,785
So here, this notion of a subgraph relationship is preserved

248
00:12:32,785 --> 00:12:38,050
because the Query 1 is embedded to the lower left of, uh, Query 2.

249
00:12:38,050 --> 00:12:42,190
And simply by comparing the positions of the embeddings of this,

250
00:12:42,190 --> 00:12:46,180
uh, anchor nodes, we can determine that, you know, uh,

251
00:12:46,180 --> 00:12:48,145
Query 1 is a subgraph of, uh,

252
00:12:48,145 --> 00:12:50,170
anchor node t, while, uh,

253
00:12:50,170 --> 00:12:53,125
Query 2 is not a subgraph of anchor node,

254
00:12:53,125 --> 00:12:56,505
uh, uh, t. So that's the cool part.

255
00:12:56,505 --> 00:13:01,230
We can very quickly read from the embedding whether one is a subgraph of the other.

256
00:13:01,230 --> 00:13:03,740
Um, you know, why does this work?

257
00:13:03,740 --> 00:13:05,695
Why do we care about this, uh,

258
00:13:05,695 --> 00:13:08,050
transitive, uh, partial ordering,

259
00:13:08,050 --> 00:13:12,700
uh, in the embedding space is because subgraph isomorphism relationship,

260
00:13:12,700 --> 00:13:15,190
um, can nicely be encoded in

261
00:13:15,190 --> 00:13:19,705
this order embedding space where the order is defined by this relation,

262
00:13:19,705 --> 00:13:21,925
are you lower left of somebody else.

263
00:13:21,925 --> 00:13:25,780
And the reason is because the- the order- order relations,

264
00:13:25,780 --> 00:13:27,880
so the lower left, uh,

265
00:13:27,880 --> 00:13:32,860
relation is transitive and subgraph isomorphism is also transitive.

266
00:13:32,860 --> 00:13:35,440
It has this property of anti-symmetry,

267
00:13:35,440 --> 00:13:37,360
which is also, um,

268
00:13:37,360 --> 00:13:39,235
encoded in the order embedding,

269
00:13:39,235 --> 00:13:43,510
is that if G_1 is a subgraph of G_2 and G_2 is a subgraph of G_1,

270
00:13:43,510 --> 00:13:46,195
then G_1 and G_2 are- are isomorphic.

271
00:13:46,195 --> 00:13:48,940
They are the same. So if one point is to the lower left

272
00:13:48,940 --> 00:13:51,925
of one and the other one is of the lower left of the first one,

273
00:13:51,925 --> 00:13:54,010
then the points are on the same location,

274
00:13:54,010 --> 00:13:55,825
so the two graphs are isomorphic.

275
00:13:55,825 --> 00:13:58,540
Transitive would mean if G_1 is a subgraph of G_2,

276
00:13:58,540 --> 00:13:59,860
G_2 is of G_3,

277
00:13:59,860 --> 00:14:03,490
then G_1 is a subgraph of G_3 as well, which again is,

278
00:14:03,490 --> 00:14:05,455
uh, encoded by the, uh,

279
00:14:05,455 --> 00:14:07,630
you know, the subgraph, uh, relation.

280
00:14:07,630 --> 00:14:11,680
And the last one is this notion of closure under intersection that,

281
00:14:11,680 --> 00:14:15,295
uh, the trivial graph of one node is a subgraph of any node.

282
00:14:15,295 --> 00:14:18,895
In our case, it would be the embedding at the coordinate origin,

283
00:14:18,895 --> 00:14:22,795
at 0, 0, 0, is a subgraph of every other embedding.

284
00:14:22,795 --> 00:14:26,740
It is to the lower left of any other- of any other embedding.

285
00:14:26,740 --> 00:14:31,870
So basically, this order embedding space defined by this relation is one point to

286
00:14:31,870 --> 00:14:33,520
the lower left of the other has

287
00:14:33,520 --> 00:14:37,750
all these properties that the subgraph relation, uh, also has.

288
00:14:37,750 --> 00:14:42,400
So, um, the reason now that- why we are interested in it,

289
00:14:42,400 --> 00:14:44,320
as I- as I said and here I show,

290
00:14:44,320 --> 00:14:46,270
uh, more- more formally, is that,

291
00:14:46,270 --> 00:14:50,230
you know, the order embedding space captures transitivity, right?

292
00:14:50,230 --> 00:14:51,580
In a sense that if, uh,

293
00:14:51,580 --> 00:14:55,060
first point is the subgraph of the second and the second is of the third,

294
00:14:55,060 --> 00:14:57,655
then first is also a subgraph of the third.

295
00:14:57,655 --> 00:15:00,280
We have this notion of anti-symmetry, uh,

296
00:15:00,280 --> 00:15:03,040
that if one is to the le- lower left of the other,

297
00:15:03,040 --> 00:15:04,870
and the other is to the lower left of the first,

298
00:15:04,870 --> 00:15:07,480
then they are- they are equivalent, they basically overlap.

299
00:15:07,480 --> 00:15:10,270
Um, and then the last one is this, uh, closure, uh,

300
00:15:10,270 --> 00:15:13,360
under intersection, uh, illustrated here,

301
00:15:13,360 --> 00:15:14,470
uh, on the- on the right.

302
00:15:14,470 --> 00:15:19,765
So basically, order embedding space defined by this lower left relation,

303
00:15:19,765 --> 00:15:22,870
captures the same type of patterns,

304
00:15:22,870 --> 00:15:26,260
properties that the subgraph, uh, relation has.

305
00:15:26,260 --> 00:15:31,495
And that's the important part and the cool part of the order embedding space.

306
00:15:31,495 --> 00:15:37,450
So now we are going to actually learn the embeddings of these,

307
00:15:37,450 --> 00:15:43,240
uh, anchored neighborhoods such that the subgraph relation is preserved, right?

308
00:15:43,240 --> 00:15:47,470
So we are going to use a GNN to learn the embeddings of neighborhoods,

309
00:15:47,470 --> 00:15:49,810
basically to learn the embedding of the anchor node,

310
00:15:49,810 --> 00:15:52,420
to preserve this order embedding structure,

311
00:15:52,420 --> 00:15:54,700
to preserve the subgraph structure.

312
00:15:54,700 --> 00:15:56,110
So the question is,

313
00:15:56,110 --> 00:15:59,770
what kind of loss function should we use so that the learned,

314
00:15:59,770 --> 00:16:03,760
uh, embedding operator reflects the subgraph relationship?

315
00:16:03,760 --> 00:16:09,415
Um, and we are going to design a loss function based on what we call order constraint.

316
00:16:09,415 --> 00:16:13,870
An order constraint specifies the ideal order of the embedding,

317
00:16:13,870 --> 00:16:17,319
um, lower left property that reflects

318
00:16:17,319 --> 00:16:19,780
a subgraph, uh, relation.

319
00:16:19,780 --> 00:16:23,140
So this specify this, what we call,

320
00:16:23,140 --> 00:16:25,150
order constraint to ensure that

321
00:16:25,150 --> 00:16:28,990
subgraph properties are preserved in the embedding space, right?

322
00:16:28,990 --> 00:16:30,955
So basically, what this means, uh,

323
00:16:30,955 --> 00:16:33,085
here is- it's written in mathematics,

324
00:16:33,085 --> 00:16:37,195
but basically it says that if a query is a subgraph of the target,

325
00:16:37,195 --> 00:16:42,250
then every coordin- every embedding coordinate of the query should be less than the,

326
00:16:42,250 --> 00:16:46,240
uh, embedding, uh- every coor- embedding coordinate of the target.

327
00:16:46,240 --> 00:16:49,360
Right. So if Q is a subgraph of T,

328
00:16:49,360 --> 00:16:52,315
then the embedding of the anchor node, uh,

329
00:16:52,315 --> 00:16:55,705
in T should be to the, um, to the,

330
00:16:55,705 --> 00:16:59,800
uh, greater and equal than the embedding of the, uh, query q.

331
00:16:59,800 --> 00:17:02,170
So the relationship is- is this, right?

332
00:17:02,170 --> 00:17:03,940
This is the query, that's the target,

333
00:17:03,940 --> 00:17:06,005
so the anchor node, uh,

334
00:17:06,005 --> 00:17:08,050
from the query should be embedded to

335
00:17:08,050 --> 00:17:11,380
the lower left of the anchor node of the target because,

336
00:17:11,380 --> 00:17:13,435
uh, que- this is, uh,

337
00:17:13,435 --> 00:17:16,045
anchored subgraph, uh, of the target.

338
00:17:16,045 --> 00:17:19,000
So that's basically what we mean by order constraint,

339
00:17:19,000 --> 00:17:21,790
is that you have to be to the lower left.

340
00:17:21,790 --> 00:17:27,444
Now, um, GNN embeddings are learned using,

341
00:17:27,444 --> 00:17:30,820
uh- by minimizing what is called a max-margin loss.

342
00:17:30,820 --> 00:17:33,280
So basically what we are going to do is to define

343
00:17:33,280 --> 00:17:36,250
this notion of a loss where we are saying,

344
00:17:36,250 --> 00:17:39,130
okay: so how much, um, is this,

345
00:17:39,130 --> 00:17:42,160
uh, constraint, um, violated?

346
00:17:42,160 --> 00:17:45,970
So basically here we say this is the maximum of zero and the,

347
00:17:45,970 --> 00:17:48,820
uh, and the difference in the coordinates, right?

348
00:17:48,820 --> 00:17:53,890
So if coordinate Z_t is always larger than the coordinate of q,

349
00:17:53,890 --> 00:17:55,660
then this difference will be negative,

350
00:17:55,660 --> 00:17:58,240
so maximum of negative in 0 is 0,

351
00:17:58,240 --> 00:18:01,000
so the violation will be 0.

352
00:18:01,000 --> 00:18:05,200
But if the subgraph relation is not preserved,

353
00:18:05,200 --> 00:18:10,585
which means that along the given coordinate q is to the right or to the top of Z,

354
00:18:10,585 --> 00:18:13,405
this means Z_q is greater than Z_t,

355
00:18:13,405 --> 00:18:16,330
then this difference will be positive and then maximum

356
00:18:16,330 --> 00:18:19,405
of 0 and a positive number will be a positive number,

357
00:18:19,405 --> 00:18:21,430
so this E is the margin.

358
00:18:21,430 --> 00:18:22,900
It will be basically, um,

359
00:18:22,900 --> 00:18:25,120
the amount of violation of

360
00:18:25,120 --> 00:18:29,860
the order constraint between a given query and a given, uh, target, right?

361
00:18:29,860 --> 00:18:31,990
So here there is no violation,

362
00:18:31,990 --> 00:18:35,935
while in this case there is violation because q is a subgraph of t,

363
00:18:35,935 --> 00:18:38,650
but q is not embedded to the lower left, uh,

364
00:18:38,650 --> 00:18:40,900
of t. So, um, eh,

365
00:18:40,900 --> 00:18:44,065
according- al- along the first dimension,

366
00:18:44,065 --> 00:18:45,730
this difference will be positive,

367
00:18:45,730 --> 00:18:47,290
so the entire maximum,

368
00:18:47,290 --> 00:18:49,600
uh, will be positive, uh, as well.

369
00:18:49,600 --> 00:18:51,250
So this is now how we've arrived,

370
00:18:51,250 --> 00:18:53,665
and what is important here is that now, um,

371
00:18:53,665 --> 00:18:56,740
this, uh, loss, this, uh, penalty, uh,

372
00:18:56,740 --> 00:18:59,700
E is differentiable, so we'll be able to, uh,

373
00:18:59,700 --> 00:19:05,030
back-propagate this penalty into the graph neural network, uh, architecture.

374
00:19:05,030 --> 00:19:07,540
So the embeddings are learned by,

375
00:19:07,540 --> 00:19:10,240
uh, minimizing this max-margin loss,

376
00:19:10,240 --> 00:19:14,680
so we have this E that determines the- the amount of, uh,

377
00:19:14,680 --> 00:19:17,890
order constraint violation between a given graph, uh,

378
00:19:17,890 --> 00:19:20,470
and a target, and we call this,

379
00:19:20,470 --> 00:19:23,035
uh, penalty, this violation the margin.

380
00:19:23,035 --> 00:19:28,150
So we wanna learn the correct order embeddings so- so that, uh,

381
00:19:28,150 --> 00:19:32,695
the- the penalty is 0 when G_q is a subgraph of, uh,

382
00:19:32,695 --> 00:19:39,175
G_t, and the penalty is greater than 0 when G_q is not a subgraph of G_t, right?

383
00:19:39,175 --> 00:19:42,310
So we want penalty of 0 when, uh,

384
00:19:42,310 --> 00:19:43,450
one is a subgraph,

385
00:19:43,450 --> 00:19:45,445
so it has to be embedded to the lower left,

386
00:19:45,445 --> 00:19:47,695
and then the penalty will be zero,

387
00:19:47,695 --> 00:19:49,615
and if it's another subgraph,

388
00:19:49,615 --> 00:19:52,720
then we want this penalty to be high because G_q

389
00:19:52,720 --> 00:19:57,260
should not be embedded to the lower left of, uh, G_t, right?

390
00:19:57,510 --> 00:19:59,950
So to learn this,

391
00:19:59,950 --> 00:20:01,435
um, uh- this, uh,

392
00:20:01,435 --> 00:20:05,065
embedding function, we need to construct training examples, right?

393
00:20:05,065 --> 00:20:07,480
Of G_q and G_t, where, uh,

394
00:20:07,480 --> 00:20:10,255
you know half of the time G_q will be a subgraph,

395
00:20:10,255 --> 00:20:13,060
and the other time- half of the time it won't be.

396
00:20:13,060 --> 00:20:18,115
Um, and then right when we are going to do the training of the embedding neural network,

397
00:20:18,115 --> 00:20:19,810
we are going to, uh,

398
00:20:19,810 --> 00:20:23,410
make it such that for positive examples we wanna minimize the penalty,

399
00:20:23,410 --> 00:20:25,390
and for negative examples we wanna,

400
00:20:25,390 --> 00:20:26,950
uh, maximize the penalty.

401
00:20:26,950 --> 00:20:30,370
So here is how- how you can write this all out, uh,

402
00:20:30,370 --> 00:20:32,230
by another kind of, um, uh,

403
00:20:32,230 --> 00:20:34,465
huge- huge loss, uh,

404
00:20:34,465 --> 00:20:36,625
type expression where we again say,

405
00:20:36,625 --> 00:20:39,100
um, if, uh- if,

406
00:20:39,100 --> 00:20:41,155
uh- if it will be, uh, um,

407
00:20:41,155 --> 00:20:43,855
for positive examples, I want this to be zero.

408
00:20:43,855 --> 00:20:45,730
So, um, you know,

409
00:20:45,730 --> 00:20:48,910
I'll- I'll get some Alpha and for negative, uh,

410
00:20:48,910 --> 00:20:51,970
examples, uh, uh, I- this will be greater than 0,

411
00:20:51,970 --> 00:20:53,155
so this- I'll- this,

412
00:20:53,155 --> 00:20:55,000
uh- this expression will be smaller.

413
00:20:55,000 --> 00:20:57,370
So I'll wanna be able to uh,

414
00:20:57,370 --> 00:20:59,875
uh, minimize this, uh, maximum.

415
00:20:59,875 --> 00:21:03,625
So, um, now how do I generate training examples?

416
00:21:03,625 --> 00:21:05,740
Is by simply picking an anchor node,

417
00:21:05,740 --> 00:21:07,840
and then doing a breadth first, kind of,

418
00:21:07,840 --> 00:21:10,225
a probabilistic breadth-first search around it,

419
00:21:10,225 --> 00:21:13,240
and this means that I'll have the- I'll generate

420
00:21:13,240 --> 00:21:17,245
the query that will be a subgraph of a given- of a given neighborhood.

421
00:21:17,245 --> 00:21:20,215
And then to generate a negative example,

422
00:21:20,215 --> 00:21:22,465
I can, you know, corrupt the query by,

423
00:21:22,465 --> 00:21:24,610
you know, perhaps removing a node,

424
00:21:24,610 --> 00:21:26,560
ending an edge, removing an edge,

425
00:21:26,560 --> 00:21:27,880
uh, things like that, right?

426
00:21:27,880 --> 00:21:32,050
So, uh- so that it is no longer, uh, a subgraph.

427
00:21:32,050 --> 00:21:35,830
So, you know, how many of these training examples do I

428
00:21:35,830 --> 00:21:39,685
choose so that I can then train my embedding neural network?

429
00:21:39,685 --> 00:21:41,740
The idea is, as I train this, I wanna,

430
00:21:41,740 --> 00:21:44,920
uh, at every iteration sample new training pairs.

431
00:21:44,920 --> 00:21:47,890
Uh, the benefit is that at every iteration the model,

432
00:21:47,890 --> 00:21:49,825
uh, will see, uh, different,

433
00:21:49,825 --> 00:21:53,080
uh, subgraph examples, and it will improve performance,

434
00:21:53,080 --> 00:21:55,120
and it will avoid, uh, overfitting.

435
00:21:55,120 --> 00:21:57,130
How deep do I wanna make

436
00:21:57,130 --> 00:22:01,435
my Breath-First Search training example sampling a neighborhood sampling?

437
00:22:01,435 --> 00:22:04,720
Um, it's, kind of, a trade-off between the runtime and performance.

438
00:22:04,720 --> 00:22:06,595
The deeper- the deeper I go,

439
00:22:06,595 --> 00:22:08,680
the longer the runtime, but usually,

440
00:22:08,680 --> 00:22:11,125
uh, the more, the better embeddings I get.

441
00:22:11,125 --> 00:22:14,275
So usually we would use the- the depth between, uh,

442
00:22:14,275 --> 00:22:16,840
3 and 5, also depending a bit,

443
00:22:16,840 --> 00:22:18,955
uh, on the data set.

444
00:22:18,955 --> 00:22:21,295
So, um, you know,

445
00:22:21,295 --> 00:22:25,015
how do I now apply this when a new query arrives?

446
00:22:25,015 --> 00:22:26,530
When a new query arrives,

447
00:22:26,530 --> 00:22:28,975
I- I- the query has an anchor.

448
00:22:28,975 --> 00:22:31,420
I simply embed the- the anchor,

449
00:22:31,420 --> 00:22:33,175
um, and then, uh,

450
00:22:33,175 --> 00:22:35,620
the procedure is that basically for every other,

451
00:22:35,620 --> 00:22:37,495
uh, target, um, anchor at the

452
00:22:37,495 --> 00:22:39,850
neighborhood of the target graph, I,

453
00:22:39,850 --> 00:22:43,030
um- I compare the embedding of the,

454
00:22:43,030 --> 00:22:45,490
um, anchor neighborhood with my,

455
00:22:45,490 --> 00:22:47,620
uh, anchored query embedding.

456
00:22:47,620 --> 00:22:53,395
And if the- if the query is embedded to the lower left of that, um, neighborhood,

457
00:22:53,395 --> 00:22:55,165
then I say that, uh,

458
00:22:55,165 --> 00:22:57,400
query is a subgraph of the neighborhood,

459
00:22:57,400 --> 00:22:59,305
and otherwise I would say, uh,

460
00:22:59,305 --> 00:23:01,450
that it's, uh, not a subgraph, right?

461
00:23:01,450 --> 00:23:05,350
So basically, um, I can quickly check this by simply asking,

462
00:23:05,350 --> 00:23:07,510
is one embedding to the lower left,

463
00:23:07,510 --> 00:23:10,300
uh, of the other embedding?

464
00:23:10,300 --> 00:23:13,975
So let me summarize, uh, this part.

465
00:23:13,975 --> 00:23:18,760
So um, we talked about neural subgraph matching, which is, uh,

466
00:23:18,760 --> 00:23:22,915
a way to formulate subgraph matching as a machine learning problem, uh,

467
00:23:22,915 --> 00:23:27,655
and this way sidestep the NP-hard problem of sub- subgraph isomorphism.

468
00:23:27,655 --> 00:23:30,940
Uh, basically given a query and given a ta- target graph,

469
00:23:30,940 --> 00:23:32,440
we embed the query,

470
00:23:32,440 --> 00:23:35,620
we embed the node anchored neighborhoods of the target graph,

471
00:23:35,620 --> 00:23:41,335
and we train our neural network embedding function such that, um,

472
00:23:41,335 --> 00:23:44,305
it embeds subgraphs in,

473
00:23:44,305 --> 00:23:48,670
uh- to be in such a way that they are located to the lower left of each other, right?

474
00:23:48,670 --> 00:23:50,935
If q is a subgraph of t,

475
00:23:50,935 --> 00:23:53,980
then q is embedded to the lower left, uh,

476
00:23:53,980 --> 00:23:58,990
of t. So this is- and at the training time of this embedding neural network,

477
00:23:58,990 --> 00:24:02,574
we force it to obey this subgraph relation,

478
00:24:02,574 --> 00:24:06,130
and this means we can then very easily and quickly find

479
00:24:06,130 --> 00:24:09,595
out whether a query is a subgraph of a given, uh,

480
00:24:09,595 --> 00:24:15,280
target neighborhood t. So basically embedding graphs with this order embedding

481
00:24:15,280 --> 00:24:21,220
property or order embedding space allows us to test subgraph isomorphism very,

482
00:24:21,220 --> 00:24:24,310
very quickly by simply just comparing the coordinates.

483
00:24:24,310 --> 00:24:27,520
Basically saying, is the query embedded to the lower left,

484
00:24:27,520 --> 00:24:29,095
uh, of the target?

485
00:24:29,095 --> 00:24:33,760
And given the properties of the subgraph isomorphism,

486
00:24:33,760 --> 00:24:36,145
uh, operator or re- relation,

487
00:24:36,145 --> 00:24:40,525
we see that we can perfectly encode it into the order embedding space,

488
00:24:40,525 --> 00:24:43,480
which means that actually all this is possible, um,

489
00:24:43,480 --> 00:24:45,340
and we can, uh- we can do it,

490
00:24:45,340 --> 00:24:48,860
and it, uh, works well in practice.

