1
00:00:20,800 --> 00:00:24,760
Traditionally, dot products or something that's
introduced really early on in a linear algebra

2
00:00:24,769 --> 00:00:25,769
course

3
00:00:25,769 --> 00:00:26,800
typically right at the start.

4
00:00:26,800 --> 00:00:29,849
So it might seem strange that I push them
back this far in the series.

5
00:00:29,849 --> 00:00:33,250
I did this because there's a standard way
to introduce the topic which

6
00:00:33,250 --> 00:00:36,320
requires nothing more than a basic understanding
of vectors,

7
00:00:36,320 --> 00:00:39,580
but a fuller understanding of the role the
dot products play in math,

8
00:00:39,580 --> 00:00:43,650
can only really be found under the light of
linear transformations.

9
00:00:43,650 --> 00:00:45,140
Before that, though, let me just briefly cover

10
00:00:45,140 --> 00:00:47,800
the standard way that products are introduced.

11
00:00:47,800 --> 00:00:51,280
Which I'm assuming is at least partially review
for a number of viewers.

12
00:00:51,280 --> 00:00:54,980
Numerically, if you have two vectors of the
same dimension;

13
00:00:54,980 --> 00:00:57,540
to list of numbers with the same length,

14
00:00:57,540 --> 00:00:59,540
taking their dot product, means,

15
00:00:59,540 --> 00:01:02,290
pairing up all of the coordinates,

16
00:01:02,290 --> 00:01:04,000
multiplying those pairs together,

17
00:01:04,000 --> 00:01:06,870
and adding the result.

18
00:01:06,870 --> 00:01:10,320
So the vector [1, 2] dotted with [3, 4],

19
00:01:10,320 --> 00:01:14,700
would be 1 x 3 + 2 x 4.

20
00:01:14,700 --> 00:01:19,810
The vector [6, 2, 8, 3] dotted with [1, 8,
5, 3] would be:

21
00:01:19,810 --> 00:01:25,570
6 x 1 + 2 x 8 + 8 x 5 + 3 x 3.

22
00:01:25,570 --> 00:01:29,359
Luckily, this computation has a really nice
geometric interpretation.

23
00:01:29,359 --> 00:01:32,990
To think about the dot product between two
vectors v and w,

24
00:01:32,990 --> 00:01:38,689
imagine projecting w onto the line that passes
through the origin and the tip of v.

25
00:01:38,689 --> 00:01:43,520
Multiplying the length of this projection
by the length of v, you have the dot product

26
00:01:43,520 --> 00:01:46,619
v・w.

27
00:01:46,619 --> 00:01:50,450
Except when this projection of w is pointing
in the opposite direction from v,

28
00:01:50,450 --> 00:01:54,079
that dot product will actually be negative.

29
00:01:54,079 --> 00:01:56,770
So when two vectors are generally pointing
in the same direction,

30
00:01:56,770 --> 00:01:59,670
their dot product is positive.

31
00:01:59,670 --> 00:02:01,250
When they're perpendicular, meaning,

32
00:02:01,250 --> 00:02:04,270
the projection of one onto the other is the
0 vector,

33
00:02:04,270 --> 00:02:06,180
the dot product is 0.

34
00:02:06,180 --> 00:02:10,720
And if they're pointing generally the opposite
direction, their dot product is negative.

35
00:02:10,720 --> 00:02:14,920
Now, this interpretation is weirdly asymmetric,

36
00:02:14,920 --> 00:02:16,480
it treats the two vectors very differently,

37
00:02:16,480 --> 00:02:21,420
so when I first learned this, I was surprised
that order doesn't matter.

38
00:02:21,420 --> 00:02:24,390
You could instead project v onto w;

39
00:02:24,390 --> 00:02:27,100
multiply the length of the projected v by
the length of w

40
00:02:27,100 --> 00:02:28,880
and get the same result.

41
00:02:28,880 --> 00:02:35,640
I mean, doesn't that feel like a really different
process?

42
00:02:35,640 --> 00:02:38,620
Here's the intuition for why order doesn't
matter:

43
00:02:38,620 --> 00:02:41,180
if v and w happened to have the same length,

44
00:02:41,180 --> 00:02:43,260
we could leverage some symmetry.

45
00:02:43,260 --> 00:02:45,180
Since projecting w onto v

46
00:02:45,180 --> 00:02:48,620
then multiplying the length of that projection
by the length of v,

47
00:02:48,620 --> 00:02:53,600
is a complete mirror image of projecting v
onto w then multiplying the length of that

48
00:02:53,600 --> 00:02:56,350
projection by the length of w.

49
00:02:56,350 --> 00:03:01,350
Now, if you “scale” one of them, say v
by some constant like 2,

50
00:03:01,350 --> 00:03:03,240
so that they don't have equal length,

51
00:03:03,240 --> 00:03:05,100
the symmetry is broken.

52
00:03:05,100 --> 00:03:10,010
But let's think through how to interpret the
dot product between this new vector 2v and

53
00:03:10,010 --> 00:03:11,010
w.

54
00:03:11,010 --> 00:03:13,550
If you think of w is getting projected onto
v

55
00:03:13,550 --> 00:03:16,670
then the dot product 2v・w will be

56
00:03:16,670 --> 00:03:20,520
exactly twice the dot product v・w.

57
00:03:20,520 --> 00:03:23,400
This is because when you “scale” v by
2,

58
00:03:23,400 --> 00:03:26,210
it doesn't change the length of the projection
of w

59
00:03:26,210 --> 00:03:29,840
but it doubles the length of the vector that
you're projecting onto.

60
00:03:29,840 --> 00:03:34,151
But, on the other hand, let's say you're thinking
about v getting projected onto w.

61
00:03:34,151 --> 00:03:39,000
Well, in that case, the length of the projection
is the thing to get “scaled” when we multiply

62
00:03:39,000 --> 00:03:40,340
v by 2.

63
00:03:40,340 --> 00:03:43,600
The length of the vector that you're projecting
onto stays constant.

64
00:03:43,600 --> 00:03:47,090
So the overall effect is still to just double
the dot product.

65
00:03:47,090 --> 00:03:49,620
So, even though symmetry is broken in this
case,

66
00:03:49,620 --> 00:03:53,720
the effect that this “scaling” has on
the value of the dot product, is the same

67
00:03:53,720 --> 00:03:57,040
under both interpretations.

68
00:03:57,040 --> 00:04:00,450
There's also one other big question that confused
me when I first learned this stuff:

69
00:04:00,450 --> 00:04:05,680
Why on earth does this numerical process of
matching coordinates, multiplying pairs and

70
00:04:05,680 --> 00:04:07,020
adding them together,

71
00:04:07,020 --> 00:04:10,040
have anything to do with projection?

72
00:04:10,040 --> 00:04:13,160
Well, to give a satisfactory answer,

73
00:04:13,160 --> 00:04:16,548
and also to do full justice to the significance
of the dot product,

74
00:04:16,548 --> 00:04:19,218
we need to unearth something a little bit
deeper going on here

75
00:04:19,219 --> 00:04:21,449
which often goes by the name "duality".

76
00:04:21,449 --> 00:04:23,290
But, before getting into that,

77
00:04:23,290 --> 00:04:26,360
I need to spend some time talking about linear
transformations

78
00:04:26,360 --> 00:04:28,710
from multiple dimensions to one dimension

79
00:04:28,710 --> 00:04:32,770
which is just the number line.

80
00:04:32,770 --> 00:04:36,210
These are functions that take in a 2D vector
and spit out some number.

81
00:04:36,210 --> 00:04:38,240
But linear transformations are, of course,

82
00:04:38,240 --> 00:04:43,090
much more restricted than your run-of-the-mill
function with a 2D input and a 1D output.

83
00:04:43,090 --> 00:04:45,150
As with transformations in higher dimensions,

84
00:04:45,150 --> 00:04:46,900
like the ones I talked about in chapter 3,

85
00:04:46,900 --> 00:04:50,350
there are some formal properties that make
these functions linear.

86
00:04:50,350 --> 00:04:54,259
But I'm going to purposely ignore those here
so as to not distract from our end goal,

87
00:04:54,259 --> 00:04:59,210
and instead focus on a certain visual property
that's equivalent to all the formal stuff.

88
00:04:59,210 --> 00:05:02,050
If you take a line of evenly spaced dots

89
00:05:02,050 --> 00:05:04,080
and apply a transformation,

90
00:05:04,080 --> 00:05:08,169
a linear transformation will keep those dots
evenly spaced,

91
00:05:08,169 --> 00:05:11,470
once they land in the output space, which
is the number line.

92
00:05:11,470 --> 00:05:15,520
Otherwise, if there's some line of dots that
gets unevenly spaced

93
00:05:15,520 --> 00:05:19,430
then your transformation is not linear.

94
00:05:19,430 --> 00:05:21,300
As with the cases we've seen before,

95
00:05:21,300 --> 00:05:23,060
one of these linear transformations

96
00:05:23,060 --> 00:05:27,029
is completely determined by where it takes
i-hat and j-hat

97
00:05:27,029 --> 00:05:30,719
but this time, each one of those basis vectors
just lands on a number.

98
00:05:30,719 --> 00:05:34,240
So when we record where they land as the columns
of a matrix

99
00:05:34,240 --> 00:05:38,529
each of those columns just has a single number.

100
00:05:38,529 --> 00:05:41,949
This is a 1 x 2 matrix.

101
00:05:41,949 --> 00:05:45,360
Let's walk through an example of what it means
to apply one of these transformations to a

102
00:05:45,360 --> 00:05:46,490
vector.

103
00:05:46,490 --> 00:05:52,490
Let's say you have a linear transformation
that takes i-hat to 1 and j-hat to -2.

104
00:05:52,490 --> 00:05:56,919
To follow where a vector with coordinates,
say, [4, 3] ends up,

105
00:05:56,919 --> 00:06:00,669
think of breaking up this vector as 4 times
i-hat + 3 times j-hat.

106
00:06:00,669 --> 00:06:05,249
A consequence of linearity, is that after
the transformation

107
00:06:05,249 --> 00:06:08,819
the vector will be: 4 times the place where
i-hat lands, 1,

108
00:06:08,819 --> 00:06:12,990
plus 3 times the place where j-hat lands,
-2.

109
00:06:12,990 --> 00:06:18,210
which in this case implies that it lands on
-2.

110
00:06:18,210 --> 00:06:24,199
When you do this calculation purely numerically,
it’s a matrix-vector multiplication.

111
00:06:24,199 --> 00:06:30,689
Now, this numerical operation of multiplying
a 1 by 2 matrix by a vector,

112
00:06:30,689 --> 00:06:33,580
feels just like taking the dot product of
two vectors.

113
00:06:33,580 --> 00:06:37,180
Doesn't that 1 x 2 matrix just look like a
vector that we tipped on its side?

114
00:06:37,180 --> 00:06:42,659
In fact, we could say right now that there's
a nice association between 1 x 2 matrices

115
00:06:42,659 --> 00:06:44,110
and 2D vectors,

116
00:06:44,110 --> 00:06:49,139
defined by tilting the numerical representation
of a vector on its side to get the associated

117
00:06:49,139 --> 00:06:50,139
matrix,

118
00:06:50,139 --> 00:06:53,720
or to tip the matrix back up to get the associated
vector.

119
00:06:53,720 --> 00:06:56,229
Since we're just looking at numerical expressions
right now,

120
00:06:56,229 --> 00:07:00,319
going back and forth between vectors and 1
x 2 matrices might feel like a silly thing

121
00:07:00,319 --> 00:07:01,849
to do.

122
00:07:01,849 --> 00:07:05,800
But this suggests something that's truly awesome
from the geometric view:

123
00:07:05,800 --> 00:07:10,330
there's some kind of connection between linear
transformations that take vectors to numbers

124
00:07:10,330 --> 00:07:15,620
and vectors themselves.

125
00:07:15,620 --> 00:07:17,909
Let me show an example that clarifies the
significance

126
00:07:17,909 --> 00:07:22,240
and which just so happens to also answer the
dot product puzzle from earlier.

127
00:07:22,240 --> 00:07:23,439
Unlearn what you have learned

128
00:07:23,439 --> 00:07:29,199
and imagine that you don't already know that
the dot product relates to projection.

129
00:07:29,199 --> 00:07:31,849
What I'm going to do here is take a copy of
the number line

130
00:07:31,849 --> 00:07:36,960
and place it diagonally and space somehow
with the number 0 sitting at the origin.

131
00:07:36,960 --> 00:07:39,110
Now think of the two-dimensional unit vector,

132
00:07:39,110 --> 00:07:42,120
whose tips sit where the number 1 on the number
line is.

133
00:07:42,120 --> 00:07:45,819
I want to give that guy a name u-hat.

134
00:07:45,819 --> 00:07:48,529
This little guy plays an important role in
what's about to happen,

135
00:07:48,529 --> 00:07:51,129
so just keep them in the back of your mind.

136
00:07:51,129 --> 00:07:54,830
If we project 2D vectors straight onto this
diagonal number line,

137
00:07:54,830 --> 00:07:59,189
in effect, we've just defined a function that
takes 2D vectors to numbers.

138
00:07:59,189 --> 00:08:02,050
What's more, this function is actually linear

139
00:08:02,050 --> 00:08:03,809
since it passes our visual test

140
00:08:03,809 --> 00:08:08,600
that any line of evenly spaced dots remains
evenly spaced once it lands on the number

141
00:08:08,600 --> 00:08:12,089
line.

142
00:08:12,089 --> 00:08:13,180
Just to be clear,

143
00:08:13,180 --> 00:08:16,469
even though I've embedded the number line
in 2D space like this,

144
00:08:16,469 --> 00:08:19,969
the output of the function are numbers, not
2D vectors.

145
00:08:19,969 --> 00:08:25,180
You should think of a function that takes
into coordinates and outputs a single coordinate.

146
00:08:25,180 --> 00:08:27,740
But that vector u-hat is a two-dimensional
vector

147
00:08:27,740 --> 00:08:29,539
living in the input space.

148
00:08:29,539 --> 00:08:34,750
It's just situated in such a way that overlaps
with the embedding of the number line.

149
00:08:34,750 --> 00:08:40,240
With this projection, we just defined a linear
transformation from 2D vectors to numbers,

150
00:08:40,240 --> 00:08:45,050
so we're going to be able to find some kind
of 1 x 2 matrix that describes that transformation.

151
00:08:45,050 --> 00:08:50,000
To find that 1 x 2 matrix, let's zoom in on
this diagonal number line setup

152
00:08:50,000 --> 00:08:53,500
and think about where i-hat and j-hat each
land,

153
00:08:53,500 --> 00:08:58,680
since those landing spots are going to be
the columns of the matrix.

154
00:08:58,680 --> 00:09:03,180
This part's super cool, we can reason through
it with a really elegant piece of symmetry:

155
00:09:03,180 --> 00:09:06,300
since i-hat and u-hat are both unit vectors,

156
00:09:06,300 --> 00:09:09,100
projecting i-hat onto the line passing through
u-hat

157
00:09:09,100 --> 00:09:13,810
looks totally symmetric to protecting u-hat
onto the x-axis.

158
00:09:13,810 --> 00:09:17,360
So when we asked what number does i-hat land
on when it gets projected

159
00:09:17,360 --> 00:09:21,820
the answer is going to be the same as whatever
u-hat lands on when its projected onto the

160
00:09:21,820 --> 00:09:22,820
x-axis

161
00:09:22,820 --> 00:09:25,800
but projecting u-hat onto the x-axis

162
00:09:25,800 --> 00:09:28,670
just means taking the x-coordinate of u-hat.

163
00:09:28,670 --> 00:09:33,800
So, by symmetry, the number where i-hat lands
when it’s projected onto that diagonal number

164
00:09:33,800 --> 00:09:34,800
line

165
00:09:34,800 --> 00:09:37,020
is going to be the x coordinate of u-hat.

166
00:09:37,020 --> 00:09:39,350
Isn't that cool?

167
00:09:39,350 --> 00:09:42,269
The reasoning is almost identical for the
j-hat case.

168
00:09:42,269 --> 00:09:49,510
Think about it for a moment.

169
00:09:49,510 --> 00:09:52,410
For all the same reasons, the y-coordinate
of u-hat

170
00:09:52,410 --> 00:09:56,730
gives us the number where j-hat lands when
it’s projected onto the number line copy.

171
00:09:56,730 --> 00:10:01,199
Pause and ponder that for a moment; I just
think that's really cool.

172
00:10:01,199 --> 00:10:05,069
So the entries of the 1 x 2 matrix describing
the projection transformation

173
00:10:05,069 --> 00:10:08,069
are going to be the coordinates of u-hat.

174
00:10:08,069 --> 00:10:12,030
And computing this projection transformation
for arbitrary vectors in space,

175
00:10:12,030 --> 00:10:15,269
which requires multiplying that matrix by
those vectors,

176
00:10:15,269 --> 00:10:22,040
is computationally identical to taking a dot
product with u-hat.

177
00:10:22,040 --> 00:10:24,920
This is why taking the dot product with a
unit vector,

178
00:10:24,920 --> 00:10:30,089
can be interpreted as projecting a vector
onto the span of that unit vector and taking

179
00:10:30,089 --> 00:10:34,319
the length.

180
00:10:34,319 --> 00:10:36,370
So what about non-unit vectors?

181
00:10:36,370 --> 00:10:37,370
For example,

182
00:10:37,370 --> 00:10:38,860
let's say we take that unit vector u-hat,

183
00:10:38,860 --> 00:10:41,290
but we “scale” it up by a factor of 3.

184
00:10:41,290 --> 00:10:44,930
Numerically, each of its components gets multiplied
by 3,

185
00:10:44,930 --> 00:10:48,029
So looking at the matrix associated with that
vector,

186
00:10:48,029 --> 00:10:55,740
it takes i-hat and j-hat to 3 times the values
where they landed before.

187
00:10:55,740 --> 00:10:57,090
Since this is all linear,

188
00:10:57,090 --> 00:10:58,750
it implies more generally,

189
00:10:58,750 --> 00:11:02,399
that the new matrix can be interpreted as
projecting any vector onto the number line

190
00:11:02,399 --> 00:11:03,399
copy

191
00:11:03,399 --> 00:11:05,600
and multiplying where it lands by 3.

192
00:11:05,600 --> 00:11:08,449
This is why the dot product with a non-unit
vector

193
00:11:08,449 --> 00:11:11,560
can be interpreted as first projecting onto
that vector

194
00:11:11,560 --> 00:11:17,970
then scaling up the length of that projection
by the length of the vector.

195
00:11:17,970 --> 00:11:20,009
Take a moment to think about what happened
here.

196
00:11:20,009 --> 00:11:23,300
We had a linear transformation from 2D space
to the number line,

197
00:11:23,300 --> 00:11:27,149
which was not defined in terms of numerical
vectors or numerical dot products.

198
00:11:27,149 --> 00:11:31,720
It was just defined by projecting space onto
a diagonal copy of the number line.

199
00:11:31,720 --> 00:11:33,760
But because the transformation is linear,

200
00:11:33,760 --> 00:11:37,370
it was necessarily described by some 1 x 2
matrix,

201
00:11:37,370 --> 00:11:40,459
and since multiplying a 1 x 2 matrix by a
2D vector

202
00:11:40,459 --> 00:11:43,920
is the same as turning that matrix on its
side and taking a dot product,

203
00:11:43,920 --> 00:11:49,870
this transformation was, inescapably, related
to some 2D vector.

204
00:11:49,870 --> 00:11:53,620
The lesson here, is that anytime you have
one of these linear transformations

205
00:11:53,620 --> 00:11:55,899
whose output space is the number line,

206
00:11:55,899 --> 00:11:59,490
no matter how it was defined there's going
to be some unique vector v

207
00:11:59,490 --> 00:12:01,529
corresponding to that transformation,

208
00:12:01,529 --> 00:12:05,569
in the sense that applying the transformation
is the same thing as taking a dot product

209
00:12:05,569 --> 00:12:09,990
with that vector.

210
00:12:09,990 --> 00:12:12,940
To me, this is utterly beautiful.

211
00:12:12,940 --> 00:12:15,779
It's an example of something in math called
“duality”.

212
00:12:15,779 --> 00:12:19,860
“Duality” shows up in many different ways
and forms throughout math

213
00:12:19,860 --> 00:12:22,259
and it's super tricky to actually define.

214
00:12:22,259 --> 00:12:27,930
Loosely speaking, it refers to situations
where you have a natural but surprising correspondence

215
00:12:27,930 --> 00:12:30,639
between two types of mathematical thing.

216
00:12:30,639 --> 00:12:33,410
For the linear algebra case that you just
learned about,

217
00:12:33,410 --> 00:12:38,800
you'd say that the “dual” of a vector
is the linear transformation that it encodes.

218
00:12:38,800 --> 00:12:42,759
And the dual of a linear transformation from
space to one dimension,

219
00:12:42,759 --> 00:12:45,180
is a certain vector in that space.

220
00:12:45,180 --> 00:12:52,250
So, to sum up, on the surface, the dot product
is a very useful geometric tool for understanding

221
00:12:52,250 --> 00:12:53,250
projections

222
00:12:53,250 --> 00:12:56,990
and for testing whether or not vectors tend
to point in the same direction.

223
00:12:56,990 --> 00:13:01,410
And that's probably the most important thing
for you to remember about the dot product,

224
00:13:01,410 --> 00:13:04,440
but at deeper level, dotting two vectors together

225
00:13:04,440 --> 00:13:08,399
is a way to translate one of them into the
world of transformations:

226
00:13:08,399 --> 00:13:12,079
again, numerically, this might feel like a
silly point to emphasize,

227
00:13:12,079 --> 00:13:15,069
it's just two computations that happen to
look similar.

228
00:13:15,069 --> 00:13:17,010
But the reason I find this so important,

229
00:13:17,010 --> 00:13:19,920
is that throughout math, when you're dealing
with a vector,

230
00:13:19,920 --> 00:13:22,190
once you really get to know its personality

231
00:13:22,190 --> 00:13:26,829
sometimes you realize that it's easier to
understand it, not as an arrow in space,

232
00:13:26,829 --> 00:13:29,790
but as the physical embodiment of a linear
transformation.

233
00:13:29,790 --> 00:13:35,670
It's as if the vector is really just a conceptual
shorthand for certain transformation,

234
00:13:35,670 --> 00:13:38,350
since it's easier for us to think about arrows
and space

235
00:13:38,350 --> 00:13:43,129
rather than moving all of that space to the
number line.

236
00:13:43,129 --> 00:13:47,610
In the next video, you'll see another really
cool example of this "duality" in action

237
00:13:47,610 --> 00:14:09,560
as I talk about the cross product.

