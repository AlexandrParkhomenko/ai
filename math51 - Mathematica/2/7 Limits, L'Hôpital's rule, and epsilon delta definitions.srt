1
00:00:14,670 --> 00:00:18,170
The last several videos have been about the
idea of a derivative, and before moving on

2
00:00:18,170 --> 00:00:21,680
to integrals, I want to take some time to
talk about limits.

3
00:00:21,680 --> 00:00:26,600
To be honest, the idea of a limit is not really
anything new. If you know what the word “approach”

4
00:00:26,600 --> 00:00:30,250
means you pretty much already know what a
limit is, you could say the rest is a matter

5
00:00:30,250 --> 00:00:36,620
of assigning fancy notation to the intuitive
idea of one value getting closer to another.

6
00:00:36,620 --> 00:00:40,320
But there are actually a few reasons to devote
a full video to this topic.

7
00:00:40,320 --> 00:00:43,850
For one thing it’s worth showing is how
the way I’ve been describing derivatives

8
00:00:43,850 --> 00:00:48,880
so far lines up with the the formal definition
of a derivative as it’s typically presented

9
00:00:48,880 --> 00:00:52,820
in most courses and textbooks.
I want to give you some confidence that thinking

10
00:00:52,820 --> 00:00:58,320
of terms like dx and df as concrete non-zero
nudges is not just some trick for building

11
00:00:58,320 --> 00:01:03,019
intuition; it’s actually backed up by the
formal definition of a derivative in all its

12
00:01:03,019 --> 00:01:05,630
rigor.
I also want to shed a little light on what

13
00:01:05,630 --> 00:01:10,220
exactly mathematicians mean by “approach”,
in terms of something called the "epsilon

14
00:01:10,220 --> 00:01:14,170
delta" definition of limits.
Then we’ll finish off with a clever trick

15
00:01:14,170 --> 00:01:17,780
for computing limits called L’Hopital’s
rule.

16
00:01:17,780 --> 00:01:22,460
So first thing’s first, let’s take a look
at the formal definition of the derivative.

17
00:01:22,460 --> 00:01:27,969
As a reminder, when you have some function
f(x), to think about the derivative at a particular

18
00:01:27,969 --> 00:01:34,329
input, maybe x=2, you start by imagining nudging
that input by some tiny dx, and looking at

19
00:01:34,329 --> 00:01:41,719
the resulting change to the output, df.
The ratio df/dx, which can nicely be thought

20
00:01:41,719 --> 00:01:45,900
of as the rise-over-run slope between the
starting point on the graph and the nudged

21
00:01:45,900 --> 00:01:52,289
point, is almost the derivative. The actual
derivative is whatever this ratio approaches

22
00:01:52,289 --> 00:01:57,890
as dx approaches 0.
Just to spell out what is meant here, that

23
00:01:57,890 --> 00:02:05,310
nudge to the output “df” is is the difference
between f(starting-input + dx) and f(starting-input);

24
00:02:05,310 --> 00:02:08,699
the change to the output caused by the nudge
dx.

25
00:02:08,699 --> 00:02:13,680
To express that you want to find what this
ratio approaches as dx approaches 0, you write

26
00:02:13,680 --> 00:02:18,180
“l-i-m”, for limit, with “dx arrow 0”
below it.

27
00:02:18,180 --> 00:02:24,560
Now, you’ll almost never see terms with
a lowercase d, like dx, inside a limit like

28
00:02:24,560 --> 00:02:30,260
this. Instead the standard is to use a different
variable, like delta-x, or commonly “h”

29
00:02:30,260 --> 00:02:33,620
for some reason.
The way I like to think of it is that terms

30
00:02:33,620 --> 00:02:39,349
with this lowercase d in the typical derivative
expression have built into them the idea of

31
00:02:39,349 --> 00:02:44,170
a limit, the idea that dx is supposed to eventually
approach 0.

32
00:02:44,170 --> 00:02:50,060
So in a sense this lefthand side “df/dx”,
the ratio we’ve been thinking about for

33
00:02:50,060 --> 00:02:55,050
the past few videos, is just shorthand for
what the righthand side spells out in more

34
00:02:55,050 --> 00:03:01,689
detail, writing out exactly what we mean by
df, and writing out the limiting process explicitly.

35
00:03:01,689 --> 00:03:06,920
And that righthand side is the formal definition
of a derivative, as you’d commonly see it

36
00:03:06,920 --> 00:03:08,069
in any calculus textbook

37
00:03:08,069 --> 00:03:12,870
Now, if you’ll pardon me for a small rant
here, I want to emphasize that nothing about

38
00:03:12,870 --> 00:03:18,230
this righthand side references the paradoxical
idea of an “infinitely small” change.

39
00:03:18,230 --> 00:03:23,260
The point of limits is to avoid that.
This value h is the exact same thing as the

40
00:03:23,260 --> 00:03:25,430
“dx” I’ve been referencing throughout
the series.

41
00:03:25,430 --> 00:03:32,310
It’s a nudge to the input of f with some
nonzero, finitely small size, like 0.001,

42
00:03:32,310 --> 00:03:37,590
it’s just that we’re analyzing what happens
for arbitrarily small choices of h.

43
00:03:37,590 --> 00:03:43,890
In fact, the only reason people introduce
a new variable name into this formal definition,

44
00:03:43,890 --> 00:03:50,219
rather than just using dx, is to be super-extra
clear that these changes to the input are

45
00:03:50,219 --> 00:03:54,780
ordinary numbers that have nothing to do with
the infinitesimal.

46
00:03:54,780 --> 00:03:59,780
You see, there are others who like to interpret
dx as an “infinitely small change”, whatever

47
00:03:59,780 --> 00:04:04,599
that would mean, or to just say that dx and
df are nothing more than symbols that shouldn’t

48
00:04:04,599 --> 00:04:07,819
be taken too seriously.
But by now in the series, you know that I’m

49
00:04:07,819 --> 00:04:12,600
not really a fan of either of those views,
I think you can and should interpret dx as

50
00:04:12,600 --> 00:04:17,700
a concrete, finitely small nudge, just so
long as you remember to ask what happens as

51
00:04:17,700 --> 00:04:21,390
it approaches 0.
For one thing, and I hope the past few videos

52
00:04:21,390 --> 00:04:25,100
have helped convince you of this, that helps
to build a stronger intuition for where the

53
00:04:25,100 --> 00:04:29,570
rules of calculus actually come from.
But it’s not just some trick for building

54
00:04:29,570 --> 00:04:34,360
intuitions. Everything I’ve been saying
about derivatives with this concrete-finitely-small-nudge

55
00:04:34,360 --> 00:04:41,390
philosophy is just a translation of the formal
definition of derivatives.

56
00:04:41,390 --> 00:04:45,880
Long story short, the big fuss about limits
is that they let us avoid talking about infinitely

57
00:04:45,880 --> 00:04:51,450
small changes by instead asking what happens
as the size of some change to our variable

58
00:04:51,450 --> 00:04:56,270
approaches 0.
And that brings us to goal #2: Understanding

59
00:04:56,270 --> 00:05:00,420
exactly it means for one value to approach
another.

60
00:05:00,420 --> 00:05:08,510
For example, consider the function [(2+h)3
- 23]/h.

61
00:05:08,510 --> 00:05:12,440
This happens to be the expression that pops
out if you unravel the definition for the

62
00:05:12,440 --> 00:05:19,170
derivative of x3 at x=2, but let’s just
think of it as any ol’ function with an

63
00:05:19,170 --> 00:05:23,110
input h.
Its graph is this nice continuous looking

64
00:05:23,110 --> 00:05:33,330
parabola. But actually, if you think about
what’s going at h=0, plugging that in you’d

65
00:05:33,330 --> 00:05:40,330
get 0/0, which is not defined. Just ask siri.
So really, this graph has a hole at that point.

66
00:05:40,330 --> 00:05:45,640
You have to exaggerate to draw that hole,
often with a little empty circle like this,

67
00:05:45,640 --> 00:05:50,120
but keep in mind the function is perfectly
well-defined for inputs as close to 0 as you

68
00:05:50,120 --> 00:05:53,790
want.
And wouldn’t you agree that as h approaches

69
00:05:53,790 --> 00:05:59,600
0, the corresponding output, the height of
this graph, approaches 12? And it doesn’t

70
00:05:59,600 --> 00:06:08,710
matter which side you come at it from. That
the limit of this ratio as h goes to 0 equals

71
00:06:08,710 --> 00:06:11,870
12.
But imagine you’re a mathematician inventing

72
00:06:11,870 --> 00:06:18,470
calculus, and someone skeptically asks “well
what exactly do you mean by approach?”

73
00:06:18,470 --> 00:06:22,710
That would be an annoying question. I mean,
come on, we all know what it means for one

74
00:06:22,710 --> 00:06:28,960
value to get closer to another.
But let me show you a way to answer completely

75
00:06:28,960 --> 00:06:33,350
unambiguously.
For a given range of inputs within some distance

76
00:06:33,350 --> 00:06:39,780
of 0, excluding the forbidden point 0, look
at the corresponding outputs, all possible

77
00:06:39,780 --> 00:06:45,660
heights of the graph above that range.
As that range of input values closes in more

78
00:06:45,660 --> 00:06:51,330
and more tightly around 0, the range of output
values closes in more and more closely around

79
00:06:51,330 --> 00:06:59,150
12. The size of that range of outputs can
be made as small as you want.

80
00:06:59,150 --> 00:07:03,740
As a counterexample, consider a function that
looks like this, which is also not defined

81
00:07:03,740 --> 00:07:09,980
at 0, but kind of jumps at that point.
As you approach h = 0 from the right, the

82
00:07:09,980 --> 00:07:16,010
function approaches 2, but as you come at
0 from the left, it approaches 1. Since there’s

83
00:07:16,010 --> 00:07:22,380
not a clear, unambiguous value that this function
approaches as h approaches 0, the limit is

84
00:07:22,380 --> 00:07:28,810
simply not defined at that point.
When you look at any range of inputs around

85
00:07:28,810 --> 00:07:35,870
0, and the corresponding range of outputs,
as you shrink that input range the corresponding

86
00:07:35,870 --> 00:07:42,270
outputs don’t narrow in on any specific
value. Instead those outputs straddle a range

87
00:07:42,270 --> 00:07:48,690
that never even shrinks smaller than 1, no
matter how small your input range.

88
00:07:48,690 --> 00:07:53,310
This perspective of shrinking an input range
around the limiting point, and seeing whether

89
00:07:53,310 --> 00:07:57,770
or not you’re restricted in how much that
shrinks the output range, leads to something

90
00:07:57,770 --> 00:08:01,970
called the “epsilon delta” definition
of limits.

91
00:08:01,970 --> 00:08:06,580
You could argue this needlessly heavy-duty
for an introduction to calculus. Like I said,

92
00:08:06,580 --> 00:08:10,060
if you know what the word “approach” means,
you know what a limit means, so there’s

93
00:08:10,060 --> 00:08:14,270
nothing new on the conceptual level here.
But this is an interesting glimpse into the

94
00:08:14,270 --> 00:08:19,610
field of real analysis, and it gives you a
taste for how mathematicians made the intuitive

95
00:08:19,610 --> 00:08:25,870
ideas of calculus fully airtight and rigorous.
You’ve already seen the main idea: when

96
00:08:25,870 --> 00:08:31,030
a limit exists, you can make this output range
as small as you want; but when the limit doesn’t

97
00:08:31,030 --> 00:08:36,440
exist, that output range can’t get smaller
than some value, no matter how much you shrink

98
00:08:36,440 --> 00:08:42,960
the input range around the limiting input.
Phrasing that same idea a little more precisely,

99
00:08:42,960 --> 00:08:47,879
maybe in the context of this example where
the limiting value was 12, think of any distance

100
00:08:47,879 --> 00:08:52,089
away from 12, where for some reason it’s
common to use the greek letter “epsilon”

101
00:08:52,089 --> 00:08:57,370
to denote that distance. And the intent here
is that that distance be something as small

102
00:08:57,370 --> 00:09:01,939
as you want.
What it means for the limit to exist is that

103
00:09:01,939 --> 00:09:08,680
you can always find a range of inputs around
our limiting input, some distance delta away

104
00:09:08,680 --> 00:09:15,050
from 0, so that any input within a distance
delta of 0 corresponds to an output with a

105
00:09:15,050 --> 00:09:21,130
distance epsilon of 12.
They key point is that this is true for any

106
00:09:21,130 --> 00:09:28,490
epsilon, no matter how small.
In contrast, when a limit doesn’t exist,

107
00:09:28,490 --> 00:09:34,899
as in this example, you can find a sufficiently
small epsilon, like 0.4, so that no matter

108
00:09:34,899 --> 00:09:40,170
how small you make your range around 0, no
matter how tiny delta is, the corresponding

109
00:09:40,170 --> 00:09:50,560
range of outputs is just always too big. There
is no limiting output value that they get

110
00:09:50,560 --> 00:09:54,600
arbitrarily close to.

111
00:09:54,600 --> 00:10:00,560
So far this is all pretty theory heavy; limits
being used to formally define the derivative,

112
00:10:00,560 --> 00:10:05,399
then epsilons and deltas being used to rigorously
define limits themselves. So let’s finish

113
00:10:05,399 --> 00:10:09,110
things off here with a trick for actually
computing limits.

114
00:10:09,110 --> 00:10:16,680
For example, let’s say for some reason you
were studying the function sin(pi*x)/(x2-1).

115
00:10:16,680 --> 00:10:22,360
Maybe this models some kind of dampened oscillation.
When you plot a bunch of points to graph it,

116
00:10:22,360 --> 00:10:29,999
it looks pretty continuous, but there’s
a problematic value, x=1.

117
00:10:29,999 --> 00:10:37,720
When you plug that in, sin(pi) is 0, and the
denominator is also 0, so the function is

118
00:10:37,720 --> 00:10:42,690
actually not defined there, and the graph
should really have a hole there.

119
00:10:42,690 --> 00:10:48,339
This also happens at -1, but let’s just
focus our attention on one of these holes

120
00:10:48,339 --> 00:10:51,850
for now.
The graph certainly does seem to approach

121
00:10:51,850 --> 00:10:59,899
some distinct value at that point, wouldn’t
you say? So you might ask, how do you figure

122
00:10:59,899 --> 00:11:06,790
out what output this approaches as x approaches
1, since you can’t just plug in 1?

123
00:11:06,790 --> 00:11:16,329
Well, one way to approximate it would be to
plug in a number very close to 1, like 1.00001.

124
00:11:16,329 --> 00:11:23,750
Doing that, you’d get a number around -1.57.
But is there a way to know exactly what it

125
00:11:23,750 --> 00:11:29,600
is? Some systematic process to take an expression
like this one, which looks like 0/0 at some

126
00:11:29,600 --> 00:11:34,440
input, and ask what its limit is as x approaches
that input?

127
00:11:34,440 --> 00:11:40,740
Well, after limits so helpfully let us write
the definition for a derivative, derivatives

128
00:11:40,740 --> 00:11:45,990
can come back to return the favor and help
us evaluate limits. Let me show you what I

129
00:11:45,990 --> 00:11:51,319
mean.
Here’s the graph of sin(pi*x), and here’s

130
00:11:51,319 --> 00:11:57,980
the graph of x2-1. That’s kind of a lot
on screen, but just focus on what’s happening

131
00:11:57,980 --> 00:12:07,269
at x=1. The point here is that sin(pi*x) and
x2-1 are both 0 at that point, so they cross

132
00:12:07,269 --> 00:12:11,290
the x-axis.
In the same spirit as plugging in a specific

133
00:12:11,290 --> 00:12:18,230
value near 1, like 1.00001, let’s zoom in
on that point and consider what happens a

134
00:12:18,230 --> 00:12:25,449
tiny nudge dx away.
The value of sin(pi*x) is bumped down, and

135
00:12:25,449 --> 00:12:29,940
the value of that nudge, which was caused
by the nudge dx to the input, is what we might

136
00:12:29,940 --> 00:12:35,040
call d(sin(pi*x)).
From our knowledge of derivatives, using the

137
00:12:35,040 --> 00:12:45,740
chain rule, that should be around cos(pi*x)*pi*dx.
Since the starting value was x=1, we plug

138
00:12:45,740 --> 00:12:54,680
in x=1 to this expression.
In other words, the size of the change to

139
00:12:54,680 --> 00:13:02,070
this sin(pi*x) graph is roughly proportional
to dx, with proportionality constant cos(pi)*pi.

140
00:13:02,070 --> 00:13:10,139
Since cos(pi) is exactly -1, we can write
that as -pi*dx.

141
00:13:10,139 --> 00:13:20,100
Similarly, the value this x2-1 graph has changed
by some d(x2-1). And taking the derivative,

142
00:13:20,100 --> 00:13:29,910
the size of that nudge should be 2*x*dx. Again,
since we started at x=1, that means the size

143
00:13:29,910 --> 00:13:38,410
of this change is about 2*1*dx.
So for values of x which are some tiny value

144
00:13:38,410 --> 00:13:48,150
dx away from 1, the ratio sin(pi*x)/(x2-1)
is approximately (-pi*dx) / (2*dx). The dx’s

145
00:13:48,150 --> 00:13:58,519
cancel, so that value is -pi/2.
Since these approximations get more and more

146
00:13:58,519 --> 00:14:05,879
accurate for smaller and smaller choices of
dx, this ratio -pi/2 actually tells us the

147
00:14:05,879 --> 00:14:11,690
precise limiting value as x approaches 1.
Remember, what that means is that the limiting

148
00:14:11,690 --> 00:14:18,600
height on our original graph is evidently
exactly -pi/2.

149
00:14:18,600 --> 00:14:22,619
What happened there is a little subtle, so
let me show it again, but this time a little

150
00:14:22,619 --> 00:14:29,161
more generally. Instead of these two specific
functions, which both equal 0 at x=1, think

151
00:14:29,161 --> 00:14:36,339
of any two functions f(x) and g(x), which
are both 0 at some common value x = a.

152
00:14:36,339 --> 00:14:41,939
And these have to be functions where you’re
able to take a derivative of them at x = a,

153
00:14:41,939 --> 00:14:48,149
meaning they each basically look like a line
when you zoom in close enough to that value.

154
00:14:48,149 --> 00:14:52,910
Even though you can’t compute f divided
by g at the trouble point, since both equal

155
00:14:52,910 --> 00:15:00,009
zero, you can ask abou this ratio for values
of x very close to a, the limit as x approach

156
00:15:00,009 --> 00:15:06,699
a. And it’s helpful to think of those nearby
inputs as a tiny nudge dx away from a.

157
00:15:06,699 --> 00:15:14,589
The value of f at that nudged point is approximately
its derivative, df/dx evaluated at a, times

158
00:15:14,589 --> 00:15:21,800
dx. Likewise the the value of g at that nudged
point is approximately the derivative of g,

159
00:15:21,800 --> 00:15:27,730
evaluated at a, times dx.
So near this trouble point, the ratio between

160
00:15:27,730 --> 00:15:34,129
the outputs of f and g is actually about the
same as the derivative of f at a, times dx,

161
00:15:34,129 --> 00:15:37,420
divided by the derivative of g at a, times
dx.

162
00:15:37,420 --> 00:15:43,929
These dx’s cancel, so the ratio of f and
g near a is about the same as the ratio between

163
00:15:43,929 --> 00:15:48,860
their derivatives.
Since those approximations get more accurate

164
00:15:48,860 --> 00:15:55,769
for smaller nudges, this ratio of derivatives
gives the precise value for the limit.

165
00:15:55,769 --> 00:16:00,529
This is a really handy trick for computing
a lot of limits. If you come across an expression

166
00:16:00,529 --> 00:16:07,310
that seems to equal 0/0 when you plug in some
input, just take the derivative of the top

167
00:16:07,310 --> 00:16:14,069
and bottom expressions, and plug in that trouble
input.

168
00:16:14,069 --> 00:16:18,759
This clever trick is called “L'Hôpital's
rule”. Interestingly, it was actually discovered

169
00:16:18,759 --> 00:16:23,579
by Johann Bernoulli, but L’Hopital was a
wealthy dude who essentially paid Bernoulli

170
00:16:23,579 --> 00:16:29,279
for the rights to some of his mathematical
discoveries.

171
00:16:29,279 --> 00:16:35,620
In a very literal way, it pays to understand
these tiny nudges.

172
00:16:35,620 --> 00:16:39,970
You might remember that the definition of
a derivative for any given function comes

173
00:16:39,970 --> 00:16:46,720
down to computing the limit of a fraction
that looks like 0/0, so you might think L’Hopital’s

174
00:16:46,720 --> 00:16:50,970
rule gives a handy way to discover new derivative
formulas.

175
00:16:50,970 --> 00:16:55,290
But that would be cheating, since presumably
you don’t yet know what the derivative on

176
00:16:55,290 --> 00:16:59,540
the numerator here is.
When it comes to discovering derivative formulas,

177
00:16:59,540 --> 00:17:04,250
something we’ve been doing a fair amount
this series, there is no systematic plug-and-chug

178
00:17:04,250 --> 00:17:09,270
method. But that’s a good thing. When creativity
is required to solve problems like these,

179
00:17:09,270 --> 00:17:13,520
it’s a good sign you’re doing something
real; something that might give you a powerful

180
00:17:13,520 --> 00:17:19,970
tool to solve future problems.

181
00:17:19,970 --> 00:17:24,369
Up next, I’ll talk about what an integral
is, as well as the fundamental theorem of

182
00:17:24,369 --> 00:17:29,220
calculus, which is another example of where
limits are used to help give a clear meaning

183
00:17:29,220 --> 00:17:33,670
to a fairly delicate idea that flirts with
infinity.

184
00:17:33,670 --> 00:17:37,700
As you know, most support for this channel
comes through Patreon, and the primary perk

185
00:17:37,700 --> 00:17:44,440
for patrons is early access to future series
like this, where the next one will be on Probability.

186
00:17:44,440 --> 00:17:49,360
But for those of you who want a more tangible
way to flag that you’re part of the community,

187
00:17:49,360 --> 00:17:54,300
there is also a small 3blue1brown store, links
on the screen and in the description.

188
00:17:54,300 --> 00:17:59,450
I’m still debating whether or to make a
preliminary batch of plushie pi creatures,

189
00:17:59,450 --> 00:18:03,960
it kind of depends on how many viewers seem
interested in the store in general, but let

190
00:18:03,960 --> 00:18:06,770
me know in comments what kind of other things
you’d like to see there.

