1
00:00:00,000 --> 00:00:04,352


2
00:00:04,352 --> 00:00:05,810
CHRISTOPHER POTTS:
Hello, everyone.

3
00:00:05,810 --> 00:00:08,080
Welcome to part 5 in our
series on grounded language

4
00:00:08,080 --> 00:00:08,680
understanding.

5
00:00:08,680 --> 00:00:11,013
We're going to be talking
about the rational speech acts

6
00:00:11,013 --> 00:00:12,153
model or RSA.

7
00:00:12,153 --> 00:00:13,570
This is an exciting
model that was

8
00:00:13,570 --> 00:00:15,820
developed by Stanford
researchers Mike Frank and Noah

9
00:00:15,820 --> 00:00:16,540
Goodman.

10
00:00:16,540 --> 00:00:18,520
And it's a chance for
us to connect ideas

11
00:00:18,520 --> 00:00:21,220
from cognitive and
psychology and linguistics

12
00:00:21,220 --> 00:00:24,487
with large-scale problems
in machine learning.

13
00:00:24,487 --> 00:00:26,320
Now what I'm going to
do for this screencast

14
00:00:26,320 --> 00:00:28,960
is kind of queue up
the high-level concepts

15
00:00:28,960 --> 00:00:31,360
and the core model
structure as a way

16
00:00:31,360 --> 00:00:33,125
of leading into the
next screencast, which

17
00:00:33,125 --> 00:00:34,750
is going to show you
how to incorporate

18
00:00:34,750 --> 00:00:37,720
pieces of this model into
standard machine learning

19
00:00:37,720 --> 00:00:38,680
models.

20
00:00:38,680 --> 00:00:41,980
If you would like a deeper
dive on the conceptual origins

21
00:00:41,980 --> 00:00:45,340
of this model and how it works
in a kind of mathematical way,

22
00:00:45,340 --> 00:00:47,720
I would encourage you to check
out these resources here.

23
00:00:47,720 --> 00:00:49,345
So this first paper,
Goodman and Frank,

24
00:00:49,345 --> 00:00:52,090
from the developers of
RSA, is a nice overview

25
00:00:52,090 --> 00:00:54,160
that shows not only
all the technical model

26
00:00:54,160 --> 00:00:57,490
details with real rigor,
but also connects the ideas

27
00:00:57,490 --> 00:01:02,020
with decision theory, game
theory, cognitive psychology,

28
00:01:02,020 --> 00:01:05,452
and Bayesian cognitive
science, and also linguistics.

29
00:01:05,452 --> 00:01:07,660
From there, you could watch
this technical screencast

30
00:01:07,660 --> 00:01:08,185
that I did.

31
00:01:08,185 --> 00:01:10,810
This is on YouTube, and here are
the associated slides for that

32
00:01:10,810 --> 00:01:12,340
if you want to follow along.

33
00:01:12,340 --> 00:01:15,100
And from there, I have this
Python reference implementation

34
00:01:15,100 --> 00:01:17,770
of the core RSA model, and
that would be a great way

35
00:01:17,770 --> 00:01:19,660
to get hands-on with
the model and begin

36
00:01:19,660 --> 00:01:21,820
to think about how you
could incorporate it

37
00:01:21,820 --> 00:01:25,578
into your own project
or original system.

38
00:01:25,578 --> 00:01:27,870
Without further ado, though,
let's dive into the model.

39
00:01:27,870 --> 00:01:28,910
And I'm going to
begin with what I've

40
00:01:28,910 --> 00:01:30,260
called pragmatic listeners.

41
00:01:30,260 --> 00:01:32,000
And we can also, as
you'll see later,

42
00:01:32,000 --> 00:01:34,290
take a speaker perspective.

43
00:01:34,290 --> 00:01:37,100
So the model begins with what's
called the literal listener.

44
00:01:37,100 --> 00:01:38,870
This is a probabilistic
agent, and you

45
00:01:38,870 --> 00:01:41,210
can see that it
conditions on a message.

46
00:01:41,210 --> 00:01:43,670
That is, it hears or
observes a message

47
00:01:43,670 --> 00:01:45,080
and makes a guess
about the state

48
00:01:45,080 --> 00:01:47,190
of the world on that basis.

49
00:01:47,190 --> 00:01:50,150
And the way it does that is by
reasoning essentially entirely

50
00:01:50,150 --> 00:01:52,382
about the truth conditions
of the language.

51
00:01:52,382 --> 00:01:53,840
Here I've got these
double brackets

52
00:01:53,840 --> 00:01:57,080
indicating that we have a
semantic lexicon mapping

53
00:01:57,080 --> 00:02:00,020
words and phrases to
their truth values.

54
00:02:00,020 --> 00:02:02,150
This agent also takes
the prior into account,

55
00:02:02,150 --> 00:02:04,280
but that's the only way
in which it's pragmatic.

56
00:02:04,280 --> 00:02:09,080
Otherwise, it's kind of a
fundamentally semantic agent.

57
00:02:09,080 --> 00:02:11,750
From there, we built
the pragmatic speaker.

58
00:02:11,750 --> 00:02:13,663
Speakers in this
model observe states

59
00:02:13,663 --> 00:02:15,830
of the world, things they
want to communicate about,

60
00:02:15,830 --> 00:02:18,433
and then they choose
messages on that basis.

61
00:02:18,433 --> 00:02:19,850
And the core thing
to observe here

62
00:02:19,850 --> 00:02:21,980
is that the pragmatic
speaker reasons

63
00:02:21,980 --> 00:02:24,320
not about the semantics
of the language

64
00:02:24,320 --> 00:02:26,210
as the literal listener
does, but rather

65
00:02:26,210 --> 00:02:28,190
about the literal
listener who reasons

66
00:02:28,190 --> 00:02:30,410
about the semantics
of the language.

67
00:02:30,410 --> 00:02:32,060
And for this pragmatic
speaker here, it

68
00:02:32,060 --> 00:02:35,150
does that taking cost of
messages into account.

69
00:02:35,150 --> 00:02:37,710
And it also has this
temperature parameter, alpha,

70
00:02:37,710 --> 00:02:40,040
which will help us control
how aggressively it

71
00:02:40,040 --> 00:02:43,435
reasons about this lower
agent, the literal listener.

72
00:02:43,435 --> 00:02:44,810
Other than that,
you can probably

73
00:02:44,810 --> 00:02:48,710
see that this model is a kind
of softmax decision rule, where

74
00:02:48,710 --> 00:02:53,480
we're combining the literal
listener with message costs.

75
00:02:53,480 --> 00:02:55,670
And then finally, we have
the pragmatic listener,

76
00:02:55,670 --> 00:02:58,190
which has essentially the same
form as the literal listener.

77
00:02:58,190 --> 00:02:59,930
It observes the message
and makes a guess

78
00:02:59,930 --> 00:03:02,630
about the state of the
world on that basis.

79
00:03:02,630 --> 00:03:05,030
And it has the same overall
form as the literal listener,

80
00:03:05,030 --> 00:03:07,340
except it's reasoning not
about the truth conditions,

81
00:03:07,340 --> 00:03:10,220
but rather about the
pragmatic speaker, who

82
00:03:10,220 --> 00:03:12,620
is reasoning about the literal
listener, who is finally

83
00:03:12,620 --> 00:03:14,652
reasoning about the
semantic grammar.

84
00:03:14,652 --> 00:03:16,610
So you can see that
there's a kind of recursive

85
00:03:16,610 --> 00:03:17,930
back and forth in this model.

86
00:03:17,930 --> 00:03:20,900
You might think of this as
reasoning about other minds,

87
00:03:20,900 --> 00:03:26,300
and it's in that recursion that
we get pragmatic language use.

88
00:03:26,300 --> 00:03:28,190
Here's a kind of shorthand
for the core model

89
00:03:28,190 --> 00:03:30,050
components of a
literal listener's

90
00:03:30,050 --> 00:03:33,410
reasoning about the lexicon
and the prior overstates.

91
00:03:33,410 --> 00:03:35,810
The pragmatic speaker reasons
about the literal listener

92
00:03:35,810 --> 00:03:38,190
taking message
costs into account.

93
00:03:38,190 --> 00:03:39,800
And finally, the
pragmatic listener

94
00:03:39,800 --> 00:03:42,920
reasons about the pragmatic
speaker taking the state prior

95
00:03:42,920 --> 00:03:43,770
into account.

96
00:03:43,770 --> 00:03:46,130
And then you can see nicely
this point of indirection

97
00:03:46,130 --> 00:03:48,110
down to the semantic lexicon.

98
00:03:48,110 --> 00:03:50,330
And as I said, it's
in that recursion

99
00:03:50,330 --> 00:03:53,700
that we get interesting
pragmatic language use.

100
00:03:53,700 --> 00:03:57,030
Let me show you how that happens
with a small example here.

101
00:03:57,030 --> 00:03:59,450
So along the rows in
this, I have the messages.

102
00:03:59,450 --> 00:04:01,620
We're imagining a very
simple language in which

103
00:04:01,620 --> 00:04:02,870
there are just three messages.

104
00:04:02,870 --> 00:04:05,240
You can think of them
as shorthand for like--

105
00:04:05,240 --> 00:04:07,650
the person I'm referring
to has a beard.

106
00:04:07,650 --> 00:04:10,860
The person I'm referring to
has glasses and so forth.

107
00:04:10,860 --> 00:04:12,290
And we have just
three reference.

108
00:04:12,290 --> 00:04:14,720
And I'll tell you that
this is David Lewis, one

109
00:04:14,720 --> 00:04:17,000
of the originators of
signaling systems, which is

110
00:04:17,000 --> 00:04:19,718
an important precursor to RSA.

111
00:04:19,718 --> 00:04:21,260
This is the philosopher
and linguist,

112
00:04:21,260 --> 00:04:25,090
Paul Grice who did foundational
work in pragmatics.

113
00:04:25,090 --> 00:04:27,590
And this is Claude Shannon,
who, of course, is the developer

114
00:04:27,590 --> 00:04:29,600
of information theory.

115
00:04:29,600 --> 00:04:32,415
And in this table here, we have
the semantic grammar, the truth

116
00:04:32,415 --> 00:04:33,540
conditions of the language.

117
00:04:33,540 --> 00:04:36,560
So you can see that Lewis
has this wonderful beard,

118
00:04:36,560 --> 00:04:39,410
but neither Grice nor
Shannon have beards.

119
00:04:39,410 --> 00:04:41,600
Glasses is true of
Lewis and Grice,

120
00:04:41,600 --> 00:04:45,540
and tie is true of
Grice and Shannon.

121
00:04:45,540 --> 00:04:49,050
The literal listener,
assuming we have flat priors,

122
00:04:49,050 --> 00:04:51,870
simply row normalizes
those truth conditions.

123
00:04:51,870 --> 00:04:55,120
So we go from all these ones
to an even distribution,

124
00:04:55,120 --> 00:04:56,820
and you can see
that already beard

125
00:04:56,820 --> 00:04:59,075
is unambiguous for this
listener, but glasses

126
00:04:59,075 --> 00:05:00,450
and a tie present
what looks like

127
00:05:00,450 --> 00:05:02,370
an insurmountable ambiguity.

128
00:05:02,370 --> 00:05:04,590
On hearing glasses,
this listener

129
00:05:04,590 --> 00:05:08,280
just has to guess about whether
the referent was Lewis or Grice

130
00:05:08,280 --> 00:05:10,837
and same thing for tie.

131
00:05:10,837 --> 00:05:12,420
When we move to the
pragmatic speaker,

132
00:05:12,420 --> 00:05:14,250
we already see that
the system starts

133
00:05:14,250 --> 00:05:15,520
to become more efficient.

134
00:05:15,520 --> 00:05:18,720
So we take the speaker
perspective along the rows now.

135
00:05:18,720 --> 00:05:21,720
And we-- because we're going
to assume zero message cost,

136
00:05:21,720 --> 00:05:23,490
we can, again,
just row normalize

137
00:05:23,490 --> 00:05:27,480
in this case from the previous
matrix having transposed it.

138
00:05:27,480 --> 00:05:29,405
And now you can
see that on trying

139
00:05:29,405 --> 00:05:31,530
to communicate about Lewis,
the speaker should just

140
00:05:31,530 --> 00:05:34,850
choose beard as an
overwhelming bias for that.

141
00:05:34,850 --> 00:05:37,260
And down here on observing
Shannon or wanting

142
00:05:37,260 --> 00:05:38,730
to talk about
Shannon, the speaker

143
00:05:38,730 --> 00:05:41,400
should say tie, that's
completely unambiguous.

144
00:05:41,400 --> 00:05:42,720
But we still have a problem.

145
00:05:42,720 --> 00:05:44,640
If we want to refer
to Grice, we have

146
00:05:44,640 --> 00:05:48,000
kind of no bias about whether we
should choose glasses or a tie.

147
00:05:48,000 --> 00:05:50,070
But already, we have a
more efficient system

148
00:05:50,070 --> 00:05:52,500
than we did for the
literal listener.

149
00:05:52,500 --> 00:05:55,080
And then, finally, when we
move to the pragmatic listener,

150
00:05:55,080 --> 00:05:57,820
we have what you might think
of as a completely separating

151
00:05:57,820 --> 00:05:59,850
linguistic system.

152
00:05:59,850 --> 00:06:02,100
On hearing beard, infer Lewis.

153
00:06:02,100 --> 00:06:04,590
On hearing glasses,
your best bet is Grice.

154
00:06:04,590 --> 00:06:06,970
And on hearing tie, your
best bet is Shannon.

155
00:06:06,970 --> 00:06:08,940
And in this way, you
can see that we started

156
00:06:08,940 --> 00:06:11,700
with a system that looked
hopelessly ambiguous,

157
00:06:11,700 --> 00:06:14,280
and now in the back and
forth RSA reasoning,

158
00:06:14,280 --> 00:06:17,280
we have arrived at a system that
is probabilistically completely

159
00:06:17,280 --> 00:06:18,030
unambiguous.

160
00:06:18,030 --> 00:06:21,870
And that's the sense in which
we can do pragmatic language use

161
00:06:21,870 --> 00:06:23,760
and end up with more
efficient languages

162
00:06:23,760 --> 00:06:27,020
as a result of this reasoning.

163
00:06:27,020 --> 00:06:29,410
Now for natural language
generation problems,

164
00:06:29,410 --> 00:06:31,730
it's often useful to take
a speaker perspective,

165
00:06:31,730 --> 00:06:33,010
as we've discussed before.

166
00:06:33,010 --> 00:06:34,468
And I just want to
point out to you

167
00:06:34,468 --> 00:06:36,670
that it's straightforward
to formulate this model,

168
00:06:36,670 --> 00:06:37,942
starting from a speaker.

169
00:06:37,942 --> 00:06:39,650
We would do that down
here at the bottom.

170
00:06:39,650 --> 00:06:42,460
This has the same form
as the previous speakers.

171
00:06:42,460 --> 00:06:44,770
We're going to subtract
out message costs,

172
00:06:44,770 --> 00:06:47,212
and we have the softmax
decision rule overall.

173
00:06:47,212 --> 00:06:49,420
But now, the speaker, of
course, will reason directly

174
00:06:49,420 --> 00:06:51,940
about the truth conditions
of the language.

175
00:06:51,940 --> 00:06:53,680
And we have our
pragmatic listener.

176
00:06:53,680 --> 00:06:55,720
There's just one for
this perspective,

177
00:06:55,720 --> 00:06:58,270
and it looks like just those
other listeners accepted

178
00:06:58,270 --> 00:07:00,070
reasons, not about
the truth conditions,

179
00:07:00,070 --> 00:07:02,800
but rather about
that literal speaker.

180
00:07:02,800 --> 00:07:04,850
And then finally, for
our pragmatic speaker,

181
00:07:04,850 --> 00:07:08,170
which is the one that you might
focus on for generation tasks.

182
00:07:08,170 --> 00:07:11,110
It has the same form as
before, except now we're

183
00:07:11,110 --> 00:07:13,630
reasoning about the pragmatic
listener, who reasoning

184
00:07:13,630 --> 00:07:14,890
about the liberal speaker.

185
00:07:14,890 --> 00:07:18,503
So we have that same
kind of indirection.

186
00:07:18,503 --> 00:07:20,920
And once again, here's a kind
of shorthand way of thinking

187
00:07:20,920 --> 00:07:22,470
about the speaker perspective.

188
00:07:22,470 --> 00:07:24,970
So the literal speaker
reasons about the lexicon,

189
00:07:24,970 --> 00:07:27,520
subtracting out costs,
the pragmatic listener

190
00:07:27,520 --> 00:07:30,305
reasons about that literal
speaker and the state prior.

191
00:07:30,305 --> 00:07:31,930
And then finally,
the pragmatic speaker

192
00:07:31,930 --> 00:07:34,150
reasons about the
pragmatic listener,

193
00:07:34,150 --> 00:07:36,110
taking message
costs into account.

194
00:07:36,110 --> 00:07:37,900
And again, you see
that recursion down

195
00:07:37,900 --> 00:07:40,263
into the lexicon.

196
00:07:40,263 --> 00:07:42,430
Now I've given you a glimpse
of why this model might

197
00:07:42,430 --> 00:07:44,800
be powerful, but let's
close with some limitations

198
00:07:44,800 --> 00:07:47,810
that we might address in the
context of doing modern NLP

199
00:07:47,810 --> 00:07:49,510
and machine learning.

200
00:07:49,510 --> 00:07:52,420
So first, we had to
hand-specify that lexicon.

201
00:07:52,420 --> 00:07:54,370
In cognitive psychology
and linguistics,

202
00:07:54,370 --> 00:07:55,270
this is often fine.

203
00:07:55,270 --> 00:07:57,062
We're going to run a
controlled experiment,

204
00:07:57,062 --> 00:07:59,977
and hand-specifying the lexicon
is not really an obstacle.

205
00:07:59,977 --> 00:08:01,810
But if we would like
to work in open domains

206
00:08:01,810 --> 00:08:05,920
with large corpora, this
is probably a deal-breaker.

207
00:08:05,920 --> 00:08:08,830
A related problem arises
if you look more closely

208
00:08:08,830 --> 00:08:11,110
at the way the speaker
agents are formulated.

209
00:08:11,110 --> 00:08:13,990
In their denominator, they
have this implicit summation

210
00:08:13,990 --> 00:08:16,000
over all possible
messages, where

211
00:08:16,000 --> 00:08:17,770
we do this computation here.

212
00:08:17,770 --> 00:08:20,110
But in the context of
a natural language,

213
00:08:20,110 --> 00:08:22,390
what does it mean to sum
over all messages that

214
00:08:22,390 --> 00:08:24,520
might be an infinite set?

215
00:08:24,520 --> 00:08:27,430
And even if it's finite, because
we make some approximations,

216
00:08:27,430 --> 00:08:29,230
it's still going to
be so large as to make

217
00:08:29,230 --> 00:08:31,210
this calculation intractable.

218
00:08:31,210 --> 00:08:32,890
So for computational
applications,

219
00:08:32,890 --> 00:08:36,890
we will have to address
this potential shortcoming.

220
00:08:36,890 --> 00:08:39,020
It's also RSA--
what you might think

221
00:08:39,020 --> 00:08:40,679
of as a very high biased model.

222
00:08:40,679 --> 00:08:43,370
We have relatively few
chances to learn from data.

223
00:08:43,370 --> 00:08:46,650
It hardwires in a particular
reasoning mechanism

224
00:08:46,650 --> 00:08:51,060
and is inflexible about how
that mechanism is applied.

225
00:08:51,060 --> 00:08:53,490
Relatedly, we might then
run up against things

226
00:08:53,490 --> 00:08:55,470
like it's difficult
to be a speaker,

227
00:08:55,470 --> 00:08:57,300
and speakers, even
the pragmatic ones,

228
00:08:57,300 --> 00:08:59,790
are not always perfectly
rational in the way

229
00:08:59,790 --> 00:09:01,733
the model might
portray them to be,

230
00:09:01,733 --> 00:09:03,150
and we might want
to capture that,

231
00:09:03,150 --> 00:09:06,450
if only to do well
with actual usage data.

232
00:09:06,450 --> 00:09:09,420
And relatedly, even setting
aside the pressures on speakers

233
00:09:09,420 --> 00:09:11,730
to be rational, they just
might have preferences

234
00:09:11,730 --> 00:09:13,470
for certain word
choices and other things

235
00:09:13,470 --> 00:09:16,530
that the model is simply
not even trying to capture,

236
00:09:16,530 --> 00:09:18,750
and we might hope in the
context of a large scale

237
00:09:18,750 --> 00:09:21,060
machine learning model, that
we would have mechanisms

238
00:09:21,060 --> 00:09:22,830
for bringing those in.

239
00:09:22,830 --> 00:09:24,780
And finally, it's
just not scalable.

240
00:09:24,780 --> 00:09:27,043
And you can see that in the
first two bullet points,

241
00:09:27,043 --> 00:09:28,710
and there are many
other senses in which

242
00:09:28,710 --> 00:09:31,080
RSA, as I've presented
it, just won't

243
00:09:31,080 --> 00:09:33,390
scale to the kind of
big ambitious problems

244
00:09:33,390 --> 00:09:35,880
that we're trying to
tackle in this class.

245
00:09:35,880 --> 00:09:37,560
The next screencast
is going to attempt

246
00:09:37,560 --> 00:09:39,330
to address all of
these limitations

247
00:09:39,330 --> 00:09:43,730
by bringing RSA into large-scale
machine learning models.

248
00:09:43,730 --> 00:09:48,160


