1
00:00:04,799 --> 00:00:06,080
приветствую всех, это первый

2
00:00:06,080 --> 00:00:07,680
скринкаст в нашей серии о

3
00:00:07,680 --> 00:00:09,599
выводе естественного языка или nli, это одна из

4
00:00:09,599 --> 00:00:11,840
моих любимых задач, что я хотел бы сделать,

5
00:00:11,840 --> 00:00:13,519
это дать вам представление о том, как формулируется задача,

6
00:00:13,519 --> 00:00:15,759
а затем поместить задачу

7
00:00:15,759 --> 00:00:17,600
в более широкий ландшафт.  идей

8
00:00:17,600 --> 00:00:20,080
для nlu,

9
00:00:20,080 --> 00:00:21,840
как обычно, у нас есть куча материалов

10
00:00:21,840 --> 00:00:23,279
, которые позволят вам

11
00:00:23,279 --> 00:00:25,279
решить эту проблему. Основной модуль —

12
00:00:25,279 --> 00:00:28,000
nli.pi, а затем есть два блокнота.

13
00:00:28,000 --> 00:00:30,080
Первый представляет три набора данных,

14
00:00:30,080 --> 00:00:32,558
которые мы будем изучать.  подробно snli

15
00:00:32,558 --> 00:00:35,520
multi-nli и adversarial nli,

16
00:00:35,520 --> 00:00:37,280
а второй блокнот предлагает

17
00:00:37,280 --> 00:00:39,600
множество различных подходов к моделированию,

18
00:00:39,600 --> 00:00:41,520
он действительно охватывает основные подходы, которые

19
00:00:41,520 --> 00:00:43,760
люди применяли к nli в прошлом, и

20
00:00:43,760 --> 00:00:45,840
я надеюсь, что он указывает на некоторые возможности для

21
00:00:45,840 --> 00:00:48,160
изменения этих архитектур, возможно,

22
00:00:48,160 --> 00:00:49,920
в сервисе  разработки оригинальной

23
00:00:49,920 --> 00:00:52,719
системы для окончательного проекта,

24
00:00:52,719 --> 00:00:54,719
есть также связанная с этим домашняя работа, и

25
00:00:54,719 --> 00:00:56,640
я подчеркиваю, что это не

26
00:00:56,640 --> 00:00:58,719
требуется для нас в этом квартале, я

27
00:00:58,719 --> 00:01:00,239
упоминаю об этом, потому что я думаю

28
00:01:00,239 --> 00:01:02,079
проблема интересная, это

29
00:01:02,079 --> 00:01:03,680
задача вывода слов, которая представляет собой

30
00:01:03,680 --> 00:01:06,080
интересную проблему небольшого масштаба, которую, я

31
00:01:06,080 --> 00:01:08,080
считаю, можно использовать для стресс-тестирования

32
00:01:08,080 --> 00:01:11,600
системы NLI интересными способами.

33
00:01:11,600 --> 00:01:13,680
Основные показания охватывают три набора данных,

34
00:01:13,680 --> 00:01:15,680
которые будут в центре внимания для нас, а

35
00:01:15,680 --> 00:01:17,920
затем  последнее чтение, указанное здесь, было, я

36
00:01:17,920 --> 00:01:19,600
думаю, документом, который представил

37
00:01:19,600 --> 00:01:21,600
механизмы внимания в изучении

38
00:01:21,600 --> 00:01:24,080
nli и оказал влияние,

39
00:01:24,080 --> 00:01:26,400
выходящее далеко за рамки этой задачи,

40
00:01:26,400 --> 00:01:28,080
а затем для дополнительных чтений я как

41
00:01:28,080 --> 00:01:30,320
бы предлагаю ряд вещей,

42
00:01:30,320 --> 00:01:32,000
которые охватывают некоторые из этих чтений.

43
00:01:32,000 --> 00:01:33,520
основные принципы глубокого обучения, которые, как я

44
00:01:33,520 --> 00:01:35,280
думаю, будут полезны в контексте

45
00:01:35,280 --> 00:01:36,960
изучения НЛИ,

46
00:01:36,960 --> 00:01:38,479
некоторые из них помогут вам получить

47
00:01:38,479 --> 00:01:40,400
базовое понимание задачи НЛИ

48
00:01:40,400 --> 00:01:42,399
и того, как вы можете думать об этом,

49
00:01:42,399 --> 00:01:44,079
а затем некоторые из них предназначены для того, чтобы как

50
00:01:44,079 --> 00:01:46,479
бы подтолкнуть  мы проводим стресс-тестирование нашей системы,

51
00:01:46,479 --> 00:01:48,560
думаем состязательно и, возможно, находим

52
00:01:48,560 --> 00:01:50,399
артефакты в наших наборах данных, и они

53
00:01:50,399 --> 00:01:52,880
станут темами более поздних скринкастов

54
00:01:52,880 --> 00:01:55,680
в этой серии,

55
00:01:55,680 --> 00:01:57,119
чтобы начать получать представление.  Чтобы понять, как

56
00:01:57,119 --> 00:01:58,960
сформулирована задача, давайте начнем с нескольких

57
00:01:58,960 --> 00:02:00,880
простых примеров,

58
00:02:00,880 --> 00:02:03,280
поэтому в nli мы имеем в качестве входных данных

59
00:02:03,280 --> 00:02:05,040
предпосылку и гипотезу,

60
00:02:05,040 --> 00:02:06,399
а задача является

61
00:02:06,399 --> 00:02:08,720
классификационной, поэтому в этом простом

62
00:02:08,720 --> 00:02:10,479
примере предпосылкой является

63
00:02:10,479 --> 00:02:12,959
танец черепахи.  гипотеза

64
00:02:12,959 --> 00:02:14,720
предложение черепаха переместилась оба из них являются входными данными системы,

65
00:02:14,720 --> 00:02:17,200
и наша задача состоит в том, чтобы присвоить одну из

66
00:02:17,200 --> 00:02:18,879
трех меток, в этом случае правильная

67
00:02:18,879 --> 00:02:22,160
метка будет в

68
00:02:22,160 --> 00:02:23,920
хвосте второй пример выглядит просто, но на

69
00:02:23,920 --> 00:02:25,920
самом деле он начинает подсказывать, как на

70
00:02:25,920 --> 00:02:27,599
самом деле формулируется задача мы  иметь в качестве нашей

71
00:02:27,599 --> 00:02:30,319
предпосылки черепаху и в качестве нашего

72
00:02:30,319 --> 00:02:32,480
лингвиста-гипотезы, и что мы хотели бы сделать

73
00:02:32,480 --> 00:02:34,480
в контексте nli, так это назначить, что

74
00:02:34,480 --> 00:02:36,800
метка противоречия теперь вы можете сделать

75
00:02:36,800 --> 00:02:39,360
паузу и подумать, что это не логический факт,

76
00:02:39,360 --> 00:02:41,599
что черепахи не могут быть лингвистами, так что,

77
00:02:41,599 --> 00:02:43,680
безусловно, противоречие  слишком сильно, но

78
00:02:43,680 --> 00:02:45,680
это факт здравого смысла, своего рода

79
00:02:45,680 --> 00:02:47,440
естественный вывод о мире, в котором мы

80
00:02:47,440 --> 00:02:49,519
живем, что никакие черепахи не являются лингвистами,

81
00:02:49,519 --> 00:02:51,120
и именно по этой причине мы бы

82
00:02:51,120 --> 00:02:52,720
выбрали  ярлык «противоречие», и это

83
00:02:52,720 --> 00:02:54,400
начинает подводить к тому факту, что в

84
00:02:54,400 --> 00:02:57,040
основе своей nli — это не задача логического

85
00:02:57,040 --> 00:02:59,840
рассуждения, а более общая

86
00:02:59,840 --> 00:03:02,959
задача рассуждения здравого смысла.

87
00:03:03,040 --> 00:03:05,280


88
00:03:05,280 --> 00:03:06,879


89
00:03:06,879 --> 00:03:08,560


90
00:03:08,560 --> 00:03:10,640
истинно или ложно независимо друг от

91
00:03:10,640 --> 00:03:11,519
друга,

92
00:03:11,519 --> 00:03:13,519
и теперь с влечет за собой противоречит нейтральному

93
00:03:13,519 --> 00:03:15,040
у нас есть три метки, которые

94
00:03:15,040 --> 00:03:17,599
стандартно используются для наборов данных nli на

95
00:03:17,599 --> 00:03:20,080
данный момент

96
00:03:20,080 --> 00:03:22,000
посмотрите на некоторые дополнительные примеры некоторые

97
00:03:22,000 --> 00:03:24,239
черепахи ходят противоречит никакие черепахи не двигаются

98
00:03:24,239 --> 00:03:26,640
я думаю это просто

99
00:03:26,640 --> 00:03:28,480
вот тот, который показывает как  запутанным это

100
00:03:28,480 --> 00:03:30,879
может стать, поэтому предпосылка заключается в том, что Джеймс Байрон

101
00:03:30,879 --> 00:03:33,360
Дин отказался двигаться без синих джинсов

102
00:03:33,360 --> 00:03:35,599
влечет за собой, что Джеймс Дин не танцевал без

103
00:03:35,599 --> 00:03:37,440
штанов, это подчеркивает два аспекта

104
00:03:37,440 --> 00:03:39,760
проблемы, во-первых, вам, возможно, придется выполнить какое-то

105
00:03:39,760 --> 00:03:42,319
сложное распознавание именованных сущностей на

106
00:03:42,319 --> 00:03:44,400
Джеймсе Байроне Дине и Джеймсе.  декана, чтобы

107
00:03:44,400 --> 00:03:46,159
понять, что это сонаправленные

108
00:03:46,159 --> 00:03:47,440
выражения,

109
00:03:47,440 --> 00:03:49,040
и вы также можете столкнуться с реальной

110
00:03:49,040 --> 00:03:50,720
лингвистической сложностью  в этом случае,

111
00:03:50,720 --> 00:03:52,400
подчеркивая вещи, связанные с тем, как

112
00:03:52,400 --> 00:03:55,840
отрицания взаимодействуют друг с другом,

113
00:03:55,840 --> 00:03:57,760
этот следующий пример начинает показывать,

114
00:03:57,760 --> 00:03:59,840
сколько рассуждений здравого смысла можно было

115
00:03:59,840 --> 00:04:02,000
бы привнести в задачу, поэтому предпосылка

116
00:04:02,000 --> 00:04:04,640
заключается в том, что продажи новых автомобилей Mitsubishi в США

117
00:04:04,640 --> 00:04:08,080
упали 46 в июне, и гипотеза заключается в том,

118
00:04:08,080 --> 00:04:11,200
что Mitsubishi  продажи выросли на 46,

119
00:04:11,200 --> 00:04:13,120
мы бы стандартно сказали, что

120
00:04:13,120 --> 00:04:15,200
это противоречие. Теперь вы снова

121
00:04:15,200 --> 00:04:17,440
можете остановиться и подумать, что

122
00:04:17,440 --> 00:04:19,440
даже в нашем мире вполне возможно, что

123
00:04:19,440 --> 00:04:22,560
Mitsubishi может увидеть рост и падение на 46

124
00:04:22,560 --> 00:04:24,720
в одном и том же месяце, поэтому, безусловно, их

125
00:04:24,720 --> 00:04:26,400
следует назвать нейтральными,

126
00:04:26,400 --> 00:04:28,800
но  я думаю, что вы обнаружите в

127
00:04:28,800 --> 00:04:30,240
наборах данных nli то, что они называются

128
00:04:30,240 --> 00:04:32,800
противоречиями в неформальном предположении,

129
00:04:32,800 --> 00:04:34,639
что посылка и гипотеза

130
00:04:34,639 --> 00:04:36,639
говорят об одном и том же событии,

131
00:04:36,639 --> 00:04:38,160
и в этом контексте мы бы сказали, что

132
00:04:38,160 --> 00:04:41,600
это противоречия здравого смысла,

133
00:04:41,600 --> 00:04:43,040
вот еще один пример, который подчеркивает

134
00:04:43,040 --> 00:04:44,639
сколько прагматики можно было бы привнести

135
00:04:44,639 --> 00:04:46,800
в проблему, посылка акме

136
00:04:46,800 --> 00:04:49,199
сообщила, что ее генеральный директор ушел в отставку, и

137
00:04:49,199 --> 00:04:52,160
гипотеза  является то, что acme ceo ушел в отставку,

138
00:04:52,160 --> 00:04:54,639
мы, вероятно, сказали бы, что это следствие,

139
00:04:54,639 --> 00:04:56,639
хотя в строгом логическом смысле

140
00:04:56,639 --> 00:04:58,720
посылка не влечет за собой гипотезу,

141
00:04:58,720 --> 00:05:00,639
потому что, конечно, компания может

142
00:05:00,639 --> 00:05:02,960
сообщать вещи, которые являются ложными, но здесь

143
00:05:02,960 --> 00:05:04,960
мы как бы делаем предположение, что

144
00:05:04,960 --> 00:05:07,039
компания  авторитетом и,

145
00:05:07,039 --> 00:05:09,280
вероятно, будет сообщать правдивые вещи о подобных фактах,

146
00:05:09,280 --> 00:05:11,440
и поэтому мы допускаем, что

147
00:05:11,440 --> 00:05:13,360
это было бы в отношении следствия

148
00:05:13,360 --> 00:05:15,759
снова не логично, а гораздо больше похоже на

149
00:05:15,759 --> 00:05:17,759
здравый смысл,

150
00:05:17,759 --> 00:05:19,520
поэтому просто чтобы подчеркнуть это, вот своего

151
00:05:19,520 --> 00:05:21,199
рода фундаментальный вопрос, с которым мы

152
00:05:21,199 --> 00:05:23,919
сталкиваемся, делает предпосылку  обосновать

153
00:05:23,919 --> 00:05:26,080
вывод гипотезы, опираясь на

154
00:05:26,080 --> 00:05:28,080
здравый смысл, а не на

155
00:05:28,080 --> 00:05:29,919
строгую логику.

156
00:05:29,919 --> 00:05:31,840
Две другие характеристики этой задачи

157
00:05:31,840 --> 00:05:33,520
в современную эпоху: во-первых,

158
00:05:33,520 --> 00:05:35,759
внимание сосредоточено на шагах локального вывода, которые представляют собой

159
00:05:35,759 --> 00:05:38,320
всего одну предпосылку и одну гипотезу,

160
00:05:38,320 --> 00:05:41,039
а не длинные дедуктивные цепочки,

161
00:05:41,039 --> 00:05:42,720
а второе заключается в том, что  упор

162
00:05:42,720 --> 00:05:44,720
действительно делается на вариативность языковых

163
00:05:44,720 --> 00:05:46,560
выражений, когда люди создали

164
00:05:46,560 --> 00:05:49,120
большую скамью.  ковчег в этой области они в

165
00:05:49,120 --> 00:05:51,120
основном сосредоточились на простом

166
00:05:51,120 --> 00:05:52,400
сборе большого количества данных

167
00:05:52,400 --> 00:05:54,960
и не уделяли особого внимания

168
00:05:54,960 --> 00:05:56,880
сбору примеров, которые имеют много

169
00:05:56,880 --> 00:05:59,280
отрицаний или квантификаторов или что-то

170
00:05:59,280 --> 00:06:01,360
, что действительно пролило бы свет на

171
00:06:01,360 --> 00:06:03,680
лингвистическую и семантическую сложность, так

172
00:06:03,680 --> 00:06:05,280
что это стоит сохранить.  иметь в виду, как

173
00:06:05,280 --> 00:06:07,120
мы думаем о задаче

174
00:06:07,120 --> 00:06:09,680
в настоящее время,

175
00:06:09,680 --> 00:06:10,800
если вы хотите получить дополнительные

176
00:06:10,800 --> 00:06:12,800
точки зрения на это, включая некоторые

177
00:06:12,800 --> 00:06:14,479
споры о том, как именно думать

178
00:06:14,479 --> 00:06:15,840
о проблеме и что было бы

179
00:06:15,840 --> 00:06:17,440
наиболее продуктивно, я бы посоветовал вам

180
00:06:17,440 --> 00:06:19,440
проверить эти три  работы многих

181
00:06:19,440 --> 00:06:21,440
стэнфордских исследователей,

182
00:06:21,440 --> 00:06:23,120
я думаю, что основным результатом этого

183
00:06:23,120 --> 00:06:24,800
является то, что мы действительно хотим сосредоточиться на

184
00:06:24,800 --> 00:06:26,639
рассуждениях здравого смысла, хотя это своего

185
00:06:26,639 --> 00:06:29,039
рода аморфная и трудная для

186
00:06:29,039 --> 00:06:32,160
определения концепция, тем не менее, возможно,

187
00:06:32,160 --> 00:06:34,240
полезная для нас, когда мы думаем

188
00:06:34,240 --> 00:06:38,080
о разработке  Практические системы

189
00:06:38,800 --> 00:06:40,880
теперь в дальновидной статье, которая действительно

190
00:06:40,880 --> 00:06:44,560
определила повестку дня для Нли Дога и Адольфа 2006 года,

191
00:06:44,560 --> 00:06:46,639
они делают много  Различия между

192
00:06:46,639 --> 00:06:49,280
nli и более широким ландшафтом nlu, так что

193
00:06:49,280 --> 00:06:50,880
позвольте мне просто прочитать это вступительное заявление

194
00:06:50,880 --> 00:06:53,599
здесь, кажется, что основные выводы,

195
00:06:53,599 --> 00:06:56,000
необходимые для нескольких приложений,

196
00:06:56,000 --> 00:06:57,919
действительно могут быть сделаны в терминах текстовых

197
00:06:57,919 --> 00:06:59,039


198
00:06:59,039 --> 00:07:01,440
следствий, следовательно, мы предполагаем, что

199
00:07:01,440 --> 00:07:03,039
распознавание текстовых следов является подходящей

200
00:07:03,039 --> 00:07:05,520
общей задачей для  оценка и

201
00:07:05,520 --> 00:07:07,520
сравнение прикладных моделей семантического вывода, в

202
00:07:07,520 --> 00:07:09,440
конечном счете, такие усилия могут

203
00:07:09,440 --> 00:07:11,360
способствовать развитию механизмов распознавания следствий,

204
00:07:11,360 --> 00:07:13,520
которые могут предоставлять

205
00:07:13,520 --> 00:07:15,520
полезные универсальные модули для

206
00:07:15,520 --> 00:07:16,800
приложений.

207
00:07:16,800 --> 00:07:18,560


208
00:07:18,560 --> 00:07:20,960


209
00:07:20,960 --> 00:07:23,039
заключается в том, что,

210
00:07:23,039 --> 00:07:23,759


211
00:07:23,759 --> 00:07:25,280
поскольку рассуждения о следствии и

212
00:07:25,280 --> 00:07:27,520
противоречии действительно фундаментальны для

213
00:07:27,520 --> 00:07:30,080
нашего использования языка, предварительная подготовка

214
00:07:30,080 --> 00:07:31,680
к задаче nli может дать нам

215
00:07:31,680 --> 00:07:33,599
представления,

216
00:07:33,599 --> 00:07:36,960
полезные во многих различных контекстах,

217
00:07:36,960 --> 00:07:38,880
и документ фактически продолжится,

218
00:07:38,880 --> 00:07:41,039
показывая, что мы можем формулировать много

219
00:07:41,039 --> 00:07:44,000
традиционных задач в виде nli-тестов, а

220
00:07:44,000 --> 00:07:46,160
вот  лишь несколько примеров того, что если нашей

221
00:07:46,160 --> 00:07:48,639
задачей является перефразирование, мы могли бы сказать, что в

222
00:07:48,639 --> 00:07:50,560
контексте nli это означает, что мы хотим

223
00:07:50,560 --> 00:07:53,120
равенства или взаимного следования

224
00:07:53,120 --> 00:07:54,879
между текстом и перефразированием, которое является

225
00:07:54,879 --> 00:07:57,280
предпосылкой и гипотезой

226
00:07:57,280 --> 00:07:58,960
для обобщения, мы бы сделали что-то

227
00:07:58,960 --> 00:08:00,800
более слабое, мы бы надеялись именно на это

228
00:08:00,800 --> 00:08:03,520
текст исходный текст влек за собой резюме,

229
00:08:03,520 --> 00:08:05,280
допуская, что резюме может быть

230
00:08:05,280 --> 00:08:07,520
более слабым или более общим

231
00:08:07,520 --> 00:08:09,280
для поиска информации, мы как бы

232
00:08:09,280 --> 00:08:10,879
делаем обратное здесь, мы хотим найти

233
00:08:10,879 --> 00:08:14,400
документы, которые влекут за собой запрос,

234
00:08:14,400 --> 00:08:15,759
а затем для ответа на вопрос это

235
00:08:15,759 --> 00:08:17,280
похоже на то, что мы могли бы сформулировать, что

236
00:08:17,280 --> 00:08:18,720
в качестве теста на следствия, сказав,

237
00:08:18,720 --> 00:08:20,960
что мы хотим найти ответы, которые

238
00:08:20,960 --> 00:08:23,120
влекут за собой вопрос, и то, как мы можем

239
00:08:23,120 --> 00:08:24,800
думать о следствии для вопросов, как

240
00:08:24,800 --> 00:08:26,960
бы проиллюстрировано здесь, где мы

241
00:08:26,960 --> 00:08:29,120
неформально преобразовали бы вопрос, например, кто

242
00:08:29,120 --> 00:08:31,680
ушел, в кого-то, кто ушел, чтобы дать нам

243
00:08:31,680 --> 00:08:33,599
утверждение, и тогда мы могли бы сказать, что

244
00:08:33,599 --> 00:08:36,880
Sandy Left — это ответ на вопрос, кто ушел, в

245
00:08:36,880 --> 00:08:40,000
том смысле, что это означает, что кто-то ушел,

246
00:08:40,000 --> 00:08:41,599
и я думаю, что есть  многие другие задачи,

247
00:08:41,599 --> 00:08:43,360
которые мы могли бы сформулировать таким образом, и

248
00:08:43,360 --> 00:08:45,839
это действительно показывает вам, насколько фундаментальны

249
00:08:45,839 --> 00:08:48,080
следствия и противоречия

250
00:08:48,080 --> 00:08:51,440
для рассуждений и языка,

251
00:08:51,440 --> 00:08:52,959
и, наконец, позвольте мне дать вам представление

252
00:08:52,959 --> 00:08:54,560
о модельном ландшафте и о том, как он

253
00:08:54,560 --> 00:08:57,120
изменился. Это довольно старая проблема в

254
00:08:57,120 --> 00:08:59,519
области, и в результате мы видели

255
00:08:59,519 --> 00:09:02,000
широкий спектр различных подходов

256
00:09:02,000 --> 00:09:03,839
в первые дни, у вас было много

257
00:09:03,839 --> 00:09:05,519
систем, которые были как бы сосредоточены на

258
00:09:05,519 --> 00:09:07,519
логике и доказательстве теорем. Я

259
00:09:07,519 --> 00:09:09,440
охарактеризовал эти системы здесь как

260
00:09:09,440 --> 00:09:12,399
предлагающие действительно глубокие представления, но

261
00:09:12,399 --> 00:09:14,160
они  были не особенно эффективны в том

262
00:09:14,160 --> 00:09:15,839
смысле, что они работали только для

263
00:09:15,839 --> 00:09:18,000
областей и примеров, которые

264
00:09:18,000 --> 00:09:20,240
проектировщики системы могли предвидеть, поэтому

265
00:09:20,240 --> 00:09:22,320
они довольно жестоки,

266
00:09:22,320 --> 00:09:24,640
следуя за тем, что у вас есть своего рода

267
00:09:24,640 --> 00:09:26,880
исследование того, что Билл Маккартни

268
00:09:26,880 --> 00:09:28,880
назвал естественной логикой.  Подходы Билл был

269
00:09:28,880 --> 00:09:30,240
одним из

270
00:09:30,240 --> 00:09:31,920
первых новаторов в этой области, я думаю, что

271
00:09:31,920 --> 00:09:33,440
он фактически ввел термин естественно-

272
00:09:33,440 --> 00:09:35,200
языковой вывод, и он исследовал

273
00:09:35,200 --> 00:09:36,959
естественную логику, которая имеет некоторые  е

274
00:09:36,959 --> 00:09:39,760
аспектов логики и доказательства теорем, но

275
00:09:39,760 --> 00:09:41,360
они более открыты и легко

276
00:09:41,360 --> 00:09:44,720
поддаются обработке большого количества данных,

277
00:09:44,720 --> 00:09:46,320
и поэтому эти системы, следовательно, были

278
00:09:46,320 --> 00:09:48,399
немного менее глубокими, но также более эффективными,

279
00:09:48,399 --> 00:09:49,680
и то же самое произошло с

280
00:09:49,680 --> 00:09:51,920
семантическими графами, которые предоставляют

281
00:09:51,920 --> 00:09:54,080
богатые концептуальные представления

282
00:09:54,080 --> 00:09:55,839
базовой области, о которой мы хотим

283
00:09:55,839 --> 00:09:57,440
рассказать,

284
00:09:57,440 --> 00:09:59,519
еще одна интересная вещь заключается в том, что

285
00:09:59,519 --> 00:10:00,480
вы знаете, что

286
00:10:00,480 --> 00:10:02,560
до недавнего времени

287
00:10:02,560 --> 00:10:04,640
это был случай, когда умные ручные

288
00:10:04,640 --> 00:10:06,320
функции, которые я покажу вам немного

289
00:10:06,320 --> 00:10:08,800
позже в этой серии скринкастов,

290
00:10:08,800 --> 00:10:10,560
они  действительно лидировали, и простые

291
00:10:10,560 --> 00:10:12,320
вариации инграмм, вы знаете, традиционные

292
00:10:12,320 --> 00:10:14,880
модели с функциями, созданными вручную, они

293
00:10:14,880 --> 00:10:16,640
были лучшими моделями,

294
00:10:16,640 --> 00:10:18,800
в начале революции глубокого обучения существовала своего рода вера в

295
00:10:18,800 --> 00:10:20,399
то, что в

296
00:10:20,399 --> 00:10:22,160
конечном итоге эти модели

297
00:10:22,160 --> 00:10:24,880
окажутся лучшими в этой задаче.  но в то время

298
00:10:24,880 --> 00:10:26,640
у нас просто не было наборов данных,

299
00:10:26,640 --> 00:10:28,480
которые бы

300
00:10:28,480 --> 00:10:31,040
подтверждали это утверждение,

301
00:10:31,040 --> 00:10:32,720
и в результате какое-то время глубоко

302
00:10:32,720 --> 00:10:34,320
системы обучения действительно отставали от

303
00:10:34,320 --> 00:10:36,399
этих более традиционных подходов, и я

304
00:10:36,399 --> 00:10:37,839
бы сказал, что примерно в

305
00:10:37,839 --> 00:10:40,160
2017 году глубокое обучение вырвалось вперед, и

306
00:10:40,160 --> 00:10:42,640
это стало результатом инноваций в моделировании,

307
00:10:42,640 --> 00:10:44,959
а также появления некоторых действительно

308
00:10:44,959 --> 00:10:46,720
больших наборов контрольных данных, которые

309
00:10:46,720 --> 00:10:49,040
позволили бы нам обучать системы.

310
00:10:49,040 --> 00:10:51,040
которые были эффективны для задачи, и

311
00:10:51,040 --> 00:10:52,399
именно в этот момент вы видите, что глубокое

312
00:10:52,399 --> 00:10:54,079
обучение взяло верх,

313
00:10:54,079 --> 00:10:55,920
и в результате в последующих

314
00:10:55,920 --> 00:10:57,839
скринкастах мы также сосредоточимся на

315
00:10:57,839 --> 00:11:00,240
архитектурах глубокого обучения для проблемы nli.

316
00:11:00,240 --> 00:11:03,240


