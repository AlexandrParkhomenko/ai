1
00:00:02,390 --> 00:00:05,499
[Music]

2
00:00:07,510 --> 00:00:12,939
[Music]

3
00:01:02,870 --> 00:01:08,959
[Music]

4
00:01:27,990 --> 00:01:31,459
[Music]

5
00:01:35,490 --> 00:01:38,800
[Music]

6
00:01:49,320 --> 00:01:53,930
[Music]

7
00:02:01,020 --> 00:02:04,200
[Music]

8
00:02:14,840 --> 00:02:17,909
[Music]

9
00:02:22,140 --> 00:02:32,340
[Music]

10
00:02:57,500 --> 00:04:10,090
[Music]

11
00:04:10,090 --> 00:04:13,270
[Applause]

12
00:04:16,500 --> 00:04:26,590
[Music]

13
00:04:26,590 --> 00:04:27,740
[Applause]

14
00:04:27,740 --> 00:04:57,779
[Music]

15
00:05:02,920 --> 00:05:06,009
[Music]

16
00:05:24,880 --> 00:05:30,720
[Music]

17
00:05:30,720 --> 00:05:32,650
so

18
00:05:32,650 --> 00:05:52,250
[Music]

19
00:05:57,100 --> 00:06:19,399
[Music]

20
00:06:28,340 --> 00:06:49,230
[Music]

21
00:06:55,940 --> 00:07:02,670
[Music]

22
00:07:25,090 --> 00:07:46,790
[Music]

23
00:07:55,750 --> 00:08:02,439
[Music]

24
00:08:05,560 --> 00:08:17,249
[Music]

25
00:08:21,530 --> 00:08:59,390
[Music]

26
00:09:01,670 --> 00:10:05,920
[Music]

27
00:10:08,950 --> 00:10:35,489
[Music]

28
00:11:12,440 --> 00:11:15,989
[Music]

29
00:11:23,980 --> 00:11:27,100
[Music]

30
00:11:37,350 --> 00:11:45,470
[Music]

31
00:11:56,330 --> 00:12:10,460
[Music]

32
00:12:13,060 --> 00:12:16,100
[Music]

33
00:12:25,320 --> 00:12:35,429
[Music]

34
00:12:37,590 --> 00:12:54,399
[Music]

35
00:12:54,399 --> 00:12:56,320
i'm not the man you want you've made a

36
00:12:56,320 --> 00:12:58,079
mistake

37
00:12:58,079 --> 00:13:00,160
i'm in touch with technological advances

38
00:13:00,160 --> 00:13:01,920
pretty well everywhere and i can tell

39
00:13:01,920 --> 00:13:03,600
you that no one has produced anything

40
00:13:03,600 --> 00:13:06,839
like this

41
00:13:10,480 --> 00:13:15,789
[Music]

42
00:13:20,130 --> 00:13:39,349
[Music]

43
00:13:44,450 --> 00:13:47,539
[Music]

44
00:13:52,630 --> 00:14:24,830
[Music]

45
00:14:40,330 --> 00:14:43,409
[Music]

46
00:14:46,350 --> 00:15:06,149
[Music]

47
00:15:08,260 --> 00:15:31,459
[Music]

48
00:15:37,460 --> 00:15:54,710
[Music]

49
00:16:13,120 --> 00:16:16,120
so

50
00:16:21,120 --> 00:16:24,220
[Music]

51
00:16:45,500 --> 00:16:59,759
[Music]

52
00:17:05,170 --> 00:17:36,880
[Music]

53
00:17:38,160 --> 00:17:41,160
oh

54
00:17:42,670 --> 00:17:48,069
[Music]

55
00:17:51,200 --> 00:17:54,200
so

56
00:18:20,180 --> 00:18:36,630
[Music]

57
00:18:37,520 --> 00:18:39,890
wow

58
00:18:39,890 --> 00:18:49,059
[Music]

59
00:18:51,120 --> 00:18:54,200
[Music]

60
00:19:07,039 --> 00:19:10,039
armed

61
00:19:17,919 --> 00:19:20,919
do

62
00:19:22,810 --> 00:19:25,839
[Music]

63
00:19:42,610 --> 00:19:45,640
[Music]

64
00:19:48,080 --> 00:19:51,080
i'm

65
00:19:58,240 --> 00:20:01,240
um

66
00:20:40,799 --> 00:20:43,799
armed

67
00:20:52,770 --> 00:21:00,589
[Music]

68
00:21:15,920 --> 00:21:55,049
[Music]

69
00:22:02,720 --> 00:22:05,310
so

70
00:22:05,310 --> 00:22:19,319
[Music]

71
00:22:23,530 --> 00:22:45,540
[Music]

72
00:22:47,930 --> 00:23:09,299
[Music]

73
00:23:17,110 --> 00:23:26,050
[Music]

74
00:23:30,600 --> 00:23:37,740
[Music]

75
00:24:04,300 --> 00:24:12,650
[Music]

76
00:24:25,360 --> 00:24:26,440
so

77
00:24:26,440 --> 00:24:29,660
[Music]

78
00:24:34,170 --> 00:24:37,249
[Music]

79
00:24:49,480 --> 00:24:52,640
[Music]

80
00:24:59,410 --> 00:25:02,529
[Music]

81
00:25:14,650 --> 00:25:17,809
[Music]

82
00:25:21,320 --> 00:25:24,440
[Music]

83
00:25:26,450 --> 00:25:31,869
[Music]

84
00:26:21,810 --> 00:26:27,900
[Music]

85
00:26:46,920 --> 00:26:50,400
[Music]

86
00:26:54,430 --> 00:26:57,739
[Music]

87
00:27:08,200 --> 00:27:12,809
[Music]

88
00:27:19,910 --> 00:27:23,079
[Music]

89
00:27:33,730 --> 00:27:36,799
[Music]

90
00:27:41,010 --> 00:27:51,229
[Music]

91
00:28:16,380 --> 00:28:28,370
[Music]

92
00:28:28,370 --> 00:28:29,080
[Applause]

93
00:28:29,080 --> 00:29:04,080
[Music]

94
00:29:04,080 --> 00:29:05,270
so

95
00:29:05,270 --> 00:29:16,990
[Music]

96
00:29:17,919 --> 00:29:20,919
so

97
00:29:23,970 --> 00:29:28,970
[Music]

98
00:29:28,970 --> 00:29:32,119
[Applause]

99
00:29:35,390 --> 00:29:45,470
[Music]

100
00:29:45,470 --> 00:29:46,610
[Applause]

101
00:29:46,610 --> 00:30:16,680
[Music]

102
00:30:18,840 --> 00:30:24,900
[Music]

103
00:30:42,240 --> 00:30:43,770
so

104
00:30:43,770 --> 00:31:38,279
[Music]

105
00:31:45,410 --> 00:31:50,000
[Music]

106
00:31:50,000 --> 00:31:52,130
so

107
00:31:52,130 --> 00:31:55,380
[Music]

108
00:31:57,660 --> 00:32:06,559
[Music]

109
00:32:06,559 --> 00:32:09,559
so

110
00:32:14,830 --> 00:32:17,880
[Music]

111
00:32:20,000 --> 00:32:23,000
so

112
00:32:24,420 --> 00:32:27,559
[Music]

113
00:32:43,970 --> 00:33:05,680
[Music]

114
00:33:07,690 --> 00:33:10,769
[Music]

115
00:33:14,640 --> 00:33:16,559
[Music]

116
00:33:16,559 --> 00:33:17,840
so

117
00:33:17,840 --> 00:33:20,890
[Music]

118
00:33:24,450 --> 00:33:36,119
[Music]

119
00:33:40,410 --> 00:34:18,280
[Music]

120
00:34:20,550 --> 00:35:54,380
[Music]

121
00:36:31,330 --> 00:36:34,869
[Music]

122
00:36:42,870 --> 00:36:45,980
[Music]

123
00:36:56,240 --> 00:37:00,250
[Music]

124
00:37:15,210 --> 00:37:29,350
[Music]

125
00:37:44,210 --> 00:37:48,360
[Music]

126
00:37:51,180 --> 00:37:54,320
[Music]

127
00:37:56,480 --> 00:38:13,280
[Music]

128
00:38:13,280 --> 00:38:16,960
i'm not the man you want you've made a

129
00:38:16,960 --> 00:38:18,480
i'm in touch with mistake

130
00:38:18,480 --> 00:38:20,480
advisors pretty well everywhere and i

131
00:38:20,480 --> 00:38:22,160
can tell you that no one has produced

132
00:38:22,160 --> 00:38:25,720
anything like this

133
00:38:29,370 --> 00:38:34,679
[Music]

134
00:38:39,020 --> 00:38:58,230
[Music]

135
00:39:03,350 --> 00:39:20,260
[Music]

136
00:39:21,359 --> 00:39:23,300
so

137
00:39:23,300 --> 00:39:32,340
[Music]

138
00:39:35,680 --> 00:39:38,650
so

139
00:39:38,650 --> 00:39:43,850
[Music]

140
00:39:50,000 --> 00:39:53,000
so

141
00:39:58,400 --> 00:40:22,690
[Music]

142
00:40:22,690 --> 00:40:23,180
[Applause]

143
00:40:23,180 --> 00:40:43,720
[Music]

144
00:40:43,720 --> 00:40:46,800
[Applause]

145
00:40:46,800 --> 00:40:52,720
[Music]

146
00:40:52,720 --> 00:40:53,330
[Applause]

147
00:40:53,330 --> 00:41:20,859
[Music]

148
00:41:31,280 --> 00:41:34,280
foreign

149
00:41:36,319 --> 00:41:39,319
so

150
00:41:46,230 --> 00:41:53,869
[Music]

151
00:42:02,000 --> 00:42:54,510
[Music]

152
00:42:56,960 --> 00:42:59,960
um

153
00:43:01,480 --> 00:43:06,820
[Music]

154
00:43:15,119 --> 00:43:18,119
so

155
00:43:30,800 --> 00:43:33,800
so

156
00:43:35,680 --> 00:43:55,440
[Music]

157
00:43:58,670 --> 00:44:04,050
[Music]

158
00:44:06,640 --> 00:44:09,390
you

159
00:44:09,390 --> 00:44:12,989
[Music]

160
00:44:15,790 --> 00:44:19,090
[Music]

161
00:44:25,839 --> 00:44:28,839
armed

162
00:44:41,610 --> 00:44:44,629
[Music]

163
00:44:55,510 --> 00:44:58,549
[Music]

164
00:45:01,410 --> 00:45:07,820
[Music]

165
00:45:12,950 --> 00:45:16,070
[Music]

166
00:45:17,119 --> 00:45:19,839
um

167
00:45:31,620 --> 00:45:34,730
[Music]

168
00:45:50,260 --> 00:45:59,599
[Music]

169
00:45:59,599 --> 00:46:02,599
armed

170
00:46:09,280 --> 00:46:20,620
[Music]

171
00:46:32,600 --> 00:46:48,880
[Music]

172
00:46:48,880 --> 00:46:51,880
do

173
00:46:54,210 --> 00:47:09,680
[Music]

174
00:47:09,680 --> 00:47:12,640
hello everyone uh sorry for the delay um

175
00:47:12,640 --> 00:47:14,079
thanks for coming

176
00:47:14,079 --> 00:47:16,240
and um sorry i had some technical

177
00:47:16,240 --> 00:47:17,760
difficulties

178
00:47:17,760 --> 00:47:20,240
really neat ai for this

179
00:47:20,240 --> 00:47:22,480
so uh what we want to

180
00:47:22,480 --> 00:47:25,440
show today is that tesla is

181
00:47:25,440 --> 00:47:27,440
much more than an electric car company

182
00:47:27,440 --> 00:47:28,880
that we have

183
00:47:28,880 --> 00:47:30,960
deep ai activity

184
00:47:30,960 --> 00:47:32,400
in

185
00:47:32,400 --> 00:47:34,800
hardware on the inference level on the

186
00:47:34,800 --> 00:47:36,400
training level

187
00:47:36,400 --> 00:47:38,000
and

188
00:47:38,000 --> 00:47:39,119
basically we

189
00:47:39,119 --> 00:47:40,640
i think we're

190
00:47:40,640 --> 00:47:42,800
i think arguably the leaders in real

191
00:47:42,800 --> 00:47:45,359
world ai as it applies to the real world

192
00:47:45,359 --> 00:47:46,400
um

193
00:47:46,400 --> 00:47:48,160
and those of you who have seen the full

194
00:47:48,160 --> 00:47:49,359
self-driving

195
00:47:49,359 --> 00:47:52,319
beta i can appreciate the rate at which

196
00:47:52,319 --> 00:47:53,680
the tesla

197
00:47:53,680 --> 00:47:56,240
neural net is learning to to drive

198
00:47:56,240 --> 00:47:57,599
and um

199
00:47:57,599 --> 00:47:59,760
so this is a particular application of

200
00:47:59,760 --> 00:48:01,599
ai but i think there's there's more

201
00:48:01,599 --> 00:48:03,520
there are more applications uh down the

202
00:48:03,520 --> 00:48:05,760
road that will make sense and we'll talk

203
00:48:05,760 --> 00:48:08,240
about that later in the presentation

204
00:48:08,240 --> 00:48:09,760
but um

205
00:48:09,760 --> 00:48:11,359
yeah we basically want to encourage

206
00:48:11,359 --> 00:48:13,040
anyone who is interested in

207
00:48:13,040 --> 00:48:15,520
solving real-world ai problems

208
00:48:15,520 --> 00:48:17,040
at either the hardware or the software

209
00:48:17,040 --> 00:48:19,200
level to join tesla or consider drawing

210
00:48:19,200 --> 00:48:20,400
tesla

211
00:48:20,400 --> 00:48:24,640
so let's see we'll start off with andre

212
00:48:30,559 --> 00:48:33,559
great

213
00:48:44,079 --> 00:48:46,480
okay hi everyone um welcome

214
00:48:46,480 --> 00:48:49,440
my name is andre and um i am

215
00:48:49,440 --> 00:48:51,440
i lead the vision team here at tesla

216
00:48:51,440 --> 00:48:53,040
autopilot and i'm incredibly excited to

217
00:48:53,040 --> 00:48:55,520
be here uh to kick off this section

218
00:48:55,520 --> 00:48:57,599
giving you a technical deep dive into

219
00:48:57,599 --> 00:49:00,079
the autopilot stack and showing you all

220
00:49:00,079 --> 00:49:01,520
the under the hood components that go

221
00:49:01,520 --> 00:49:05,040
into making the car drive all by itself

222
00:49:05,040 --> 00:49:06,319
so we're going to start off with the

223
00:49:06,319 --> 00:49:07,839
vision component here

224
00:49:07,839 --> 00:49:09,119
now in division component what we're

225
00:49:09,119 --> 00:49:10,559
trying to do is we're trying to design a

226
00:49:10,559 --> 00:49:12,559
neural network that processes the raw

227
00:49:12,559 --> 00:49:14,000
information

228
00:49:14,000 --> 00:49:15,760
which in our case is the eight cameras

229
00:49:15,760 --> 00:49:17,680
that are positioned around the vehicle

230
00:49:17,680 --> 00:49:19,280
and they send us images and we need to

231
00:49:19,280 --> 00:49:21,200
process that in real time into what we

232
00:49:21,200 --> 00:49:22,960
call the vector space and this is a

233
00:49:22,960 --> 00:49:24,240
three-dimensional representation of

234
00:49:24,240 --> 00:49:26,240
everything you need for driving so this

235
00:49:26,240 --> 00:49:27,520
is the three-dimensional positions of

236
00:49:27,520 --> 00:49:29,760
lines edges curbs

237
00:49:29,760 --> 00:49:31,760
traffic signs traffic lights

238
00:49:31,760 --> 00:49:34,400
cars their positions orientations

239
00:49:34,400 --> 00:49:37,680
depth velocities and so on

240
00:49:39,359 --> 00:49:42,079
so here i'm showing a video of

241
00:49:42,079 --> 00:49:45,559
actually hold on

242
00:49:46,079 --> 00:49:47,839
apologies

243
00:49:47,839 --> 00:49:50,000
so here i'm showing the video of the raw

244
00:49:50,000 --> 00:49:52,640
inputs that come into the stack and then

245
00:49:52,640 --> 00:49:54,640
neural processes that into the vector

246
00:49:54,640 --> 00:49:56,400
space and you are seeing parts of that

247
00:49:56,400 --> 00:49:58,160
vector space rendered in the instrument

248
00:49:58,160 --> 00:50:00,880
cluster on the car

249
00:50:10,000 --> 00:50:11,599
now

250
00:50:11,599 --> 00:50:12,960
what i find kind of fascinating about

251
00:50:12,960 --> 00:50:14,480
this is that we are effectively building

252
00:50:14,480 --> 00:50:17,200
a synthetic animal from the ground up so

253
00:50:17,200 --> 00:50:18,720
the car can be thought of as an animal

254
00:50:18,720 --> 00:50:19,920
it moves around it senses the

255
00:50:19,920 --> 00:50:22,079
environment and uh you know acts

256
00:50:22,079 --> 00:50:24,640
autonomously and intelligently and

257
00:50:24,640 --> 00:50:25,920
we are building all the components from

258
00:50:25,920 --> 00:50:27,760
scratch in-house so we are building of

259
00:50:27,760 --> 00:50:29,119
course all of the mechanical components

260
00:50:29,119 --> 00:50:31,200
of the body the nervous system which is

261
00:50:31,200 --> 00:50:32,720
all the electrical components and for

262
00:50:32,720 --> 00:50:34,880
our purposes the brain of the autopilot

263
00:50:34,880 --> 00:50:37,119
and specifically for this section the

264
00:50:37,119 --> 00:50:39,040
synthetic visual cortex

265
00:50:39,040 --> 00:50:40,559
now the biological visual cortex

266
00:50:40,559 --> 00:50:41,920
actually has quite intricate structure

267
00:50:41,920 --> 00:50:43,599
and a number of areas

268
00:50:43,599 --> 00:50:46,000
that organize the information flow of

269
00:50:46,000 --> 00:50:48,079
this brain and so in particular in our

270
00:50:48,079 --> 00:50:51,119
in your visual cortices

271
00:50:51,119 --> 00:50:53,119
the information hits the

272
00:50:53,119 --> 00:50:54,480
light hits the retina it goes through

273
00:50:54,480 --> 00:50:55,839
the lgn all the way to the back of your

274
00:50:55,839 --> 00:50:58,079
visual cortex goes through areas v1 v2

275
00:50:58,079 --> 00:51:00,079
v4 the it the venture on the dorsal

276
00:51:00,079 --> 00:51:02,079
streams and the information is organized

277
00:51:02,079 --> 00:51:04,800
in a certain layout and so when we are

278
00:51:04,800 --> 00:51:07,520
designing the visual cortex of the car

279
00:51:07,520 --> 00:51:08,960
we also want to design the neural

280
00:51:08,960 --> 00:51:10,240
network architecture of how the

281
00:51:10,240 --> 00:51:13,680
information flows in the system

282
00:51:13,680 --> 00:51:15,599
so the processing starts in the

283
00:51:15,599 --> 00:51:17,760
beginning when light hits our artificial

284
00:51:17,760 --> 00:51:19,760
retina and we are going to process this

285
00:51:19,760 --> 00:51:21,520
information with neural networks now i'm

286
00:51:21,520 --> 00:51:24,319
going to roughly organize this section

287
00:51:24,319 --> 00:51:26,079
chronologically so starting off with

288
00:51:26,079 --> 00:51:27,040
some of the neural networks and what

289
00:51:27,040 --> 00:51:28,400
they looked like roughly four years ago

290
00:51:28,400 --> 00:51:29,839
when i joined the team and how they have

291
00:51:29,839 --> 00:51:31,520
developed over time

292
00:51:31,520 --> 00:51:32,800
so

293
00:51:32,800 --> 00:51:34,160
roughly um

294
00:51:34,160 --> 00:51:35,760
four years ago the car was mostly

295
00:51:35,760 --> 00:51:37,440
driving in a single lane going forward

296
00:51:37,440 --> 00:51:39,680
on the highway and so it had to keep

297
00:51:39,680 --> 00:51:41,040
lane and it had to keep distance away

298
00:51:41,040 --> 00:51:42,800
from the car in front of us and at that

299
00:51:42,800 --> 00:51:45,200
time all of processing was only on

300
00:51:45,200 --> 00:51:47,359
individual image level so a single image

301
00:51:47,359 --> 00:51:48,880
has to be analyzed by a neural net and

302
00:51:48,880 --> 00:51:51,119
make little pieces of the vector space

303
00:51:51,119 --> 00:51:52,400
process that into little pieces of the

304
00:51:52,400 --> 00:51:55,680
vector space so this processing

305
00:51:55,680 --> 00:51:57,920
took the following shape we take a 1280

306
00:51:57,920 --> 00:52:00,480
by 960 input and this is 12 bit integers

307
00:52:00,480 --> 00:52:02,880
streaming in at roughly 36 hertz now

308
00:52:02,880 --> 00:52:04,079
we're going to process that with the

309
00:52:04,079 --> 00:52:06,160
neural network so instantiate a feature

310
00:52:06,160 --> 00:52:08,480
extractor backbone in this case we use

311
00:52:08,480 --> 00:52:10,160
residual neural networks so we have a

312
00:52:10,160 --> 00:52:11,839
stem and a number of residual blocks

313
00:52:11,839 --> 00:52:13,359
connected in series

314
00:52:13,359 --> 00:52:14,960
now the specific class of resnets that

315
00:52:14,960 --> 00:52:17,920
we use are regnets because we like this

316
00:52:17,920 --> 00:52:19,760
is like a very rec nets offer a very

317
00:52:19,760 --> 00:52:21,520
nice design space for neural networks

318
00:52:21,520 --> 00:52:23,200
because they allow you to very nicely

319
00:52:23,200 --> 00:52:26,400
trade off latency and uh accuracy

320
00:52:26,400 --> 00:52:29,599
now these reg nets give us as an output

321
00:52:29,599 --> 00:52:31,200
a number of features at different

322
00:52:31,200 --> 00:52:33,040
resolutions in different scales so in

323
00:52:33,040 --> 00:52:34,400
particular on the very bottom of this

324
00:52:34,400 --> 00:52:36,000
feature hierarchy we have very high

325
00:52:36,000 --> 00:52:37,440
resolution information with very low

326
00:52:37,440 --> 00:52:39,760
channel counts and all the way at the

327
00:52:39,760 --> 00:52:42,480
top we have low spatial low resolution

328
00:52:42,480 --> 00:52:44,880
especially but high channel counts so on

329
00:52:44,880 --> 00:52:46,240
the bottom we have a lot of neurons that

330
00:52:46,240 --> 00:52:47,520
are really scrutinizing the detail of

331
00:52:47,520 --> 00:52:49,520
the image and on the top we have neurons

332
00:52:49,520 --> 00:52:50,960
that can see most of the image and a lot

333
00:52:50,960 --> 00:52:52,640
of that context have a lot of that scene

334
00:52:52,640 --> 00:52:54,640
context

335
00:52:54,640 --> 00:52:56,319
we then like to process this with

336
00:52:56,319 --> 00:52:57,920
feature pyramid networks in our case we

337
00:52:57,920 --> 00:53:00,000
like to use by fbns and they get the

338
00:53:00,000 --> 00:53:02,319
mult they get to multiple scales to talk

339
00:53:02,319 --> 00:53:03,760
to each other effectively and share a

340
00:53:03,760 --> 00:53:05,440
lot of information so for example if

341
00:53:05,440 --> 00:53:07,280
you're a neuron all the way down in the

342
00:53:07,280 --> 00:53:08,480
network and you're looking at a small

343
00:53:08,480 --> 00:53:09,839
patch and you're not sure this is a car

344
00:53:09,839 --> 00:53:11,920
or not it definitely helps to know from

345
00:53:11,920 --> 00:53:13,599
the top players that hey you are

346
00:53:13,599 --> 00:53:14,960
actually in the vanishing point of this

347
00:53:14,960 --> 00:53:16,480
highway and so that helps you

348
00:53:16,480 --> 00:53:19,760
disambiguate that this is probably a car

349
00:53:19,760 --> 00:53:21,440
after a buy fbn and a feature fusion

350
00:53:21,440 --> 00:53:23,920
across scales we then go into task

351
00:53:23,920 --> 00:53:25,920
specific heads so for example if you are

352
00:53:25,920 --> 00:53:27,839
doing object detection we have a one

353
00:53:27,839 --> 00:53:30,319
stage yolo like object detector here

354
00:53:30,319 --> 00:53:32,720
where we initialize a raster and there's

355
00:53:32,720 --> 00:53:34,720
a binary bit per position telling you

356
00:53:34,720 --> 00:53:36,160
whether or not there's a car there and

357
00:53:36,160 --> 00:53:38,160
then in addition to that if there is

358
00:53:38,160 --> 00:53:39,440
here's a bunch of other attributes you

359
00:53:39,440 --> 00:53:41,119
might be interested in so the x y with

360
00:53:41,119 --> 00:53:42,559
height offset or any of the other

361
00:53:42,559 --> 00:53:43,920
attributes like what type of a car is

362
00:53:43,920 --> 00:53:45,359
this and so on

363
00:53:45,359 --> 00:53:47,599
so this is for the detection by itself

364
00:53:47,599 --> 00:53:49,280
now very quickly we discovered that we

365
00:53:49,280 --> 00:53:50,880
don't just want to detect cars we want

366
00:53:50,880 --> 00:53:53,839
to do a large number of tasks so for

367
00:53:53,839 --> 00:53:55,040
example we want to do traffic light

368
00:53:55,040 --> 00:53:56,480
recognition and detection a lane

369
00:53:56,480 --> 00:53:58,800
prediction and so on so very quickly we

370
00:53:58,800 --> 00:54:00,319
conversion this kind of architectural

371
00:54:00,319 --> 00:54:02,079
layout where there's a common shared

372
00:54:02,079 --> 00:54:04,000
backbone and then branches off into a

373
00:54:04,000 --> 00:54:05,839
number of heads so

374
00:54:05,839 --> 00:54:07,839
we call these uh therefore hydronets and

375
00:54:07,839 --> 00:54:10,640
these are the heads of the hydra

376
00:54:10,640 --> 00:54:11,839
now

377
00:54:11,839 --> 00:54:13,520
this architectural layout has a number

378
00:54:13,520 --> 00:54:16,240
of benefits so number one

379
00:54:16,240 --> 00:54:18,160
because of the feature sharing we can

380
00:54:18,160 --> 00:54:20,400
amortize the forward pass inference in

381
00:54:20,400 --> 00:54:22,079
the car at test time and so this is very

382
00:54:22,079 --> 00:54:23,680
efficient to run

383
00:54:23,680 --> 00:54:25,040
because if we had to have a backbone for

384
00:54:25,040 --> 00:54:27,200
every single task that would be a lot of

385
00:54:27,200 --> 00:54:28,800
backbones in the car

386
00:54:28,800 --> 00:54:30,480
number two this decouples all of the

387
00:54:30,480 --> 00:54:32,240
tasks so we can individually work on

388
00:54:32,240 --> 00:54:34,079
every one task in isolation and for

389
00:54:34,079 --> 00:54:36,079
example we can we can upgrade any of the

390
00:54:36,079 --> 00:54:37,200
data sets or change some of the

391
00:54:37,200 --> 00:54:38,720
architecture of the head and so on and

392
00:54:38,720 --> 00:54:40,160
you are not impacting any of the other

393
00:54:40,160 --> 00:54:42,240
tasks and so we don't have to revalidate

394
00:54:42,240 --> 00:54:43,359
all the other tasks which can be

395
00:54:43,359 --> 00:54:44,720
expensive

396
00:54:44,720 --> 00:54:46,400
and number three because there's this

397
00:54:46,400 --> 00:54:48,960
bottleneck here and features

398
00:54:48,960 --> 00:54:50,559
what we do fairly often is that we

399
00:54:50,559 --> 00:54:52,559
actually cache these features to disk

400
00:54:52,559 --> 00:54:54,000
and when we are doing these fine tuning

401
00:54:54,000 --> 00:54:56,559
uh workflows we only fine-tune from from

402
00:54:56,559 --> 00:54:58,240
the cached features up and only find you

403
00:54:58,240 --> 00:55:00,319
in the heads so most often in terms of

404
00:55:00,319 --> 00:55:02,319
our training workflows we will do an

405
00:55:02,319 --> 00:55:04,160
end-to-end training run once in a while

406
00:55:04,160 --> 00:55:06,400
where we train everything jointly then

407
00:55:06,400 --> 00:55:08,880
we cache the features

408
00:55:08,880 --> 00:55:10,799
at the multiscale feature level and then

409
00:55:10,799 --> 00:55:13,280
we fine-tune off of that for a while and

410
00:55:13,280 --> 00:55:15,359
then end-to-end train once again and so

411
00:55:15,359 --> 00:55:16,799
on

412
00:55:16,799 --> 00:55:18,640
so here's the kinds of predictions that

413
00:55:18,640 --> 00:55:20,400
we were obtaining i would say several

414
00:55:20,400 --> 00:55:21,680
years ago now

415
00:55:21,680 --> 00:55:23,839
uh from one of these hydronitis so again

416
00:55:23,839 --> 00:55:27,119
we are processing individual images

417
00:55:27,119 --> 00:55:28,720
there we go we are processing just

418
00:55:28,720 --> 00:55:30,240
individual image and we're making a

419
00:55:30,240 --> 00:55:31,520
large number of predictions about these

420
00:55:31,520 --> 00:55:33,359
images so for example here you can see

421
00:55:33,359 --> 00:55:35,280
predictions of the stop signs uh the

422
00:55:35,280 --> 00:55:37,920
stop lines uh the lines the edges the

423
00:55:37,920 --> 00:55:40,720
cars uh the traffic lights uh the curbs

424
00:55:40,720 --> 00:55:41,520
here

425
00:55:41,520 --> 00:55:43,599
uh whether or not the car is sparked uh

426
00:55:43,599 --> 00:55:45,200
all of the static objects like trash

427
00:55:45,200 --> 00:55:47,200
cans cones and so on and everything here

428
00:55:47,200 --> 00:55:48,720
is coming out of the net

429
00:55:48,720 --> 00:55:50,960
here in this case out of the hydra net

430
00:55:50,960 --> 00:55:52,720
so that was all fine and great but as we

431
00:55:52,720 --> 00:55:54,720
worked towards fsd we quickly found that

432
00:55:54,720 --> 00:55:57,200
this is not enough so where this first

433
00:55:57,200 --> 00:55:59,359
started to break was when we started to

434
00:55:59,359 --> 00:56:01,920
work on smart summon here i am showing

435
00:56:01,920 --> 00:56:03,440
some of the predictions of only the curb

436
00:56:03,440 --> 00:56:04,960
detection task and i'm showing it now

437
00:56:04,960 --> 00:56:07,040
for every one of the cameras

438
00:56:07,040 --> 00:56:08,480
so we'd like to wind our way around the

439
00:56:08,480 --> 00:56:10,000
parking lot to find the person who is

440
00:56:10,000 --> 00:56:11,920
summoning the car now the problem is

441
00:56:11,920 --> 00:56:13,760
that you can't just directly drive on

442
00:56:13,760 --> 00:56:15,520
image space predictions you actually

443
00:56:15,520 --> 00:56:16,960
need to cast them out and form some kind

444
00:56:16,960 --> 00:56:19,520
of a vector space around you

445
00:56:19,520 --> 00:56:21,839
so we attempted to do this using c plus

446
00:56:21,839 --> 00:56:23,920
and developed what we call

447
00:56:23,920 --> 00:56:27,440
the occupancy tracker at the time

448
00:56:27,839 --> 00:56:29,760
so here we see that the curb detections

449
00:56:29,760 --> 00:56:31,280
from the images are being stitched up

450
00:56:31,280 --> 00:56:33,520
across camera scenes camera boundaries

451
00:56:33,520 --> 00:56:35,040
and over time

452
00:56:35,040 --> 00:56:36,640
now there are two pro two major problems

453
00:56:36,640 --> 00:56:38,240
i would say with the setup number one we

454
00:56:38,240 --> 00:56:39,839
very quickly discovered that tuning the

455
00:56:39,839 --> 00:56:41,359
occupancy tracker and all of its hyper

456
00:56:41,359 --> 00:56:43,359
parameters was extremely complicated you

457
00:56:43,359 --> 00:56:45,119
don't want to do this explicitly by hand

458
00:56:45,119 --> 00:56:47,040
in c plus you want this to be inside the

459
00:56:47,040 --> 00:56:49,280
neural network and train that end to end

460
00:56:49,280 --> 00:56:51,040
number two we very quickly discovered

461
00:56:51,040 --> 00:56:52,880
that the image space is not the correct

462
00:56:52,880 --> 00:56:54,559
output space uh you don't want to make

463
00:56:54,559 --> 00:56:55,839
predictions in image space you really

464
00:56:55,839 --> 00:56:57,200
want to make it directly in the vector

465
00:56:57,200 --> 00:56:59,760
space so here's a way of illustrating

466
00:56:59,760 --> 00:57:01,280
the issue

467
00:57:01,280 --> 00:57:02,960
so here i'm showing on the first row the

468
00:57:02,960 --> 00:57:05,280
predictions of our curves and our lines

469
00:57:05,280 --> 00:57:07,680
in red and blue and

470
00:57:07,680 --> 00:57:09,760
they look great in the image but once

471
00:57:09,760 --> 00:57:11,760
you cast them out into the vector space

472
00:57:11,760 --> 00:57:13,920
things start to look really terrible and

473
00:57:13,920 --> 00:57:15,440
we are not going to be able to drive on

474
00:57:15,440 --> 00:57:16,960
this so

475
00:57:16,960 --> 00:57:18,319
you see how the predictions are quite

476
00:57:18,319 --> 00:57:20,640
bad in vector space and the reason for

477
00:57:20,640 --> 00:57:22,160
this fundamentally is because you need

478
00:57:22,160 --> 00:57:24,240
to have an extremely accurate depth per

479
00:57:24,240 --> 00:57:25,839
pixel in order to actually do this

480
00:57:25,839 --> 00:57:28,079
projection and so you can imagine just

481
00:57:28,079 --> 00:57:29,839
how high of the bar it is to predict

482
00:57:29,839 --> 00:57:32,880
that depth so accurately in these tiny

483
00:57:32,880 --> 00:57:34,720
in every single pixel of the image and

484
00:57:34,720 --> 00:57:36,160
also if there's any occluded area where

485
00:57:36,160 --> 00:57:37,599
you'd like to make predictions you will

486
00:57:37,599 --> 00:57:40,400
not be able to because it's not an image

487
00:57:40,400 --> 00:57:41,680
space

488
00:57:41,680 --> 00:57:43,599
concept in that case

489
00:57:43,599 --> 00:57:45,280
so we very quickly

490
00:57:45,280 --> 00:57:46,559
real of

491
00:57:46,559 --> 00:57:47,920
the other problems with this by the way

492
00:57:47,920 --> 00:57:50,000
is also for object detection if you are

493
00:57:50,000 --> 00:57:52,799
only making predictions per camera then

494
00:57:52,799 --> 00:57:54,640
sometimes you will encounter cases like

495
00:57:54,640 --> 00:57:56,319
this where a single car actually spans

496
00:57:56,319 --> 00:57:58,319
five of the eight cameras

497
00:57:58,319 --> 00:58:00,000
and so if you are making individual

498
00:58:00,000 --> 00:58:02,319
predictions then no single camera since

499
00:58:02,319 --> 00:58:04,480
sees all of the car and so obviously

500
00:58:04,480 --> 00:58:05,599
you're not going to be able to do a very

501
00:58:05,599 --> 00:58:07,359
good job of predicting that whole car

502
00:58:07,359 --> 00:58:08,400
and it's going to be incredibly

503
00:58:08,400 --> 00:58:10,640
difficult to fuse these measurements

504
00:58:10,640 --> 00:58:12,160
so we have this intuition that what we'd

505
00:58:12,160 --> 00:58:13,760
like to do instead is we'd like to take

506
00:58:13,760 --> 00:58:15,359
all of the images and simultaneously

507
00:58:15,359 --> 00:58:17,200
feed them into a single neural net and

508
00:58:17,200 --> 00:58:19,520
directly output in vector space now this

509
00:58:19,520 --> 00:58:22,240
is very easily said much more difficult

510
00:58:22,240 --> 00:58:24,799
to actually achieve but roughly we want

511
00:58:24,799 --> 00:58:26,720
to lay out a neural net in this way

512
00:58:26,720 --> 00:58:28,400
where we process every single image with

513
00:58:28,400 --> 00:58:29,839
a backbone

514
00:58:29,839 --> 00:58:32,000
and then we want to somehow fuse them

515
00:58:32,000 --> 00:58:34,720
and we want to re-represent it the the

516
00:58:34,720 --> 00:58:36,640
features from image space features to

517
00:58:36,640 --> 00:58:37,920
directly some kind of vector space

518
00:58:37,920 --> 00:58:39,520
features and then go into the decoding

519
00:58:39,520 --> 00:58:41,119
of the head

520
00:58:41,119 --> 00:58:42,160
now

521
00:58:42,160 --> 00:58:44,480
um so there are two problems with this

522
00:58:44,480 --> 00:58:45,920
problem number one

523
00:58:45,920 --> 00:58:47,839
how do you actually create the neural

524
00:58:47,839 --> 00:58:48,960
network components that do this

525
00:58:48,960 --> 00:58:51,119
transformation

526
00:58:51,119 --> 00:58:52,720
and you have to make it differentiable

527
00:58:52,720 --> 00:58:54,720
so that end-to-end training is possible

528
00:58:54,720 --> 00:58:56,960
and number two uh

529
00:58:56,960 --> 00:58:58,720
the if you want vector space predictions

530
00:58:58,720 --> 00:59:00,000
from your neural net you need vector

531
00:59:00,000 --> 00:59:02,400
specif based data sets so just labeling

532
00:59:02,400 --> 00:59:04,000
images and so on is not going to get you

533
00:59:04,000 --> 00:59:05,839
there you need vector space labels we're

534
00:59:05,839 --> 00:59:07,520
going to talk a lot more about problem

535
00:59:07,520 --> 00:59:09,440
number two later in the talk for now i

536
00:59:09,440 --> 00:59:10,720
want to focus on the neural network

537
00:59:10,720 --> 00:59:12,559
architectures so i'm going to deep dive

538
00:59:12,559 --> 00:59:15,119
into problem number one

539
00:59:15,119 --> 00:59:16,880
so here's the rough problem right we're

540
00:59:16,880 --> 00:59:18,480
trying to have this bird's eye view

541
00:59:18,480 --> 00:59:19,839
prediction instead of image space

542
00:59:19,839 --> 00:59:21,520
predictions so for example let's focus

543
00:59:21,520 --> 00:59:23,040
on a single pixel in the output space in

544
00:59:23,040 --> 00:59:24,720
yellow and this pixel is trying to

545
00:59:24,720 --> 00:59:27,119
decide am i part of a curb or not as an

546
00:59:27,119 --> 00:59:28,160
example

547
00:59:28,160 --> 00:59:30,559
and now where should the support for

548
00:59:30,559 --> 00:59:32,079
this kind of a prediction come from in

549
00:59:32,079 --> 00:59:33,359
the image space

550
00:59:33,359 --> 00:59:34,960
well we know roughly how the cameras are

551
00:59:34,960 --> 00:59:36,319
positioned and their extrinsics and

552
00:59:36,319 --> 00:59:38,799
intrinsics so we can roughly project

553
00:59:38,799 --> 00:59:41,040
this point into the camera images and

554
00:59:41,040 --> 00:59:42,400
you know the evidence for whether or not

555
00:59:42,400 --> 00:59:43,839
this is a curve may come from somewhere

556
00:59:43,839 --> 00:59:45,680
here in the images the problem is that

557
00:59:45,680 --> 00:59:47,040
this projection is really hard to

558
00:59:47,040 --> 00:59:48,880
actually get correct because it is a

559
00:59:48,880 --> 00:59:50,240
function of the road surface the road

560
00:59:50,240 --> 00:59:51,760
surface could be sloping up or sloping

561
00:59:51,760 --> 00:59:53,760
down or also there could be other data

562
00:59:53,760 --> 00:59:55,200
dependent issues for example there could

563
00:59:55,200 --> 00:59:57,200
be occlusion due to a car so if there's

564
00:59:57,200 --> 01:00:00,160
a car occluding this this viewport this

565
01:00:00,160 --> 01:00:02,000
this part of the image then actually you

566
01:00:02,000 --> 01:00:03,200
may want to pay attention to a different

567
01:00:03,200 --> 01:00:05,359
part of the image not the part where it

568
01:00:05,359 --> 01:00:07,280
projects and so because this is data

569
01:00:07,280 --> 01:00:08,480
dependent it's really hard to have a

570
01:00:08,480 --> 01:00:10,960
fixed transformation for this component

571
01:00:10,960 --> 01:00:13,599
so in order to solve this issue

572
01:00:13,599 --> 01:00:16,000
we use a transformer to represent this

573
01:00:16,000 --> 01:00:18,640
space and this transformer

574
01:00:18,640 --> 01:00:20,559
uses multi-headed self-attention and

575
01:00:20,559 --> 01:00:22,079
blocks off it

576
01:00:22,079 --> 01:00:23,599
in this case actually we can get away

577
01:00:23,599 --> 01:00:25,200
with even a single block

578
01:00:25,200 --> 01:00:26,720
doing a lot of this work

579
01:00:26,720 --> 01:00:27,520
and

580
01:00:27,520 --> 01:00:29,359
effectively what this does is you

581
01:00:29,359 --> 01:00:31,760
initialize a raster of the size of the

582
01:00:31,760 --> 01:00:33,280
output space that you would like and you

583
01:00:33,280 --> 01:00:34,880
tile it with positional encodings with

584
01:00:34,880 --> 01:00:36,880
size and coses in the output space and

585
01:00:36,880 --> 01:00:38,960
then these get encoded with an mlp into

586
01:00:38,960 --> 01:00:40,640
a set of query vectors

587
01:00:40,640 --> 01:00:42,000
and then all of the images and their

588
01:00:42,000 --> 01:00:44,079
features also emit their own keys and

589
01:00:44,079 --> 01:00:45,920
values and then the queries keys and

590
01:00:45,920 --> 01:00:47,599
values feed into the multi-headed

591
01:00:47,599 --> 01:00:49,440
self-attention and so effectively what's

592
01:00:49,440 --> 01:00:50,720
happening is that every single image

593
01:00:50,720 --> 01:00:53,760
piece is broadcasting in its key

594
01:00:53,760 --> 01:00:56,000
what it is what is it a part of so hey

595
01:00:56,000 --> 01:00:57,520
i'm part of a pillar in roughly this

596
01:00:57,520 --> 01:00:58,960
location and i'm seeing this kind of

597
01:00:58,960 --> 01:01:00,799
stuff and that's in the key and then

598
01:01:00,799 --> 01:01:02,240
every query is something along the lines

599
01:01:02,240 --> 01:01:04,160
of hey i'm a pixel in the output space

600
01:01:04,160 --> 01:01:06,000
at this position and i'm looking for

601
01:01:06,000 --> 01:01:07,520
features of this type

602
01:01:07,520 --> 01:01:08,960
then the keys and the queries interact

603
01:01:08,960 --> 01:01:10,960
multiplicatively and then the values get

604
01:01:10,960 --> 01:01:13,280
pulled accordingly

605
01:01:13,280 --> 01:01:15,119
and so this re-represents the space and

606
01:01:15,119 --> 01:01:16,799
we find this to be very effective for

607
01:01:16,799 --> 01:01:19,359
this transformation so if you do all of

608
01:01:19,359 --> 01:01:20,960
the engineering correctly this again is

609
01:01:20,960 --> 01:01:22,319
very easily said

610
01:01:22,319 --> 01:01:24,000
difficult to do you do all of the

611
01:01:24,000 --> 01:01:27,280
engineering correctly um

612
01:01:27,280 --> 01:01:28,640
there's one more there's no problem

613
01:01:28,640 --> 01:01:30,640
actually before

614
01:01:30,640 --> 01:01:32,480
i'm not sure what's up with the slides

615
01:01:32,480 --> 01:01:34,240
so one more thing you have to be careful

616
01:01:34,240 --> 01:01:35,440
with some of the details here when you

617
01:01:35,440 --> 01:01:36,640
are trying to get this to work so in

618
01:01:36,640 --> 01:01:38,960
particular all of our cars

619
01:01:38,960 --> 01:01:41,040
uh are slightly cockeyed in a slightly

620
01:01:41,040 --> 01:01:42,720
different way and so if you're doing

621
01:01:42,720 --> 01:01:44,079
this transformation from image space to

622
01:01:44,079 --> 01:01:45,280
the output space you really need to know

623
01:01:45,280 --> 01:01:47,359
what your camera calibration is and you

624
01:01:47,359 --> 01:01:48,799
need to feed that in somehow into the

625
01:01:48,799 --> 01:01:50,880
neural net and so you could definitely

626
01:01:50,880 --> 01:01:52,480
just like concatenate the camera

627
01:01:52,480 --> 01:01:54,559
calibrations of all of the images and

628
01:01:54,559 --> 01:01:56,559
somehow feed them in with an mlp

629
01:01:56,559 --> 01:01:58,240
but actually we found that we can do

630
01:01:58,240 --> 01:01:59,839
much better by transforming all of the

631
01:01:59,839 --> 01:02:02,240
images into a synthetic virtual camera

632
01:02:02,240 --> 01:02:04,640
using a special rectification transform

633
01:02:04,640 --> 01:02:07,200
so this is what that would look like

634
01:02:07,200 --> 01:02:09,599
we insert a new layer right above the

635
01:02:09,599 --> 01:02:11,280
image rectification layer it's a

636
01:02:11,280 --> 01:02:13,119
function of camera calibration and it

637
01:02:13,119 --> 01:02:14,720
translates all of the images into a

638
01:02:14,720 --> 01:02:17,520
virtual common camera so if you were to

639
01:02:17,520 --> 01:02:19,280
average up a lot of repeater images for

640
01:02:19,280 --> 01:02:21,039
example which faced at the back

641
01:02:21,039 --> 01:02:22,319
you would without doing this you would

642
01:02:22,319 --> 01:02:24,559
get a kind of a blur but after doing the

643
01:02:24,559 --> 01:02:26,160
rectification transformation you see

644
01:02:26,160 --> 01:02:30,160
that the back mirror gets really crisp

645
01:02:30,160 --> 01:02:32,720
so once you do this uh this improves the

646
01:02:32,720 --> 01:02:34,799
performance quite a bit

647
01:02:34,799 --> 01:02:36,799
so here are some of the results so on

648
01:02:36,799 --> 01:02:38,240
the left we are seeing what we had

649
01:02:38,240 --> 01:02:39,920
before and on the right we're now seeing

650
01:02:39,920 --> 01:02:41,200
significantly improved predictions

651
01:02:41,200 --> 01:02:42,799
coming directly out of the neural net

652
01:02:42,799 --> 01:02:44,400
this is a multi-camera network

653
01:02:44,400 --> 01:02:46,319
predicting directly in vector space and

654
01:02:46,319 --> 01:02:48,000
you can see that it's basically night

655
01:02:48,000 --> 01:02:49,680
and day uh

656
01:02:49,680 --> 01:02:51,920
you can actually drive on this and uh

657
01:02:51,920 --> 01:02:54,000
this took some time and some engineering

658
01:02:54,000 --> 01:02:56,160
and incredible work from the ai team to

659
01:02:56,160 --> 01:02:57,680
actually get this to work and deploy and

660
01:02:57,680 --> 01:03:00,799
make it efficient in the car

661
01:03:01,599 --> 01:03:03,119
this also improved a lot of our object

662
01:03:03,119 --> 01:03:05,200
detection so for example here in this

663
01:03:05,200 --> 01:03:06,720
video i'm showing single camera

664
01:03:06,720 --> 01:03:08,880
predictions in orange and multi-camera

665
01:03:08,880 --> 01:03:11,359
predictions in blue and basically if you

666
01:03:11,359 --> 01:03:13,440
if you can't predict these cars if you

667
01:03:13,440 --> 01:03:15,119
are only seeing a tiny sliver of a car

668
01:03:15,119 --> 01:03:16,559
so your detections are not going to be

669
01:03:16,559 --> 01:03:18,000
very good and their positions are not

670
01:03:18,000 --> 01:03:19,200
going to be good but a multi-camera

671
01:03:19,200 --> 01:03:20,880
network does not have an issue

672
01:03:20,880 --> 01:03:22,960
here's another video from a more nominal

673
01:03:22,960 --> 01:03:24,799
sort of situation and we see that as

674
01:03:24,799 --> 01:03:27,520
these cars in this tight space cross

675
01:03:27,520 --> 01:03:29,520
camera boundaries there's a lot of jank

676
01:03:29,520 --> 01:03:31,119
that enters into the predictions and

677
01:03:31,119 --> 01:03:32,480
basically the whole setup just doesn't

678
01:03:32,480 --> 01:03:33,920
make sense especially for very large

679
01:03:33,920 --> 01:03:35,359
vehicles like this one and we can see

680
01:03:35,359 --> 01:03:36,880
that the multi-camera networks struggle

681
01:03:36,880 --> 01:03:38,480
significantly less with these kinds of

682
01:03:38,480 --> 01:03:40,640
predictions

683
01:03:40,640 --> 01:03:41,920
okay so at this point we have

684
01:03:41,920 --> 01:03:43,280
multi-camera networks and they're giving

685
01:03:43,280 --> 01:03:45,359
predictions directly in vector space but

686
01:03:45,359 --> 01:03:47,119
we are still operating at every single

687
01:03:47,119 --> 01:03:49,760
instant in time completely independently

688
01:03:49,760 --> 01:03:51,039
so very quickly we discovered that

689
01:03:51,039 --> 01:03:52,319
there's a large number of predictions we

690
01:03:52,319 --> 01:03:54,079
want to make that actually require the

691
01:03:54,079 --> 01:03:55,599
video context and we need to somehow

692
01:03:55,599 --> 01:03:57,440
figure out how to feed this into the net

693
01:03:57,440 --> 01:03:59,440
so in particular is this car parked or

694
01:03:59,440 --> 01:04:01,680
not is it moving how fast is it moving

695
01:04:01,680 --> 01:04:02,960
is it still there even though it's

696
01:04:02,960 --> 01:04:05,119
temporarily occluded or for example if

697
01:04:05,119 --> 01:04:06,480
i'm trying to predict the road geometry

698
01:04:06,480 --> 01:04:07,520
ahead

699
01:04:07,520 --> 01:04:09,280
it's very helpful to know of the signs

700
01:04:09,280 --> 01:04:11,119
or the road markings that i saw 50

701
01:04:11,119 --> 01:04:12,640
meters ago

702
01:04:12,640 --> 01:04:13,440
so

703
01:04:13,440 --> 01:04:15,119
we try to develop

704
01:04:15,119 --> 01:04:16,799
we try to insert video modules into our

705
01:04:16,799 --> 01:04:18,079
neural network architecture and this is

706
01:04:18,079 --> 01:04:19,119
kind of one of the solutions that we've

707
01:04:19,119 --> 01:04:20,400
converged on

708
01:04:20,400 --> 01:04:21,680
so we have the multi-scale features as

709
01:04:21,680 --> 01:04:23,520
we had them from before and what we are

710
01:04:23,520 --> 01:04:25,280
going to now insert is a feature queue

711
01:04:25,280 --> 01:04:27,200
module that is going to cache some of

712
01:04:27,200 --> 01:04:28,880
these features over time

713
01:04:28,880 --> 01:04:30,559
and then a video module that is going to

714
01:04:30,559 --> 01:04:33,119
fuse this information temporally and

715
01:04:33,119 --> 01:04:34,960
then we're going to continue into the

716
01:04:34,960 --> 01:04:36,799
heads that do the decoding

717
01:04:36,799 --> 01:04:38,480
now i'm going to go into both of these

718
01:04:38,480 --> 01:04:40,960
blocks one by one also in addition

719
01:04:40,960 --> 01:04:42,319
notice here that we are also feeding in

720
01:04:42,319 --> 01:04:44,079
the kinematics this is basically the

721
01:04:44,079 --> 01:04:45,359
velocity and the acceleration that's

722
01:04:45,359 --> 01:04:47,119
telling us about how the car is moving

723
01:04:47,119 --> 01:04:49,119
so not only are not only are we going to

724
01:04:49,119 --> 01:04:50,960
keep track of what we're seeing from all

725
01:04:50,960 --> 01:04:52,880
the cameras but also how the car has

726
01:04:52,880 --> 01:04:54,720
traveled

727
01:04:54,720 --> 01:04:55,839
so here's the feature queue and the

728
01:04:55,839 --> 01:04:57,520
rough layout of it we are basically

729
01:04:57,520 --> 01:05:00,079
concatenating these features um

730
01:05:00,079 --> 01:05:02,079
over time and the kinematics of how the

731
01:05:02,079 --> 01:05:03,280
car has moved

732
01:05:03,280 --> 01:05:05,039
and the positional encodings and that's

733
01:05:05,039 --> 01:05:07,200
being concatenated encoded and stored in

734
01:05:07,200 --> 01:05:08,400
a feature queue

735
01:05:08,400 --> 01:05:09,520
and that's going to be consumed by a

736
01:05:09,520 --> 01:05:11,280
video module now there's a few details

737
01:05:11,280 --> 01:05:13,280
here again to get right so in particular

738
01:05:13,280 --> 01:05:14,640
with respect to the pop and push

739
01:05:14,640 --> 01:05:17,039
mechanisms and when do you push and how

740
01:05:17,039 --> 01:05:17,920
and

741
01:05:17,920 --> 01:05:20,160
especially when do you push basically so

742
01:05:20,160 --> 01:05:22,319
here's a cartoon diagram illustrating

743
01:05:22,319 --> 01:05:24,559
some of the challenges here

744
01:05:24,559 --> 01:05:26,240
there's going to be the ego cars coming

745
01:05:26,240 --> 01:05:27,680
from the bottom and coming up to this

746
01:05:27,680 --> 01:05:29,760
intersection here and then traffic is

747
01:05:29,760 --> 01:05:31,599
going to start crossing in front of us

748
01:05:31,599 --> 01:05:32,720
and it's going to temporarily start

749
01:05:32,720 --> 01:05:34,720
occluding some of the cars ahead and

750
01:05:34,720 --> 01:05:35,760
then we're going to be stuck at this

751
01:05:35,760 --> 01:05:36,960
intersection for a while and just

752
01:05:36,960 --> 01:05:38,480
waiting our turn this is something that

753
01:05:38,480 --> 01:05:40,240
happens all the time and is a cartoon

754
01:05:40,240 --> 01:05:41,839
representation of some of the challenges

755
01:05:41,839 --> 01:05:42,640
here

756
01:05:42,640 --> 01:05:44,640
so number one with respect to

757
01:05:44,640 --> 01:05:46,000
the feature queue and when we want to

758
01:05:46,000 --> 01:05:48,000
push into a queue obviously we'd like to

759
01:05:48,000 --> 01:05:49,520
have some kind of a time-based queue

760
01:05:49,520 --> 01:05:51,359
where for example we enter the features

761
01:05:51,359 --> 01:05:53,920
into the queue say every 27 milliseconds

762
01:05:53,920 --> 01:05:55,520
and so if a car gets temporarily

763
01:05:55,520 --> 01:05:57,359
occluded then the neural network now has

764
01:05:57,359 --> 01:05:59,680
the power to be able to look and

765
01:05:59,680 --> 01:06:02,240
reference the memory in time and and

766
01:06:02,240 --> 01:06:03,599
learn the association that hey even

767
01:06:03,599 --> 01:06:04,960
though this thing looks occluded right

768
01:06:04,960 --> 01:06:07,119
now there's a record of it in my

769
01:06:07,119 --> 01:06:08,880
previous features and i can use this to

770
01:06:08,880 --> 01:06:10,480
still make a detection

771
01:06:10,480 --> 01:06:11,760
so that's kind of like the more obvious

772
01:06:11,760 --> 01:06:13,119
one but the one that we also discovered

773
01:06:13,119 --> 01:06:16,160
is necessary in our case is for example

774
01:06:16,160 --> 01:06:17,039
suppose you're trying to make

775
01:06:17,039 --> 01:06:19,839
predictions about the road surface and

776
01:06:19,839 --> 01:06:21,520
the road geometry ahead and you're

777
01:06:21,520 --> 01:06:23,200
trying to predict that i'm in a turning

778
01:06:23,200 --> 01:06:25,359
lane and the lane next to us is going

779
01:06:25,359 --> 01:06:26,880
straight

780
01:06:26,880 --> 01:06:28,000
then

781
01:06:28,000 --> 01:06:29,520
it's really necessary to know about the

782
01:06:29,520 --> 01:06:30,960
line markings and the signs and

783
01:06:30,960 --> 01:06:33,440
sometimes they occur a long time ago and

784
01:06:33,440 --> 01:06:35,039
so if you only have a time-based queue

785
01:06:35,039 --> 01:06:37,359
you may forget the features while you're

786
01:06:37,359 --> 01:06:39,280
waiting at your red light so in addition

787
01:06:39,280 --> 01:06:40,799
to a time-based q we also have a

788
01:06:40,799 --> 01:06:42,960
space-based view so we push every time

789
01:06:42,960 --> 01:06:45,440
the car travels a certain fixed distance

790
01:06:45,440 --> 01:06:47,280
so some of these details actually can

791
01:06:47,280 --> 01:06:48,799
matter quite a bit and so in this case

792
01:06:48,799 --> 01:06:50,160
we have a time based key and a space

793
01:06:50,160 --> 01:06:52,319
base key to cache our features and that

794
01:06:52,319 --> 01:06:54,400
continues into the video module

795
01:06:54,400 --> 01:06:56,079
now for the video module we looked at a

796
01:06:56,079 --> 01:06:58,319
number of possibilities of how to fuse

797
01:06:58,319 --> 01:07:00,319
this information temporally so we looked

798
01:07:00,319 --> 01:07:01,760
at three-dimensional convolutions

799
01:07:01,760 --> 01:07:04,000
transformers axial transformers in an

800
01:07:04,000 --> 01:07:05,039
effort to try to make them more

801
01:07:05,039 --> 01:07:06,880
efficient recurrent neural networks over

802
01:07:06,880 --> 01:07:08,319
a large number of flavors

803
01:07:08,319 --> 01:07:10,000
but the one that we actually like quite

804
01:07:10,000 --> 01:07:11,200
a bit as well and i want to spend some

805
01:07:11,200 --> 01:07:13,599
time on is a spatial recurrent neural

806
01:07:13,599 --> 01:07:15,760
network video module and so what we're

807
01:07:15,760 --> 01:07:17,680
doing here is

808
01:07:17,680 --> 01:07:19,359
because of the structure of the problem

809
01:07:19,359 --> 01:07:20,480
we're driving on two-dimensional

810
01:07:20,480 --> 01:07:22,240
surfaces we can actually organize the

811
01:07:22,240 --> 01:07:23,839
hidden state into a two-dimensional

812
01:07:23,839 --> 01:07:25,760
lattice and then as the car is driving

813
01:07:25,760 --> 01:07:27,599
around we update only the parts that are

814
01:07:27,599 --> 01:07:29,280
near the car and where the car has

815
01:07:29,280 --> 01:07:31,599
visibility so as the car is driving

816
01:07:31,599 --> 01:07:33,599
around we are using the kinematics to

817
01:07:33,599 --> 01:07:35,760
integrate the position of the car in the

818
01:07:35,760 --> 01:07:37,119
hidden features

819
01:07:37,119 --> 01:07:40,640
grid and we are only updating the rnn at

820
01:07:40,640 --> 01:07:42,799
the points where where we have uh that

821
01:07:42,799 --> 01:07:45,760
are nearby us sort of

822
01:07:45,760 --> 01:07:47,599
so here's an example of what that looks

823
01:07:47,599 --> 01:07:49,839
like

824
01:07:50,319 --> 01:07:51,599
here what i'm going to show you is the

825
01:07:51,599 --> 01:07:53,039
car driving around

826
01:07:53,039 --> 01:07:53,920
and

827
01:07:53,920 --> 01:07:56,160
we're looking at the hidden state of

828
01:07:56,160 --> 01:07:58,880
this rnn

829
01:07:59,280 --> 01:08:00,720
and these are different channels in the

830
01:08:00,720 --> 01:08:03,119
hidden state so you can see that this is

831
01:08:03,119 --> 01:08:04,559
after optimization and training this

832
01:08:04,559 --> 01:08:06,000
neural net you can see that some of the

833
01:08:06,000 --> 01:08:07,599
channels are keeping track of different

834
01:08:07,599 --> 01:08:09,440
aspects of the road like for example the

835
01:08:09,440 --> 01:08:11,839
centers of the road the edges the lines

836
01:08:11,839 --> 01:08:14,000
the road surface and so on

837
01:08:14,000 --> 01:08:16,238
here's another cool video of this so

838
01:08:16,238 --> 01:08:18,238
this is looking at the mean of the first

839
01:08:18,238 --> 01:08:19,920
10 channels in the hidden state for

840
01:08:19,920 --> 01:08:21,040
different

841
01:08:21,040 --> 01:08:23,679
traversals of different intersections

842
01:08:23,679 --> 01:08:25,120
and all i want you to see basically is

843
01:08:25,120 --> 01:08:27,040
that there's cool activity as the

844
01:08:27,040 --> 01:08:28,238
recurrent neural network is keeping

845
01:08:28,238 --> 01:08:29,679
track of what's happening at any point

846
01:08:29,679 --> 01:08:31,359
in time and you can imagine that we've

847
01:08:31,359 --> 01:08:32,640
now given the power to the neural

848
01:08:32,640 --> 01:08:34,640
network to actually selectively read and

849
01:08:34,640 --> 01:08:36,319
write to this memory so for example if

850
01:08:36,319 --> 01:08:37,759
there's a car right next to us and is

851
01:08:37,759 --> 01:08:39,520
occluding some parts of the road then

852
01:08:39,520 --> 01:08:41,520
now the network has a has the ability to

853
01:08:41,520 --> 01:08:43,439
not write to those locations but when

854
01:08:43,439 --> 01:08:44,799
the car goes away and we have a really

855
01:08:44,799 --> 01:08:46,640
good view then the recurring neural net

856
01:08:46,640 --> 01:08:48,000
can say okay we have very clear

857
01:08:48,000 --> 01:08:49,679
visibility we definitely want to write

858
01:08:49,679 --> 01:08:51,040
information about what's in that part of

859
01:08:51,040 --> 01:08:53,120
space

860
01:08:53,120 --> 01:08:56,080
here's a few predictions that show

861
01:08:56,080 --> 01:08:58,080
what this looks like

862
01:08:58,080 --> 01:08:59,439
so here we are making predictions about

863
01:08:59,439 --> 01:09:01,198
the road boundaries in red intersection

864
01:09:01,198 --> 01:09:02,880
areas in blue

865
01:09:02,880 --> 01:09:04,799
road centers and so on so we're only

866
01:09:04,799 --> 01:09:06,238
showing a few of the predictions here

867
01:09:06,238 --> 01:09:08,719
just to keep the visualization clean

868
01:09:08,719 --> 01:09:10,479
um

869
01:09:10,479 --> 01:09:12,080
and yeah this is this is done by the

870
01:09:12,080 --> 01:09:15,040
spatial rnn and this is only showing a

871
01:09:15,040 --> 01:09:17,040
single clip a single traversal but you

872
01:09:17,040 --> 01:09:19,120
can imagine there could be multiple

873
01:09:19,120 --> 01:09:20,799
trips through here and basically number

874
01:09:20,799 --> 01:09:22,000
of cars a number of clips could be

875
01:09:22,000 --> 01:09:23,600
collaborating to build this map

876
01:09:23,600 --> 01:09:25,520
basically and effectively an hd map

877
01:09:25,520 --> 01:09:28,158
except it's not in a space of explicit

878
01:09:28,158 --> 01:09:30,640
items it's in a space of features of a

879
01:09:30,640 --> 01:09:31,920
recurrent neural network which is kind

880
01:09:31,920 --> 01:09:35,439
of cool i haven't seen that before

881
01:09:35,439 --> 01:09:38,000
the video networks also improved our

882
01:09:38,000 --> 01:09:39,679
object detection quite a bit so in this

883
01:09:39,679 --> 01:09:41,679
example i want to show you a case where

884
01:09:41,679 --> 01:09:43,120
there are two cars

885
01:09:43,120 --> 01:09:45,198
over there and one car is going to drive

886
01:09:45,198 --> 01:09:47,120
by and occlude them briefly so look at

887
01:09:47,120 --> 01:09:48,238
what's happening with the single frame

888
01:09:48,238 --> 01:09:50,640
and the video predictions as the cars

889
01:09:50,640 --> 01:09:53,600
pass in front of us

890
01:09:55,920 --> 01:09:58,000
yeah so that makes a lot of sense so a

891
01:09:58,000 --> 01:09:59,600
quick

892
01:09:59,600 --> 01:10:01,040
playthrough through what's happening

893
01:10:01,040 --> 01:10:02,640
when both of them are in view the

894
01:10:02,640 --> 01:10:04,560
predictions are roughly equivalent

895
01:10:04,560 --> 01:10:06,480
and you are seeing multiple orange boxes

896
01:10:06,480 --> 01:10:07,440
because they're coming from different

897
01:10:07,440 --> 01:10:09,840
cameras

898
01:10:10,080 --> 01:10:12,159
when they are occluded the single frame

899
01:10:12,159 --> 01:10:13,840
networks drop the detection but the

900
01:10:13,840 --> 01:10:15,840
video module remembers it and we can

901
01:10:15,840 --> 01:10:17,920
persist the cars and then when they are

902
01:10:17,920 --> 01:10:19,920
only partially occluded the single frame

903
01:10:19,920 --> 01:10:22,320
network is forced to make its best guess

904
01:10:22,320 --> 01:10:23,760
about what it's seeing and it's forced

905
01:10:23,760 --> 01:10:25,120
to make a prediction and it makes a

906
01:10:25,120 --> 01:10:26,719
really terrible prediction but the video

907
01:10:26,719 --> 01:10:29,600
module knows that there's only a partial

908
01:10:29,600 --> 01:10:31,760
that you know it has the information and

909
01:10:31,760 --> 01:10:33,280
knows that this is not a very easily

910
01:10:33,280 --> 01:10:34,480
visible

911
01:10:34,480 --> 01:10:35,920
part right now and doesn't actually take

912
01:10:35,920 --> 01:10:37,440
that into account

913
01:10:37,440 --> 01:10:39,120
we also saw significant improvements in

914
01:10:39,120 --> 01:10:40,560
our ability to estimate depth and of

915
01:10:40,560 --> 01:10:42,719
course especially velocity so here i'm

916
01:10:42,719 --> 01:10:44,800
showing a clip from our remove the radar

917
01:10:44,800 --> 01:10:47,199
push where we are seeing the radar depth

918
01:10:47,199 --> 01:10:49,679
and velocity in green and we were trying

919
01:10:49,679 --> 01:10:50,800
to

920
01:10:50,800 --> 01:10:52,320
match or even surpass of course the

921
01:10:52,320 --> 01:10:54,560
signal just from video networks alone

922
01:10:54,560 --> 01:10:57,600
and what you're seeing here is in

923
01:10:57,600 --> 01:10:59,199
orange we are seeing a single frame

924
01:10:59,199 --> 01:11:00,239
performance

925
01:11:00,239 --> 01:11:02,239
and in blue we are seeing again video

926
01:11:02,239 --> 01:11:03,840
modules and so you see that the quality

927
01:11:03,840 --> 01:11:06,000
of depth is much higher and for velocity

928
01:11:06,000 --> 01:11:07,360
the orange signal of course you can't

929
01:11:07,360 --> 01:11:08,719
get velocity out of a single frame

930
01:11:08,719 --> 01:11:10,159
network so we use uh we just

931
01:11:10,159 --> 01:11:12,080
differentiate depth to get that but the

932
01:11:12,080 --> 01:11:13,679
video module actually is basically right

933
01:11:13,679 --> 01:11:16,480
on top of the radar signal and so we

934
01:11:16,480 --> 01:11:18,080
found that this worked extremely well

935
01:11:18,080 --> 01:11:20,000
for us

936
01:11:20,000 --> 01:11:22,000
so here's putting everything together

937
01:11:22,000 --> 01:11:23,280
this is what our architectural roughly

938
01:11:23,280 --> 01:11:25,520
looks like today so

939
01:11:25,520 --> 01:11:28,159
we have raw images feeding on the bottom

940
01:11:28,159 --> 01:11:29,679
they go through rectification layer to

941
01:11:29,679 --> 01:11:31,679
correct for camera calibration and put

942
01:11:31,679 --> 01:11:33,679
everything into a common uh virtual

943
01:11:33,679 --> 01:11:35,920
camera we pass them through

944
01:11:35,920 --> 01:11:38,080
regnets residual networks to process

945
01:11:38,080 --> 01:11:39,440
them into a number of features at

946
01:11:39,440 --> 01:11:41,440
different scales we fuse the multi-scale

947
01:11:41,440 --> 01:11:43,280
information with by fbn this goes

948
01:11:43,280 --> 01:11:44,400
through transformer module to

949
01:11:44,400 --> 01:11:46,159
re-represent it into the vector space in

950
01:11:46,159 --> 01:11:47,760
the output space this feeds into a

951
01:11:47,760 --> 01:11:50,000
feature queue in time or space that gets

952
01:11:50,000 --> 01:11:51,600
processed by a video module like the

953
01:11:51,600 --> 01:11:53,840
spatial rnn and then continues into the

954
01:11:53,840 --> 01:11:55,360
branching structure of the hydra net

955
01:11:55,360 --> 01:11:56,960
with trunks and heads for all the

956
01:11:56,960 --> 01:11:58,320
different tasks

957
01:11:58,320 --> 01:12:00,480
and so that's the architecture roughly

958
01:12:00,480 --> 01:12:01,600
what it looks like today and on the

959
01:12:01,600 --> 01:12:02,560
right you are seeing some of its

960
01:12:02,560 --> 01:12:04,800
predictions uh sort of visualize both in

961
01:12:04,800 --> 01:12:06,719
a top-down vector space and also in

962
01:12:06,719 --> 01:12:10,000
images so definitely uh

963
01:12:10,000 --> 01:12:11,120
this architecture has definitely

964
01:12:11,120 --> 01:12:12,880
complexified from just a very simple

965
01:12:12,880 --> 01:12:14,719
image based single network about three

966
01:12:14,719 --> 01:12:16,080
or four years ago and continues to

967
01:12:16,080 --> 01:12:18,080
evolve um it's definitely quite

968
01:12:18,080 --> 01:12:18,960
impressive now there's still

969
01:12:18,960 --> 01:12:20,320
opportunities for improvements that the

970
01:12:20,320 --> 01:12:22,159
team is actively working on for example

971
01:12:22,159 --> 01:12:23,920
you'll notice that our fusion of time

972
01:12:23,920 --> 01:12:25,920
and space is fairly late in neural

973
01:12:25,920 --> 01:12:27,679
network terms so maybe we can actually

974
01:12:27,679 --> 01:12:29,600
do earlier fusion of space or time and

975
01:12:29,600 --> 01:12:31,360
do for example cost volumes or optical

976
01:12:31,360 --> 01:12:33,600
flow-like networks on the bottom

977
01:12:33,600 --> 01:12:35,520
or for example our outputs are dense

978
01:12:35,520 --> 01:12:36,960
rasters and it's actually pretty

979
01:12:36,960 --> 01:12:38,400
expensive to post-process some of these

980
01:12:38,400 --> 01:12:40,400
dense rasters in the car and of course

981
01:12:40,400 --> 01:12:41,679
we are under very strict latency

982
01:12:41,679 --> 01:12:43,440
requirements so this is not ideal we

983
01:12:43,440 --> 01:12:44,880
actually are looking into all kinds of

984
01:12:44,880 --> 01:12:46,239
ways of predicting just the sparse

985
01:12:46,239 --> 01:12:48,320
structure of the road maybe like you

986
01:12:48,320 --> 01:12:50,000
know point by point or in some other

987
01:12:50,000 --> 01:12:51,520
fashion that is

988
01:12:51,520 --> 01:12:52,640
that doesn't require expensive

989
01:12:52,640 --> 01:12:54,960
post-processing

990
01:12:54,960 --> 01:12:56,800
but this basically is how you achieve a

991
01:12:56,800 --> 01:12:58,880
very nice vector space and now i believe

992
01:12:58,880 --> 01:13:01,120
ashok is going to talk about how we can

993
01:13:01,120 --> 01:13:04,190
run playing control on top of it

994
01:13:04,190 --> 01:13:11,920
[Applause]

995
01:13:11,920 --> 01:13:13,840
thank you andre hi everyone my name is

996
01:13:13,840 --> 01:13:15,520
ashok i lead the planning and controls

997
01:13:15,520 --> 01:13:19,360
auto labeling and simulation teams

998
01:13:19,360 --> 01:13:21,760
so like on dimension the visual networks

999
01:13:21,760 --> 01:13:23,760
take dense video data and then compress

1000
01:13:23,760 --> 01:13:26,239
it down into a 3d vector space the role

1001
01:13:26,239 --> 01:13:27,760
of the planner now is to consume this

1002
01:13:27,760 --> 01:13:29,440
vector space and get the car to the

1003
01:13:29,440 --> 01:13:31,440
destination while maximizing the safety

1004
01:13:31,440 --> 01:13:34,239
comfort and the efficiency of the car

1005
01:13:34,239 --> 01:13:36,320
even back in 2019 our planet was pretty

1006
01:13:36,320 --> 01:13:38,480
capable driver it was able to stay in

1007
01:13:38,480 --> 01:13:40,640
the lanes make lane changes as necessary

1008
01:13:40,640 --> 01:13:42,960
and take exits off the highway but cdc

1009
01:13:42,960 --> 01:13:45,600
driving is much more complicated

1010
01:13:45,600 --> 01:13:47,360
radley there are

1011
01:13:47,360 --> 01:13:49,280
structured lane lines um vehicles do

1012
01:13:49,280 --> 01:13:51,360
much more free from driving then the car

1013
01:13:51,360 --> 01:13:53,199
has to respond to all of

1014
01:13:53,199 --> 01:13:55,360
curtains and crossing vehicles and

1015
01:13:55,360 --> 01:13:59,560
pedestrians doing funny things

1016
01:14:00,320 --> 01:14:03,120
what is the key problem in planning

1017
01:14:03,120 --> 01:14:05,360
number one the action space is very

1018
01:14:05,360 --> 01:14:06,800
non-convex

1019
01:14:06,800 --> 01:14:10,159
and number two it is high dimensional

1020
01:14:10,159 --> 01:14:12,840
what i mean by non-convex

1021
01:14:12,840 --> 01:14:15,280
is there can be multiple possible

1022
01:14:15,280 --> 01:14:17,120
solutions that can be independently good

1023
01:14:17,120 --> 01:14:18,560
but getting a globally consistent

1024
01:14:18,560 --> 01:14:20,640
solution is pretty tricky so there can

1025
01:14:20,640 --> 01:14:22,719
be pockets of local minima that the

1026
01:14:22,719 --> 01:14:24,880
planning can get stuck into

1027
01:14:24,880 --> 01:14:26,800
and secondly uh the high dimensionality

1028
01:14:26,800 --> 01:14:29,280
comes because the car needs to plan for

1029
01:14:29,280 --> 01:14:31,440
the next 10 to 15 seconds and needs to

1030
01:14:31,440 --> 01:14:32,880
produce the position velocities and

1031
01:14:32,880 --> 01:14:35,360
acceleration uh or this entire window

1032
01:14:35,360 --> 01:14:37,120
this is a lot of parameters to produce

1033
01:14:37,120 --> 01:14:39,120
at runtime

1034
01:14:39,120 --> 01:14:41,120
discrete search methods are really great

1035
01:14:41,120 --> 01:14:42,800
at solving non-context problems because

1036
01:14:42,800 --> 01:14:44,239
they are discrete they can they don't

1037
01:14:44,239 --> 01:14:45,760
get stuck in local minima whereas

1038
01:14:45,760 --> 01:14:47,520
continuous function optimization can

1039
01:14:47,520 --> 01:14:49,120
easily get stuck in local minima and

1040
01:14:49,120 --> 01:14:50,560
produce poor solutions that are not

1041
01:14:50,560 --> 01:14:52,480
great

1042
01:14:52,480 --> 01:14:53,840
on the other end for high dimensional

1043
01:14:53,840 --> 01:14:57,040
problems discrete search sucks because

1044
01:14:57,040 --> 01:14:58,560
of the

1045
01:14:58,560 --> 01:15:00,239
it is discrete it does not use any

1046
01:15:00,239 --> 01:15:01,679
graded information so literally has to

1047
01:15:01,679 --> 01:15:03,440
go and explore each point to know how

1048
01:15:03,440 --> 01:15:05,040
good it is whereas continuous

1049
01:15:05,040 --> 01:15:06,480
optimization use gradient-based methods

1050
01:15:06,480 --> 01:15:10,560
to very quickly go to a good solution

1051
01:15:10,560 --> 01:15:12,560
our solution to this printer problem is

1052
01:15:12,560 --> 01:15:14,719
to break it down hierarchically first

1053
01:15:14,719 --> 01:15:16,880
use a code search method to crunch down

1054
01:15:16,880 --> 01:15:18,000
the uh

1055
01:15:18,000 --> 01:15:20,080
non-convexity and come up with a convex

1056
01:15:20,080 --> 01:15:21,840
corridor and then use continuous

1057
01:15:21,840 --> 01:15:23,600
optimization techniques to make the

1058
01:15:23,600 --> 01:15:26,800
final smooth trajectory

1059
01:15:26,800 --> 01:15:28,320
let's see an example of how the search

1060
01:15:28,320 --> 01:15:30,719
operates

1061
01:15:30,960 --> 01:15:33,760
so here we're trying to do a lane change

1062
01:15:33,760 --> 01:15:35,760
in this case the car needs to do two

1063
01:15:35,760 --> 01:15:37,600
back to back lane changes to make the

1064
01:15:37,600 --> 01:15:40,159
left turn up ahead

1065
01:15:40,159 --> 01:15:43,440
for this the car searches over uh

1066
01:15:43,440 --> 01:15:46,239
different maneuvers um

1067
01:15:46,239 --> 01:15:48,719
so the the first one it searches is a

1068
01:15:48,719 --> 01:15:51,280
lane change that's close by but the

1069
01:15:51,280 --> 01:15:53,199
car breaks pretty harshly so it's pretty

1070
01:15:53,199 --> 01:15:55,760
uncomfortable

1071
01:15:56,080 --> 01:15:58,000
the next maneuver it tries does the lane

1072
01:15:58,000 --> 01:15:59,600
change bit late so it speeds up goes

1073
01:15:59,600 --> 01:16:00,960
beyond the other car goes in front of

1074
01:16:00,960 --> 01:16:02,320
the other cars and find it at the lane

1075
01:16:02,320 --> 01:16:04,400
change but now it risks missing the left

1076
01:16:04,400 --> 01:16:06,560
turn

1077
01:16:06,560 --> 01:16:08,400
we do thousands of such searches in a

1078
01:16:08,400 --> 01:16:11,440
very short time span

1079
01:16:11,440 --> 01:16:12,640
because these are all physics-based

1080
01:16:12,640 --> 01:16:14,560
models these features are very easy to

1081
01:16:14,560 --> 01:16:16,719
simulate and in the end we have a set of

1082
01:16:16,719 --> 01:16:18,560
candidates and we finally choose one

1083
01:16:18,560 --> 01:16:20,000
based on the optimality conditions of

1084
01:16:20,000 --> 01:16:21,520
safety comfort and easily making the

1085
01:16:21,520 --> 01:16:23,760
turn

1086
01:16:23,840 --> 01:16:25,760
so now the car has chosen this path and

1087
01:16:25,760 --> 01:16:27,440
you can see that as the car executes

1088
01:16:27,440 --> 01:16:29,600
this trajectory it pretty much matches

1089
01:16:29,600 --> 01:16:31,920
what we had planned the cyan plot on the

1090
01:16:31,920 --> 01:16:34,400
right side here and that one is the

1091
01:16:34,400 --> 01:16:36,400
actual velocity of the car and the white

1092
01:16:36,400 --> 01:16:39,360
line be underneath it is was the plan so

1093
01:16:39,360 --> 01:16:41,360
we are able to plan for 10 seconds here

1094
01:16:41,360 --> 01:16:43,040
and able to match that

1095
01:16:43,040 --> 01:16:44,960
when you see in hindsight so this is a

1096
01:16:44,960 --> 01:16:48,440
well-made plan

1097
01:16:48,800 --> 01:16:50,640
when driving alongside other agents it's

1098
01:16:50,640 --> 01:16:52,960
important to not just plan for ourselves

1099
01:16:52,960 --> 01:16:54,640
but instead we have to plan for everyone

1100
01:16:54,640 --> 01:16:56,480
jointly and optimize for the overall

1101
01:16:56,480 --> 01:16:59,440
scenes traffic flow

1102
01:16:59,440 --> 01:17:00,960
in order to do this what we do is we

1103
01:17:00,960 --> 01:17:02,800
literally run the autopilot planner on

1104
01:17:02,800 --> 01:17:04,080
every single relevant object in the

1105
01:17:04,080 --> 01:17:05,360
scene

1106
01:17:05,360 --> 01:17:06,719
here's an example of why that's

1107
01:17:06,719 --> 01:17:09,280
necessary

1108
01:17:09,520 --> 01:17:10,719
this is an auto corridor i'll let you

1109
01:17:10,719 --> 01:17:14,360
watch the video for a second

1110
01:17:25,760 --> 01:17:27,280
yeah that was autopilot driving an auto

1111
01:17:27,280 --> 01:17:29,440
corridor going around parked cars cones

1112
01:17:29,440 --> 01:17:31,600
and poles uh here there's a 3d view of

1113
01:17:31,600 --> 01:17:32,960
the same thing

1114
01:17:32,960 --> 01:17:34,560
the oncoming car arrives now and

1115
01:17:34,560 --> 01:17:36,080
autopilot slows down a little bit but

1116
01:17:36,080 --> 01:17:37,840
then realizes that we cannot yield to

1117
01:17:37,840 --> 01:17:39,199
them because we don't have any space to

1118
01:17:39,199 --> 01:17:41,280
our side but the other car can heal to

1119
01:17:41,280 --> 01:17:43,360
us instead so instead of just blindly

1120
01:17:43,360 --> 01:17:45,280
breaking here all of our reasons about

1121
01:17:45,280 --> 01:17:47,040
that car uh

1122
01:17:47,040 --> 01:17:48,480
has low enough velocity that they can

1123
01:17:48,480 --> 01:17:50,159
pull over and should yield to us because

1124
01:17:50,159 --> 01:17:51,840
we cannot yield to them and assertively

1125
01:17:51,840 --> 01:17:54,480
makes progress

1126
01:17:54,800 --> 01:17:57,199
a second oncoming car arrives now

1127
01:17:57,199 --> 01:17:59,600
this vehicle has higher velocity

1128
01:17:59,600 --> 01:18:01,040
and like i said earlier we literally run

1129
01:18:01,040 --> 01:18:02,560
the autopilot planner for the other

1130
01:18:02,560 --> 01:18:04,080
object so in this case we run the

1131
01:18:04,080 --> 01:18:06,640
printer for them that object's plan now

1132
01:18:06,640 --> 01:18:08,239
goes around their part their site's

1133
01:18:08,239 --> 01:18:10,320
parked cars and then after they pass the

1134
01:18:10,320 --> 01:18:12,320
parkours goes back to the right side of

1135
01:18:12,320 --> 01:18:14,320
the road for them

1136
01:18:14,320 --> 01:18:15,760
since we don't know what's in the mind

1137
01:18:15,760 --> 01:18:17,840
of the driver we actually have multiple

1138
01:18:17,840 --> 01:18:20,080
possible features for this car here one

1139
01:18:20,080 --> 01:18:21,360
feature is shown in red the other one is

1140
01:18:21,360 --> 01:18:22,640
shown as green

1141
01:18:22,640 --> 01:18:24,480
the green one is a plan that yields to

1142
01:18:24,480 --> 01:18:26,320
us but since this object's velocity and

1143
01:18:26,320 --> 01:18:28,159
acceleration are pretty high we don't

1144
01:18:28,159 --> 01:18:29,280
think that this person is going to yield

1145
01:18:29,280 --> 01:18:30,560
to us and they are actually going to go

1146
01:18:30,560 --> 01:18:32,159
around these sparked cars

1147
01:18:32,159 --> 01:18:34,239
so autopilot decides that okay i have

1148
01:18:34,239 --> 01:18:35,840
space here uh this person is definitely

1149
01:18:35,840 --> 01:18:38,719
going to come so i'm going to pull over

1150
01:18:38,719 --> 01:18:40,880
so as autopilot is pulling over we

1151
01:18:40,880 --> 01:18:42,800
notice that that car has chosen to yield

1152
01:18:42,800 --> 01:18:44,800
to us based on their yaw rate and their

1153
01:18:44,800 --> 01:18:46,719
acceleration and autopilot immediately

1154
01:18:46,719 --> 01:18:48,480
changes his mind and continues to make

1155
01:18:48,480 --> 01:18:49,679
progress

1156
01:18:49,679 --> 01:18:51,199
this is why we need to plan for everyone

1157
01:18:51,199 --> 01:18:52,480
because otherwise we wouldn't know that

1158
01:18:52,480 --> 01:18:53,760
this person is going to go around the

1159
01:18:53,760 --> 01:18:55,120
other park cars

1160
01:18:55,120 --> 01:18:56,880
and come back to their site if you

1161
01:18:56,880 --> 01:18:58,159
didn't do this autopilot would be too

1162
01:18:58,159 --> 01:18:59,520
timid and it would not be a practical

1163
01:18:59,520 --> 01:19:02,239
self-driving car

1164
01:19:03,120 --> 01:19:04,800
so now we saw how the search and

1165
01:19:04,800 --> 01:19:06,560
planning for other people set up

1166
01:19:06,560 --> 01:19:08,880
convicts valley uh finally we do a

1167
01:19:08,880 --> 01:19:10,640
continuous optimization to produce the

1168
01:19:10,640 --> 01:19:12,159
final trajectory that the planet uh

1169
01:19:12,159 --> 01:19:13,520
needs to take

1170
01:19:13,520 --> 01:19:16,239
here the grave uh thing is the convex

1171
01:19:16,239 --> 01:19:18,719
corridor and we initialize the spline in

1172
01:19:18,719 --> 01:19:20,560
heading and acceleration parameterized

1173
01:19:20,560 --> 01:19:23,199
over the arc length of the plan

1174
01:19:23,199 --> 01:19:24,159
and you can see that the

1175
01:19:24,159 --> 01:19:25,760
countermeasuration continuously makes

1176
01:19:25,760 --> 01:19:27,360
fine-grained changes to reduce all of

1177
01:19:27,360 --> 01:19:29,199
its cost some of the costs for example

1178
01:19:29,199 --> 01:19:31,440
are distance from obstacles

1179
01:19:31,440 --> 01:19:34,560
traversal time and comfort for comfort

1180
01:19:34,560 --> 01:19:35,520
you can see that the lateral

1181
01:19:35,520 --> 01:19:37,199
acceleration plots on the right have

1182
01:19:37,199 --> 01:19:39,199
nice trapezoidal shapes uh it's going to

1183
01:19:39,199 --> 01:19:40,719
come up yeah here on the right side the

1184
01:19:40,719 --> 01:19:43,120
green plot um that's a nice trapezoidal

1185
01:19:43,120 --> 01:19:44,239
shape and if you record on a human

1186
01:19:44,239 --> 01:19:45,600
trajectory this is pretty much how it

1187
01:19:45,600 --> 01:19:47,280
looked like the lateral jerk is also

1188
01:19:47,280 --> 01:19:49,040
minimized

1189
01:19:49,040 --> 01:19:51,600
so in summary we do a search for both us

1190
01:19:51,600 --> 01:19:53,520
and everyone else in the scene uh we set

1191
01:19:53,520 --> 01:19:55,199
up a context corridor and then optimize

1192
01:19:55,199 --> 01:19:56,640
for a smooth path

1193
01:19:56,640 --> 01:19:58,560
together these can do some really neat

1194
01:19:58,560 --> 01:19:59,600
things like

1195
01:19:59,600 --> 01:20:02,080
shown above

1196
01:20:02,080 --> 01:20:03,360
but driving looks a bit different in

1197
01:20:03,360 --> 01:20:05,520
other places like where i grew up from

1198
01:20:05,520 --> 01:20:07,120
um

1199
01:20:07,120 --> 01:20:10,080
it's very much more unstructured

1200
01:20:10,080 --> 01:20:12,639
cars and pedestrians cutting each other

1201
01:20:12,639 --> 01:20:14,880
arch braking honking um

1202
01:20:14,880 --> 01:20:16,880
it's a crazy world um

1203
01:20:16,880 --> 01:20:18,639
we can try to scale up these methods uh

1204
01:20:18,639 --> 01:20:20,000
but it's going to be really difficult to

1205
01:20:20,000 --> 01:20:21,920
efficiently solve this at runtime what

1206
01:20:21,920 --> 01:20:23,760
we instead want to do is use learning

1207
01:20:23,760 --> 01:20:25,760
based methods to efficiently solve them

1208
01:20:25,760 --> 01:20:28,080
um and i want to show why this is true

1209
01:20:28,080 --> 01:20:29,360
um so we're going to go from this

1210
01:20:29,360 --> 01:20:31,120
complicated problem to a much simpler

1211
01:20:31,120 --> 01:20:32,960
toy parking problem but still

1212
01:20:32,960 --> 01:20:35,679
illustrates the core of the issue

1213
01:20:35,679 --> 01:20:38,320
here this is a parking lot the ego car

1214
01:20:38,320 --> 01:20:40,080
is in blue and needs to park in the

1215
01:20:40,080 --> 01:20:41,679
green parking spot here so it needs to

1216
01:20:41,679 --> 01:20:44,159
go around the curbs the park cars and

1217
01:20:44,159 --> 01:20:46,480
the cones shown in orange here

1218
01:20:46,480 --> 01:20:48,639
let's do this simple bass line it's a

1219
01:20:48,639 --> 01:20:50,560
star the standard algorithm that uses a

1220
01:20:50,560 --> 01:20:52,800
ladder space search um and and the

1221
01:20:52,800 --> 01:20:54,560
heuristic here is a distance uh the

1222
01:20:54,560 --> 01:20:56,880
euclidean distance to the goal

1223
01:20:56,880 --> 01:20:58,239
so you can see that it directly shoots

1224
01:20:58,239 --> 01:21:00,080
towards the goal but very quickly gets

1225
01:21:00,080 --> 01:21:01,679
trapped in a local minima and it

1226
01:21:01,679 --> 01:21:03,199
backtracks from there

1227
01:21:03,199 --> 01:21:04,480
and then searches a different path to

1228
01:21:04,480 --> 01:21:07,199
try to go around this parkour

1229
01:21:07,199 --> 01:21:09,520
eventually it makes progress and gets to

1230
01:21:09,520 --> 01:21:12,080
the goal but ends up using 400 000 nodes

1231
01:21:12,080 --> 01:21:14,000
for making this

1232
01:21:14,000 --> 01:21:16,159
obviously this is a terrible heuristic

1233
01:21:16,159 --> 01:21:18,800
we want to do better than this so

1234
01:21:18,800 --> 01:21:20,480
if you added a navigation route to it

1235
01:21:20,480 --> 01:21:22,159
and has the car to follow the navigation

1236
01:21:22,159 --> 01:21:24,480
route while being close to the goal this

1237
01:21:24,480 --> 01:21:27,120
is what happens

1238
01:21:27,120 --> 01:21:28,960
the navigation route helps immediately

1239
01:21:28,960 --> 01:21:31,440
uh but still when it enter encounters uh

1240
01:21:31,440 --> 01:21:34,320
cones or other obstacles it basically

1241
01:21:34,320 --> 01:21:35,679
that's the same thing as before

1242
01:21:35,679 --> 01:21:37,120
backtracks and then searches that whole

1243
01:21:37,120 --> 01:21:40,080
new path and the support search has no

1244
01:21:40,080 --> 01:21:41,600
idea that these obstacles exist it

1245
01:21:41,600 --> 01:21:43,199
literally has to go there check if it's

1246
01:21:43,199 --> 01:21:44,880
in collision and if it's in collision

1247
01:21:44,880 --> 01:21:46,560
back up

1248
01:21:46,560 --> 01:21:48,000
the navigation heuristic helped but

1249
01:21:48,000 --> 01:21:51,760
still this took 22 000 notes

1250
01:21:51,760 --> 01:21:53,120
we can design more and more of these

1251
01:21:53,120 --> 01:21:55,280
heuristics to help the search make go

1252
01:21:55,280 --> 01:21:57,040
faster and faster but it's really

1253
01:21:57,040 --> 01:22:00,480
tedious and hard to design a globally

1254
01:22:00,480 --> 01:22:02,080
optimal heuristic

1255
01:22:02,080 --> 01:22:03,679
even if you had a distance function from

1256
01:22:03,679 --> 01:22:05,760
the cones that guided the search this

1257
01:22:05,760 --> 01:22:06,880
would not this would not be this would

1258
01:22:06,880 --> 01:22:08,239
only be effective for the single cone

1259
01:22:08,239 --> 01:22:09,920
but what we need is a global global

1260
01:22:09,920 --> 01:22:11,520
value function so instead of what we

1261
01:22:11,520 --> 01:22:13,120
want to use is neural networks to give

1262
01:22:13,120 --> 01:22:15,199
this heuristic for us

1263
01:22:15,199 --> 01:22:17,040
the visual networks produces vector

1264
01:22:17,040 --> 01:22:19,120
space and we have cars moving around in

1265
01:22:19,120 --> 01:22:20,800
it this basically looks like a atari

1266
01:22:20,800 --> 01:22:21,920
game

1267
01:22:21,920 --> 01:22:24,000
and it's a multiplayer version uh so we

1268
01:22:24,000 --> 01:22:26,400
can use techniques such as mu0 alpha

1269
01:22:26,400 --> 01:22:28,159
zero et cetera that was used to solve go

1270
01:22:28,159 --> 01:22:29,679
and other authority games to solve the

1271
01:22:29,679 --> 01:22:32,239
same problem so we're working on neural

1272
01:22:32,239 --> 01:22:33,520
networks that can produce state and

1273
01:22:33,520 --> 01:22:35,120
action distributions that can then be

1274
01:22:35,120 --> 01:22:37,120
plugged into multicolored research with

1275
01:22:37,120 --> 01:22:38,639
various cost functions

1276
01:22:38,639 --> 01:22:39,760
some of the cost functions can be

1277
01:22:39,760 --> 01:22:41,520
explicit cost functions like distance

1278
01:22:41,520 --> 01:22:43,280
like collisions comfort traversal time

1279
01:22:43,280 --> 01:22:45,440
etc but they can also be

1280
01:22:45,440 --> 01:22:46,880
interventions from the actual manual

1281
01:22:46,880 --> 01:22:49,440
driving events

1282
01:22:49,440 --> 01:22:50,880
we train such a network for this simple

1283
01:22:50,880 --> 01:22:52,719
parking problem so here again same

1284
01:22:52,719 --> 01:22:57,360
problem let's see how mcts researched us

1285
01:23:01,520 --> 01:23:03,760
so here you notice that the

1286
01:23:03,760 --> 01:23:05,840
planet is basically able to in one shot

1287
01:23:05,840 --> 01:23:07,760
make progress towards the goal uh to

1288
01:23:07,760 --> 01:23:09,600
notice that this is not even using a

1289
01:23:09,600 --> 01:23:11,360
navigation heuristic just given the

1290
01:23:11,360 --> 01:23:12,400
scene

1291
01:23:12,400 --> 01:23:14,000
the planet is able to go directly

1292
01:23:14,000 --> 01:23:15,520
towards the goal all the other options

1293
01:23:15,520 --> 01:23:17,199
you're seeing are possible options it's

1294
01:23:17,199 --> 01:23:19,040
not choosing any of them just using the

1295
01:23:19,040 --> 01:23:20,960
option that directly takes it towards

1296
01:23:20,960 --> 01:23:22,000
the goal

1297
01:23:22,000 --> 01:23:23,440
the reason is that the neural network is

1298
01:23:23,440 --> 01:23:25,040
able to absorb the global context of the

1299
01:23:25,040 --> 01:23:26,960
scene and then produce a value function

1300
01:23:26,960 --> 01:23:28,639
that effectively guides it towards the

1301
01:23:28,639 --> 01:23:30,000
global minima as opposed to getting

1302
01:23:30,000 --> 01:23:32,400
certain any local minima

1303
01:23:32,400 --> 01:23:34,639
so this only takes 288 notes and several

1304
01:23:34,639 --> 01:23:36,400
orders of magnitude less than what was

1305
01:23:36,400 --> 01:23:38,320
done in the a star with the equilibrium

1306
01:23:38,320 --> 01:23:40,960
distance heuristic

1307
01:23:40,960 --> 01:23:42,800
so this is what a final architecture is

1308
01:23:42,800 --> 01:23:44,480
going to look like the vision system is

1309
01:23:44,480 --> 01:23:46,239
going to crush down the dense video data

1310
01:23:46,239 --> 01:23:47,600
into a vector space

1311
01:23:47,600 --> 01:23:49,120
uh it's going to be consumed by both an

1312
01:23:49,120 --> 01:23:50,400
explicit planner and a neural network

1313
01:23:50,400 --> 01:23:52,080
planner in addition to this the network

1314
01:23:52,080 --> 01:23:53,840
panel can also consume intermediate

1315
01:23:53,840 --> 01:23:55,520
features of the network

1316
01:23:55,520 --> 01:23:56,960
together this produces a trajectory

1317
01:23:56,960 --> 01:23:58,239
distribution

1318
01:23:58,239 --> 01:24:00,560
and it can be optimized end to end both

1319
01:24:00,560 --> 01:24:02,400
with explicit cost functions and human

1320
01:24:02,400 --> 01:24:05,040
intervention and other imitation data

1321
01:24:05,040 --> 01:24:06,480
this then goes into explicit planning

1322
01:24:06,480 --> 01:24:07,520
function that

1323
01:24:07,520 --> 01:24:09,760
does whatever is easy for that and

1324
01:24:09,760 --> 01:24:10,960
produces the final steering and

1325
01:24:10,960 --> 01:24:14,480
acceleration commands for the car

1326
01:24:15,360 --> 01:24:18,080
with that we need to now explain how we

1327
01:24:18,080 --> 01:24:19,520
train these networks and for training

1328
01:24:19,520 --> 01:24:21,360
these networks we need uh large data

1329
01:24:21,360 --> 01:24:22,560
sets

1330
01:24:22,560 --> 01:24:24,560
um and wait i'm ready to speak briefly

1331
01:24:24,560 --> 01:24:28,120
about manual labeling

1332
01:24:34,719 --> 01:24:36,320
yeah so the data the story of data sets

1333
01:24:36,320 --> 01:24:37,840
is critical of course so far we've

1334
01:24:37,840 --> 01:24:39,760
talked only about neural networks but

1335
01:24:39,760 --> 01:24:41,600
neural networks only establish an upper

1336
01:24:41,600 --> 01:24:43,360
bound on your performance many of these

1337
01:24:43,360 --> 01:24:45,199
neural networks uh they have hundreds of

1338
01:24:45,199 --> 01:24:46,639
millions of parameters and these

1339
01:24:46,639 --> 01:24:48,320
hundreds of millions of parameters they

1340
01:24:48,320 --> 01:24:50,239
have to be set correctly

1341
01:24:50,239 --> 01:24:51,679
if you have a bad setting of parameters

1342
01:24:51,679 --> 01:24:53,199
it's not going to work so neural

1343
01:24:53,199 --> 01:24:54,400
networks are just an upper bound you

1344
01:24:54,400 --> 01:24:56,000
also need massive data sets to actually

1345
01:24:56,000 --> 01:24:58,800
train the correct algorithms inside them

1346
01:24:58,800 --> 01:25:00,239
now in particular i mentioned we want

1347
01:25:00,239 --> 01:25:02,080
data sets directly in the vector space

1348
01:25:02,080 --> 01:25:03,679
and so the really the question becomes

1349
01:25:03,679 --> 01:25:05,199
how can you accumulate because our

1350
01:25:05,199 --> 01:25:06,320
networks have hundreds of millions of

1351
01:25:06,320 --> 01:25:08,239
parameters how do you accumulate

1352
01:25:08,239 --> 01:25:10,080
millions and millions of vector space

1353
01:25:10,080 --> 01:25:12,480
examples that are clean and diverse

1354
01:25:12,480 --> 01:25:13,920
to actually train these neural networks

1355
01:25:13,920 --> 01:25:15,440
effectively

1356
01:25:15,440 --> 01:25:17,600
now so there's a story of data sets and

1357
01:25:17,600 --> 01:25:20,400
how they've evolved on the side of uh

1358
01:25:20,400 --> 01:25:22,239
all of the models and developments that

1359
01:25:22,239 --> 01:25:24,239
we've achieved

1360
01:25:24,239 --> 01:25:26,000
now in particular when i joined roughly

1361
01:25:26,000 --> 01:25:27,440
four years ago we were working with a

1362
01:25:27,440 --> 01:25:29,199
third party to obtain a lot of our data

1363
01:25:29,199 --> 01:25:31,120
sets now unfortunately we found very

1364
01:25:31,120 --> 01:25:32,960
quickly that working with a third party

1365
01:25:32,960 --> 01:25:34,400
to get data sets for something this

1366
01:25:34,400 --> 01:25:36,239
critical was just not going to cut it

1367
01:25:36,239 --> 01:25:37,440
the latency of working with a third

1368
01:25:37,440 --> 01:25:40,239
party was extremely high and honestly

1369
01:25:40,239 --> 01:25:42,320
the quality was not amazing and so in

1370
01:25:42,320 --> 01:25:44,800
the spirit of full vertical integration

1371
01:25:44,800 --> 01:25:46,960
at tesla we brought all of the labeling

1372
01:25:46,960 --> 01:25:49,199
in-house and so over time we've grown

1373
01:25:49,199 --> 01:25:51,840
more than one thousand person uh data

1374
01:25:51,840 --> 01:25:53,840
labeling org that is full of

1375
01:25:53,840 --> 01:25:55,520
professional labelers who are working

1376
01:25:55,520 --> 01:25:57,199
very closely with the engineers so

1377
01:25:57,199 --> 01:25:58,480
actually they're here in the u.s and

1378
01:25:58,480 --> 01:26:00,000
co-located with the engineers here in

1379
01:26:00,000 --> 01:26:01,920
the area as well and so we work very

1380
01:26:01,920 --> 01:26:04,400
closely with them and we also build um

1381
01:26:04,400 --> 01:26:06,080
all of the infrastructure for them from

1382
01:26:06,080 --> 01:26:08,239
scratch ourselves so we have a team we

1383
01:26:08,239 --> 01:26:10,080
are going to meet later today

1384
01:26:10,080 --> 01:26:11,760
that develops and maintains all of this

1385
01:26:11,760 --> 01:26:13,520
infrastructure for data labeling and so

1386
01:26:13,520 --> 01:26:14,800
here for example i'm showing some of the

1387
01:26:14,800 --> 01:26:16,800
screenshots of some of the latency

1388
01:26:16,800 --> 01:26:18,320
throughput and quality statistics that

1389
01:26:18,320 --> 01:26:20,400
we maintain about all of the labeling

1390
01:26:20,400 --> 01:26:22,960
workflows and the individual people

1391
01:26:22,960 --> 01:26:24,639
involved and all the tasks and how the

1392
01:26:24,639 --> 01:26:28,639
numbers of labels are growing over time

1393
01:26:28,719 --> 01:26:30,560
so we found this to be quite critical

1394
01:26:30,560 --> 01:26:32,480
and we're very proud of this

1395
01:26:32,480 --> 01:26:34,159
now in the beginning roughly three or

1396
01:26:34,159 --> 01:26:35,760
four years ago most of our labeling was

1397
01:26:35,760 --> 01:26:38,239
in image space and so you can

1398
01:26:38,239 --> 01:26:39,760
imagine that this is taking quite some

1399
01:26:39,760 --> 01:26:41,600
time to annotate an image like this and

1400
01:26:41,600 --> 01:26:43,040
this is what it looked like

1401
01:26:43,040 --> 01:26:44,400
where we are sort of drawing polygons

1402
01:26:44,400 --> 01:26:46,639
and polylines on top of

1403
01:26:46,639 --> 01:26:48,560
on top of these single individual images

1404
01:26:48,560 --> 01:26:50,080
as i mentioned we need millions of

1405
01:26:50,080 --> 01:26:51,280
vector space

1406
01:26:51,280 --> 01:26:53,520
labels so this is not going to cut it so

1407
01:26:53,520 --> 01:26:55,520
very quickly we graduated to

1408
01:26:55,520 --> 01:26:57,520
three-dimensional or four-dimensional

1409
01:26:57,520 --> 01:27:00,000
labeling where we are directly labeling

1410
01:27:00,000 --> 01:27:02,400
in vector space not in individual images

1411
01:27:02,400 --> 01:27:04,639
so here what i'm showing

1412
01:27:04,639 --> 01:27:06,400
is a clip and you are seeing a very

1413
01:27:06,400 --> 01:27:08,159
small reconstruction you're about to see

1414
01:27:08,159 --> 01:27:10,080
a lot more reconstructions soon but it's

1415
01:27:10,080 --> 01:27:11,679
very small reconstruction of the ground

1416
01:27:11,679 --> 01:27:13,520
plane on which the car drove and a

1417
01:27:13,520 --> 01:27:15,199
little bit of the point cloud here that

1418
01:27:15,199 --> 01:27:17,199
was reconstructed and what you're seeing

1419
01:27:17,199 --> 01:27:19,760
here is that the labeler is uh changing

1420
01:27:19,760 --> 01:27:20,719
the

1421
01:27:20,719 --> 01:27:22,560
labels directly in vector space and then

1422
01:27:22,560 --> 01:27:24,639
we are reprojecting those changes into

1423
01:27:24,639 --> 01:27:26,560
camera images uh so we're labeling

1424
01:27:26,560 --> 01:27:27,920
directly in vector space and this gave

1425
01:27:27,920 --> 01:27:29,840
us a massive increase in throughput for

1426
01:27:29,840 --> 01:27:31,199
a lot of our labels because you're

1427
01:27:31,199 --> 01:27:32,880
labeled once in 3d and then you get to

1428
01:27:32,880 --> 01:27:34,480
reproject

1429
01:27:34,480 --> 01:27:37,040
but even this we realized was actually

1430
01:27:37,040 --> 01:27:39,679
not going to cut it

1431
01:27:39,679 --> 01:27:40,719
so

1432
01:27:40,719 --> 01:27:41,840
because people and computers have

1433
01:27:41,840 --> 01:27:43,280
different pros and cons so people are

1434
01:27:43,280 --> 01:27:44,960
extremely good at things like semantics

1435
01:27:44,960 --> 01:27:47,760
but computers are very good at geometry

1436
01:27:47,760 --> 01:27:50,639
reconstruction triangulation tracking

1437
01:27:50,639 --> 01:27:52,320
and so really for us it's much more

1438
01:27:52,320 --> 01:27:53,920
becoming a story of how do humans and

1439
01:27:53,920 --> 01:27:55,760
computers collaborate to actually create

1440
01:27:55,760 --> 01:27:57,600
these vector space data sets and so

1441
01:27:57,600 --> 01:27:59,280
we're gonna not talk about auto labeling

1442
01:27:59,280 --> 01:28:00,239
which is some of the infrastructure

1443
01:28:00,239 --> 01:28:02,000
we've developed for labeling these clips

1444
01:28:02,000 --> 01:28:04,480
at scale

1445
01:28:04,530 --> 01:28:08,880
[Applause]

1446
01:28:08,880 --> 01:28:11,360
hi again

1447
01:28:11,679 --> 01:28:13,199
so even though we have lots of human

1448
01:28:13,199 --> 01:28:15,280
laborers the amount of training data

1449
01:28:15,280 --> 01:28:16,639
needed for training with networks

1450
01:28:16,639 --> 01:28:18,639
significantly outnumbers them so we try

1451
01:28:18,639 --> 01:28:20,159
to invest in a massive auto labeling

1452
01:28:20,159 --> 01:28:22,480
pipeline here's an example of how we

1453
01:28:22,480 --> 01:28:25,280
label a single clip a clip is a entity

1454
01:28:25,280 --> 01:28:28,080
that has dense sensor data like videos

1455
01:28:28,080 --> 01:28:30,639
imu data gps odometry etc

1456
01:28:30,639 --> 01:28:32,639
this can be 45 second to a minute long

1457
01:28:32,639 --> 01:28:33,840
these can be uploaded by our own

1458
01:28:33,840 --> 01:28:36,480
engineering cars or from customer cars

1459
01:28:36,480 --> 01:28:38,159
we collect these clips and then send

1460
01:28:38,159 --> 01:28:39,280
them to

1461
01:28:39,280 --> 01:28:41,280
our servers where we run a lot of neural

1462
01:28:41,280 --> 01:28:43,199
networks offline to produce intermediate

1463
01:28:43,199 --> 01:28:45,679
results like segmentation masks depth

1464
01:28:45,679 --> 01:28:47,840
point matching etc this then goes

1465
01:28:47,840 --> 01:28:49,120
through a lot of robotics and a

1466
01:28:49,120 --> 01:28:50,639
algorithm to produce a final set of

1467
01:28:50,639 --> 01:28:52,239
labels that can be used to train the

1468
01:28:52,239 --> 01:28:54,719
networks

1469
01:28:55,199 --> 01:28:57,360
one of the first tasks we want to label

1470
01:28:57,360 --> 01:28:59,440
is the road surface typically we can use

1471
01:28:59,440 --> 01:29:00,960
splines or meshes to represent the road

1472
01:29:00,960 --> 01:29:02,639
surface but those are

1473
01:29:02,639 --> 01:29:04,080
because of the topology restrictions are

1474
01:29:04,080 --> 01:29:06,159
not differentiable and not amenable to

1475
01:29:06,159 --> 01:29:08,159
producing this so what we do instead is

1476
01:29:08,159 --> 01:29:09,840
in the style of neural radiance fields

1477
01:29:09,840 --> 01:29:11,679
work from last year which is quite

1478
01:29:11,679 --> 01:29:13,040
popular so we use an implicit

1479
01:29:13,040 --> 01:29:14,400
representation to represent the road

1480
01:29:14,400 --> 01:29:15,520
surface

1481
01:29:15,520 --> 01:29:18,320
here we are querying xy points on the

1482
01:29:18,320 --> 01:29:19,840
ground and asking for the network to

1483
01:29:19,840 --> 01:29:22,080
predict the height of the ground surface

1484
01:29:22,080 --> 01:29:24,159
along with various semantics such as

1485
01:29:24,159 --> 01:29:26,639
curves lane boundaries road surface

1486
01:29:26,639 --> 01:29:28,719
rival space etc

1487
01:29:28,719 --> 01:29:31,679
so given a single xy we get a z together

1488
01:29:31,679 --> 01:29:33,679
these make a 3d point and they can be

1489
01:29:33,679 --> 01:29:36,239
reprojected into all the camera views

1490
01:29:36,239 --> 01:29:38,239
so we make millions of such queries and

1491
01:29:38,239 --> 01:29:40,639
get lots of points these points are

1492
01:29:40,639 --> 01:29:42,800
reprojected into all the camera views

1493
01:29:42,800 --> 01:29:45,360
in we are showing on the top right here

1494
01:29:45,360 --> 01:29:46,960
one such camera image with all these

1495
01:29:46,960 --> 01:29:48,800
points reprojected

1496
01:29:48,800 --> 01:29:51,440
now we can compare this point

1497
01:29:51,440 --> 01:29:54,080
reprojected point with the image space

1498
01:29:54,080 --> 01:29:56,480
prediction of the segmentations

1499
01:29:56,480 --> 01:29:58,239
and jointly optimizing this or all the

1500
01:29:58,239 --> 01:30:00,639
camera views was across space and time

1501
01:30:00,639 --> 01:30:03,040
produced an excellent reconstruction

1502
01:30:03,040 --> 01:30:05,520
here's an example of how that looks like

1503
01:30:05,520 --> 01:30:06,800
so here this is an optimized road

1504
01:30:06,800 --> 01:30:08,800
surface that reproduction to the eight

1505
01:30:08,800 --> 01:30:10,960
cameras that the car has and across all

1506
01:30:10,960 --> 01:30:12,239
of time and you can see how it's

1507
01:30:12,239 --> 01:30:16,239
consistent across both space and time

1508
01:30:17,520 --> 01:30:19,120
so a single car driving through some

1509
01:30:19,120 --> 01:30:21,679
location can sweep out some patch around

1510
01:30:21,679 --> 01:30:25,120
the trajectory using this technique

1511
01:30:25,120 --> 01:30:27,199
but we don't have to stop there

1512
01:30:27,199 --> 01:30:29,440
so here we collect collected different

1513
01:30:29,440 --> 01:30:30,400
clips

1514
01:30:30,400 --> 01:30:31,840
from the same location from different

1515
01:30:31,840 --> 01:30:33,199
cars maybe

1516
01:30:33,199 --> 01:30:35,360
and each of them sweeps out some part of

1517
01:30:35,360 --> 01:30:37,280
the road

1518
01:30:37,280 --> 01:30:38,560
cool thing is we can bring them all

1519
01:30:38,560 --> 01:30:40,239
together into a single giant

1520
01:30:40,239 --> 01:30:42,239
optimization so here these 16 different

1521
01:30:42,239 --> 01:30:44,960
trips are organized using

1522
01:30:44,960 --> 01:30:46,719
aligned using various features such as

1523
01:30:46,719 --> 01:30:48,560
roadages lane lines all of them should

1524
01:30:48,560 --> 01:30:50,480
agree with each other and also agree

1525
01:30:50,480 --> 01:30:51,440
with all of their image space

1526
01:30:51,440 --> 01:30:52,639
observations

1527
01:30:52,639 --> 01:30:54,159
together this is this produces an

1528
01:30:54,159 --> 01:30:56,239
effective way to label the road surface

1529
01:30:56,239 --> 01:30:58,159
not just where the car drove but also in

1530
01:30:58,159 --> 01:31:01,199
other locations that it hasn't driven it

1531
01:31:01,199 --> 01:31:02,560
again the point of this is not to just

1532
01:31:02,560 --> 01:31:04,400
build hd maps or anything like that it's

1533
01:31:04,400 --> 01:31:05,920
only to label the clips through these

1534
01:31:05,920 --> 01:31:07,600
intersections so we don't have to

1535
01:31:07,600 --> 01:31:09,360
maintain them forever as long as the

1536
01:31:09,360 --> 01:31:11,120
labels are consistent with the videos

1537
01:31:11,120 --> 01:31:14,000
that they were collected at

1538
01:31:14,000 --> 01:31:15,440
optionally then humans can come on top

1539
01:31:15,440 --> 01:31:17,360
of this and clean up any noise or

1540
01:31:17,360 --> 01:31:19,040
additional metadata to make it even

1541
01:31:19,040 --> 01:31:21,440
richer

1542
01:31:21,920 --> 01:31:23,360
we don't have to stop at just the road

1543
01:31:23,360 --> 01:31:25,120
surface we can also arbitrarily

1544
01:31:25,120 --> 01:31:28,480
reconstruct 3d static obstacles um here

1545
01:31:28,480 --> 01:31:30,719
this is a reconstructed 3d point cloud

1546
01:31:30,719 --> 01:31:33,199
from our cameras

1547
01:31:33,199 --> 01:31:34,880
the main innovation here is the density

1548
01:31:34,880 --> 01:31:36,560
of the point cloud typically these

1549
01:31:36,560 --> 01:31:38,239
points require texture

1550
01:31:38,239 --> 01:31:40,239
to form associations from one frame to

1551
01:31:40,239 --> 01:31:42,080
the next frame but here we are able to

1552
01:31:42,080 --> 01:31:43,760
produce these points even on textual

1553
01:31:43,760 --> 01:31:46,239
surfaces like the road surface or walls

1554
01:31:46,239 --> 01:31:47,920
and this is really useful to annotate

1555
01:31:47,920 --> 01:31:50,320
arbitrary obstacles that

1556
01:31:50,320 --> 01:31:54,000
we can see on the scene in the world

1557
01:31:55,040 --> 01:31:56,800
one more cool advantage of doing all of

1558
01:31:56,800 --> 01:31:59,440
this on server on the servers offline is

1559
01:31:59,440 --> 01:32:01,199
that we have the benefit of hindsight

1560
01:32:01,199 --> 01:32:04,080
this is a super useful hack because uh

1561
01:32:04,080 --> 01:32:06,080
say in the car then the network needs to

1562
01:32:06,080 --> 01:32:07,920
produce the velocity it just has to use

1563
01:32:07,920 --> 01:32:09,520
the historical information and guess

1564
01:32:09,520 --> 01:32:11,120
what the velocity is

1565
01:32:11,120 --> 01:32:12,800
but here

1566
01:32:12,800 --> 01:32:14,880
we can look at both the history but also

1567
01:32:14,880 --> 01:32:17,280
the future and basically cheat and get

1568
01:32:17,280 --> 01:32:19,600
the correct answer uh of the kinematics

1569
01:32:19,600 --> 01:32:22,000
like velocity acceleration etc

1570
01:32:22,000 --> 01:32:23,600
one more advantage is that we can have

1571
01:32:23,600 --> 01:32:25,280
different tracks but we can switch them

1572
01:32:25,280 --> 01:32:26,880
together that even through occlusions

1573
01:32:26,880 --> 01:32:28,000
because we know the future we have

1574
01:32:28,000 --> 01:32:29,760
future tracks we can match them and then

1575
01:32:29,760 --> 01:32:31,679
associate them so here you can see the

1576
01:32:31,679 --> 01:32:33,040
pedestrians on the other side of the

1577
01:32:33,040 --> 01:32:35,120
road are persisted even through multiple

1578
01:32:35,120 --> 01:32:37,360
occlusions by these cars

1579
01:32:37,360 --> 01:32:38,719
this is really important for the planner

1580
01:32:38,719 --> 01:32:40,320
because the planner needs to know if

1581
01:32:40,320 --> 01:32:42,960
it's if it saw someone it still needs to

1582
01:32:42,960 --> 01:32:44,239
account for them even then they are

1583
01:32:44,239 --> 01:32:48,400
occluded so this is a massive advantage

1584
01:32:49,360 --> 01:32:51,040
combining everything together we can

1585
01:32:51,040 --> 01:32:52,880
produce these amazing data sets that

1586
01:32:52,880 --> 01:32:55,440
annotate all of the road texture

1587
01:32:55,440 --> 01:32:57,440
or the static objects and all of the

1588
01:32:57,440 --> 01:32:59,520
moving objects even through occlusions

1589
01:32:59,520 --> 01:33:01,840
producing excellent kinematic

1590
01:33:01,840 --> 01:33:02,880
labels

1591
01:33:02,880 --> 01:33:04,400
all you can see how the cards turn

1592
01:33:04,400 --> 01:33:07,040
smoothly produce really smooth labels or

1593
01:33:07,040 --> 01:33:08,960
the pedestrians are consistently tracked

1594
01:33:08,960 --> 01:33:10,639
the park cars uh

1595
01:33:10,639 --> 01:33:12,239
obviously zero velocity so we can also

1596
01:33:12,239 --> 01:33:13,760
know that they are parked

1597
01:33:13,760 --> 01:33:16,320
so this is huge for us

1598
01:33:16,320 --> 01:33:17,760
this is one more example of the same

1599
01:33:17,760 --> 01:33:19,280
thing

1600
01:33:19,280 --> 01:33:20,960
you can see how everything is consistent

1601
01:33:20,960 --> 01:33:23,600
we want to produce a million such uh

1602
01:33:23,600 --> 01:33:24,639
labeled

1603
01:33:24,639 --> 01:33:26,880
clips and train our video

1604
01:33:26,880 --> 01:33:28,800
multicam video networks with such large

1605
01:33:28,800 --> 01:33:31,199
data set and really crush this problem

1606
01:33:31,199 --> 01:33:32,560
we want to get the same view that's

1607
01:33:32,560 --> 01:33:34,400
consistent that we're seeing here in the

1608
01:33:34,400 --> 01:33:36,639
car

1609
01:33:36,639 --> 01:33:38,320
we started our first exploration of this

1610
01:33:38,320 --> 01:33:40,159
with the remove the data project uh we

1611
01:33:40,159 --> 01:33:42,000
removed it in a very top a short time

1612
01:33:42,000 --> 01:33:44,400
span i think within three months

1613
01:33:44,400 --> 01:33:45,679
in the early days of the network we

1614
01:33:45,679 --> 01:33:47,280
noticed for example in low security

1615
01:33:47,280 --> 01:33:49,520
conditions the network can suffer

1616
01:33:49,520 --> 01:33:51,280
understandably because obviously this

1617
01:33:51,280 --> 01:33:52,719
truck just dumped a bunch of snow on us

1618
01:33:52,719 --> 01:33:54,800
and it's really hard to see but we

1619
01:33:54,800 --> 01:33:56,080
should still remember that this car was

1620
01:33:56,080 --> 01:33:57,520
in front of us

1621
01:33:57,520 --> 01:33:59,840
but our networks early on did not do

1622
01:33:59,840 --> 01:34:01,520
this because of the lack of data in such

1623
01:34:01,520 --> 01:34:04,000
conditions

1624
01:34:04,000 --> 01:34:05,520
so what we did we added the fleet to

1625
01:34:05,520 --> 01:34:07,920
produce lots of similar clips

1626
01:34:07,920 --> 01:34:10,400
and the fleet responded it did

1627
01:34:10,400 --> 01:34:13,760
so it produces um

1628
01:34:14,159 --> 01:34:16,719
is it play

1629
01:34:16,840 --> 01:34:19,920
yeah it produces lots of video clips

1630
01:34:19,920 --> 01:34:21,520
where shit's falling out of all other

1631
01:34:21,520 --> 01:34:22,960
vehicles

1632
01:34:22,960 --> 01:34:24,560
and we send this through our auto living

1633
01:34:24,560 --> 01:34:26,639
pipeline that was able to label 10k

1634
01:34:26,639 --> 01:34:28,400
clips in within a week this would have

1635
01:34:28,400 --> 01:34:30,159
taken several months with humans

1636
01:34:30,159 --> 01:34:32,480
labeling every single clip here

1637
01:34:32,480 --> 01:34:35,679
so we did this for 200 of different

1638
01:34:35,679 --> 01:34:37,199
conditions and we were able to very

1639
01:34:37,199 --> 01:34:38,719
quickly create large data sets and

1640
01:34:38,719 --> 01:34:41,119
that's how we were able to remove this

1641
01:34:41,119 --> 01:34:42,719
so once we train the networks with this

1642
01:34:42,719 --> 01:34:43,600
data

1643
01:34:43,600 --> 01:34:45,679
you can see that it's totally working

1644
01:34:45,679 --> 01:34:47,840
and keeps the memory that the subject

1645
01:34:47,840 --> 01:34:48,880
was there

1646
01:34:48,880 --> 01:34:52,159
and provides this

1647
01:34:52,400 --> 01:34:53,920
so finally we wanted to actually get a

1648
01:34:53,920 --> 01:34:55,679
cyber truck into a data set

1649
01:34:55,679 --> 01:34:57,199
for the remote radar

1650
01:34:57,199 --> 01:34:58,880
can you all guess where we got this clip

1651
01:34:58,880 --> 01:35:02,800
from i'll give you a moment

1652
01:35:03,520 --> 01:35:05,920
someone said it yes yes it's rendered

1653
01:35:05,920 --> 01:35:07,679
it's our simulation

1654
01:35:07,679 --> 01:35:09,440
it was hard for me to tell initially and

1655
01:35:09,440 --> 01:35:11,199
i if i may if i may say so myself it

1656
01:35:11,199 --> 01:35:15,360
looks pretty it looks very pretty um

1657
01:35:15,360 --> 01:35:17,360
so yeah in addition to auto labeling we

1658
01:35:17,360 --> 01:35:19,119
also invest heavily in using simulation

1659
01:35:19,119 --> 01:35:20,560
for labeling our

1660
01:35:20,560 --> 01:35:22,320
data

1661
01:35:22,320 --> 01:35:24,320
so this is the same scene as

1662
01:35:24,320 --> 01:35:25,440
seen before

1663
01:35:25,440 --> 01:35:29,280
but from a different camera angle

1664
01:35:29,280 --> 01:35:30,880
so a few things that i wanted to point

1665
01:35:30,880 --> 01:35:33,440
out for example the ground surface it's

1666
01:35:33,440 --> 01:35:35,520
not a plane asphalt there are lots of

1667
01:35:35,520 --> 01:35:38,560
cars and cracks and tower seams

1668
01:35:38,560 --> 01:35:41,040
there's some patchwork done on top of it

1669
01:35:41,040 --> 01:35:42,639
vehicles move realistically the truck is

1670
01:35:42,639 --> 01:35:44,719
articulated uh even goes over the curb

1671
01:35:44,719 --> 01:35:47,520
and makes a wide turn um the other cars

1672
01:35:47,520 --> 01:35:49,360
behave smartly they avoid collisions go

1673
01:35:49,360 --> 01:35:51,600
around cars uh and also smooth and

1674
01:35:51,600 --> 01:35:53,360
actual great smooth uh brake and

1675
01:35:53,360 --> 01:35:56,159
accelerate smoothly

1676
01:35:56,159 --> 01:35:58,000
the car here with the logo on the top is

1677
01:35:58,000 --> 01:35:59,600
autopilot actually auto part is driving

1678
01:35:59,600 --> 01:36:00,800
that car and it's making unproductive

1679
01:36:00,800 --> 01:36:03,199
left hand

1680
01:36:03,600 --> 01:36:05,199
and since it's a simulation it starts

1681
01:36:05,199 --> 01:36:06,880
from the vector space so it has perfect

1682
01:36:06,880 --> 01:36:08,080
labels

1683
01:36:08,080 --> 01:36:09,520
here we show a few of the labels that we

1684
01:36:09,520 --> 01:36:10,719
produce

1685
01:36:10,719 --> 01:36:12,159
these are vehicle cuboids with

1686
01:36:12,159 --> 01:36:13,520
kinematics

1687
01:36:13,520 --> 01:36:14,400
depth

1688
01:36:14,400 --> 01:36:17,679
surface normals segmentation but

1689
01:36:17,679 --> 01:36:19,360
andre can name a new task that he wants

1690
01:36:19,360 --> 01:36:20,639
next week and we can very quickly

1691
01:36:20,639 --> 01:36:22,800
produce this because we already have a

1692
01:36:22,800 --> 01:36:24,239
vector space and we can write the code

1693
01:36:24,239 --> 01:36:25,440
to produce these labels very very

1694
01:36:25,440 --> 01:36:27,840
quickly

1695
01:36:28,159 --> 01:36:30,080
so when does simulation help

1696
01:36:30,080 --> 01:36:31,840
it helps number one when the data is

1697
01:36:31,840 --> 01:36:33,840
difficult to source as large as our

1698
01:36:33,840 --> 01:36:36,159
fleet is it can still be hard to get

1699
01:36:36,159 --> 01:36:37,679
some crazy scenes like this couple and

1700
01:36:37,679 --> 01:36:39,920
their dog running on the highway while

1701
01:36:39,920 --> 01:36:43,360
there are other high-speed cars around

1702
01:36:43,360 --> 01:36:45,360
this is a pretty rare scene i'd say but

1703
01:36:45,360 --> 01:36:46,800
still can happen

1704
01:36:46,800 --> 01:36:48,320
and autopilot still needs to handle it

1705
01:36:48,320 --> 01:36:50,480
when it happens

1706
01:36:50,480 --> 01:36:52,320
when data is difficult to label um there

1707
01:36:52,320 --> 01:36:53,520
are hundreds of pedestrians crossing the

1708
01:36:53,520 --> 01:36:56,000
road this could be a mountain downtown

1709
01:36:56,000 --> 01:36:57,440
people crossing the road it's going to

1710
01:36:57,440 --> 01:36:58,960
take several hours for humans to label

1711
01:36:58,960 --> 01:37:00,320
this clip and even for automatic

1712
01:37:00,320 --> 01:37:01,920
labeling algorithms this is really hard

1713
01:37:01,920 --> 01:37:03,440
to get the association right and it can

1714
01:37:03,440 --> 01:37:05,360
produce like bad velocities but in

1715
01:37:05,360 --> 01:37:06,880
simulation this is trivial because you

1716
01:37:06,880 --> 01:37:08,159
already have the objects you just have

1717
01:37:08,159 --> 01:37:09,840
to spit out the cuboids and the

1718
01:37:09,840 --> 01:37:11,040
velocities

1719
01:37:11,040 --> 01:37:12,480
and also finally when we introduce

1720
01:37:12,480 --> 01:37:14,719
closed loop behavior where the cars

1721
01:37:14,719 --> 01:37:16,800
needs to be in a determining situation

1722
01:37:16,800 --> 01:37:19,199
or the data depends on the actions this

1723
01:37:19,199 --> 01:37:20,960
is pretty much the only way to get it

1724
01:37:20,960 --> 01:37:23,040
reliably

1725
01:37:23,040 --> 01:37:24,560
all this is great

1726
01:37:24,560 --> 01:37:27,679
what's needed to make this happen

1727
01:37:28,239 --> 01:37:31,199
number one accurate sensor simulation

1728
01:37:31,199 --> 01:37:32,639
again the point of the simulation is not

1729
01:37:32,639 --> 01:37:34,639
to just produce pretty pictures

1730
01:37:34,639 --> 01:37:36,800
it needs to produce what the camera in

1731
01:37:36,800 --> 01:37:38,400
the car would see and other sensors

1732
01:37:38,400 --> 01:37:40,239
would see so here we are stepping

1733
01:37:40,239 --> 01:37:41,760
through different exposure settings of

1734
01:37:41,760 --> 01:37:43,679
the real camera on the left side and the

1735
01:37:43,679 --> 01:37:46,320
simulation on the right side

1736
01:37:46,320 --> 01:37:47,760
we're able to pretty much match what the

1737
01:37:47,760 --> 01:37:50,560
real cameras do

1738
01:37:50,639 --> 01:37:52,239
in order to do this we had to model a

1739
01:37:52,239 --> 01:37:54,800
lot of the properties of the camera in

1740
01:37:54,800 --> 01:37:57,119
our sensor simulation um starting from

1741
01:37:57,119 --> 01:37:59,280
sensor noise motion blur optical

1742
01:37:59,280 --> 01:38:02,000
distortions even headlight transmissions

1743
01:38:02,000 --> 01:38:03,360
uh

1744
01:38:03,360 --> 01:38:05,199
even like diffraction patterns of the

1745
01:38:05,199 --> 01:38:06,960
windshield etcetera

1746
01:38:06,960 --> 01:38:08,560
we don't use this just for the autopilot

1747
01:38:08,560 --> 01:38:10,239
software we also use it to make hardware

1748
01:38:10,239 --> 01:38:11,920
decisions such as lens design camera

1749
01:38:11,920 --> 01:38:14,239
design sensor placement even headlight

1750
01:38:14,239 --> 01:38:17,639
transmission properties

1751
01:38:19,360 --> 01:38:22,320
second we need to render the visuals uh

1752
01:38:22,320 --> 01:38:24,719
in a realistic manner you cannot have

1753
01:38:24,719 --> 01:38:27,280
what in the game industry called jaggies

1754
01:38:27,280 --> 01:38:29,119
these are aliasing artifacts that are

1755
01:38:29,119 --> 01:38:31,360
dead giveaway that this is simulation we

1756
01:38:31,360 --> 01:38:32,960
don't want them so we go through a lot

1757
01:38:32,960 --> 01:38:35,440
of paints to produce a nice special

1758
01:38:35,440 --> 01:38:38,480
temple a special temporal anti-aliasing

1759
01:38:38,480 --> 01:38:40,320
we also are working on neural rendering

1760
01:38:40,320 --> 01:38:41,440
techniques to make this even more

1761
01:38:41,440 --> 01:38:44,440
realistic

1762
01:38:47,679 --> 01:38:49,280
yeah in addition we also use ray tracing

1763
01:38:49,280 --> 01:38:50,719
to produce realistic lighting and global

1764
01:38:50,719 --> 01:38:52,560
illumination okay that's the last of the

1765
01:38:52,560 --> 01:38:55,280
cop cars i think

1766
01:38:56,880 --> 01:38:58,719
we obviously cannot have uh really just

1767
01:38:58,719 --> 01:38:59,920
four or five cars because the network

1768
01:38:59,920 --> 01:39:01,520
will easily overfit because it knows the

1769
01:39:01,520 --> 01:39:03,920
sizes um so we need to have realistic

1770
01:39:03,920 --> 01:39:05,760
assets like the moose on the road here

1771
01:39:05,760 --> 01:39:06,800
um

1772
01:39:06,800 --> 01:39:08,080
we have thousands of assets in our

1773
01:39:08,080 --> 01:39:10,000
library and they can wear different

1774
01:39:10,000 --> 01:39:11,199
shirts and actually can move

1775
01:39:11,199 --> 01:39:13,520
realistically so this is really cool

1776
01:39:13,520 --> 01:39:14,560
we also have a lot of different

1777
01:39:14,560 --> 01:39:16,960
locations mapped and created uh to

1778
01:39:16,960 --> 01:39:19,440
create these uh sim environments

1779
01:39:19,440 --> 01:39:22,080
we have actually 2000 miles of uh

1780
01:39:22,080 --> 01:39:24,000
road built and this is almost the length

1781
01:39:24,000 --> 01:39:25,760
of the roadway from the east coast the

1782
01:39:25,760 --> 01:39:27,119
west coast of the united states which i

1783
01:39:27,119 --> 01:39:28,400
think is pretty cool

1784
01:39:28,400 --> 01:39:29,840
in addition we have built efficient

1785
01:39:29,840 --> 01:39:32,400
tooling to build several miles more on a

1786
01:39:32,400 --> 01:39:36,080
single day on a for a single artist

1787
01:39:36,719 --> 01:39:38,719
but this is just tip of the iceberg

1788
01:39:38,719 --> 01:39:40,800
actually most of the data that we use to

1789
01:39:40,800 --> 01:39:43,440
train is created procedurally using

1790
01:39:43,440 --> 01:39:45,360
algorithms as opposed to artists making

1791
01:39:45,360 --> 01:39:47,679
these simulation scenarios

1792
01:39:47,679 --> 01:39:49,199
so these are all procedurally created

1793
01:39:49,199 --> 01:39:51,199
roads with lots of parameters such as

1794
01:39:51,199 --> 01:39:52,320
curvature

1795
01:39:52,320 --> 01:39:55,119
various varying trees cones poles cars

1796
01:39:55,119 --> 01:39:56,560
with different velocities and the

1797
01:39:56,560 --> 01:39:58,239
interaction produce an endless stream of

1798
01:39:58,239 --> 01:40:00,000
data for the network

1799
01:40:00,000 --> 01:40:01,520
but a lot of this data can be boring

1800
01:40:01,520 --> 01:40:02,880
because the network might already get it

1801
01:40:02,880 --> 01:40:04,719
correct so what we do is we use also ml

1802
01:40:04,719 --> 01:40:06,639
based techniques to basically put up the

1803
01:40:06,639 --> 01:40:08,880
network to see where it's failing at and

1804
01:40:08,880 --> 01:40:10,719
create more data around the failure

1805
01:40:10,719 --> 01:40:12,400
points of the network so this is in

1806
01:40:12,400 --> 01:40:13,760
closed loop trying to make the network

1807
01:40:13,760 --> 01:40:16,960
performance be better

1808
01:40:18,000 --> 01:40:19,840
we don't want to stop there so actually

1809
01:40:19,840 --> 01:40:22,800
we want to create recreate any failures

1810
01:40:22,800 --> 01:40:24,080
that happens to the autopilot in

1811
01:40:24,080 --> 01:40:25,840
simulation so that we can hold autopilot

1812
01:40:25,840 --> 01:40:28,000
to the same bar from then on

1813
01:40:28,000 --> 01:40:29,840
so here on the left side you are seeing

1814
01:40:29,840 --> 01:40:31,600
a real clip that was collected from a

1815
01:40:31,600 --> 01:40:33,040
car

1816
01:40:33,040 --> 01:40:34,719
it then goes through our auto labeling

1817
01:40:34,719 --> 01:40:36,880
pipeline to produce a 3d reconstruction

1818
01:40:36,880 --> 01:40:38,239
of the scene along with all the moving

1819
01:40:38,239 --> 01:40:40,320
objects

1820
01:40:40,320 --> 01:40:42,000
with this combined with the original

1821
01:40:42,000 --> 01:40:44,239
visual information we recreate the same

1822
01:40:44,239 --> 01:40:46,080
scene synthetically and create a

1823
01:40:46,080 --> 01:40:48,400
simulation scenario entirely out of it

1824
01:40:48,400 --> 01:40:50,320
so and then when we replay autopilot on

1825
01:40:50,320 --> 01:40:52,080
it autopilot can do entirely new things

1826
01:40:52,080 --> 01:40:54,320
and we can form new worlds new outcomes

1827
01:40:54,320 --> 01:40:56,320
from the original failure this is

1828
01:40:56,320 --> 01:40:58,000
amazing because we really don't want

1829
01:40:58,000 --> 01:40:59,520
autopilot to fail and when it fails we

1830
01:40:59,520 --> 01:41:02,239
want to capture it and keep it to that

1831
01:41:02,239 --> 01:41:05,239
bar

1832
01:41:07,040 --> 01:41:08,719
not just that we can actually take the

1833
01:41:08,719 --> 01:41:10,159
same approach that we said earlier and

1834
01:41:10,159 --> 01:41:11,840
take it one step further

1835
01:41:11,840 --> 01:41:14,000
we can use neural rendering techniques

1836
01:41:14,000 --> 01:41:16,400
to make it look even more realistic

1837
01:41:16,400 --> 01:41:18,239
so we take the original original video

1838
01:41:18,239 --> 01:41:19,119
clip

1839
01:41:19,119 --> 01:41:21,280
we create a synthetic uh simulation from

1840
01:41:21,280 --> 01:41:22,000
it

1841
01:41:22,000 --> 01:41:23,360
and then apply neural rendering

1842
01:41:23,360 --> 01:41:24,880
techniques on top of it and it produces

1843
01:41:24,880 --> 01:41:26,560
this which looks amazing in my opinion

1844
01:41:26,560 --> 01:41:28,639
because this one is very realistic and

1845
01:41:28,639 --> 01:41:30,000
looks almost like it was captured by the

1846
01:41:30,000 --> 01:41:31,360
actual cameras

1847
01:41:31,360 --> 01:41:33,440
they saw results from last night because

1848
01:41:33,440 --> 01:41:35,920
it was cool and we wanted to present it

1849
01:41:35,920 --> 01:41:37,040
but yeah

1850
01:41:37,040 --> 01:41:38,480
yeah i'm very excited for what sim can

1851
01:41:38,480 --> 01:41:39,600
achieve

1852
01:41:39,600 --> 01:41:41,119
but this is not all because

1853
01:41:41,119 --> 01:41:42,960
network's trained in the car already

1854
01:41:42,960 --> 01:41:45,600
used simulation data we used 300 million

1855
01:41:45,600 --> 01:41:48,080
images with almost half a billion labels

1856
01:41:48,080 --> 01:41:49,679
and we want to crush down all the tasks

1857
01:41:49,679 --> 01:41:51,280
that are going to come up for uh the

1858
01:41:51,280 --> 01:41:53,360
next several months

1859
01:41:53,360 --> 01:41:55,760
with that i invite milan to see uh to

1860
01:41:55,760 --> 01:41:57,280
explain how we scale these operations

1861
01:41:57,280 --> 01:41:59,760
and really build a label factory

1862
01:41:59,760 --> 01:42:02,780
and spit out millions of labels

1863
01:42:02,780 --> 01:42:09,920
[Applause]

1864
01:42:09,920 --> 01:42:11,360
all right thanks ashok

1865
01:42:11,360 --> 01:42:13,600
hey everyone i'm milan i'm responsible

1866
01:42:13,600 --> 01:42:15,280
for the integration of our neural

1867
01:42:15,280 --> 01:42:17,280
networks in the car and for most of our

1868
01:42:17,280 --> 01:42:18,960
neural network training and evaluation

1869
01:42:18,960 --> 01:42:20,480
infrastructure

1870
01:42:20,480 --> 01:42:22,159
and so tonight i'd just like to start by

1871
01:42:22,159 --> 01:42:23,520
giving you some perspective into the

1872
01:42:23,520 --> 01:42:25,840
amount of compute that's needed to power

1873
01:42:25,840 --> 01:42:28,480
this type of data generation factory and

1874
01:42:28,480 --> 01:42:30,880
so in the specific context of the push

1875
01:42:30,880 --> 01:42:32,239
we went through as a team here a few

1876
01:42:32,239 --> 01:42:34,560
months ago to get rid of the dependency

1877
01:42:34,560 --> 01:42:36,960
on the radar sensor for the pilot we

1878
01:42:36,960 --> 01:42:39,360
generated over 10 billion labels across

1879
01:42:39,360 --> 01:42:41,280
two and a half million clips

1880
01:42:41,280 --> 01:42:43,360
and so to do that we had to

1881
01:42:43,360 --> 01:42:44,400
scale

1882
01:42:44,400 --> 01:42:46,719
our huge offline neural networks and our

1883
01:42:46,719 --> 01:42:48,960
simulation engine across thousands of

1884
01:42:48,960 --> 01:42:51,920
gpus and just a little bit shy of 20 000

1885
01:42:51,920 --> 01:42:54,560
cpu cars on top of that we also included

1886
01:42:54,560 --> 01:42:56,639
over 2000 actual autopilot full

1887
01:42:56,639 --> 01:42:58,560
self-driving computers in the loop with

1888
01:42:58,560 --> 01:43:00,320
our simulation engine

1889
01:43:00,320 --> 01:43:05,040
and that's our smallest compute cluster

1890
01:43:07,440 --> 01:43:09,119
so i'd like to give you some

1891
01:43:09,119 --> 01:43:10,639
idea of what it takes to take our neural

1892
01:43:10,639 --> 01:43:12,639
networks and

1893
01:43:12,639 --> 01:43:14,400
move them in the car

1894
01:43:14,400 --> 01:43:15,760
and so the

1895
01:43:15,760 --> 01:43:17,040
the two main constraints that we're

1896
01:43:17,040 --> 01:43:18,880
working on there here

1897
01:43:18,880 --> 01:43:22,159
are mostly latency and frame rate

1898
01:43:22,159 --> 01:43:24,000
which are very important for safety but

1899
01:43:24,000 --> 01:43:26,159
also to get proper estimates of

1900
01:43:26,159 --> 01:43:27,920
acceleration and velocity of our

1901
01:43:27,920 --> 01:43:29,440
surroundings

1902
01:43:29,440 --> 01:43:31,040
and so the meat of the problem really is

1903
01:43:31,040 --> 01:43:34,080
around uh the ai compiler that we write

1904
01:43:34,080 --> 01:43:36,000
and extend here within the group that

1905
01:43:36,000 --> 01:43:38,080
essentially maps the compute operations

1906
01:43:38,080 --> 01:43:39,840
for my apart torch model

1907
01:43:39,840 --> 01:43:43,840
to a set of dedicated and accelerated uh

1908
01:43:43,840 --> 01:43:46,080
pieces of hardware and we do that while

1909
01:43:46,080 --> 01:43:48,239
figuring out a schedule that's optimized

1910
01:43:48,239 --> 01:43:49,600
for throat put

1911
01:43:49,600 --> 01:43:51,520
while working on their severe sram

1912
01:43:51,520 --> 01:43:53,760
constraints

1913
01:43:53,760 --> 01:43:55,280
and so by the way we're not doing that

1914
01:43:55,280 --> 01:43:57,119
just on one engine but on across two

1915
01:43:57,119 --> 01:43:58,880
engines on the autopilot computer and

1916
01:43:58,880 --> 01:44:00,239
the way we use those engines here at

1917
01:44:00,239 --> 01:44:02,639
tesla is such that at any given time

1918
01:44:02,639 --> 01:44:04,320
only one of them will actually output

1919
01:44:04,320 --> 01:44:06,159
control commands to the vehicle while

1920
01:44:06,159 --> 01:44:08,000
the other one is used as an extension of

1921
01:44:08,000 --> 01:44:09,040
compute

1922
01:44:09,040 --> 01:44:11,280
but those roles are interchangeable both

1923
01:44:11,280 --> 01:44:14,320
at the hardware and software level

1924
01:44:14,320 --> 01:44:16,239
so how do we interact quickly together

1925
01:44:16,239 --> 01:44:18,480
as a group through these ai development

1926
01:44:18,480 --> 01:44:21,199
cycles well first we have been scaling

1927
01:44:21,199 --> 01:44:22,159
our

1928
01:44:22,159 --> 01:44:24,000
capacity to evaluate our software neural

1929
01:44:24,000 --> 01:44:25,520
network dramatically over the past few

1930
01:44:25,520 --> 01:44:27,679
years and today we're running over a

1931
01:44:27,679 --> 01:44:30,159
million evaluations per week on any code

1932
01:44:30,159 --> 01:44:31,280
change

1933
01:44:31,280 --> 01:44:33,840
that the team is producing and those

1934
01:44:33,840 --> 01:44:36,000
evaluations runs on over three thousand

1935
01:44:36,000 --> 01:44:37,840
actual footstar driving computers that

1936
01:44:37,840 --> 01:44:40,320
are hooked up together in a dedicated uh

1937
01:44:40,320 --> 01:44:42,320
cluster

1938
01:44:42,320 --> 01:44:43,600
and so on top of this we've been

1939
01:44:43,600 --> 01:44:45,840
developing really cool uh debugging

1940
01:44:45,840 --> 01:44:47,520
tools and so here is a video of one of

1941
01:44:47,520 --> 01:44:49,920
our tools which is uh helping developers

1942
01:44:49,920 --> 01:44:52,320
uh iterate through the development of

1943
01:44:52,320 --> 01:44:54,960
neural networks and comparing live the

1944
01:44:54,960 --> 01:44:56,960
outputs from different revisions of a

1945
01:44:56,960 --> 01:44:59,280
same neural network model as reiterating

1946
01:44:59,280 --> 01:45:02,639
life through a video clips

1947
01:45:02,639 --> 01:45:05,119
and so last but not least uh we've been

1948
01:45:05,119 --> 01:45:07,280
scaling our neural network training

1949
01:45:07,280 --> 01:45:09,040
compute dramatically over the past few

1950
01:45:09,040 --> 01:45:12,080
years and today we're barely shy of 10

1951
01:45:12,080 --> 01:45:14,239
000 gpus which just to give you some

1952
01:45:14,239 --> 01:45:17,119
sense in terms of number of gpu is more

1953
01:45:17,119 --> 01:45:18,560
than the top five publicly known

1954
01:45:18,560 --> 01:45:20,800
supercomputers in the world

1955
01:45:20,800 --> 01:45:22,480
but that's not enough and so i'd like to

1956
01:45:22,480 --> 01:45:24,320
invite ganesh to talk about the next

1957
01:45:24,320 --> 01:45:27,250
steps

1958
01:45:27,250 --> 01:45:34,080
[Applause]

1959
01:45:34,080 --> 01:45:36,719
thank you milan

1960
01:45:40,239 --> 01:45:41,760
my name is ganesh

1961
01:45:41,760 --> 01:45:44,880
and i lead project dojo

1962
01:45:44,880 --> 01:45:46,960
it's an honor to present this project on

1963
01:45:46,960 --> 01:45:49,280
behalf of the multidisciplinary tesla

1964
01:45:49,280 --> 01:45:53,280
team that is working on this project

1965
01:45:53,280 --> 01:45:55,840
as you saw from milan

1966
01:45:55,840 --> 01:45:59,199
there's an insatiable demand for speed

1967
01:45:59,199 --> 01:46:01,440
as well as capacity for neural network

1968
01:46:01,440 --> 01:46:04,000
training and elon prefetched this and a

1969
01:46:04,000 --> 01:46:06,320
few years back he asked us to design a

1970
01:46:06,320 --> 01:46:08,560
super fast training computer and that's

1971
01:46:08,560 --> 01:46:12,719
how we started project dojo

1972
01:46:12,719 --> 01:46:15,199
our goal is to achieve best ai training

1973
01:46:15,199 --> 01:46:18,000
performance and support all these larger

1974
01:46:18,000 --> 01:46:21,440
more complex models that andres team is

1975
01:46:21,440 --> 01:46:24,080
dreaming of and be power efficient and

1976
01:46:24,080 --> 01:46:27,199
cost effective at the same time

1977
01:46:27,199 --> 01:46:29,440
so we thought about how to build this

1978
01:46:29,440 --> 01:46:31,199
and we came up with

1979
01:46:31,199 --> 01:46:33,840
a distributed compute architecture

1980
01:46:33,840 --> 01:46:36,480
after all all the training computers out

1981
01:46:36,480 --> 01:46:38,560
there are distributed computers in one

1982
01:46:38,560 --> 01:46:40,719
form or the other they have compute

1983
01:46:40,719 --> 01:46:43,840
elements in the box out here connected

1984
01:46:43,840 --> 01:46:46,320
with some kind of network in this case

1985
01:46:46,320 --> 01:46:48,239
it's a two-dimensional network but it

1986
01:46:48,239 --> 01:46:51,280
could be any different network cpu gpu

1987
01:46:51,280 --> 01:46:53,600
accelerators all of them have compute

1988
01:46:53,600 --> 01:46:55,520
little memory

1989
01:46:55,520 --> 01:46:58,080
and network but one thing which is

1990
01:46:58,080 --> 01:47:01,199
common trend amongst this is it's easy

1991
01:47:01,199 --> 01:47:02,480
to scale

1992
01:47:02,480 --> 01:47:03,679
the compute

1993
01:47:03,679 --> 01:47:05,920
it's very difficult to scale up

1994
01:47:05,920 --> 01:47:08,159
bandwidth and extremely difficult to

1995
01:47:08,159 --> 01:47:10,880
reduce latencies and you'll see how our

1996
01:47:10,880 --> 01:47:13,840
design point catered to that how our

1997
01:47:13,840 --> 01:47:15,040
philosophy

1998
01:47:15,040 --> 01:47:17,600
addressed these aspects of traditional

1999
01:47:17,600 --> 01:47:19,920
limits

2000
01:47:19,920 --> 01:47:23,119
for dojo we envisioned a large compute

2001
01:47:23,119 --> 01:47:24,080
plane

2002
01:47:24,080 --> 01:47:27,040
filled with very robust compute elements

2003
01:47:27,040 --> 01:47:29,199
backed with large pool of memory and

2004
01:47:29,199 --> 01:47:31,440
interconnected with very high bandwidth

2005
01:47:31,440 --> 01:47:34,840
and low latency fabric and in a 2d mesh

2006
01:47:34,840 --> 01:47:38,800
format and on to this for extreme scale

2007
01:47:38,800 --> 01:47:41,199
big neural networks will be partitioned

2008
01:47:41,199 --> 01:47:43,760
and mapped to extract different

2009
01:47:43,760 --> 01:47:47,520
parallelism model graph data parallelism

2010
01:47:47,520 --> 01:47:50,480
and then in neural compiler

2011
01:47:50,480 --> 01:47:52,159
of ours will

2012
01:47:52,159 --> 01:47:54,880
exploit spatial and

2013
01:47:54,880 --> 01:47:57,040
temporal locality such that it can

2014
01:47:57,040 --> 01:47:59,280
reduce communication footprint to local

2015
01:47:59,280 --> 01:48:01,920
zones and reduce global communication

2016
01:48:01,920 --> 01:48:03,600
and if we do that

2017
01:48:03,600 --> 01:48:05,679
our bandwidth utilization can keep

2018
01:48:05,679 --> 01:48:08,960
scaling with the plane of compute that

2019
01:48:08,960 --> 01:48:12,239
we desire out here

2020
01:48:12,880 --> 01:48:15,840
we wanted to attack this all the way

2021
01:48:15,840 --> 01:48:18,639
top to the bottom of the stack

2022
01:48:18,639 --> 01:48:20,960
and remove any bottlenecks at any of

2023
01:48:20,960 --> 01:48:22,639
these levels

2024
01:48:22,639 --> 01:48:24,560
and let's start this journey in an

2025
01:48:24,560 --> 01:48:26,719
inside out fashion starting with the

2026
01:48:26,719 --> 01:48:28,159
chip

2027
01:48:28,159 --> 01:48:29,679
as i described

2028
01:48:29,679 --> 01:48:32,239
chips have compute elements our smallest

2029
01:48:32,239 --> 01:48:34,080
entity or scale is called a training

2030
01:48:34,080 --> 01:48:35,119
node

2031
01:48:35,119 --> 01:48:37,600
and the choice of this node is

2032
01:48:37,600 --> 01:48:40,480
very important to ensure seamless

2033
01:48:40,480 --> 01:48:41,600
scaling

2034
01:48:41,600 --> 01:48:44,719
if you go too small it will run fast but

2035
01:48:44,719 --> 01:48:47,679
the overheads of synchronization

2036
01:48:47,679 --> 01:48:50,320
will end software will dominate if you

2037
01:48:50,320 --> 01:48:52,239
pick it too big

2038
01:48:52,239 --> 01:48:54,080
it will have complexities in

2039
01:48:54,080 --> 01:48:56,480
implementation in the real hardware and

2040
01:48:56,480 --> 01:48:58,560
ultimately run into memory bottleneck

2041
01:48:58,560 --> 01:48:59,520
issues

2042
01:48:59,520 --> 01:49:03,040
because we wanted to address

2043
01:49:03,040 --> 01:49:05,119
we wanted to address latency and

2044
01:49:05,119 --> 01:49:07,760
bandwidth as our primary optimization

2045
01:49:07,760 --> 01:49:10,000
point let's see how we went about doing

2046
01:49:10,000 --> 01:49:11,119
this

2047
01:49:11,119 --> 01:49:13,679
what we did was we picked the farthest

2048
01:49:13,679 --> 01:49:16,000
distance a signal could traverse in a

2049
01:49:16,000 --> 01:49:18,560
very clock very high clock cycle in this

2050
01:49:18,560 --> 01:49:21,520
case two gigahertz plus and we drew a

2051
01:49:21,520 --> 01:49:23,920
box around it this is the

2052
01:49:23,920 --> 01:49:26,480
smallest latency that a signal can

2053
01:49:26,480 --> 01:49:28,880
traverse one cycle at a very high

2054
01:49:28,880 --> 01:49:31,679
frequency and then we filled up the box

2055
01:49:31,679 --> 01:49:33,520
with wires to the brink

2056
01:49:33,520 --> 01:49:35,599
this is the highest bandwidth you can

2057
01:49:35,599 --> 01:49:37,920
feed the box with and then we added

2058
01:49:37,920 --> 01:49:40,159
machine learning compute underneath and

2059
01:49:40,159 --> 01:49:42,560
then a large pool of sram

2060
01:49:42,560 --> 01:49:44,560
and last but not the least a

2061
01:49:44,560 --> 01:49:45,760
programmable

2062
01:49:45,760 --> 01:49:47,679
core to control

2063
01:49:47,679 --> 01:49:50,960
and this gave us our high performance

2064
01:49:50,960 --> 01:49:52,159
training node

2065
01:49:52,159 --> 01:49:55,920
what this is is a 64-bit superscalar cpu

2066
01:49:55,920 --> 01:49:58,800
optimized around matrix multiply units

2067
01:49:58,800 --> 01:50:00,320
and vector cmd

2068
01:50:00,320 --> 01:50:04,320
it supports floating point 32 b float 16

2069
01:50:04,320 --> 01:50:09,679
and a new format cfp8 configurable fp8

2070
01:50:09,679 --> 01:50:11,760
and it is backed by

2071
01:50:11,760 --> 01:50:14,480
one and a quarter megabyte of fast ecc

2072
01:50:14,480 --> 01:50:17,520
protected sram and the low latency high

2073
01:50:17,520 --> 01:50:20,880
bandwidth fabric that we designed

2074
01:50:20,880 --> 01:50:22,960
this might be our smallest entity of

2075
01:50:22,960 --> 01:50:25,440
scale but it packs a big punch

2076
01:50:25,440 --> 01:50:28,960
more than one teraflop of compute in our

2077
01:50:28,960 --> 01:50:31,599
smallest entity of scale

2078
01:50:31,599 --> 01:50:33,199
so let's look at the architecture of

2079
01:50:33,199 --> 01:50:34,159
this

2080
01:50:34,159 --> 01:50:36,480
the computer architects out here may

2081
01:50:36,480 --> 01:50:38,960
recognize this this is a pretty capable

2082
01:50:38,960 --> 01:50:41,920
architecture as soon as you see this

2083
01:50:41,920 --> 01:50:44,639
it is a super scalar in order cpu

2084
01:50:44,639 --> 01:50:47,360
with four wide vector and two wide vect

2085
01:50:47,360 --> 01:50:49,840
two wide uh four wide scaler and two

2086
01:50:49,840 --> 01:50:53,440
wide vector pipes we call it in order

2087
01:50:53,440 --> 01:50:55,599
although the vector and the scalar pipes

2088
01:50:55,599 --> 01:50:57,599
can go out of order but for the purest

2089
01:50:57,599 --> 01:51:00,239
out there we still call it in order and

2090
01:51:00,239 --> 01:51:02,639
it also has four-way multi-threading

2091
01:51:02,639 --> 01:51:04,639
this increases utilization because we

2092
01:51:04,639 --> 01:51:06,920
could do compute and data transfers

2093
01:51:06,920 --> 01:51:10,000
simultaneously and our custom isa which

2094
01:51:10,000 --> 01:51:11,840
is the instruction set architecture is

2095
01:51:11,840 --> 01:51:13,840
fully optimized for machine learning

2096
01:51:13,840 --> 01:51:17,599
workloads it has features like transpose

2097
01:51:17,599 --> 01:51:18,639
gather

2098
01:51:18,639 --> 01:51:21,280
link traversals broadcast just to name a

2099
01:51:21,280 --> 01:51:23,040
few

2100
01:51:23,040 --> 01:51:25,840
and even in the physical realm we made

2101
01:51:25,840 --> 01:51:28,560
it extremely modular such that we could

2102
01:51:28,560 --> 01:51:31,599
start averting these training nodes in

2103
01:51:31,599 --> 01:51:34,320
any direction and start forming the

2104
01:51:34,320 --> 01:51:38,719
compute plane that we envisioned

2105
01:51:39,599 --> 01:51:41,239
when we click together

2106
01:51:41,239 --> 01:51:44,080
354 of these training nodes we get our

2107
01:51:44,080 --> 01:51:47,760
compute array it's capable of delivering

2108
01:51:47,760 --> 01:51:51,679
teraflops of machine learning compute

2109
01:51:51,679 --> 01:51:53,920
and of course the high bandwidth fabric

2110
01:51:53,920 --> 01:51:56,239
that interconnects these

2111
01:51:56,239 --> 01:51:58,480
and around this compute array we

2112
01:51:58,480 --> 01:52:00,239
surrounded it with

2113
01:52:00,239 --> 01:52:04,239
high speed low power services 576

2114
01:52:04,239 --> 01:52:08,239
of them to to enable us to have extreme

2115
01:52:08,239 --> 01:52:11,040
i o bandwidth coming out of this chip

2116
01:52:11,040 --> 01:52:14,480
just to give you a comparison point this

2117
01:52:14,480 --> 01:52:17,520
is more than two times the bandwidth

2118
01:52:17,520 --> 01:52:19,760
coming out of the state-of-the-art

2119
01:52:19,760 --> 01:52:22,000
networking switch chips which are out

2120
01:52:22,000 --> 01:52:24,560
there today and network switch chips are

2121
01:52:24,560 --> 01:52:27,119
supposed to be the gold standards for i

2122
01:52:27,119 --> 01:52:29,360
o bandwidth

2123
01:52:29,360 --> 01:52:31,760
if we put all of it together

2124
01:52:31,760 --> 01:52:33,520
we get

2125
01:52:33,520 --> 01:52:35,599
training optimized chip

2126
01:52:35,599 --> 01:52:37,840
our d1 chip

2127
01:52:37,840 --> 01:52:40,080
this chip is manufactured in seven

2128
01:52:40,080 --> 01:52:43,199
nanometer technology it packs 50 billion

2129
01:52:43,199 --> 01:52:46,000
transistors in a miserly 645 millimeter

2130
01:52:46,000 --> 01:52:46,960
square

2131
01:52:46,960 --> 01:52:50,159
one thing you'll notice 100 of the area

2132
01:52:50,159 --> 01:52:52,239
out here is going towards machine

2133
01:52:52,239 --> 01:52:54,880
learning training and bandwidth there is

2134
01:52:54,880 --> 01:52:56,800
no dark silicon there is no legacy

2135
01:52:56,800 --> 01:52:59,440
support this is a pure machine learning

2136
01:52:59,440 --> 01:53:01,840
machine

2137
01:53:03,040 --> 01:53:05,360
and

2138
01:53:07,840 --> 01:53:09,280
this

2139
01:53:09,280 --> 01:53:12,239
is the d1 chip in a flip chip bga

2140
01:53:12,239 --> 01:53:13,760
package

2141
01:53:13,760 --> 01:53:15,840
this was entirely designed

2142
01:53:15,840 --> 01:53:19,440
by tesla team internally all the way

2143
01:53:19,440 --> 01:53:21,119
from the architecture

2144
01:53:21,119 --> 01:53:22,320
to

2145
01:53:22,320 --> 01:53:24,840
gds out and

2146
01:53:24,840 --> 01:53:27,040
package this chip

2147
01:53:27,040 --> 01:53:28,800
is like a

2148
01:53:28,800 --> 01:53:31,840
gpu level compute with a cpu level

2149
01:53:31,840 --> 01:53:35,119
flexibility and twice the network chip

2150
01:53:35,119 --> 01:53:37,760
level i o bandwidth

2151
01:53:37,760 --> 01:53:40,000
if i were to plot

2152
01:53:40,000 --> 01:53:42,480
the i o bandwidth on the vertical scale

2153
01:53:42,480 --> 01:53:45,280
versus teraflops of compute that is

2154
01:53:45,280 --> 01:53:47,040
available in the state-of-the-art

2155
01:53:47,040 --> 01:53:49,520
machine learning chips are there

2156
01:53:49,520 --> 01:53:51,440
including some of the startups you can

2157
01:53:51,440 --> 01:53:54,480
easily see why our design point excels

2158
01:53:54,480 --> 01:53:56,880
beyond power

2159
01:53:56,880 --> 01:53:58,880
now that we had this fundamental

2160
01:53:58,880 --> 01:54:02,000
physical building block

2161
01:54:02,000 --> 01:54:04,960
how to design the system around it

2162
01:54:04,960 --> 01:54:06,960
let's see

2163
01:54:06,960 --> 01:54:09,760
since d1

2164
01:54:09,760 --> 01:54:13,520
chips can seamlessly connect without any

2165
01:54:13,520 --> 01:54:16,080
glue to each other we just started

2166
01:54:16,080 --> 01:54:18,080
putting them together

2167
01:54:18,080 --> 01:54:21,719
we just put

2168
01:54:24,639 --> 01:54:26,400
500 000

2169
01:54:26,400 --> 01:54:28,800
training nodes together to form our

2170
01:54:28,800 --> 01:54:30,560
compute plane

2171
01:54:30,560 --> 01:54:34,320
this is 1500 d1 chips seamlessly

2172
01:54:34,320 --> 01:54:37,520
connected to each other

2173
01:54:37,520 --> 01:54:38,800
and then

2174
01:54:38,800 --> 01:54:40,080
we add

2175
01:54:40,080 --> 01:54:42,159
dojo interface process

2176
01:54:42,159 --> 01:54:44,239
processors on each end

2177
01:54:44,239 --> 01:54:47,599
this is the host bridge to typical hosts

2178
01:54:47,599 --> 01:54:49,440
in the data centers

2179
01:54:49,440 --> 01:54:53,119
it's connected with pci gen4 on one side

2180
01:54:53,119 --> 01:54:55,040
with a high bandwidth fabric to our

2181
01:54:55,040 --> 01:54:56,320
compute plane

2182
01:54:56,320 --> 01:54:58,800
the interface processors provide not

2183
01:54:58,800 --> 01:55:01,920
only the host bridge but high bandwidth

2184
01:55:01,920 --> 01:55:05,760
dram shared memory for the compute plane

2185
01:55:05,760 --> 01:55:06,960
in addition

2186
01:55:06,960 --> 01:55:08,880
the interface processors

2187
01:55:08,880 --> 01:55:11,920
can also allow us to have a higher radix

2188
01:55:11,920 --> 01:55:14,560
network connection

2189
01:55:14,560 --> 01:55:18,320
in order to achieve this compute plane

2190
01:55:18,320 --> 01:55:20,480
we had to come up with a new way of

2191
01:55:20,480 --> 01:55:23,040
integrating these chips together

2192
01:55:23,040 --> 01:55:26,080
and this is what we call as a training

2193
01:55:26,080 --> 01:55:27,199
tile

2194
01:55:27,199 --> 01:55:31,440
this is the unit of scale for our system

2195
01:55:31,440 --> 01:55:34,639
this is a groundbreaking integration of

2196
01:55:34,639 --> 01:55:38,480
25 known good d1 dies onto a

2197
01:55:38,480 --> 01:55:41,760
fan out wafer process tightly integrated

2198
01:55:41,760 --> 01:55:43,440
such that it preserves the bandwidth

2199
01:55:43,440 --> 01:55:45,520
between them the maximum bandwidth is

2200
01:55:45,520 --> 01:55:48,400
preserved there and in addition

2201
01:55:48,400 --> 01:55:50,320
we generated

2202
01:55:50,320 --> 01:55:51,199
a

2203
01:55:51,199 --> 01:55:54,400
connector a high bandwidth high density

2204
01:55:54,400 --> 01:55:56,800
connector that preserves the bandwidth

2205
01:55:56,800 --> 01:56:00,080
coming out of this training tile

2206
01:56:00,080 --> 01:56:03,440
and this style gives us nine beta flaps

2207
01:56:03,440 --> 01:56:04,960
of compute

2208
01:56:04,960 --> 01:56:07,599
with a massive i o bandwidth coming out

2209
01:56:07,599 --> 01:56:09,520
of it

2210
01:56:09,520 --> 01:56:10,480
this

2211
01:56:10,480 --> 01:56:13,679
perhaps is the biggest organic mcm in

2212
01:56:13,679 --> 01:56:18,159
the chip industry multi-chip module

2213
01:56:18,639 --> 01:56:20,400
it was not easy to design this there

2214
01:56:20,400 --> 01:56:23,119
were no tools that existed all the tools

2215
01:56:23,119 --> 01:56:25,440
were croaking even our compute cluster

2216
01:56:25,440 --> 01:56:27,760
couldn't handle it we had to our

2217
01:56:27,760 --> 01:56:30,480
engineers came up with different ways of

2218
01:56:30,480 --> 01:56:33,599
solving this they created new methods to

2219
01:56:33,599 --> 01:56:36,080
make this a reality

2220
01:56:36,080 --> 01:56:38,560
now that we had our compute plane

2221
01:56:38,560 --> 01:56:40,320
tile

2222
01:56:40,320 --> 01:56:42,719
with high bandwidth ios

2223
01:56:42,719 --> 01:56:44,800
we had to feed it with power

2224
01:56:44,800 --> 01:56:47,599
and here we came up with a new way of

2225
01:56:47,599 --> 01:56:50,320
feeding power vertically

2226
01:56:50,320 --> 01:56:53,440
we created a custom

2227
01:56:53,440 --> 01:56:55,840
voltage regulator module

2228
01:56:55,840 --> 01:56:58,880
that could be reflowed directly directly

2229
01:56:58,880 --> 01:57:01,679
onto this fan out wafer so what did we

2230
01:57:01,679 --> 01:57:04,639
did out here is we got chip

2231
01:57:04,639 --> 01:57:07,040
package and we brought pcb level

2232
01:57:07,040 --> 01:57:10,239
technology of reflow on fan art wafer

2233
01:57:10,239 --> 01:57:12,880
technology this is

2234
01:57:12,880 --> 01:57:15,280
a lot of integration already out here

2235
01:57:15,280 --> 01:57:16,880
but we didn't stop here

2236
01:57:16,880 --> 01:57:18,719
we integrated

2237
01:57:18,719 --> 01:57:21,280
the entire electrical thermal and

2238
01:57:21,280 --> 01:57:25,119
mechanical pieces out here

2239
01:57:25,119 --> 01:57:26,800
to form

2240
01:57:26,800 --> 01:57:30,239
our training tile fully integrated

2241
01:57:30,239 --> 01:57:35,520
interfacing with a 52 volt dc input

2242
01:57:35,760 --> 01:57:38,719
it's unprecedented this is an amazing

2243
01:57:38,719 --> 01:57:41,840
piece of engineering

2244
01:57:41,840 --> 01:57:43,760
our compute plane is completely

2245
01:57:43,760 --> 01:57:45,360
orthogonal

2246
01:57:45,360 --> 01:57:46,960
to power supply

2247
01:57:46,960 --> 01:57:48,719
and cooling

2248
01:57:48,719 --> 01:57:50,400
that makes

2249
01:57:50,400 --> 01:57:53,440
high bandwidth compute planes

2250
01:57:53,440 --> 01:57:56,000
possible

2251
01:57:59,599 --> 01:58:00,800
what it is

2252
01:58:00,800 --> 01:58:03,040
is a nine petaflop

2253
01:58:03,040 --> 01:58:05,520
training tile this becomes our unit of

2254
01:58:05,520 --> 01:58:09,040
scale for our system

2255
01:58:09,440 --> 01:58:12,000
and this

2256
01:58:12,880 --> 01:58:16,119
is real

2257
01:58:26,880 --> 01:58:28,400
i can't believe i'm holding nine

2258
01:58:28,400 --> 01:58:32,199
petaflops out here

2259
01:58:39,840 --> 01:58:41,840
and in fact

2260
01:58:41,840 --> 01:58:44,239
last week we got our first

2261
01:58:44,239 --> 01:58:46,719
functional training tile

2262
01:58:46,719 --> 01:58:49,440
and on a limited limited cooling

2263
01:58:49,440 --> 01:58:51,599
benchtop setup

2264
01:58:51,599 --> 01:58:54,000
we got some networks running

2265
01:58:54,000 --> 01:58:56,320
and i was told andre doesn't believe

2266
01:58:56,320 --> 01:58:58,400
that we could run networks

2267
01:58:58,400 --> 01:59:01,840
till we could run one of his creations

2268
01:59:01,840 --> 01:59:05,599
this is min gpt2 running on dojo

2269
01:59:05,599 --> 01:59:08,239
do you believe it

2270
01:59:12,480 --> 01:59:14,480
next up

2271
01:59:14,480 --> 01:59:18,320
how to form a compute cluster out of it

2272
01:59:18,320 --> 01:59:20,239
by now you must have realized our

2273
01:59:20,239 --> 01:59:24,639
modularity story is pretty strong

2274
01:59:24,639 --> 01:59:26,880
we just put together some tiles we just

2275
01:59:26,880 --> 01:59:29,520
styled together tiles

2276
01:59:29,520 --> 01:59:31,840
a two by three

2277
01:59:31,840 --> 01:59:35,840
tile in a tray makes our training matrix

2278
01:59:35,840 --> 01:59:38,320
and two trays in a cabinet

2279
01:59:38,320 --> 01:59:40,480
give 100 petaflops

2280
01:59:40,480 --> 01:59:43,040
of compute

2281
01:59:43,599 --> 01:59:46,880
did we stop here no

2282
01:59:47,360 --> 01:59:48,639
we just

2283
01:59:48,639 --> 01:59:51,520
integrated seamlessly we broke the

2284
01:59:51,520 --> 01:59:54,639
cabinet walls we integrated these styles

2285
01:59:54,639 --> 01:59:56,800
seamlessly all the way through

2286
01:59:56,800 --> 01:59:58,560
preserving the bandwidth there is no

2287
01:59:58,560 --> 02:00:00,639
bandwidth divert out here there is no

2288
02:00:00,639 --> 02:00:02,880
bandwidth clips all the tiles are

2289
02:00:02,880 --> 02:00:05,360
seamlessly connected with the same

2290
02:00:05,360 --> 02:00:06,480
bandwidth

2291
02:00:06,480 --> 02:00:09,880
and with this

2292
02:00:12,320 --> 02:00:15,760
we have an exopod

2293
02:00:15,760 --> 02:00:17,040
this is

2294
02:00:17,040 --> 02:00:21,119
one extra flop of compute

2295
02:00:21,119 --> 02:00:24,239
in 10 cabinets

2296
02:00:24,239 --> 02:00:26,480
it's more than a million training nodes

2297
02:00:26,480 --> 02:00:28,560
that you saw we paid meticulous

2298
02:00:28,560 --> 02:00:30,639
attention to that training node and

2299
02:00:30,639 --> 02:00:34,080
there are one million nodes out here

2300
02:00:34,080 --> 02:00:37,440
with uniform bandwidth

2301
02:00:39,520 --> 02:00:41,199
not just the hardware

2302
02:00:41,199 --> 02:00:44,080
the software aspects are so important

2303
02:00:44,080 --> 02:00:46,480
to ensure scaling

2304
02:00:46,480 --> 02:00:49,440
and not every job requires a huge

2305
02:00:49,440 --> 02:00:52,239
cluster so we plan for it

2306
02:00:52,239 --> 02:00:55,040
right from the get go

2307
02:00:55,040 --> 02:00:56,960
our compute plane

2308
02:00:56,960 --> 02:00:59,840
can be subdivided can be partitioned

2309
02:00:59,840 --> 02:01:00,960
into

2310
02:01:00,960 --> 02:01:04,560
units called dojo processing unit

2311
02:01:04,560 --> 02:01:05,840
a dpu

2312
02:01:05,840 --> 02:01:08,960
consists of one or more

2313
02:01:08,960 --> 02:01:11,599
d1 chips

2314
02:01:11,599 --> 02:01:13,920
it also has our interface processor and

2315
02:01:13,920 --> 02:01:16,960
one or more hosts

2316
02:01:17,840 --> 02:01:20,560
and this can be scaled up or down as per

2317
02:01:20,560 --> 02:01:23,760
the needs of any algorithm any network

2318
02:01:23,760 --> 02:01:26,480
running on it

2319
02:01:26,800 --> 02:01:28,719
what does the user have to do they have

2320
02:01:28,719 --> 02:01:32,719
to change their scripts minimally

2321
02:01:33,040 --> 02:01:34,080
and this

2322
02:01:34,080 --> 02:01:35,199
is because

2323
02:01:35,199 --> 02:01:37,679
of our strong compiler suite

2324
02:01:37,679 --> 02:01:39,040
it takes care of fine-grained

2325
02:01:39,040 --> 02:01:42,239
parallelism and mapping the pro problems

2326
02:01:42,239 --> 02:01:44,639
of mapping the neural networks very

2327
02:01:44,639 --> 02:01:48,639
efficiently onto our compute plane

2328
02:01:48,639 --> 02:01:51,040
our compiler is

2329
02:01:51,040 --> 02:01:53,599
uses multiple techniques to extract

2330
02:01:53,599 --> 02:01:55,280
parallelism

2331
02:01:55,280 --> 02:01:58,400
it can transform the networks to achieve

2332
02:01:58,400 --> 02:02:00,960
not only fine-grained parallelism using

2333
02:02:00,960 --> 02:02:02,320
data model

2334
02:02:02,320 --> 02:02:05,280
graph parallelism techniques

2335
02:02:05,280 --> 02:02:07,119
it also

2336
02:02:07,119 --> 02:02:09,840
can do optimizations to reduce memory

2337
02:02:09,840 --> 02:02:12,400
footprints

2338
02:02:12,400 --> 02:02:14,639
one thing because of our

2339
02:02:14,639 --> 02:02:17,520
high bandwidth nature of the fabric is

2340
02:02:17,520 --> 02:02:20,159
enabled out here is model parallelism

2341
02:02:20,159 --> 02:02:22,480
could not have been extended to the same

2342
02:02:22,480 --> 02:02:24,400
level as what we can

2343
02:02:24,400 --> 02:02:26,719
it was limited to chip boundaries now we

2344
02:02:26,719 --> 02:02:29,199
can because of our high bandwidth we can

2345
02:02:29,199 --> 02:02:32,159
extend it to training tiles and beyond

2346
02:02:32,159 --> 02:02:33,199
thus

2347
02:02:33,199 --> 02:02:36,000
large networks can be efficiently mapped

2348
02:02:36,000 --> 02:02:39,040
here at low batch sizes and extract

2349
02:02:39,040 --> 02:02:40,800
utilization and new levels of

2350
02:02:40,800 --> 02:02:42,639
performance

2351
02:02:42,639 --> 02:02:45,520
in addition our compiler is capable of

2352
02:02:45,520 --> 02:02:48,159
handling high level dynamic control

2353
02:02:48,159 --> 02:02:52,880
flows like loops if then else etc

2354
02:02:52,880 --> 02:02:55,920
and our compiler engine is just part of

2355
02:02:55,920 --> 02:02:58,639
our entire software suite

2356
02:02:58,639 --> 02:03:01,920
the stack consists of

2357
02:03:01,920 --> 02:03:04,880
a extension to pytarch that ensures the

2358
02:03:04,880 --> 02:03:07,360
same user-level interfaces that ml

2359
02:03:07,360 --> 02:03:09,199
scientists are used to

2360
02:03:09,199 --> 02:03:11,599
and our compiler generates code on the

2361
02:03:11,599 --> 02:03:12,560
fly

2362
02:03:12,560 --> 02:03:14,320
such that it could be reused for

2363
02:03:14,320 --> 02:03:17,679
subsequent execution it has a llvm

2364
02:03:17,679 --> 02:03:19,520
backend that generates the binary for

2365
02:03:19,520 --> 02:03:20,800
the hardware

2366
02:03:20,800 --> 02:03:24,320
and this ensures we can create optimized

2367
02:03:24,320 --> 02:03:25,520
code

2368
02:03:25,520 --> 02:03:28,239
for the hardware without relying on even

2369
02:03:28,239 --> 02:03:32,639
single line of handwritten kernel

2370
02:03:32,719 --> 02:03:34,719
our driver stack

2371
02:03:34,719 --> 02:03:36,480
takes care of the multi-host

2372
02:03:36,480 --> 02:03:39,040
multi-partitioning that you saw

2373
02:03:39,040 --> 02:03:41,199
a few slides back

2374
02:03:41,199 --> 02:03:43,840
and then we also have

2375
02:03:43,840 --> 02:03:45,199
profilers

2376
02:03:45,199 --> 02:03:49,119
and debuggers in our software stack

2377
02:03:49,119 --> 02:03:51,119
so with all this

2378
02:03:51,119 --> 02:03:53,520
we integrated

2379
02:03:53,520 --> 02:03:56,159
in a vertical fashion we broke the

2380
02:03:56,159 --> 02:03:59,199
traditional barriers to scaling

2381
02:03:59,199 --> 02:04:00,800
and that's how

2382
02:04:00,800 --> 02:04:04,320
we got modularity up and down the stack

2383
02:04:04,320 --> 02:04:07,360
to add to new levels of performance

2384
02:04:07,360 --> 02:04:08,880
to sum it all

2385
02:04:08,880 --> 02:04:11,520
this is what it will be it will be a

2386
02:04:11,520 --> 02:04:14,079
fastest ai training computer

2387
02:04:14,079 --> 02:04:17,679
for x the performance at the same cost

2388
02:04:17,679 --> 02:04:19,440
1.3 x

2389
02:04:19,440 --> 02:04:21,199
better performance per watt that is

2390
02:04:21,199 --> 02:04:25,199
energy saving and 5x smaller footprint

2391
02:04:25,199 --> 02:04:29,880
this will be dojo computer

2392
02:04:38,000 --> 02:04:40,239
we are not done we are

2393
02:04:40,239 --> 02:04:43,199
assembling our first cabinets pretty

2394
02:04:43,199 --> 02:04:44,320
soon

2395
02:04:44,320 --> 02:04:47,280
and we have a whole next generation plan

2396
02:04:47,280 --> 02:04:49,360
already we are thinking about

2397
02:04:49,360 --> 02:04:52,239
10x more with different aspects that we

2398
02:04:52,239 --> 02:04:54,960
can do all the way from silicon

2399
02:04:54,960 --> 02:04:57,280
to the system again we will have this

2400
02:04:57,280 --> 02:05:00,079
journey again we're recruiting heavily

2401
02:05:00,079 --> 02:05:02,320
for all of these

2402
02:05:02,320 --> 02:05:06,599
areas thank you very much

2403
02:05:14,320 --> 02:05:15,760
and next up

2404
02:05:15,760 --> 02:05:19,040
elon will update us on what's beyond our

2405
02:05:19,040 --> 02:05:23,480
vehicle feet fleet for ai

2406
02:05:29,210 --> 02:05:35,440
[Music]

2407
02:05:35,440 --> 02:05:38,440
oh

2408
02:05:39,030 --> 02:06:05,750
[Music]

2409
02:06:07,119 --> 02:06:08,740
so

2410
02:06:08,740 --> 02:06:31,840
[Music]

2411
02:06:31,840 --> 02:06:34,840
oh

2412
02:06:36,410 --> 02:06:47,739
[Music]

2413
02:06:51,119 --> 02:06:53,720
thank you

2414
02:06:53,720 --> 02:06:59,920
[Applause]

2415
02:06:59,920 --> 02:07:02,159
now unlike unlike dojo obviously that

2416
02:07:02,159 --> 02:07:04,239
was not real

2417
02:07:04,239 --> 02:07:05,040
uh

2418
02:07:05,040 --> 02:07:07,440
so doj is real uh the tesla bot will be

2419
02:07:07,440 --> 02:07:08,800
real

2420
02:07:08,800 --> 02:07:09,760
um but

2421
02:07:09,760 --> 02:07:11,760
basically if you think about what we're

2422
02:07:11,760 --> 02:07:13,599
doing right now with the cars tesla is

2423
02:07:13,599 --> 02:07:15,040
arguably the world's biggest robotics

2424
02:07:15,040 --> 02:07:17,040
company because our cars are

2425
02:07:17,040 --> 02:07:17,840
like

2426
02:07:17,840 --> 02:07:20,560
semi-sentient robots on wheels

2427
02:07:20,560 --> 02:07:22,320
and with

2428
02:07:22,320 --> 02:07:23,199
the

2429
02:07:23,199 --> 02:07:24,639
full self-driving computer essentially

2430
02:07:24,639 --> 02:07:26,960
the the inference engine on the car

2431
02:07:26,960 --> 02:07:29,040
which will keep evolving obviously and

2432
02:07:29,040 --> 02:07:30,480
uh dojo

2433
02:07:30,480 --> 02:07:33,119
and all the

2434
02:07:33,360 --> 02:07:35,199
neural nets recognizing the world

2435
02:07:35,199 --> 02:07:36,239
understanding how to navigate through

2436
02:07:36,239 --> 02:07:37,280
the world

2437
02:07:37,280 --> 02:07:39,520
uh it it kind of makes sense to put that

2438
02:07:39,520 --> 02:07:42,480
onto a humanoid form

2439
02:07:42,480 --> 02:07:44,320
they're also quite good at sensors and

2440
02:07:44,320 --> 02:07:46,560
batteries and

2441
02:07:46,560 --> 02:07:47,760
actuators

2442
02:07:47,760 --> 02:07:48,960
so

2443
02:07:48,960 --> 02:07:50,760
we think we'll probably have

2444
02:07:50,760 --> 02:07:56,000
a prototype sometime next year that

2445
02:07:56,000 --> 02:07:57,920
basically looks like this

2446
02:07:57,920 --> 02:08:00,960
and it's intended to

2447
02:08:03,040 --> 02:08:06,079
be friendly of course

2448
02:08:06,800 --> 02:08:09,119
and uh navigate through a world uh built

2449
02:08:09,119 --> 02:08:10,239
for humans

2450
02:08:10,239 --> 02:08:11,360
and

2451
02:08:11,360 --> 02:08:13,599
uh eliminate dangerous repetitive and

2452
02:08:13,599 --> 02:08:14,960
boring tasks

2453
02:08:14,960 --> 02:08:19,360
um we're setting it such that it is um

2454
02:08:19,360 --> 02:08:20,800
at a mechanical level at a physical

2455
02:08:20,800 --> 02:08:24,480
level you can run away from it

2456
02:08:26,000 --> 02:08:29,599
and and most likely overpower it

2457
02:08:29,599 --> 02:08:30,560
so

2458
02:08:30,560 --> 02:08:33,840
hopefully that doesn't ever happen but

2459
02:08:33,840 --> 02:08:36,719
um you never know

2460
02:08:36,719 --> 02:08:39,679
so it's uh it'll be a you know

2461
02:08:39,679 --> 02:08:40,560
a light

2462
02:08:40,560 --> 02:08:42,079
a light

2463
02:08:42,079 --> 02:08:44,239
yeah five miles an hour you can get run

2464
02:08:44,239 --> 02:08:46,440
faster than that'd be fine

2465
02:08:46,440 --> 02:08:50,000
[Laughter]

2466
02:08:50,000 --> 02:08:51,360
um so

2467
02:08:51,360 --> 02:08:53,360
yes it's a

2468
02:08:53,360 --> 02:08:54,400
round

2469
02:08:54,400 --> 02:08:56,000
uh 5.8

2470
02:08:56,000 --> 02:08:57,360
um

2471
02:08:57,360 --> 02:08:59,119
has sort of a screen where the head is

2472
02:08:59,119 --> 02:09:01,440
for useful information um but as

2473
02:09:01,440 --> 02:09:03,440
otherwise basically got the autopilot

2474
02:09:03,440 --> 02:09:05,599
system in it so it's got cameras got

2475
02:09:05,599 --> 02:09:08,400
eight cameras and

2476
02:09:14,079 --> 02:09:15,920
full-size driving computer

2477
02:09:15,920 --> 02:09:17,840
and making use of all of the same tools

2478
02:09:17,840 --> 02:09:19,360
that we use in the car

2479
02:09:19,360 --> 02:09:20,400
so

2480
02:09:20,400 --> 02:09:22,159
um i mean things i think that are really

2481
02:09:22,159 --> 02:09:23,840
hard about uh

2482
02:09:23,840 --> 02:09:26,639
having a useful humanoid robot is cannot

2483
02:09:26,639 --> 02:09:28,400
navigate through the world without being

2484
02:09:28,400 --> 02:09:30,079
explicitly trained

2485
02:09:30,079 --> 02:09:33,199
i mean without explicit like uh

2486
02:09:33,199 --> 02:09:35,119
line-by-line instructions

2487
02:09:35,119 --> 02:09:36,239
um

2488
02:09:36,239 --> 02:09:37,840
can you can you talk to it and say you

2489
02:09:37,840 --> 02:09:40,560
know please uh pick up that bolt

2490
02:09:40,560 --> 02:09:43,280
and uh attach it to

2491
02:09:43,280 --> 02:09:45,520
the car with that wrench

2492
02:09:45,520 --> 02:09:48,079
and it should be able to do that

2493
02:09:48,079 --> 02:09:49,280
um

2494
02:09:49,280 --> 02:09:50,880
it should be able to you know please you

2495
02:09:50,880 --> 02:09:52,800
know please go to the store and get me

2496
02:09:52,800 --> 02:09:54,400
the following groceries

2497
02:09:54,400 --> 02:09:56,239
um that kind of thing

2498
02:09:56,239 --> 02:09:58,159
so

2499
02:09:58,159 --> 02:10:00,480
yeah i think we can do that

2500
02:10:00,480 --> 02:10:02,719
um

2501
02:10:03,760 --> 02:10:04,639
and

2502
02:10:04,639 --> 02:10:05,920
yeah

2503
02:10:05,920 --> 02:10:07,280
this i think will be quite quite

2504
02:10:07,280 --> 02:10:10,079
profound because if you say like what is

2505
02:10:10,079 --> 02:10:12,800
the economy it is uh

2506
02:10:12,800 --> 02:10:15,760
at the foundation it is labor so

2507
02:10:15,760 --> 02:10:18,480
what happens when there is uh

2508
02:10:18,480 --> 02:10:19,840
you know

2509
02:10:19,840 --> 02:10:22,079
no shortage of labor

2510
02:10:22,079 --> 02:10:23,840
um that's why i think long-term that

2511
02:10:23,840 --> 02:10:25,199
there will need to be universal basic

2512
02:10:25,199 --> 02:10:27,040
income

2513
02:10:27,040 --> 02:10:29,840
yeah

2514
02:10:29,840 --> 02:10:31,360
but but not right now because this robot

2515
02:10:31,360 --> 02:10:33,920
doesn't work so

2516
02:10:33,920 --> 02:10:36,079
we just didn't need a minute

2517
02:10:36,079 --> 02:10:36,880
so

2518
02:10:36,880 --> 02:10:38,159
um

2519
02:10:38,159 --> 02:10:39,679
yeah but i think essentially in the

2520
02:10:39,679 --> 02:10:42,079
future physical work will be a choice if

2521
02:10:42,079 --> 02:10:43,679
you want to do it you can but you won't

2522
02:10:43,679 --> 02:10:45,199
need to do it

2523
02:10:45,199 --> 02:10:46,800
and

2524
02:10:46,800 --> 02:10:48,480
yeah i think it obviously has profound

2525
02:10:48,480 --> 02:10:51,119
implications for the economy because

2526
02:10:51,119 --> 02:10:52,320
given that the economy at its

2527
02:10:52,320 --> 02:10:54,639
foundational level is labor i mean

2528
02:10:54,639 --> 02:10:56,320
capital is capital equipment it's just

2529
02:10:56,320 --> 02:10:58,159
distilled labor

2530
02:10:58,159 --> 02:11:00,320
then

2531
02:11:00,320 --> 02:11:02,480
is there any actual limit to the economy

2532
02:11:02,480 --> 02:11:04,960
maybe not

2533
02:11:05,119 --> 02:11:06,639
so

2534
02:11:06,639 --> 02:11:08,880
yeah

2535
02:11:09,599 --> 02:11:12,400
join our team and help build this

2536
02:11:12,400 --> 02:11:13,920
all right so i think we'll we'll have

2537
02:11:13,920 --> 02:11:15,119
everyone come back on the stage and you

2538
02:11:15,119 --> 02:11:18,320
guys can ask questions if you'd like

2539
02:11:18,320 --> 02:11:21,120
yeah

2540
02:11:21,120 --> 02:11:28,050
[Applause]

2541
02:11:37,760 --> 02:11:39,840
you

2542
02:11:45,300 --> 02:11:53,180
[Music]

2543
02:11:57,599 --> 02:12:00,239
all right there we go

2544
02:12:00,960 --> 02:12:02,159
[Music]

2545
02:12:02,159 --> 02:12:03,599
all right cool you guys brought me back

2546
02:12:03,599 --> 02:12:04,960
on

2547
02:12:04,960 --> 02:12:06,000
i just like stage

2548
02:12:06,000 --> 02:12:07,040
try to get

2549
02:12:07,040 --> 02:12:08,719
the camera angle from there

2550
02:12:08,719 --> 02:12:11,520
but not from the side

2551
02:12:16,000 --> 02:12:17,679
all right cool

2552
02:12:17,679 --> 02:12:19,119
so we'll probably turn the lights back

2553
02:12:19,119 --> 02:12:20,880
on

2554
02:12:20,880 --> 02:12:23,440
and uh

2555
02:12:24,400 --> 02:12:26,239
yeah great um

2556
02:12:26,239 --> 02:12:27,760
so we're having to answer any questions

2557
02:12:27,760 --> 02:12:30,320
you have about anything on the software

2558
02:12:30,320 --> 02:12:32,480
hardware side where things are going

2559
02:12:32,480 --> 02:12:35,199
and yeah fire away

2560
02:12:35,199 --> 02:12:37,520
um we have because the lights are like

2561
02:12:37,520 --> 02:12:38,960
interrogation lights so we actually

2562
02:12:38,960 --> 02:12:42,320
cannot see ah there we go great

2563
02:12:43,280 --> 02:12:46,520
all right cool

2564
02:12:57,520 --> 02:12:59,360
i can just okay there we go first off i

2565
02:12:59,360 --> 02:13:00,560
mean thanks to all the presenters that

2566
02:13:00,560 --> 02:13:02,639
was just super cool to see everything

2567
02:13:02,639 --> 02:13:03,920
i'm just curious at a high level and

2568
02:13:03,920 --> 02:13:05,520
this is kind of a question for really

2569
02:13:05,520 --> 02:13:08,079
anyone who wants to take it um to what

2570
02:13:08,079 --> 02:13:10,320
extent are you interested in publishing

2571
02:13:10,320 --> 02:13:13,360
or open sourcing anything that you do

2572
02:13:13,360 --> 02:13:17,159
for the future

2573
02:13:27,360 --> 02:13:30,880
um well i mean it is fundamentally

2574
02:13:30,880 --> 02:13:33,280
extremely expensive to create uh the

2575
02:13:33,280 --> 02:13:35,119
system so

2576
02:13:35,119 --> 02:13:36,480
uh

2577
02:13:36,480 --> 02:13:38,079
somehow that has to be paid for i'm not

2578
02:13:38,079 --> 02:13:39,280
sure how to pay for it if it's fully

2579
02:13:39,280 --> 02:13:40,639
open sourced

2580
02:13:40,639 --> 02:13:42,960
um

2581
02:13:43,599 --> 02:13:47,280
yeah unless people want to work for free

2582
02:13:50,800 --> 02:13:53,840
but but i should say that uh this is

2583
02:13:53,840 --> 02:13:56,560
if other car companies want to license

2584
02:13:56,560 --> 02:13:58,320
it and use it in their cars that would

2585
02:13:58,320 --> 02:13:59,920
be cool this is not intended to be just

2586
02:13:59,920 --> 02:14:03,040
limited to tesla cars

2587
02:14:05,280 --> 02:14:08,480
is for the dojo supercomputer so did you

2588
02:14:08,480 --> 02:14:10,960
solve the compiler problem of scaling to

2589
02:14:10,960 --> 02:14:14,079
these many nodes or is or

2590
02:14:14,079 --> 02:14:16,560
if it is solved is it only applicable to

2591
02:14:16,560 --> 02:14:17,679
dojo

2592
02:14:17,679 --> 02:14:19,040
because

2593
02:14:19,040 --> 02:14:21,280
i'm doing research in

2594
02:14:21,280 --> 02:14:23,520
deep learning accelerators and getting

2595
02:14:23,520 --> 02:14:25,679
the correct scalability

2596
02:14:25,679 --> 02:14:29,599
or the distribution even in one ship is

2597
02:14:29,599 --> 02:14:31,840
extremely difficult from the

2598
02:14:31,840 --> 02:14:33,440
research projects perspective so i was

2599
02:14:33,440 --> 02:14:35,679
just curious

2600
02:14:35,679 --> 02:14:38,880
excuse me mike for bill

2601
02:14:38,880 --> 02:14:40,800
you

2602
02:14:40,800 --> 02:14:43,199
have we solved the problem not yet are

2603
02:14:43,199 --> 02:14:45,040
we confident we will solve the problem

2604
02:14:45,040 --> 02:14:46,159
yes

2605
02:14:46,159 --> 02:14:47,840
we have demonstrated networks on

2606
02:14:47,840 --> 02:14:49,840
prototype hardware now we have models

2607
02:14:49,840 --> 02:14:52,159
performance models showing the scaling

2608
02:14:52,159 --> 02:14:54,320
the difficulty is as you said how do we

2609
02:14:54,320 --> 02:14:56,079
keep the localities

2610
02:14:56,079 --> 02:14:57,920
if we can do enough model parallel

2611
02:14:57,920 --> 02:15:00,320
enough data parallel to keep most of the

2612
02:15:00,320 --> 02:15:02,320
things local we just keep scaling we

2613
02:15:02,320 --> 02:15:03,599
have to fit the parameters in our

2614
02:15:03,599 --> 02:15:06,239
working set in our sram that we have

2615
02:15:06,239 --> 02:15:09,840
and we flow through the pipe

2616
02:15:11,199 --> 02:15:13,040
there's plenty of opportunities

2617
02:15:13,040 --> 02:15:15,040
sorry as we get further scale for

2618
02:15:15,040 --> 02:15:16,880
further processor nodes have more local

2619
02:15:16,880 --> 02:15:17,920
memory

2620
02:15:17,920 --> 02:15:20,159
memory trade also bandwidth we can do

2621
02:15:20,159 --> 02:15:22,400
more things but as we see it now

2622
02:15:22,400 --> 02:15:24,880
the applications that tesla has we see a

2623
02:15:24,880 --> 02:15:27,360
clear path

2624
02:15:28,000 --> 02:15:30,400
and our our modularity story means we

2625
02:15:30,400 --> 02:15:32,880
can have different ratios different

2626
02:15:32,880 --> 02:15:35,599
aspects created out of it i mean this is

2627
02:15:35,599 --> 02:15:37,119
something that we chose for our

2628
02:15:37,119 --> 02:15:38,400
applications

2629
02:15:38,400 --> 02:15:40,960
internally

2630
02:15:43,360 --> 02:15:45,599
sure

2631
02:15:45,599 --> 02:15:47,920
the locality portion of it given that

2632
02:15:47,920 --> 02:15:49,440
training is such a soft scaling

2633
02:15:49,440 --> 02:15:50,639
application

2634
02:15:50,639 --> 02:15:52,880
uh even though you have all this compute

2635
02:15:52,880 --> 02:15:55,119
and have a high bandwidth

2636
02:15:55,119 --> 02:15:57,760
high bandwidth interconnect

2637
02:15:57,760 --> 02:15:59,599
it it could not

2638
02:15:59,599 --> 02:16:01,119
give you that performance because you

2639
02:16:01,119 --> 02:16:03,520
are doing computations on limited memory

2640
02:16:03,520 --> 02:16:06,079
at different locations so i was that's

2641
02:16:06,079 --> 02:16:07,599
very curious to me when you said it

2642
02:16:07,599 --> 02:16:09,920
solved because i i just jumped onto the

2643
02:16:09,920 --> 02:16:12,639
opportunity and would love to know more

2644
02:16:12,639 --> 02:16:15,440
given that how much you can open source

2645
02:16:15,440 --> 02:16:18,440
yeah

2646
02:16:18,639 --> 02:16:20,400
yeah i guess the proof's in the pudding

2647
02:16:20,400 --> 02:16:21,360
um

2648
02:16:21,360 --> 02:16:23,679
so we should have dojo operational next

2649
02:16:23,679 --> 02:16:25,760
year um and

2650
02:16:25,760 --> 02:16:27,679
um i think we'll we'll obviously use it

2651
02:16:27,679 --> 02:16:28,560
for

2652
02:16:28,560 --> 02:16:30,560
uh training video training it's i mean

2653
02:16:30,560 --> 02:16:33,359
fundamentally this is about like um

2654
02:16:33,359 --> 02:16:34,478
the the

2655
02:16:34,478 --> 02:16:36,160
primary application initially is we've

2656
02:16:36,160 --> 02:16:38,160
got vast amounts of video and how we

2657
02:16:38,160 --> 02:16:40,240
train vast amounts of video uh

2658
02:16:40,240 --> 02:16:42,160
as efficiently as possible

2659
02:16:42,160 --> 02:16:44,399
and

2660
02:16:45,120 --> 02:16:47,040
uh also shorten the amount of time like

2661
02:16:47,040 --> 02:16:48,879
if you're trying to train train to a

2662
02:16:48,879 --> 02:16:50,638
task um

2663
02:16:50,638 --> 02:16:53,599
like just in general innovation is um

2664
02:16:53,599 --> 02:16:55,120
how many iterations and what is the

2665
02:16:55,120 --> 02:16:57,439
average progress between each iteration

2666
02:16:57,439 --> 02:16:59,040
and so if

2667
02:16:59,040 --> 02:17:00,718
if you can reduce the time between

2668
02:17:00,718 --> 02:17:03,280
iterations uh the rate of improvement is

2669
02:17:03,280 --> 02:17:04,558
is much better

2670
02:17:04,558 --> 02:17:05,679
so

2671
02:17:05,679 --> 02:17:07,840
um you know if it takes like sometimes a

2672
02:17:07,840 --> 02:17:10,080
couple days for a model to train versus

2673
02:17:10,080 --> 02:17:13,519
a couple hours that's a big deal

2674
02:17:13,599 --> 02:17:16,718
but the the asset test here and um you

2675
02:17:16,718 --> 02:17:18,000
know what i've

2676
02:17:18,000 --> 02:17:20,959
told the dojo team is like it's

2677
02:17:20,959 --> 02:17:23,120
it's successful if the

2678
02:17:23,120 --> 02:17:24,000
uh

2679
02:17:24,000 --> 02:17:26,318
software team wants to turn off the gpu

2680
02:17:26,318 --> 02:17:27,359
cluster

2681
02:17:27,359 --> 02:17:29,280
but if they want to keep the gpp cluster

2682
02:17:29,280 --> 02:17:30,000
on

2683
02:17:30,000 --> 02:17:32,558
it's not successful

2684
02:17:32,558 --> 02:17:35,358
so yeah

2685
02:17:38,638 --> 02:17:39,920
hi

2686
02:17:39,920 --> 02:17:41,120
right over here

2687
02:17:41,120 --> 02:17:43,120
i love the presentation thank you for

2688
02:17:43,120 --> 02:17:44,799
getting us out here loved everything

2689
02:17:44,799 --> 02:17:46,318
especially the simulation part of the

2690
02:17:46,318 --> 02:17:48,240
presentation i was wondering uh it

2691
02:17:48,240 --> 02:17:50,000
looked very very

2692
02:17:50,000 --> 02:17:52,160
very uh realistic are there any plans to

2693
02:17:52,160 --> 02:17:53,519
maybe expand simulation to other parts

2694
02:17:53,519 --> 02:17:57,800
of the company in any way

2695
02:17:58,638 --> 02:18:00,558
hi i'm ian glow uh i manage the

2696
02:18:00,558 --> 02:18:02,879
autopilot simulation team

2697
02:18:02,879 --> 02:18:05,359
so as we go down the path to

2698
02:18:05,359 --> 02:18:06,478
full self driving we're gonna have to

2699
02:18:06,478 --> 02:18:09,120
simulate more and more of the vehicle

2700
02:18:09,120 --> 02:18:10,959
currently we're simulating vehicle

2701
02:18:10,959 --> 02:18:12,478
dynamics but we're going to need bms

2702
02:18:12,478 --> 02:18:13,599
we're going to need the mcu we're going

2703
02:18:13,599 --> 02:18:15,040
to need every single part of the vehicle

2704
02:18:15,040 --> 02:18:16,718
integrated and that actually makes the

2705
02:18:16,718 --> 02:18:18,478
autopilot simulator really useful for

2706
02:18:18,478 --> 02:18:20,959
places outside of autopilot so i want to

2707
02:18:20,959 --> 02:18:23,280
expand or we want to expand eventually

2708
02:18:23,280 --> 02:18:25,840
to being a universal simulation platform

2709
02:18:25,840 --> 02:18:27,280
but i think before that we're going to

2710
02:18:27,280 --> 02:18:29,359
be spinning up a lot of optimist support

2711
02:18:29,359 --> 02:18:30,799
and then a little bit further down the

2712
02:18:30,799 --> 02:18:33,200
line that we have some rough ideas on

2713
02:18:33,200 --> 02:18:34,879
potentially how to get uh

2714
02:18:34,879 --> 02:18:36,398
the simulation infrastructure and some

2715
02:18:36,398 --> 02:18:37,599
of the cool things we've built into the

2716
02:18:37,599 --> 02:18:40,959
hands of people outside of the company

2717
02:18:40,959 --> 02:18:42,799
optimus is the code name for the tesla

2718
02:18:42,799 --> 02:18:44,000
bot

2719
02:18:44,000 --> 02:18:46,319
oops

2720
02:18:49,280 --> 02:18:50,968
optimus uprine

2721
02:18:50,968 --> 02:18:54,588
[Laughter]

2722
02:18:56,160 --> 02:18:57,200
hi

2723
02:18:57,200 --> 02:18:59,040
this is ali jahanian

2724
02:18:59,040 --> 02:19:01,519
thank you for the great presentation and

2725
02:19:01,519 --> 02:19:03,200
putting all of these cool things

2726
02:19:03,200 --> 02:19:04,240
together

2727
02:19:04,240 --> 02:19:06,160
yeah for a while i have been thinking

2728
02:19:06,160 --> 02:19:09,840
that uh the car is already a robot so

2729
02:19:09,840 --> 02:19:12,318
why not a humanity robot

2730
02:19:12,318 --> 02:19:14,959
and i'm so happy that today

2731
02:19:14,959 --> 02:19:16,558
you mentioned that you are going to

2732
02:19:16,558 --> 02:19:18,240
build such thing

2733
02:19:18,240 --> 02:19:21,200
especially i think that this can uh give

2734
02:19:21,200 --> 02:19:24,718
opportunity for rays of uh putting multi

2735
02:19:24,718 --> 02:19:27,439
modality together for instance we know

2736
02:19:27,439 --> 02:19:29,120
that in

2737
02:19:29,120 --> 02:19:31,439
the example that you are showed that

2738
02:19:31,439 --> 02:19:33,359
there was a dog and

2739
02:19:33,359 --> 02:19:38,080
with some passengers or running together

2740
02:19:38,080 --> 02:19:39,040
the

2741
02:19:39,040 --> 02:19:40,160
language

2742
02:19:40,160 --> 02:19:42,718
and symbolic processing can really help

2743
02:19:42,718 --> 02:19:43,519
for

2744
02:19:43,519 --> 02:19:45,040
visualizing that

2745
02:19:45,040 --> 02:19:48,559
so i was wondering

2746
02:19:48,960 --> 02:19:51,600
if i could hear a little more about

2747
02:19:51,600 --> 02:19:54,880
this type of putting modalities together

2748
02:19:54,880 --> 02:19:57,680
including language and vision because i

2749
02:19:57,680 --> 02:19:59,840
have been working with for instance mini

2750
02:19:59,840 --> 02:20:02,800
gpt's and andre put out there

2751
02:20:02,800 --> 02:20:04,000
and

2752
02:20:04,000 --> 02:20:07,359
yeah i had i didn't hear much about

2753
02:20:07,359 --> 02:20:09,920
other modalities that's going into the

2754
02:20:09,920 --> 02:20:12,720
car or at least in the simulation

2755
02:20:12,720 --> 02:20:14,640
is is there any comment

2756
02:20:14,640 --> 02:20:15,439
that

2757
02:20:15,439 --> 02:20:16,960
you could tell us

2758
02:20:16,960 --> 02:20:20,720
well driving is fundamentally uh

2759
02:20:20,720 --> 02:20:22,080
basically

2760
02:20:22,080 --> 02:20:24,560
almost entirely vision neural nets uh

2761
02:20:24,560 --> 02:20:26,319
like we're basically it's running on a

2762
02:20:26,319 --> 02:20:27,680
biological vision

2763
02:20:27,680 --> 02:20:30,240
neural net and what we're doing here is

2764
02:20:30,240 --> 02:20:33,520
a silicon camera neural net um

2765
02:20:33,520 --> 02:20:34,319
so

2766
02:20:34,319 --> 02:20:35,680
and there are there's there is some

2767
02:20:35,680 --> 02:20:37,840
amount of uh audio uh you know you want

2768
02:20:37,840 --> 02:20:40,319
to hear uh if um there's like emergency

2769
02:20:40,319 --> 02:20:42,160
vehicles or

2770
02:20:42,160 --> 02:20:42,960
uh

2771
02:20:42,960 --> 02:20:45,120
you know uh

2772
02:20:45,120 --> 02:20:47,040
i guess converse with the

2773
02:20:47,040 --> 02:20:48,479
people in the car

2774
02:20:48,479 --> 02:20:50,000
um

2775
02:20:50,000 --> 02:20:52,399
you know if somebody's yelling something

2776
02:20:52,399 --> 02:20:54,720
at the at the car that car needs to

2777
02:20:54,720 --> 02:20:56,399
understand what that is

2778
02:20:56,399 --> 02:20:57,359
um

2779
02:20:57,359 --> 02:20:59,040
so

2780
02:20:59,040 --> 02:21:00,479
you know all things that are necessary

2781
02:21:00,479 --> 02:21:01,920
for it to

2782
02:21:01,920 --> 02:21:04,000
be fully autonomous

2783
02:21:04,000 --> 02:21:05,280
yeah

2784
02:21:05,280 --> 02:21:07,600
thank you

2785
02:21:11,520 --> 02:21:13,359
hi uh thank you for all the great work

2786
02:21:13,359 --> 02:21:15,680
that you've shown uh my question is for

2787
02:21:15,680 --> 02:21:18,080
the team uh because the data that was

2788
02:21:18,080 --> 02:21:20,080
shown was seems to be predominantly from

2789
02:21:20,080 --> 02:21:22,319
the united states that the the fsd

2790
02:21:22,319 --> 02:21:24,560
computer is being trained on but as it

2791
02:21:24,560 --> 02:21:26,160
is being as it gets rolled out to

2792
02:21:26,160 --> 02:21:28,080
different countries which have their own

2793
02:21:28,080 --> 02:21:29,760
road systems and

2794
02:21:29,760 --> 02:21:31,920
challenges that come with it how do you

2795
02:21:31,920 --> 02:21:34,479
think that it's going to scale like like

2796
02:21:34,479 --> 02:21:36,479
i'm assuming like the ground up is not a

2797
02:21:36,479 --> 02:21:38,640
very viable solution so how does it

2798
02:21:38,640 --> 02:21:41,680
transfer to different countries

2799
02:21:41,680 --> 02:21:45,439
uh well there is we actually do train on

2800
02:21:45,439 --> 02:21:47,280
using data from

2801
02:21:47,280 --> 02:21:49,120
probably like 50 different countries

2802
02:21:49,120 --> 02:21:52,319
um but we have to pick

2803
02:21:53,359 --> 02:21:54,880
you know in as we're trying to advance

2804
02:21:54,880 --> 02:21:56,240
full self driving we need to pick one

2805
02:21:56,240 --> 02:21:58,880
country and since we're located here we

2806
02:21:58,880 --> 02:22:00,880
pick the us um

2807
02:22:00,880 --> 02:22:02,080
and then we get a lot of questions like

2808
02:22:02,080 --> 02:22:03,680
why not even canada like well because

2809
02:22:03,680 --> 02:22:04,720
the roads are a little different in

2810
02:22:04,720 --> 02:22:07,040
canada different enough um

2811
02:22:07,040 --> 02:22:08,880
and so when trying to solve a hard

2812
02:22:08,880 --> 02:22:11,120
problem uh you want to

2813
02:22:11,120 --> 02:22:14,479
uh say like okay what's the

2814
02:22:14,479 --> 02:22:16,560
let's not add additional complexity

2815
02:22:16,560 --> 02:22:18,720
right now uh let's just solve it for the

2816
02:22:18,720 --> 02:22:20,160
us and then we'll extrapolate to the

2817
02:22:20,160 --> 02:22:21,600
rest of the world but we do use video

2818
02:22:21,600 --> 02:22:23,760
from all around the world yeah i think a

2819
02:22:23,760 --> 02:22:25,280
lot of a lot of what we are building is

2820
02:22:25,280 --> 02:22:27,680
very country agnostic fundamentally all

2821
02:22:27,680 --> 02:22:29,120
the computer vision components and so on

2822
02:22:29,120 --> 02:22:30,560
don't care too much about country

2823
02:22:30,560 --> 02:22:32,800
specific uh

2824
02:22:32,800 --> 02:22:34,479
sort of features every you know

2825
02:22:34,479 --> 02:22:35,840
different countries have roads and they

2826
02:22:35,840 --> 02:22:37,280
have curbs and they have cars and

2827
02:22:37,280 --> 02:22:38,560
everything we're building is fairly

2828
02:22:38,560 --> 02:22:40,319
general for that

2829
02:22:40,319 --> 02:22:42,479
yeah and there's the the prime directive

2830
02:22:42,479 --> 02:22:44,720
is don't crash right and that's true for

2831
02:22:44,720 --> 02:22:46,560
every country yes this is the prime

2832
02:22:46,560 --> 02:22:48,080
directive

2833
02:22:48,080 --> 02:22:49,280
um

2834
02:22:49,280 --> 02:22:50,880
and um

2835
02:22:50,880 --> 02:22:52,800
even right now the car is pretty good at

2836
02:22:52,800 --> 02:22:54,399
not crashing um

2837
02:22:54,399 --> 02:22:55,359
and so

2838
02:22:55,359 --> 02:22:57,600
just basically um

2839
02:22:57,600 --> 02:22:59,280
whatever it is don't hit it even if it's

2840
02:22:59,280 --> 02:23:02,399
a ufo that crash landed uh on the

2841
02:23:02,399 --> 02:23:06,160
highway and still don't hit it

2842
02:23:06,160 --> 02:23:07,680
you should not need to recognize it in

2843
02:23:07,680 --> 02:23:09,200
order to not hit it

2844
02:23:09,200 --> 02:23:12,920
so that's very important

2845
02:23:20,800 --> 02:23:23,200
and i want to ask that

2846
02:23:23,200 --> 02:23:25,120
when you do the photometric process

2847
02:23:25,120 --> 02:23:27,760
multiview geometry how much of an error

2848
02:23:27,760 --> 02:23:30,479
do you see is it like one millimeter one

2849
02:23:30,479 --> 02:23:32,960
centimeter so i'm just if it's not

2850
02:23:32,960 --> 02:23:35,040
confidential

2851
02:23:35,040 --> 02:23:37,439
sorry question what is the what's it

2852
02:23:37,439 --> 02:23:38,640
what's the difference between the

2853
02:23:38,640 --> 02:23:40,240
synthetic

2854
02:23:40,240 --> 02:23:42,080
sure

2855
02:23:42,080 --> 02:23:43,520
what is the difference between the

2856
02:23:43,520 --> 02:23:45,439
synthetically created geometry to the

2857
02:23:45,439 --> 02:23:47,840
actual geometry

2858
02:23:47,840 --> 02:23:49,359
yeah it's usually within a couple

2859
02:23:49,359 --> 02:23:52,720
centimeters three or four centimeters

2860
02:23:52,720 --> 02:23:55,920
that's the standard deviation

2861
02:23:55,920 --> 02:23:58,880
merge with different kind of modalities

2862
02:23:58,880 --> 02:24:02,479
to bring down that error

2863
02:24:02,640 --> 02:24:04,720
we primarily try to find scalable ways

2864
02:24:04,720 --> 02:24:06,880
to label um in some occasions we use

2865
02:24:06,880 --> 02:24:08,240
other sensors to

2866
02:24:08,240 --> 02:24:10,000
help benchmark but we primarily use

2867
02:24:10,000 --> 02:24:12,800
cameras for this system

2868
02:24:12,800 --> 02:24:15,439
okay thanks yeah i i mean i think we

2869
02:24:15,439 --> 02:24:17,600
want to aim for the car to be positioned

2870
02:24:17,600 --> 02:24:20,000
uh accurately to the the sort of

2871
02:24:20,000 --> 02:24:21,920
centimeter level um

2872
02:24:21,920 --> 02:24:22,720
you know

2873
02:24:22,720 --> 02:24:24,240
something on that order obviously it

2874
02:24:24,240 --> 02:24:25,600
will depend on distance like close by

2875
02:24:25,600 --> 02:24:27,200
things can be much more accurate than

2876
02:24:27,200 --> 02:24:28,880
farther away things because and they

2877
02:24:28,880 --> 02:24:30,160
would matter less because the car

2878
02:24:30,160 --> 02:24:31,680
doesn't have to make decisions much

2879
02:24:31,680 --> 02:24:33,200
farther away and as it comes close it

2880
02:24:33,200 --> 02:24:36,080
will become more and more accurate

2881
02:24:36,080 --> 02:24:38,479
exactly

2882
02:24:39,040 --> 02:24:40,960
a lot of questions

2883
02:24:40,960 --> 02:24:43,120
thanks everybody my question has to do

2884
02:24:43,120 --> 02:24:44,960
with sort of ai and manufacturing it's

2885
02:24:44,960 --> 02:24:46,640
been a while since we've heard about the

2886
02:24:46,640 --> 02:24:48,560
alien dreadnought concept

2887
02:24:48,560 --> 02:24:50,640
is the humanoid that's behind you guys

2888
02:24:50,640 --> 02:24:52,160
is that kind of brought out of the

2889
02:24:52,160 --> 02:24:53,920
production health timeline and saying

2890
02:24:53,920 --> 02:24:55,200
that humans are underrated in that

2891
02:24:55,200 --> 02:24:57,840
process

2892
02:24:57,920 --> 02:25:00,399
um well sometimes like some

2893
02:25:00,399 --> 02:25:02,479
you know something that i say is uh

2894
02:25:02,479 --> 02:25:04,800
taken to too much of an extreme

2895
02:25:04,800 --> 02:25:07,040
there

2896
02:25:08,000 --> 02:25:09,359
there are parts of the tesla system that

2897
02:25:09,359 --> 02:25:11,680
are almost completely automated and then

2898
02:25:11,680 --> 02:25:12,960
there are some parts that are almost

2899
02:25:12,960 --> 02:25:15,200
completely manual

2900
02:25:15,200 --> 02:25:16,560
and

2901
02:25:16,560 --> 02:25:17,600
if you were to walk through the whole

2902
02:25:17,600 --> 02:25:19,680
production system you would see a very

2903
02:25:19,680 --> 02:25:22,479
wide range from yeah like i said fully

2904
02:25:22,479 --> 02:25:23,840
automatic to

2905
02:25:23,840 --> 02:25:25,760
almost completely manual

2906
02:25:25,760 --> 02:25:28,560
but the vast majority it's most of it is

2907
02:25:28,560 --> 02:25:31,520
is already uh automated

2908
02:25:31,520 --> 02:25:33,040
um

2909
02:25:33,040 --> 02:25:34,479
so and then

2910
02:25:34,479 --> 02:25:35,920
with the

2911
02:25:35,920 --> 02:25:37,520
some of the design architecture changes

2912
02:25:37,520 --> 02:25:39,120
like going to

2913
02:25:39,120 --> 02:25:40,080
large

2914
02:25:40,080 --> 02:25:41,600
aluminum

2915
02:25:41,600 --> 02:25:43,120
high pressure die cast

2916
02:25:43,120 --> 02:25:45,600
components we can take the entire rear

2917
02:25:45,600 --> 02:25:47,680
third of the car and cast it as a single

2918
02:25:47,680 --> 02:25:50,560
piece and now we're going to do that

2919
02:25:50,560 --> 02:25:52,160
the front third of the car is a single

2920
02:25:52,160 --> 02:25:53,040
piece

2921
02:25:53,040 --> 02:25:54,960
so the the body line

2922
02:25:54,960 --> 02:25:55,840
um

2923
02:25:55,840 --> 02:25:59,680
drops by like 60 to 70 percent in size

2924
02:25:59,680 --> 02:26:01,840
um

2925
02:26:01,840 --> 02:26:04,080
but yeah the the robot is not is not

2926
02:26:04,080 --> 02:26:05,920
prompted by

2927
02:26:05,920 --> 02:26:08,160
specifically by manufacturing

2928
02:26:08,160 --> 02:26:11,120
needs it's it's just that

2929
02:26:11,120 --> 02:26:13,200
we're just obviously making the pieces

2930
02:26:13,200 --> 02:26:14,560
that

2931
02:26:14,560 --> 02:26:19,120
are needed for a useful humanoid robot

2932
02:26:19,359 --> 02:26:21,439
so i guess we probably should make it

2933
02:26:21,439 --> 02:26:23,040
and if we don't someone else would well

2934
02:26:23,040 --> 02:26:26,640
and so i guess we should make it

2935
02:26:26,640 --> 02:26:29,680
and make sure it's safe

2936
02:26:32,960 --> 02:26:34,880
i should say like also manufacturing

2937
02:26:34,880 --> 02:26:36,160
volume manufacturing is extremely

2938
02:26:36,160 --> 02:26:38,720
difficult um and underrated and we've

2939
02:26:38,720 --> 02:26:40,800
gotten pretty good at that

2940
02:26:40,800 --> 02:26:42,160
it's also important for that humanoid

2941
02:26:42,160 --> 02:26:44,000
robot like how do you make the human

2942
02:26:44,000 --> 02:26:46,160
robot not be super expensive

2943
02:26:46,160 --> 02:26:49,160
and

2944
02:26:49,520 --> 02:26:50,720
hi

2945
02:26:50,720 --> 02:26:53,040
uh thank you for the present

2946
02:26:53,040 --> 02:26:54,399
presentation

2947
02:26:54,399 --> 02:26:57,040
and my question will be about skilling

2948
02:26:57,040 --> 02:26:58,720
of dojo

2949
02:26:58,720 --> 02:27:01,760
and uh in particular how do you scale

2950
02:27:01,760 --> 02:27:04,640
the compute nodes in terms of

2951
02:27:04,640 --> 02:27:06,160
thermal

2952
02:27:06,160 --> 02:27:08,640
thermals and power delivery because

2953
02:27:08,640 --> 02:27:11,200
there is only so much heat that you can

2954
02:27:11,200 --> 02:27:12,479
dispense

2955
02:27:12,479 --> 02:27:14,960
and only so much power that you can

2956
02:27:14,960 --> 02:27:16,560
bring to

2957
02:27:16,560 --> 02:27:18,640
like cluster rack

2958
02:27:18,640 --> 02:27:21,520
and how do you want to scale it and how

2959
02:27:21,520 --> 02:27:24,080
do you point to scale it in multiple

2960
02:27:24,080 --> 02:27:26,880
data centers

2961
02:27:27,200 --> 02:27:29,920
sure

2962
02:27:33,600 --> 02:27:34,319
hi

2963
02:27:34,319 --> 02:27:35,920
i'm bill i

2964
02:27:35,920 --> 02:27:38,479
one of the dojo engineers the um

2965
02:27:38,479 --> 02:27:41,200
so from a thermal standpoint and power

2966
02:27:41,200 --> 02:27:42,240
standpoint

2967
02:27:42,240 --> 02:27:44,319
we've designed it very modular so what

2968
02:27:44,319 --> 02:27:46,640
you saw on the compute tile that will

2969
02:27:46,640 --> 02:27:50,080
that will cool the entire tile so we we

2970
02:27:50,080 --> 02:27:51,920
once we hook it up to it is liquid

2971
02:27:51,920 --> 02:27:53,680
cooled on both the top and the bottom

2972
02:27:53,680 --> 02:27:57,600
side um it doesn't need anything else

2973
02:27:57,600 --> 02:28:00,000
and so when we talk about clicking these

2974
02:28:00,000 --> 02:28:01,439
together

2975
02:28:01,439 --> 02:28:03,520
once we click it to power and we once we

2976
02:28:03,520 --> 02:28:05,120
click it to um

2977
02:28:05,120 --> 02:28:07,120
cooling it will be fully powered and

2978
02:28:07,120 --> 02:28:08,240
fully cooled

2979
02:28:08,240 --> 02:28:10,000
and all of that is

2980
02:28:10,000 --> 02:28:12,319
less than a cubic foot

2981
02:28:12,319 --> 02:28:13,359
yeah

2982
02:28:13,359 --> 02:28:15,439
so tesla has a lot of expertise in power

2983
02:28:15,439 --> 02:28:18,720
electronics and in uh in cooling so we

2984
02:28:18,720 --> 02:28:21,359
took uh the power electronics expertise

2985
02:28:21,359 --> 02:28:23,439
from the vehicle powertrain

2986
02:28:23,439 --> 02:28:25,200
and the sort of the advanced cooling

2987
02:28:25,200 --> 02:28:26,960
that we developed

2988
02:28:26,960 --> 02:28:28,399
for the power electronics and for the

2989
02:28:28,399 --> 02:28:30,319
vehicle and applied that to the super

2990
02:28:30,319 --> 02:28:31,840
computer

2991
02:28:31,840 --> 02:28:34,160
because as you point out uh getting heat

2992
02:28:34,160 --> 02:28:35,200
out is

2993
02:28:35,200 --> 02:28:36,720
extremely important just really heat

2994
02:28:36,720 --> 02:28:38,160
limited

2995
02:28:38,160 --> 02:28:39,600
so

2996
02:28:39,600 --> 02:28:40,640
um

2997
02:28:40,640 --> 02:28:42,800
yeah so it's funny that like

2998
02:28:42,800 --> 02:28:44,640
at the compute level it's operating at

2999
02:28:44,640 --> 02:28:46,240
less than a volt

3000
02:28:46,240 --> 02:28:48,399
which is a

3001
02:28:48,399 --> 02:28:50,640
very low voltage there's a lot of amps

3002
02:28:50,640 --> 02:28:52,399
so therefore a lot of heat

3003
02:28:52,399 --> 02:28:54,240
i squared r is what really bites you on

3004
02:28:54,240 --> 02:28:56,560
the ass

3005
02:28:58,240 --> 02:29:01,359
um hi uh my question's also similarly a

3006
02:29:01,359 --> 02:29:02,880
question of scaling

3007
02:29:02,880 --> 02:29:04,399
um so it seems like a natural

3008
02:29:04,399 --> 02:29:06,000
consequence of using you know

3009
02:29:06,000 --> 02:29:07,680
significantly faster training hardware

3010
02:29:07,680 --> 02:29:09,200
is that you'd be either training models

3011
02:29:09,200 --> 02:29:10,640
over a lot more data

3012
02:29:10,640 --> 02:29:12,319
or you'd be training a lot more complex

3013
02:29:12,319 --> 02:29:14,240
models which would be

3014
02:29:14,240 --> 02:29:16,000
potentially significantly more expensive

3015
02:29:16,000 --> 02:29:18,640
to run at inference time on the cars

3016
02:29:18,640 --> 02:29:20,240
uh i guess i was wondering like if there

3017
02:29:20,240 --> 02:29:23,200
was a plan to like also

3018
02:29:23,200 --> 02:29:24,479
um

3019
02:29:24,479 --> 02:29:27,280
apply dojo as something that you'd be uh

3020
02:29:27,280 --> 02:29:30,000
using like on the self-driving cars and

3021
02:29:30,000 --> 02:29:31,520
if so like

3022
02:29:31,520 --> 02:29:32,880
you know do you foresee additional

3023
02:29:32,880 --> 02:29:36,000
challenges there

3024
02:29:36,000 --> 02:29:36,960
i can

3025
02:29:36,960 --> 02:29:39,120
so as you could see like android's

3026
02:29:39,120 --> 02:29:41,359
models are not just for cars like there

3027
02:29:41,359 --> 02:29:43,520
are auto labeling models there are other

3028
02:29:43,520 --> 02:29:45,439
models that are

3029
02:29:45,439 --> 02:29:48,080
like beyond car application but they

3030
02:29:48,080 --> 02:29:51,680
feed into the car stack so so dojo will

3031
02:29:51,680 --> 02:29:54,560
be used for all of those too

3032
02:29:54,560 --> 02:29:56,080
not just the car

3033
02:29:56,080 --> 02:29:59,760
inference part of the training

3034
02:29:59,760 --> 02:30:02,240
yeah i mean the dojo's

3035
02:30:02,240 --> 02:30:04,479
first application will be consuming

3036
02:30:04,479 --> 02:30:06,399
video data for training for that would

3037
02:30:06,399 --> 02:30:08,240
then be run in the inverse inference

3038
02:30:08,240 --> 02:30:09,840
engine on the car

3039
02:30:09,840 --> 02:30:11,040
but uh

3040
02:30:11,040 --> 02:30:13,040
and that i think is an important uh test

3041
02:30:13,040 --> 02:30:15,760
to see if it actually is good or but is

3042
02:30:15,760 --> 02:30:17,040
it actually better than gpu cluster or

3043
02:30:17,040 --> 02:30:19,680
not um so

3044
02:30:19,680 --> 02:30:21,359
but then beyond that it's basically a

3045
02:30:21,359 --> 02:30:23,840
general a generalized neural net

3046
02:30:23,840 --> 02:30:25,200
training computer

3047
02:30:25,200 --> 02:30:27,359
but it's very much optimized to be a

3048
02:30:27,359 --> 02:30:29,600
neural net so

3049
02:30:29,600 --> 02:30:33,439
you know cpus and gpus uh

3050
02:30:33,439 --> 02:30:35,439
they're they're they're not made to be

3051
02:30:35,439 --> 02:30:36,240
um

3052
02:30:36,240 --> 02:30:37,359
they're not they're not designed

3053
02:30:37,359 --> 02:30:40,560
specifically for training neural nets um

3054
02:30:40,560 --> 02:30:42,960
we've been able to make gpus especially

3055
02:30:42,960 --> 02:30:44,960
very efficient for

3056
02:30:44,960 --> 02:30:46,479
portraying neural nets but that's not

3057
02:30:46,479 --> 02:30:48,399
that was never their design intent so

3058
02:30:48,399 --> 02:30:50,960
it's it's bc gpus are still essentially

3059
02:30:50,960 --> 02:30:53,280
running it uh neural net training in

3060
02:30:53,280 --> 02:30:55,439
emulation mode so

3061
02:30:55,439 --> 02:30:57,439
um with with dojo we're saying like okay

3062
02:30:57,439 --> 02:30:58,880
let's just let's just asic the whole

3063
02:30:58,880 --> 02:30:59,600
thing

3064
02:30:59,600 --> 02:31:00,560
let's just

3065
02:31:00,560 --> 02:31:02,160
have this thing that's it's built for

3066
02:31:02,160 --> 02:31:04,000
one purpose and that is neural net

3067
02:31:04,000 --> 02:31:05,040
training

3068
02:31:05,040 --> 02:31:07,200
and just generally any system that is

3069
02:31:07,200 --> 02:31:08,880
designed for a specific

3070
02:31:08,880 --> 02:31:10,640
purpose will be better than one that is

3071
02:31:10,640 --> 02:31:14,240
designed for a general purpose

3072
02:31:14,240 --> 02:31:16,080
hey i had a question here

3073
02:31:16,080 --> 02:31:18,399
hi um

3074
02:31:18,399 --> 02:31:20,160
so you described two separate systems

3075
02:31:20,160 --> 02:31:22,080
one was for vision therefore planner and

3076
02:31:22,080 --> 02:31:25,280
control um does dojo love you train

3077
02:31:25,280 --> 02:31:27,600
networks that cross that boundary and

3078
02:31:27,600 --> 02:31:29,280
second thing is if you were able to

3079
02:31:29,280 --> 02:31:30,880
train such networks would you have the

3080
02:31:30,880 --> 02:31:32,640
onboard compute capability in the fst

3081
02:31:32,640 --> 02:31:34,479
system to be able to run that in in

3082
02:31:34,479 --> 02:31:36,160
under your tight latency constraints

3083
02:31:36,160 --> 02:31:38,399
thanks

3084
02:31:39,600 --> 02:31:40,960
yeah i think we should be able to train

3085
02:31:40,960 --> 02:31:44,240
uh planner networks on dojo or any gpus

3086
02:31:44,240 --> 02:31:47,040
it's really invariant to the platform um

3087
02:31:47,040 --> 02:31:49,120
and i think uh if anything once we make

3088
02:31:49,120 --> 02:31:50,560
this entire thing end to end it'll be

3089
02:31:50,560 --> 02:31:52,160
more efficient than decoding a lot of

3090
02:31:52,160 --> 02:31:53,280
these intermediate states so you should

3091
02:31:53,280 --> 02:31:54,800
be able to run faster if you make the

3092
02:31:54,800 --> 02:31:56,640
entire thing uh into in your neural

3093
02:31:56,640 --> 02:31:58,160
networks we can avoid a lot of decoding

3094
02:31:58,160 --> 02:31:59,760
of the intermediate states and only

3095
02:31:59,760 --> 02:32:01,680
decode essential things required for

3096
02:32:01,680 --> 02:32:03,040
driving the car

3097
02:32:03,040 --> 02:32:05,359
yep certainly and to endness and as the

3098
02:32:05,359 --> 02:32:06,640
guiding principle behind a lot of the

3099
02:32:06,640 --> 02:32:08,240
network developments and over time in

3100
02:32:08,240 --> 02:32:10,000
the stack neural networks have taken on

3101
02:32:10,000 --> 02:32:13,040
more and more functionality and so

3102
02:32:13,040 --> 02:32:14,240
we want everything to be trained

3103
02:32:14,240 --> 02:32:15,359
end-to-end because we see that that

3104
02:32:15,359 --> 02:32:16,960
works best but we are building it

3105
02:32:16,960 --> 02:32:18,720
incrementally so right now the interface

3106
02:32:18,720 --> 02:32:20,240
there is vector space and we are

3107
02:32:20,240 --> 02:32:22,080
consuming it in the planner but nothing

3108
02:32:22,080 --> 02:32:23,920
really fundamentally prevents you from

3109
02:32:23,920 --> 02:32:25,520
actually taking features and eventually

3110
02:32:25,520 --> 02:32:27,680
fine-tuning end-to-end uh so i think

3111
02:32:27,680 --> 02:32:29,120
that's definitely where this is headed

3112
02:32:29,120 --> 02:32:30,640
yeah and the discovery really is like

3113
02:32:30,640 --> 02:32:32,399
what are the right architectures that we

3114
02:32:32,399 --> 02:32:34,479
need to place in network blocks to make

3115
02:32:34,479 --> 02:32:36,399
it amenable to the task so like on a

3116
02:32:36,399 --> 02:32:38,720
describe we can place spatial rnns to

3117
02:32:38,720 --> 02:32:41,040
help with the uh perception problem uh

3118
02:32:41,040 --> 02:32:42,240
and now it's just neutral network so

3119
02:32:42,240 --> 02:32:43,600
similarly for planning we need to bake

3120
02:32:43,600 --> 02:32:45,280
in search and optimization into the

3121
02:32:45,280 --> 02:32:46,800
planning into the network architecture

3122
02:32:46,800 --> 02:32:48,080
and once we do that you should be able

3123
02:32:48,080 --> 02:32:50,240
to do planning very quickly uh similar

3124
02:32:50,240 --> 02:32:53,800
to c plus plus algorithms

3125
02:32:58,240 --> 02:33:00,160
okay

3126
02:33:00,160 --> 02:33:01,600
okay

3127
02:33:01,600 --> 02:33:03,520
i think i had a question very similar to

3128
02:33:03,520 --> 02:33:05,359
what he was asking about

3129
02:33:05,359 --> 02:33:07,120
it seems like a lot of neural nets

3130
02:33:07,120 --> 02:33:08,880
around computer vision

3131
02:33:08,880 --> 02:33:10,560
and kind of traditional planning you had

3132
02:33:10,560 --> 02:33:12,240
model predictive control in solving

3133
02:33:12,240 --> 02:33:13,840
convex optimization problems very

3134
02:33:13,840 --> 02:33:14,960
quickly

3135
02:33:14,960 --> 02:33:16,160
and

3136
02:33:16,160 --> 02:33:17,359
i'd wonder if there's a compute

3137
02:33:17,359 --> 02:33:19,600
architecture that's more suited for

3138
02:33:19,600 --> 02:33:21,439
convex optimization or the model

3139
02:33:21,439 --> 02:33:23,760
predictive control uh solutions very

3140
02:33:23,760 --> 02:33:24,880
quickly

3141
02:33:24,880 --> 02:33:26,479
yeah 100 if you want to bake in like i

3142
02:33:26,479 --> 02:33:27,520
said earlier if you want to bake in

3143
02:33:27,520 --> 02:33:28,880
these architectures that do say model

3144
02:33:28,880 --> 02:33:30,399
protein control but just like replace

3145
02:33:30,399 --> 02:33:32,800
some of the blocks with neural networks

3146
02:33:32,800 --> 02:33:34,479
or if we know the physics of it we can

3147
02:33:34,479 --> 02:33:36,160
also use physics-based models part of

3148
02:33:36,160 --> 02:33:37,920
the neural network's forward pass itself

3149
02:33:37,920 --> 02:33:40,160
so we are going to go towards a hybrid

3150
02:33:40,160 --> 02:33:41,359
system where

3151
02:33:41,359 --> 02:33:44,640
we will have neural network blocks

3152
02:33:45,600 --> 02:33:47,680
placed together with a physics-based

3153
02:33:47,680 --> 02:33:49,760
blocks and more networks later so it'll

3154
02:33:49,760 --> 02:33:51,920
be a hybrid stack and what we know to do

3155
02:33:51,920 --> 02:33:53,359
well we place with explicitly and what

3156
02:33:53,359 --> 02:33:54,479
the networks are created we'll use the

3157
02:33:54,479 --> 02:33:56,800
networks to optimize this uh so better

3158
02:33:56,800 --> 02:33:58,319
end-to-end stack with this architecture

3159
02:33:58,319 --> 02:34:00,399
baked in

3160
02:34:00,399 --> 02:34:02,399
i i mean i do think that

3161
02:34:02,399 --> 02:34:05,680
so as long as you've got like um

3162
02:34:05,680 --> 02:34:07,280
surround video

3163
02:34:07,280 --> 02:34:08,160
uh

3164
02:34:08,160 --> 02:34:09,439
neural nets for understanding what's

3165
02:34:09,439 --> 02:34:12,080
going on and can uh

3166
02:34:12,080 --> 02:34:14,160
convert

3167
02:34:14,160 --> 02:34:16,640
those surround video into vector space

3168
02:34:16,640 --> 02:34:18,720
then you basically have a video game

3169
02:34:18,720 --> 02:34:20,319
um and if

3170
02:34:20,319 --> 02:34:21,760
you know if you

3171
02:34:21,760 --> 02:34:23,200
it's like if you're in grand theft auto

3172
02:34:23,200 --> 02:34:24,319
whatever you can you can make the cars

3173
02:34:24,319 --> 02:34:26,000
drive around and pedestrians walk around

3174
02:34:26,000 --> 02:34:27,840
without crashing so

3175
02:34:27,840 --> 02:34:31,200
um you can do you don't have to have a

3176
02:34:31,200 --> 02:34:34,399
neural net for control and planning um

3177
02:34:34,399 --> 02:34:36,479
but it's probably

3178
02:34:36,479 --> 02:34:38,560
ultimately better um

3179
02:34:38,560 --> 02:34:39,359
so

3180
02:34:39,359 --> 02:34:41,280
but i think you can probably get to

3181
02:34:41,280 --> 02:34:42,880
in fact i'm sure you can get to much

3182
02:34:42,880 --> 02:34:45,040
safer than human with control and

3183
02:34:45,040 --> 02:34:46,560
planning

3184
02:34:46,560 --> 02:34:49,120
primarily in c plus plus with

3185
02:34:49,120 --> 02:34:51,680
perception vision in

3186
02:34:51,680 --> 02:34:54,160
neural nets

3187
02:34:56,319 --> 02:34:57,760
hi

3188
02:34:57,760 --> 02:34:59,760
my question is we've seen other

3189
02:34:59,760 --> 02:35:02,160
companies for example use reinforcement

3190
02:35:02,160 --> 02:35:03,359
learning and machine learning to

3191
02:35:03,359 --> 02:35:04,560
optimize

3192
02:35:04,560 --> 02:35:06,080
power consumption and data centers and

3193
02:35:06,080 --> 02:35:07,680
all kinds of other internal processes my

3194
02:35:07,680 --> 02:35:10,720
question is are is tesla using machine

3195
02:35:10,720 --> 02:35:13,359
learning within its manufacturing design

3196
02:35:13,359 --> 02:35:16,800
or other engineering processes

3197
02:35:19,439 --> 02:35:21,600
i

3198
02:35:22,319 --> 02:35:26,160
i discourage use of machine learning

3199
02:35:26,160 --> 02:35:27,920
because it's really difficult

3200
02:35:27,920 --> 02:35:30,000
unless you basically unless you

3201
02:35:30,000 --> 02:35:33,680
have to use machine learning don't do it

3202
02:35:34,399 --> 02:35:35,920
it's usually a red flag when somebody

3203
02:35:35,920 --> 02:35:37,520
says we want to use machine learning to

3204
02:35:37,520 --> 02:35:39,280
solve this test i'm like that sounds

3205
02:35:39,280 --> 02:35:41,359
like um

3206
02:35:41,359 --> 02:35:42,479
so

3207
02:35:42,479 --> 02:35:43,439
uh

3208
02:35:43,439 --> 02:35:46,080
99.9 percent of time you do not need it

3209
02:35:46,080 --> 02:35:47,359
um

3210
02:35:47,359 --> 02:35:49,200
so

3211
02:35:49,200 --> 02:35:50,160
yeah

3212
02:35:50,160 --> 02:35:53,280
but so it's kind of like a

3213
02:35:53,280 --> 02:35:55,200
you you reach for machine learning when

3214
02:35:55,200 --> 02:35:56,319
you when you

3215
02:35:56,319 --> 02:35:58,880
need to not but it's i've not found it

3216
02:35:58,880 --> 02:36:01,280
to be a convenient easy thing to do

3217
02:36:01,280 --> 02:36:03,520
um it's a super hard thing to do

3218
02:36:03,520 --> 02:36:04,960
that may change if you've got a humanoid

3219
02:36:04,960 --> 02:36:06,800
robot that can

3220
02:36:06,800 --> 02:36:08,880
you know understand

3221
02:36:08,880 --> 02:36:10,240
normal instructions

3222
02:36:10,240 --> 02:36:11,600
um

3223
02:36:11,600 --> 02:36:12,880
but

3224
02:36:12,880 --> 02:36:13,680
yeah

3225
02:36:13,680 --> 02:36:15,280
generally minimize use of machine

3226
02:36:15,280 --> 02:36:16,560
learning in the

3227
02:36:16,560 --> 02:36:19,040
factory

3228
02:36:20,880 --> 02:36:23,359
hi um based on your videos from the

3229
02:36:23,359 --> 02:36:25,280
simulator uh it looked like a

3230
02:36:25,280 --> 02:36:27,280
combination of graphical and neural

3231
02:36:27,280 --> 02:36:29,439
approaches i'm curious what the set of

3232
02:36:29,439 --> 02:36:31,520
underlying techniques uh that are used

3233
02:36:31,520 --> 02:36:34,319
for your simulator and specifically for

3234
02:36:34,319 --> 02:36:37,840
neural rendering if you can share

3235
02:36:38,640 --> 02:36:41,280
yeah so we're doing uh

3236
02:36:41,280 --> 02:36:42,800
at the bottom of the stack it's just

3237
02:36:42,800 --> 02:36:44,720
traditional game techniques

3238
02:36:44,720 --> 02:36:47,200
uh just rasterization real time

3239
02:36:47,200 --> 02:36:49,120
uh you know very similar to what you'd

3240
02:36:49,120 --> 02:36:51,359
seen like gta

3241
02:36:51,359 --> 02:36:53,040
on top of that we're doing real-time ray

3242
02:36:53,040 --> 02:36:56,160
tracing and then those results were

3243
02:36:56,160 --> 02:36:58,479
really hot off the press um i mean we

3244
02:36:58,479 --> 02:36:59,920
had that little asterisk at the bottom

3245
02:36:59,920 --> 02:37:01,600
that that was from last night

3246
02:37:01,600 --> 02:37:02,960
we're going into the neural rendering

3247
02:37:02,960 --> 02:37:04,160
space we're trying out a bunch of

3248
02:37:04,160 --> 02:37:05,359
different things

3249
02:37:05,359 --> 02:37:06,479
we want to get to the point where the

3250
02:37:06,479 --> 02:37:08,640
neural rendering is the

3251
02:37:08,640 --> 02:37:10,160
the cherry on the top that pushes it to

3252
02:37:10,160 --> 02:37:11,840
the point where the models will never be

3253
02:37:11,840 --> 02:37:15,280
able to overfit on our simulator

3254
02:37:15,280 --> 02:37:17,600
currently we're doing things similar to

3255
02:37:17,600 --> 02:37:19,280
photorealism enhancement

3256
02:37:19,280 --> 02:37:20,880
there's a paper a recent paper photo

3257
02:37:20,880 --> 02:37:23,120
enhancing photo realism enhancement

3258
02:37:23,120 --> 02:37:24,960
but we can do a lot more than what they

3259
02:37:24,960 --> 02:37:26,640
could do in that paper because we have

3260
02:37:26,640 --> 02:37:29,600
way more labeled data way more compute

3261
02:37:29,600 --> 02:37:31,760
and also much we have a lot more control

3262
02:37:31,760 --> 02:37:33,439
over environments

3263
02:37:33,439 --> 02:37:34,640
and we also have a lot of people who can

3264
02:37:34,640 --> 02:37:36,560
help us make this run at real time

3265
02:37:36,560 --> 02:37:38,319
um but we're going to try whatever we

3266
02:37:38,319 --> 02:37:40,800
can do to get to the point where we can

3267
02:37:40,800 --> 02:37:43,600
train everything just with the simulator

3268
02:37:43,600 --> 02:37:45,840
uh if we had to but we will never have

3269
02:37:45,840 --> 02:37:47,439
to because we have so much real world

3270
02:37:47,439 --> 02:37:49,920
data that no one else has

3271
02:37:49,920 --> 02:37:51,760
it's just to fill in the little gaps in

3272
02:37:51,760 --> 02:37:53,120
the real world

3273
02:37:53,120 --> 02:37:54,240
yeah i mean

3274
02:37:54,240 --> 02:37:55,920
the simulator

3275
02:37:55,920 --> 02:37:58,240
is very helpful when there's like these

3276
02:37:58,240 --> 02:38:00,640
rare cases like like um

3277
02:38:00,640 --> 02:38:01,760
you know like

3278
02:38:01,760 --> 02:38:03,439
collision avoidance right before an

3279
02:38:03,439 --> 02:38:04,399
accident

3280
02:38:04,399 --> 02:38:05,680
um and then

3281
02:38:05,680 --> 02:38:07,359
ironically that the better our cars

3282
02:38:07,359 --> 02:38:09,040
become at avoiding accidents the fewer

3283
02:38:09,040 --> 02:38:10,720
accidents there are so then our training

3284
02:38:10,720 --> 02:38:12,319
set is small so then we have to make

3285
02:38:12,319 --> 02:38:14,800
them crash in the simulation

3286
02:38:14,800 --> 02:38:17,760
so it's like okay minimize potential

3287
02:38:17,760 --> 02:38:19,040
injury to

3288
02:38:19,040 --> 02:38:22,640
uh pedestrians and people in the car

3289
02:38:22,640 --> 02:38:26,160
you have five meters you're traveling at

3290
02:38:26,160 --> 02:38:29,200
you know 20 meters per second um

3291
02:38:29,200 --> 02:38:32,000
take what actions would minimize

3292
02:38:32,000 --> 02:38:34,640
probability of injury

3293
02:38:34,640 --> 02:38:38,439
we can run that in some

3294
02:38:42,080 --> 02:38:43,359
cars driving down the wrong side of the

3295
02:38:43,359 --> 02:38:45,439
highway that kind of thing

3296
02:38:45,439 --> 02:38:48,800
happens occasionally but not that often

3297
02:38:48,800 --> 02:38:50,960
um for your humanoid contacts i'm

3298
02:38:50,960 --> 02:38:52,720
wondering if you've decided on what use

3299
02:38:52,720 --> 02:38:54,560
cases you're gonna start with and what

3300
02:38:54,560 --> 02:38:56,319
the grand challenges

3301
02:38:56,319 --> 02:38:57,359
um

3302
02:38:57,359 --> 02:39:01,359
are in that context to make this viable

3303
02:39:01,359 --> 02:39:03,439
well i think for the humanoid for the

3304
02:39:03,439 --> 02:39:06,000
tesla bot um

3305
02:39:06,000 --> 02:39:07,680
optimus

3306
02:39:07,680 --> 02:39:10,080
it's basically going to start with

3307
02:39:10,080 --> 02:39:11,920
just dealing with

3308
02:39:11,920 --> 02:39:13,760
work that is

3309
02:39:13,760 --> 02:39:17,040
boring repetitive and dangerous

3310
02:39:17,040 --> 02:39:18,240
basically what is the work that people

3311
02:39:18,240 --> 02:39:22,040
would least like to do

3312
02:39:27,920 --> 02:39:28,720
um

3313
02:39:28,720 --> 02:39:31,600
hi um so quick question about

3314
02:39:31,600 --> 02:39:34,160
your simulations um obviously they're

3315
02:39:34,160 --> 02:39:36,560
not perfect right now so are you using

3316
02:39:36,560 --> 02:39:38,640
any sort of domain adaptation techniques

3317
02:39:38,640 --> 02:39:40,960
to basically bridge the gap between your

3318
02:39:40,960 --> 02:39:42,640
simulated data and your actual

3319
02:39:42,640 --> 02:39:44,880
real-world data because i imagine it's

3320
02:39:44,880 --> 02:39:46,479
kind of dangerous to

3321
02:39:46,479 --> 02:39:48,319
just deploy models which are solely

3322
02:39:48,319 --> 02:39:50,640
trained on simulated data so maybe some

3323
02:39:50,640 --> 02:39:52,720
sort of explicit domain adaptation or

3324
02:39:52,720 --> 02:39:54,640
something is that going on anywhere in

3325
02:39:54,640 --> 02:39:56,399
your pipeline

3326
02:39:56,399 --> 02:39:59,359
so currently uh i mean we're producing

3327
02:39:59,359 --> 02:40:01,200
the videos straight out of the simulator

3328
02:40:01,200 --> 02:40:03,040
uh the the full clips of kinematics and

3329
02:40:03,040 --> 02:40:04,880
everything and then we're just

3330
02:40:04,880 --> 02:40:06,319
immediately training on them but it's

3331
02:40:06,319 --> 02:40:08,080
not the entire data set it's just a

3332
02:40:08,080 --> 02:40:10,160
small targeted segment and we only are

3333
02:40:10,160 --> 02:40:13,120
evaluating based on real world video um

3334
02:40:13,120 --> 02:40:14,560
we're paying a lot of attention to make

3335
02:40:14,560 --> 02:40:16,720
sure we don't ever fit uh and if we have

3336
02:40:16,720 --> 02:40:18,399
to start doing fancier things we will

3337
02:40:18,399 --> 02:40:21,040
but currently it's we're not having an

3338
02:40:21,040 --> 02:40:22,080
issue with it overfitting on the

3339
02:40:22,080 --> 02:40:23,920
simulator we will as we scale up the

3340
02:40:23,920 --> 02:40:25,920
data um and that's what we're hoping to

3341
02:40:25,920 --> 02:40:28,000
use neural rendering to bridge that gap

3342
02:40:28,000 --> 02:40:29,920
to push that even further out um we've

3343
02:40:29,920 --> 02:40:31,359
already done things where we're using

3344
02:40:31,359 --> 02:40:33,439
like the same networks in the car but

3345
02:40:33,439 --> 02:40:35,359
retrain it to detect sim versus rail to

3346
02:40:35,359 --> 02:40:36,960
drive our art decisions

3347
02:40:36,960 --> 02:40:39,520
um and that's actually helped um prevent

3348
02:40:39,520 --> 02:40:42,479
some of these things as well

3349
02:40:42,640 --> 02:40:43,760
yeah just to emphasize that

3350
02:40:43,760 --> 02:40:46,399
overwhelmingly the data set is the real

3351
02:40:46,399 --> 02:40:48,399
video from the cars on the actual roads

3352
02:40:48,399 --> 02:40:50,800
uh nothing's weirder or uh or has more

3353
02:40:50,800 --> 02:40:52,640
corner cases than reality

3354
02:40:52,640 --> 02:40:56,479
um it's gets really strange out there

3355
02:40:56,479 --> 02:40:59,279
but but then if if we find say a few

3356
02:40:59,279 --> 02:41:02,960
examples of something very odd

3357
02:41:02,960 --> 02:41:04,319
and there's some very some for some very

3358
02:41:04,319 --> 02:41:06,560
odd pictures we've seen

3359
02:41:06,560 --> 02:41:09,279
then in order to train it effectively we

3360
02:41:09,279 --> 02:41:10,399
want to

3361
02:41:10,399 --> 02:41:12,000
create simulations

3362
02:41:12,000 --> 02:41:14,640
uh say a thousand simulations that are

3363
02:41:14,640 --> 02:41:16,560
that are variants of that

3364
02:41:16,560 --> 02:41:18,240
quirky thing that we saw

3365
02:41:18,240 --> 02:41:20,319
the foot to fill in the some important

3366
02:41:20,319 --> 02:41:22,960
gaps and and make the system better and

3367
02:41:22,960 --> 02:41:24,880
really all of this is about over time

3368
02:41:24,880 --> 02:41:26,000
just

3369
02:41:26,000 --> 02:41:28,560
reducing the probability of of a crash

3370
02:41:28,560 --> 02:41:31,279
or an injury and

3371
02:41:31,279 --> 02:41:33,120
it's called the march of nines like how

3372
02:41:33,120 --> 02:41:36,439
do you get to 99.999999

3373
02:41:36,880 --> 02:41:40,319
uh safe you know and

3374
02:41:40,319 --> 02:41:41,520
it yeah

3375
02:41:41,520 --> 02:41:43,359
each nine is an order of magnitude

3376
02:41:43,359 --> 02:41:46,479
difficulty increase

3377
02:41:47,840 --> 02:41:50,160
uh thanks so much for the presentation i

3378
02:41:50,160 --> 02:41:51,520
was curious about

3379
02:41:51,520 --> 02:41:53,680
the tesla bot um

3380
02:41:53,680 --> 02:41:55,279
specifically i'm wondering

3381
02:41:55,279 --> 02:41:57,040
if there are any specific applications

3382
02:41:57,040 --> 02:41:59,279
that you think the humanoid form factor

3383
02:41:59,279 --> 02:42:00,880
lends itself to

3384
02:42:00,880 --> 02:42:02,800
and then secondary

3385
02:42:02,800 --> 02:42:04,479
um

3386
02:42:04,479 --> 02:42:06,640
because of its human form factor is

3387
02:42:06,640 --> 02:42:08,960
emotion or companionship at all thought

3388
02:42:08,960 --> 02:42:09,920
about

3389
02:42:09,920 --> 02:42:13,840
on the product roadmap at all

3390
02:42:17,279 --> 02:42:18,160
um

3391
02:42:18,160 --> 02:42:20,160
well we certainly hope this does not

3392
02:42:20,160 --> 02:42:22,399
feature in a dystopian

3393
02:42:22,399 --> 02:42:25,960
sci-fi movie

3394
02:42:26,640 --> 02:42:29,520
but uh you know like

3395
02:42:29,520 --> 02:42:31,279
really at this point

3396
02:42:31,279 --> 02:42:33,439
we're saying like maybe this robot can

3397
02:42:33,439 --> 02:42:34,720
just we're trying we're trying to be as

3398
02:42:34,720 --> 02:42:37,600
literal as possible can it do um boring

3399
02:42:37,600 --> 02:42:39,920
dangerous repetitive

3400
02:42:39,920 --> 02:42:41,760
jobs that people don't want to do

3401
02:42:41,760 --> 02:42:43,200
and

3402
02:42:43,200 --> 02:42:44,880
uh

3403
02:42:44,880 --> 02:42:46,640
you know once you can have it do that

3404
02:42:46,640 --> 02:42:48,240
then maybe you can do other things too

3405
02:42:48,240 --> 02:42:49,120
but

3406
02:42:49,120 --> 02:42:51,200
that's the that's the thing that we

3407
02:42:51,200 --> 02:42:53,439
really great to have

3408
02:42:53,439 --> 02:42:55,040
so

3409
02:42:55,040 --> 02:42:56,880
it could be your buddy too i mean buy

3410
02:42:56,880 --> 02:42:58,880
one and have it be or your friend and

3411
02:42:58,880 --> 02:43:01,200
whatever

3412
02:43:02,160 --> 02:43:03,920
i'm sure that people think of some very

3413
02:43:03,920 --> 02:43:07,240
creative uses

3414
02:43:08,560 --> 02:43:09,600
so

3415
02:43:09,600 --> 02:43:12,240
uh so

3416
02:43:12,960 --> 02:43:15,439
um so firstly thanks for the the really

3417
02:43:15,439 --> 02:43:17,840
incredible presentation um my question

3418
02:43:17,840 --> 02:43:20,240
is on the ai side um so one thing we've

3419
02:43:20,240 --> 02:43:22,000
been seeing is that with some of these

3420
02:43:22,000 --> 02:43:23,920
language modeling ais we've seen that

3421
02:43:23,920 --> 02:43:27,040
scaling has just had incredible impacts

3422
02:43:27,040 --> 02:43:28,479
in their capabilities and what they're

3423
02:43:28,479 --> 02:43:29,600
able to do

3424
02:43:29,600 --> 02:43:30,960
so i was wondering whether you're seeing

3425
02:43:30,960 --> 02:43:33,439
similar kinds of effects of scaling in

3426
02:43:33,439 --> 02:43:34,479
in your

3427
02:43:34,479 --> 02:43:37,680
neural networks in your applications

3428
02:43:37,680 --> 02:43:39,600
absolutely a bigger network typically we

3429
02:43:39,600 --> 02:43:41,279
see it performs better provided you have

3430
02:43:41,279 --> 02:43:43,520
the data to also train it with and this

3431
02:43:43,520 --> 02:43:45,680
is also what we see for ourselves

3432
02:43:45,680 --> 02:43:46,800
definitely in the car we have some

3433
02:43:46,800 --> 02:43:49,200
latency consideration to be mindful of

3434
02:43:49,200 --> 02:43:50,560
and so there we have to get creative to

3435
02:43:50,560 --> 02:43:51,920
actually deploy much much larger

3436
02:43:51,920 --> 02:43:54,240
networks but as we mentioned we don't

3437
02:43:54,240 --> 02:43:56,000
only train neural networks for what goes

3438
02:43:56,000 --> 02:43:58,080
in the car we have these um

3439
02:43:58,080 --> 02:43:59,760
auto labeling pipelines that can utilize

3440
02:43:59,760 --> 02:44:01,600
models of arbitrary size so in fact

3441
02:44:01,600 --> 02:44:03,040
we've traded a number of models that are

3442
02:44:03,040 --> 02:44:04,640
not deployable that are significantly

3443
02:44:04,640 --> 02:44:06,160
larger and work much better because we

3444
02:44:06,160 --> 02:44:07,760
want 100 like we want much higher

3445
02:44:07,760 --> 02:44:10,240
accuracy for the auto labeling and so

3446
02:44:10,240 --> 02:44:11,680
we've done a lot of that and there we

3447
02:44:11,680 --> 02:44:14,080
definitely see this trend

3448
02:44:14,080 --> 02:44:16,640
yeah the order labeling is uh

3449
02:44:16,640 --> 02:44:18,560
an extremely important important part of

3450
02:44:18,560 --> 02:44:21,359
this whole whole situation

3451
02:44:21,359 --> 02:44:23,359
without the order labeling i think we

3452
02:44:23,359 --> 02:44:24,720
would not be able to solve the

3453
02:44:24,720 --> 02:44:26,560
self-driving problem it's kind of a

3454
02:44:26,560 --> 02:44:28,000
funny form of distillation where you're

3455
02:44:28,000 --> 02:44:30,000
using these very massive models plus the

3456
02:44:30,000 --> 02:44:31,920
structure of the problem to do this

3457
02:44:31,920 --> 02:44:33,920
reconstruction and then you distill that

3458
02:44:33,920 --> 02:44:35,439
into neural networks that you deploy to

3459
02:44:35,439 --> 02:44:37,200
the car but we basically have a lot of

3460
02:44:37,200 --> 02:44:38,720
neural networks and a lot of tasks that

3461
02:44:38,720 --> 02:44:41,439
are never intended to go into the car

3462
02:44:41,439 --> 02:44:43,680
yeah and also as time goes on that you

3463
02:44:43,680 --> 02:44:45,359
get new frames of information so you

3464
02:44:45,359 --> 02:44:46,640
really want to make sure your computer

3465
02:44:46,640 --> 02:44:48,080
is distributed across all the

3466
02:44:48,080 --> 02:44:49,600
information as opposed to just taking a

3467
02:44:49,600 --> 02:44:51,680
single frame and hogging on it for say

3468
02:44:51,680 --> 02:44:53,600
200 milliseconds you actually have newer

3469
02:44:53,600 --> 02:44:55,040
frames coming in so you want to like use

3470
02:44:55,040 --> 02:44:56,800
all of the information and not just use

3471
02:44:56,800 --> 02:44:59,120
that one frame

3472
02:44:59,120 --> 02:45:00,640
i think

3473
02:45:00,640 --> 02:45:01,600
one of the things we're seeing is that

3474
02:45:01,600 --> 02:45:04,720
the car's predictive ability is um is

3475
02:45:04,720 --> 02:45:06,479
quite is eerily good

3476
02:45:06,479 --> 02:45:07,520
um

3477
02:45:07,520 --> 02:45:09,439
it's really getting better than human in

3478
02:45:09,439 --> 02:45:11,840
terms of predicting like you say like

3479
02:45:11,840 --> 02:45:12,880
what

3480
02:45:12,880 --> 02:45:15,760
predict what this road will look like

3481
02:45:15,760 --> 02:45:17,200
out when it's out of sight like it's

3482
02:45:17,200 --> 02:45:19,600
around the bend and it predicts the road

3483
02:45:19,600 --> 02:45:22,080
with very high accuracy

3484
02:45:22,080 --> 02:45:23,120
and

3485
02:45:23,120 --> 02:45:24,080
you know

3486
02:45:24,080 --> 02:45:26,319
predict pedestrians or cyclists wherever

3487
02:45:26,319 --> 02:45:28,080
behind you know where to just see a

3488
02:45:28,080 --> 02:45:30,560
little corner of the bicycle and

3489
02:45:30,560 --> 02:45:31,760
a little bit through through the windows

3490
02:45:31,760 --> 02:45:34,399
of the bus and its ability to predict

3491
02:45:34,399 --> 02:45:36,560
things is going to be much better than

3492
02:45:36,560 --> 02:45:39,600
humans like really way way beyond right

3493
02:45:39,600 --> 02:45:41,200
yeah we see this often where we have

3494
02:45:41,200 --> 02:45:42,399
something that is not visible but the

3495
02:45:42,399 --> 02:45:44,080
neural network is making up stuff that

3496
02:45:44,080 --> 02:45:46,000
actually is very sensible sometimes it's

3497
02:45:46,000 --> 02:45:47,920
eerily good and you have to like you're

3498
02:45:47,920 --> 02:45:49,680
wondering this is in the training set

3499
02:45:49,680 --> 02:45:50,800
and actually

3500
02:45:50,800 --> 02:45:52,399
actually in the limit you can imagine

3501
02:45:52,399 --> 02:45:54,000
the neural net has enough parameters to

3502
02:45:54,000 --> 02:45:56,399
potentially remember earth so

3503
02:45:56,399 --> 02:45:57,680
in the limit it could actually give you

3504
02:45:57,680 --> 02:45:58,720
the correct answer and it's kind of like

3505
02:45:58,720 --> 02:46:00,800
an hd map back baked into the weights of

3506
02:46:00,800 --> 02:46:03,439
the neural net

3507
02:46:08,960 --> 02:46:11,120
i have a question about the design of

3508
02:46:11,120 --> 02:46:14,399
the tesla bot specifically in order uh

3509
02:46:14,399 --> 02:46:16,240
how important is it to maintain that

3510
02:46:16,240 --> 02:46:18,080
humanoid form

3511
02:46:18,080 --> 02:46:20,800
to build hands with five fingers

3512
02:46:20,800 --> 02:46:23,279
uh that also respects the weight limits

3513
02:46:23,279 --> 02:46:24,640
could be quite challenging you might

3514
02:46:24,640 --> 02:46:26,399
have to use cable driven and then that

3515
02:46:26,399 --> 02:46:29,920
also causes all kinds of issues

3516
02:46:30,880 --> 02:46:32,720
um i mean this is just going to be

3517
02:46:32,720 --> 02:46:35,120
bought version one and we'll see

3518
02:46:35,120 --> 02:46:36,800
so

3519
02:46:36,800 --> 02:46:37,520
the

3520
02:46:37,520 --> 02:46:38,399
it's

3521
02:46:38,399 --> 02:46:40,240
it needs to be able to do things that

3522
02:46:40,240 --> 02:46:43,120
that people do um and uh

3523
02:46:43,120 --> 02:46:44,960
you know be a generalized you know

3524
02:46:44,960 --> 02:46:46,560
humanoid robot

3525
02:46:46,560 --> 02:46:48,800
um

3526
02:46:49,680 --> 02:46:50,880
i mean you could make you potentially

3527
02:46:50,880 --> 02:46:53,520
have it give it like you know

3528
02:46:53,520 --> 02:46:54,800
two fingers and a thumb or something

3529
02:46:54,800 --> 02:46:55,760
like that

3530
02:46:55,760 --> 02:46:56,880
um

3531
02:46:56,880 --> 02:46:58,319
you know for now we'll we'll give it

3532
02:46:58,319 --> 02:47:00,080
five fingers and and see

3533
02:47:00,080 --> 02:47:01,760
see if that works out okay

3534
02:47:01,760 --> 02:47:03,279
it probably will it doesn't need to be

3535
02:47:03,279 --> 02:47:05,600
like uh you know have like

3536
02:47:05,600 --> 02:47:07,760
incredible grip strength

3537
02:47:07,760 --> 02:47:09,680
but it needs to be able to work with

3538
02:47:09,680 --> 02:47:11,120
tools

3539
02:47:11,120 --> 02:47:12,800
so and you know carry a bag that kind of

3540
02:47:12,800 --> 02:47:14,960
thing

3541
02:47:15,680 --> 02:47:16,640
all right thanks a lot for the

3542
02:47:16,640 --> 02:47:18,960
presentation

3543
02:47:18,960 --> 02:47:21,200
so an old professor of mine told me that

3544
02:47:21,200 --> 02:47:22,960
um the thing he disliked a lot about his

3545
02:47:22,960 --> 02:47:25,120
tesla was that the autopilot ux didn't

3546
02:47:25,120 --> 02:47:26,720
really inspire much confidence in the

3547
02:47:26,720 --> 02:47:28,479
system especially when like objects are

3548
02:47:28,479 --> 02:47:31,120
spinning classifications are flickering

3549
02:47:31,120 --> 02:47:34,000
i was wondering like even if you have a

3550
02:47:34,000 --> 02:47:35,920
good self-driving system how are you

3551
02:47:35,920 --> 02:47:38,960
working on convincing tesla owners other

3552
02:47:38,960 --> 02:47:41,600
road users or other road users and just

3553
02:47:41,600 --> 02:47:43,200
the general public that your system is

3554
02:47:43,200 --> 02:47:45,520
safe and reliable

3555
02:47:45,520 --> 02:47:47,359
well i think that's that's

3556
02:47:47,359 --> 02:47:48,880
the cars

3557
02:47:48,880 --> 02:47:50,240
a while back cars used to spend they

3558
02:47:50,240 --> 02:47:52,479
don't they don't spin anymore not in the

3559
02:47:52,479 --> 02:47:54,160
if you've seen the fsd

3560
02:47:54,160 --> 02:47:56,000
beta videos they

3561
02:47:56,000 --> 02:47:58,399
they're they're pretty solid um

3562
02:47:58,399 --> 02:48:00,479
and they will be getting more solid yeah

3563
02:48:00,479 --> 02:48:02,160
as him add more and more data and train

3564
02:48:02,160 --> 02:48:03,600
these multi-camera networks like these

3565
02:48:03,600 --> 02:48:04,720
are pretty decent actually just like few

3566
02:48:04,720 --> 02:48:06,319
months old and it's really improving

3567
02:48:06,319 --> 02:48:08,479
it's not a done product uh and that

3568
02:48:08,479 --> 02:48:10,399
we've never minds we can clearly see how

3569
02:48:10,399 --> 02:48:11,760
this is just going to be like perfect

3570
02:48:11,760 --> 02:48:14,160
but perfect for space because why not uh

3571
02:48:14,160 --> 02:48:15,120
all the information is that in the

3572
02:48:15,120 --> 02:48:16,880
videos it should produce a given lots of

3573
02:48:16,880 --> 02:48:18,720
data and good architectures

3574
02:48:18,720 --> 02:48:19,840
um

3575
02:48:19,840 --> 02:48:21,200
and this is just an intermediate point

3576
02:48:21,200 --> 02:48:23,840
in the timeline

3577
02:48:23,920 --> 02:48:26,479
i mean it's clearly headed to way better

3578
02:48:26,479 --> 02:48:30,520
than human without question

3579
02:48:33,520 --> 02:48:34,960
my turn oh

3580
02:48:34,960 --> 02:48:37,359
hi here um i was wondering if you could

3581
02:48:37,359 --> 02:48:38,800
talk a little bit about the short to

3582
02:48:38,800 --> 02:48:42,160
medium-term economics of the bot i guess

3583
02:48:42,160 --> 02:48:43,840
i understand the long-term vision of

3584
02:48:43,840 --> 02:48:46,240
replacing physical labor

3585
02:48:46,240 --> 02:48:49,120
but i also think repetitive dangerous

3586
02:48:49,120 --> 02:48:51,520
and boring tasks tend to not be

3587
02:48:51,520 --> 02:48:53,920
so highly compensated and so i just

3588
02:48:53,920 --> 02:48:56,640
don't see how to reproduce uh

3589
02:48:56,640 --> 02:48:58,560
you know start with a supercar and then

3590
02:48:58,560 --> 02:49:00,399
break into like the lower end of the

3591
02:49:00,399 --> 02:49:02,479
market how do you do that for a robot

3592
02:49:02,479 --> 02:49:05,040
humanoid

3593
02:49:05,040 --> 02:49:09,160
well i guess you'll just have to see

3594
02:49:16,000 --> 02:49:17,439
hello hi

3595
02:49:17,439 --> 02:49:20,240
um i was curious to know how the car ai

3596
02:49:20,240 --> 02:49:21,760
prioritizes

3597
02:49:21,760 --> 02:49:24,640
occupant safety versus pedestrian safety

3598
02:49:24,640 --> 02:49:27,120
and what thought process goes into like

3599
02:49:27,120 --> 02:49:30,960
deciding how to make this into the ai

3600
02:49:32,800 --> 02:49:34,880
well i mean we

3601
02:49:34,880 --> 02:49:36,960
the the thing to appreciate

3602
02:49:36,960 --> 02:49:38,960
is that from the computer standpoint

3603
02:49:38,960 --> 02:49:41,279
everything is moving slowly

3604
02:49:41,279 --> 02:49:44,880
so uh think you know to a human uh

3605
02:49:44,880 --> 02:49:46,560
things are moving fast to the computer

3606
02:49:46,560 --> 02:49:48,960
they are not moving fast so i think this

3607
02:49:48,960 --> 02:49:50,960
is in reality somewhat of a false

3608
02:49:50,960 --> 02:49:52,560
dichotomy not that it will never happen

3609
02:49:52,560 --> 02:49:54,479
but it will be very rare

3610
02:49:54,479 --> 02:49:56,080
um

3611
02:49:56,080 --> 02:49:58,160
you know if you think it was like

3612
02:49:58,160 --> 02:50:00,160
you know going the other direction

3613
02:50:00,160 --> 02:50:02,080
like rendering

3614
02:50:02,080 --> 02:50:04,880
you know with full ray tracing uh

3615
02:50:04,880 --> 02:50:07,120
neural net enhanced graphics on

3616
02:50:07,120 --> 02:50:09,920
something like cyberpunk or in any you

3617
02:50:09,920 --> 02:50:11,840
know advanced video game

3618
02:50:11,840 --> 02:50:14,640
you know doing 60 frames a second

3619
02:50:14,640 --> 02:50:15,439
uh

3620
02:50:15,439 --> 02:50:17,120
perfectly rendered

3621
02:50:17,120 --> 02:50:18,640
like how long would it take a person to

3622
02:50:18,640 --> 02:50:20,960
even render one frame

3623
02:50:20,960 --> 02:50:24,080
and without any mistakes

3624
02:50:24,080 --> 02:50:26,240
can be done i mean it would take like a

3625
02:50:26,240 --> 02:50:27,120
month

3626
02:50:27,120 --> 02:50:28,640
just to

3627
02:50:28,640 --> 02:50:31,760
just render one one frame out of 60 in a

3628
02:50:31,760 --> 02:50:34,800
second in a video game

3629
02:50:35,520 --> 02:50:37,040
it's uh

3630
02:50:37,040 --> 02:50:40,800
computers are fast and humans are slow

3631
02:50:43,520 --> 02:50:45,520
i mean for example

3632
02:50:45,520 --> 02:50:48,560
uh on on the rocket side the you you

3633
02:50:48,560 --> 02:50:51,359
cannot steer the rocket to orbit

3634
02:50:51,359 --> 02:50:53,680
um we actually hooked up a joystick to

3635
02:50:53,680 --> 02:50:55,120
see if anyone could steal the rocket

3636
02:50:55,120 --> 02:50:56,479
orbit but

3637
02:50:56,479 --> 02:50:58,080
you need uh

3638
02:50:58,080 --> 02:51:00,080
to react at

3639
02:51:00,080 --> 02:51:01,279
roughly

3640
02:51:01,279 --> 02:51:05,279
six seven hertz uh people can't do it

3641
02:51:05,279 --> 02:51:08,000
not even now that's pretty low you know

3642
02:51:08,000 --> 02:51:09,359
we're talking more like

3643
02:51:09,359 --> 02:51:10,960
even for like

3644
02:51:10,960 --> 02:51:14,240
30 hertz type of thing

3645
02:51:15,359 --> 02:51:19,680
hi um with the over here uh with

3646
02:51:19,680 --> 02:51:21,040
hardware 3 there's been lots of

3647
02:51:21,040 --> 02:51:23,200
speculation that with larger nets it's

3648
02:51:23,200 --> 02:51:24,960
hitting the limits of what it can

3649
02:51:24,960 --> 02:51:25,920
provide

3650
02:51:25,920 --> 02:51:27,760
how much headroom has the extended

3651
02:51:27,760 --> 02:51:29,680
compute modes provided at what point

3652
02:51:29,680 --> 02:51:33,840
would hardware 4 be required if at all

3653
02:51:34,560 --> 02:51:37,840
well i'm confident that hardware 3 or

3654
02:51:37,840 --> 02:51:40,240
the full stop driving computer 1 will be

3655
02:51:40,240 --> 02:51:42,240
able to

3656
02:51:42,240 --> 02:51:44,000
achieve full self driving at a safety

3657
02:51:44,000 --> 02:51:46,319
level much greater than a human probably

3658
02:51:46,319 --> 02:51:47,439
i don't know

3659
02:51:47,439 --> 02:51:48,960
at least two or three hundred percent

3660
02:51:48,960 --> 02:51:51,680
better than a human um then obviously

3661
02:51:51,680 --> 02:51:53,920
there will be a future hardware for or

3662
02:51:53,920 --> 02:51:56,240
full self-driving computer too

3663
02:51:56,240 --> 02:51:57,880
which we'll probably introduce with the

3664
02:51:57,880 --> 02:52:00,880
cybertruck um so maybe in about a year

3665
02:52:00,880 --> 02:52:02,080
or so

3666
02:52:02,080 --> 02:52:03,120
uh

3667
02:52:03,120 --> 02:52:04,640
that is

3668
02:52:04,640 --> 02:52:05,920
probably well that'll be about four

3669
02:52:05,920 --> 02:52:08,880
times more capable roughly

3670
02:52:08,880 --> 02:52:09,760
um

3671
02:52:09,760 --> 02:52:12,880
but it's really just going to be

3672
02:52:12,880 --> 02:52:14,800
like can we take it from say for

3673
02:52:14,800 --> 02:52:17,120
argument's sake 300 safer than a person

3674
02:52:17,120 --> 02:52:19,760
to a thousand percent safer

3675
02:52:19,760 --> 02:52:20,560
um

3676
02:52:20,560 --> 02:52:21,680
you know just like there are people on

3677
02:52:21,680 --> 02:52:24,080
the road who with with varying driving

3678
02:52:24,080 --> 02:52:26,560
abilities but we still let people drive

3679
02:52:26,560 --> 02:52:27,840
it you don't have to be the world's best

3680
02:52:27,840 --> 02:52:30,560
driver to be on the road

3681
02:52:30,560 --> 02:52:33,439
so as we see

3682
02:52:33,439 --> 02:52:34,399
so

3683
02:52:34,399 --> 02:52:35,840
yeah

3684
02:52:35,840 --> 02:52:38,479
guess what's new

3685
02:52:39,520 --> 02:52:41,439
all

3686
02:52:41,439 --> 02:52:42,399
um right

3687
02:52:42,399 --> 02:52:44,160
are you worried at all since you don't

3688
02:52:44,160 --> 02:52:46,319
have any depth sensors on the car that

3689
02:52:46,319 --> 02:52:48,240
people might try like adversarial

3690
02:52:48,240 --> 02:52:49,680
attacks like

3691
02:52:49,680 --> 02:52:51,680
printed out photos or something to try

3692
02:52:51,680 --> 02:52:54,319
to trick the rgb

3693
02:52:54,319 --> 02:52:56,479
neural network

3694
02:52:56,479 --> 02:52:58,560
yeah like what pull some like wiley cody

3695
02:52:58,560 --> 02:52:59,520
stuff

3696
02:52:59,520 --> 02:53:01,680
you know like paint the tunnel on the on

3697
02:53:01,680 --> 02:53:04,080
the wall

3698
02:53:04,240 --> 02:53:06,720
it's like oops

3699
02:53:06,720 --> 02:53:08,000
um

3700
02:53:08,000 --> 02:53:10,640
we haven't really seen much of that um

3701
02:53:10,640 --> 02:53:12,960
i mean

3702
02:53:13,359 --> 02:53:16,240
for sure like like right now if you

3703
02:53:16,240 --> 02:53:18,399
pr most likely if you had like a

3704
02:53:18,399 --> 02:53:19,680
a t-shirt with a

3705
02:53:19,680 --> 02:53:21,120
t-shirt with like a stop sign on it

3706
02:53:21,120 --> 02:53:22,640
which i actually have a t-shirt with a

3707
02:53:22,640 --> 02:53:25,279
stop sign on it and and then you like

3708
02:53:25,279 --> 02:53:28,000
flash the car

3709
02:53:28,160 --> 02:53:31,200
it will it will stop

3710
02:53:31,279 --> 02:53:34,240
i i proved that

3711
02:53:34,399 --> 02:53:35,520
um but

3712
02:53:35,520 --> 02:53:37,359
we can obviously as we see these uh

3713
02:53:37,359 --> 02:53:40,000
adversarial attacks then we can we train

3714
02:53:40,000 --> 02:53:42,479
uh the cars to uh

3715
02:53:42,479 --> 02:53:44,479
you know notice that well it's actually

3716
02:53:44,479 --> 02:53:46,800
a person wearing a t-shirt the stop sign

3717
02:53:46,800 --> 02:53:48,000
on it so it's probably not a real stop

3718
02:53:48,000 --> 02:53:50,720
sign

3719
02:53:54,640 --> 02:53:57,120
hi uh my question is about um the

3720
02:53:57,120 --> 02:53:59,600
prediction and the planning i'm curious

3721
02:53:59,600 --> 02:54:02,560
how do you incorporate uncertainty into

3722
02:54:02,560 --> 02:54:05,359
your uh you know planning algorithms

3723
02:54:05,359 --> 02:54:08,000
do you just basically assume you know

3724
02:54:08,000 --> 02:54:10,160
you mentioned that you run the um

3725
02:54:10,160 --> 02:54:12,080
the autopilot for all the other cars on

3726
02:54:12,080 --> 02:54:13,920
the road do you assume that they're all

3727
02:54:13,920 --> 02:54:15,680
going to follow those rules or are you

3728
02:54:15,680 --> 02:54:17,680
accounting for the possibility that well

3729
02:54:17,680 --> 02:54:20,720
they might be bad drivers for example

3730
02:54:20,720 --> 02:54:22,640
yeah we do account for multi-modal

3731
02:54:22,640 --> 02:54:24,640
futures it's not that we just choose one

3732
02:54:24,640 --> 02:54:26,240
we account for this person can actually

3733
02:54:26,240 --> 02:54:28,479
do many things and

3734
02:54:28,479 --> 02:54:30,000
we use that actual

3735
02:54:30,000 --> 02:54:31,760
physics and kinematics to make sure that

3736
02:54:31,760 --> 02:54:33,439
they're not doing a thing that would

3737
02:54:33,439 --> 02:54:36,160
interfere with us before we act um so if

3738
02:54:36,160 --> 02:54:37,439
there's any uncertainty we are

3739
02:54:37,439 --> 02:54:39,120
conservative and then would yield to

3740
02:54:39,120 --> 02:54:40,640
them of course there's a limit to this

3741
02:54:40,640 --> 02:54:42,319
because if you're too conservative then

3742
02:54:42,319 --> 02:54:44,399
it's probably not practical so at some

3743
02:54:44,399 --> 02:54:45,920
point we have to assert

3744
02:54:45,920 --> 02:54:47,279
and we even then we make sure that the

3745
02:54:47,279 --> 02:54:48,479
other person can

3746
02:54:48,479 --> 02:54:50,000
yield to us and

3747
02:54:50,000 --> 02:54:52,800
act sensibly

3748
02:54:54,800 --> 02:54:56,080
i should say like

3749
02:54:56,080 --> 02:54:56,880
um

3750
02:54:56,880 --> 02:54:59,120
like before we introduce something into

3751
02:54:59,120 --> 02:55:02,960
the fleet we will run it in shadow mode

3752
02:55:02,960 --> 02:55:05,920
and so and we'll see what what would

3753
02:55:05,920 --> 02:55:08,560
this neural net for example have done in

3754
02:55:08,560 --> 02:55:10,399
this particular situation

3755
02:55:10,399 --> 02:55:11,760
um

3756
02:55:11,760 --> 02:55:13,760
because and then effectively the drivers

3757
02:55:13,760 --> 02:55:16,640
uh are training it training the net so

3758
02:55:16,640 --> 02:55:18,240
if the neural net would have

3759
02:55:18,240 --> 02:55:20,479
uh controlled and you know and say

3760
02:55:20,479 --> 02:55:22,479
veered right but the person actually

3761
02:55:22,479 --> 02:55:24,240
went left it's like oh there's a

3762
02:55:24,240 --> 02:55:27,920
difference why was there that difference

3763
02:55:27,920 --> 02:55:29,600
yeah and secondly

3764
02:55:29,600 --> 02:55:31,120
all the human drivers are essentially

3765
02:55:31,120 --> 02:55:34,080
training the neural net uh as to what is

3766
02:55:34,080 --> 02:55:36,479
the correct course of action

3767
02:55:36,479 --> 02:55:38,319
assuming it doesn't then end up in a

3768
02:55:38,319 --> 02:55:39,760
crash you know doesn't count in that

3769
02:55:39,760 --> 02:55:40,560
case

3770
02:55:40,560 --> 02:55:41,760
yeah and secondly we have various

3771
02:55:41,760 --> 02:55:44,080
estimates of uncertainty like flickr

3772
02:55:44,080 --> 02:55:46,640
and when we observe this we actually uh

3773
02:55:46,640 --> 02:55:48,160
say we are not able to see something we

3774
02:55:48,160 --> 02:55:50,399
actually slow down the car to be again

3775
02:55:50,399 --> 02:55:52,319
safe and get more information before

3776
02:55:52,319 --> 02:55:54,000
acting uh yeah we don't want to be

3777
02:55:54,000 --> 02:55:55,359
brazen and just go into something that

3778
02:55:55,359 --> 02:55:56,800
we don't know about we only go into

3779
02:55:56,800 --> 02:55:58,960
places where we know about

3780
02:55:58,960 --> 02:56:01,760
yeah but um yeah

3781
02:56:01,760 --> 02:56:03,279
it should be like

3782
02:56:03,279 --> 02:56:04,640
aspirationally that the car should be

3783
02:56:04,640 --> 02:56:06,640
the less it knows the sl you know the

3784
02:56:06,640 --> 02:56:08,240
slower it goes yeah

3785
02:56:08,240 --> 02:56:10,800
which is not true at some point but now

3786
02:56:10,800 --> 02:56:12,479
yeah yeah we've yeah

3787
02:56:12,479 --> 02:56:13,600
should we

3788
02:56:13,600 --> 02:56:17,279
speed proportionate to confidence

3789
02:56:22,640 --> 02:56:24,960
thanks for the presentation so i am

3790
02:56:24,960 --> 02:56:26,960
curious

3791
02:56:26,960 --> 02:56:29,200
appreciate the fact that the fsd is

3792
02:56:29,200 --> 02:56:31,600
improving but if you have the ability to

3793
02:56:31,600 --> 02:56:34,720
improve one component along the ai stack

3794
02:56:34,720 --> 02:56:36,640
to present it today whether it is

3795
02:56:36,640 --> 02:56:38,720
simulation data collections planning

3796
02:56:38,720 --> 02:56:41,120
control et cetera which one in your

3797
02:56:41,120 --> 02:56:42,399
opinion is going to have the biggest

3798
02:56:42,399 --> 02:56:44,720
impact for the performance of the full

3799
02:56:44,720 --> 02:56:46,160
self driving

3800
02:56:46,160 --> 02:56:48,479
system

3801
02:56:51,680 --> 02:56:53,200
it's really the area under the curve of

3802
02:56:53,200 --> 02:56:55,200
this like multiple points and if you

3803
02:56:55,200 --> 02:56:56,960
improve anything uh it should improve

3804
02:56:56,960 --> 02:56:59,040
the area

3805
02:56:59,040 --> 02:57:01,200
i mean in the short term it's arguably

3806
02:57:01,200 --> 02:57:04,000
we need all of the nets to be um

3807
02:57:04,000 --> 02:57:06,319
surround video uh and so we still have

3808
02:57:06,319 --> 02:57:08,399
some legacy this is a very short term

3809
02:57:08,399 --> 02:57:10,000
obviously we're fixing it fast but

3810
02:57:10,000 --> 02:57:11,040
there's

3811
02:57:11,040 --> 02:57:12,640
there's still some nets that are not

3812
02:57:12,640 --> 02:57:14,399
using surround video

3813
02:57:14,399 --> 02:57:16,640
um and i think ideally that all use

3814
02:57:16,640 --> 02:57:18,560
surround video

3815
02:57:18,560 --> 02:57:21,120
yeah very yeah i think a lot of puzzle

3816
02:57:21,120 --> 02:57:22,720
pieces are there for success we just

3817
02:57:22,720 --> 02:57:24,319
need more strong people to also just

3818
02:57:24,319 --> 02:57:25,600
help us

3819
02:57:25,600 --> 02:57:27,200
make it work yeah that is the actual box

3820
02:57:27,200 --> 02:57:28,720
so that is the actual bottleneck i would

3821
02:57:28,720 --> 02:57:30,000
say i'm really one of the reasons that

3822
02:57:30,000 --> 02:57:31,840
we are putting on this event exactly

3823
02:57:31,840 --> 02:57:34,240
what well said andre that um

3824
02:57:34,240 --> 02:57:35,520
there's just a tremendous amount of work

3825
02:57:35,520 --> 02:57:37,359
to do to make

3826
02:57:37,359 --> 02:57:40,399
make it work so that's why we need um

3827
02:57:40,399 --> 02:57:42,960
talented people to join in and

3828
02:57:42,960 --> 02:57:45,520
solve the problem

3829
02:57:49,520 --> 02:57:51,760
uh thank you for the great presentation

3830
02:57:51,760 --> 02:57:53,840
lots of my questions answered

3831
02:57:53,840 --> 02:57:55,760
but one thing is

3832
02:57:55,760 --> 02:57:57,279
uh when

3833
02:57:57,279 --> 02:57:59,359
imagine that now you have

3834
02:57:59,359 --> 02:58:02,479
a large amount of data even unnecessary

3835
02:58:02,479 --> 02:58:04,560
how do you consider that like there's a

3836
02:58:04,560 --> 02:58:07,600
forgetting problem in neural networks

3837
02:58:07,600 --> 02:58:09,840
like how are you considering those

3838
02:58:09,840 --> 02:58:12,080
aspects and also

3839
02:58:12,080 --> 02:58:14,240
another one are you considering online

3840
02:58:14,240 --> 02:58:16,479
learning or continuous learning

3841
02:58:16,479 --> 02:58:17,200
so

3842
02:58:17,200 --> 02:58:18,640
that maybe

3843
02:58:18,640 --> 02:58:21,520
each driver can have their version of

3844
02:58:21,520 --> 02:58:23,840
uh self-driving

3845
02:58:23,840 --> 02:58:25,840
software

3846
02:58:25,840 --> 02:58:27,040
i think i think i know the literature

3847
02:58:27,040 --> 02:58:28,240
that you're referring to that's not some

3848
02:58:28,240 --> 02:58:29,600
of the problems that we've seen and we

3849
02:58:29,600 --> 02:58:30,720
haven't done too much continuous

3850
02:58:30,720 --> 02:58:32,800
learning we train the system once we

3851
02:58:32,800 --> 02:58:34,560
find in a few times

3852
02:58:34,560 --> 02:58:36,160
that sort of goes into the car we need

3853
02:58:36,160 --> 02:58:37,680
something stable that we can evaluate

3854
02:58:37,680 --> 02:58:39,359
extensively and then we think that

3855
02:58:39,359 --> 02:58:41,279
that's good and that goes into cars so

3856
02:58:41,279 --> 02:58:43,200
we don't do too much learning on spot or

3857
02:58:43,200 --> 02:58:44,560
continuous learning and don't face the

3858
02:58:44,560 --> 02:58:47,120
forgetting problem uh but there will be

3859
02:58:47,120 --> 02:58:49,279
settings that you can say like if you do

3860
02:58:49,279 --> 02:58:50,800
do you want are you typically a

3861
02:58:50,800 --> 02:58:52,479
conservative driver or do you want to

3862
02:58:52,479 --> 02:58:54,319
drive fast or slow you know it's like

3863
02:58:54,319 --> 02:58:56,240
i'm late for my i'm late for the airport

3864
02:58:56,240 --> 02:58:58,240
uh could you go faster than you know

3865
02:58:58,240 --> 02:58:59,439
basically the kind of instructions you'd

3866
02:58:59,439 --> 02:59:01,040
give to your uber driver

3867
02:59:01,040 --> 02:59:02,800
it's like i'm late for the flight please

3868
02:59:02,800 --> 02:59:05,359
hurry um or take it easy or you know

3869
02:59:05,359 --> 02:59:08,319
whatever your style is

3870
02:59:12,560 --> 02:59:14,960
so let's take a few more questions here

3871
02:59:14,960 --> 02:59:17,520
so and then we'll call it a day all

3872
02:59:17,520 --> 02:59:19,600
right so as our models have become more

3873
02:59:19,600 --> 02:59:21,760
and more capable and i guess you're

3874
02:59:21,760 --> 02:59:23,359
deploying these models into the real

3875
02:59:23,359 --> 02:59:25,439
world um one thing i guess that's

3876
02:59:25,439 --> 02:59:28,240
possible is for ai to become more i

3877
02:59:28,240 --> 02:59:31,040
guess misaligned with what humans desire

3878
02:59:31,040 --> 02:59:32,479
so i guess is that something that you

3879
02:59:32,479 --> 02:59:33,600
guys are worried about as you guys

3880
02:59:33,600 --> 02:59:36,399
deploy more and more robots um or do you

3881
02:59:36,399 --> 02:59:38,080
guys like we'll solve that problem when

3882
02:59:38,080 --> 02:59:40,479
we get there

3883
02:59:40,560 --> 02:59:42,160
yeah i think that we should be worried

3884
02:59:42,160 --> 02:59:46,080
about ai um you know like

3885
02:59:46,080 --> 02:59:48,399
what we're trying to do here is i say

3886
02:59:48,399 --> 02:59:50,160
narrow ai uh

3887
02:59:50,160 --> 02:59:52,240
pretty narrow like just make the car

3888
02:59:52,240 --> 02:59:54,640
drive better than a human um

3889
02:59:54,640 --> 02:59:57,120
and then have the humanoid robot be able

3890
02:59:57,120 --> 03:00:00,479
to do basic stuff um

3891
03:00:00,479 --> 03:00:01,279
uh

3892
03:00:01,279 --> 03:00:03,439
you know so

3893
03:00:03,439 --> 03:00:05,680
um at the point at which you sort of

3894
03:00:05,680 --> 03:00:08,160
start get uh superhuman intelligence uh

3895
03:00:08,160 --> 03:00:10,560
yeah i don't know all bets are off

3896
03:00:10,560 --> 03:00:12,319
um

3897
03:00:12,319 --> 03:00:13,439
but

3898
03:00:13,439 --> 03:00:14,880
you know and that's that's that's you

3899
03:00:14,880 --> 03:00:16,160
know

3900
03:00:16,160 --> 03:00:18,000
that'll that'll probably happen but but

3901
03:00:18,000 --> 03:00:20,399
what we're trying to do here at tesla is

3902
03:00:20,399 --> 03:00:21,680
make useful

3903
03:00:21,680 --> 03:00:23,120
ai that

3904
03:00:23,120 --> 03:00:25,520
people love and and is

3905
03:00:25,520 --> 03:00:28,240
unequivocally good that's our

3906
03:00:28,240 --> 03:00:31,359
you know try to aim for that

3907
03:00:31,359 --> 03:00:34,800
okay maybe one more question

3908
03:00:35,760 --> 03:00:37,760
hi uh my question is about the camera

3909
03:00:37,760 --> 03:00:39,439
sensor in the beginning of the talk you

3910
03:00:39,439 --> 03:00:41,279
had mentioned about building a synthetic

3911
03:00:41,279 --> 03:00:42,240
animal

3912
03:00:42,240 --> 03:00:44,479
and if you think about it

3913
03:00:44,479 --> 03:00:46,399
a camera is a very poor approximation of

3914
03:00:46,399 --> 03:00:48,880
a human eye and a human eye does a lot

3915
03:00:48,880 --> 03:00:51,439
more than take a sequence of frames

3916
03:00:51,439 --> 03:00:53,439
have you looked into like there are like

3917
03:00:53,439 --> 03:00:54,960
these days are like cameras like event

3918
03:00:54,960 --> 03:00:57,200
cameras have you looked into them or are

3919
03:00:57,200 --> 03:00:59,840
you looking into a more flexible camera

3920
03:00:59,840 --> 03:01:01,439
design or building your own camera for

3921
03:01:01,439 --> 03:01:03,840
example

3922
03:01:04,479 --> 03:01:06,240
well with hardware four we will we will

3923
03:01:06,240 --> 03:01:09,359
have a next generation camera uh but i

3924
03:01:09,359 --> 03:01:11,840
have to say that the the current cameras

3925
03:01:11,840 --> 03:01:13,040
we have not reached the limit of the

3926
03:01:13,040 --> 03:01:15,439
current cameras uh so

3927
03:01:15,439 --> 03:01:17,200
um

3928
03:01:17,200 --> 03:01:19,359
and i'm confident we can achieve full

3929
03:01:19,359 --> 03:01:20,960
self-driving with much higher safety

3930
03:01:20,960 --> 03:01:21,760
than

3931
03:01:21,760 --> 03:01:23,439
humans with the current cameras and

3932
03:01:23,439 --> 03:01:25,439
current compute hardware

3933
03:01:25,439 --> 03:01:26,319
um

3934
03:01:26,319 --> 03:01:27,200
but

3935
03:01:27,200 --> 03:01:29,439
you know

3936
03:01:29,439 --> 03:01:30,800
are we good to be a thousand percent

3937
03:01:30,800 --> 03:01:33,120
better rather than 300 better

3938
03:01:33,120 --> 03:01:34,880
so

3939
03:01:34,880 --> 03:01:37,040
we'll see continued evolution on on our

3940
03:01:37,040 --> 03:01:38,160
levels

3941
03:01:38,160 --> 03:01:40,000
and pursue that goal and i think in the

3942
03:01:40,000 --> 03:01:41,200
future

3943
03:01:41,200 --> 03:01:43,040
people will look back and say

3944
03:01:43,040 --> 03:01:44,160
wow i can't believe we had to drive

3945
03:01:44,160 --> 03:01:45,920
these cars ourselves

3946
03:01:45,920 --> 03:01:47,920
you know it'll like self-driving cars

3947
03:01:47,920 --> 03:01:49,600
will just be just a normal like

3948
03:01:49,600 --> 03:01:51,439
self-driving elevators

3949
03:01:51,439 --> 03:01:53,359
you know uh elevators used to have

3950
03:01:53,359 --> 03:01:54,800
elevator operators

3951
03:01:54,800 --> 03:01:56,240
and uh there's someone there with like

3952
03:01:56,240 --> 03:01:58,640
you know big big relay switch

3953
03:01:58,640 --> 03:02:00,080
operating the elevator

3954
03:02:00,080 --> 03:02:01,439
and then every now and then they'd get

3955
03:02:01,439 --> 03:02:03,760
tired or you know some make a mistake

3956
03:02:03,760 --> 03:02:06,319
and share somebody in half so

3957
03:02:06,319 --> 03:02:09,120
um so now we uh you know we made

3958
03:02:09,120 --> 03:02:11,120
elevators automatic and you just go and

3959
03:02:11,120 --> 03:02:12,880
you press the button and you can be in a

3960
03:02:12,880 --> 03:02:15,120
100 story skyscraper and

3961
03:02:15,120 --> 03:02:16,479
don't really worry about it just go and

3962
03:02:16,479 --> 03:02:18,160
press a button and

3963
03:02:18,160 --> 03:02:19,279
the elevator takes you where you want to

3964
03:02:19,279 --> 03:02:20,880
go

3965
03:02:20,880 --> 03:02:22,240
but it used to be that all elevators

3966
03:02:22,240 --> 03:02:24,000
were operated manually manually it'll be

3967
03:02:24,000 --> 03:02:25,760
the same thing like for cars

3968
03:02:25,760 --> 03:02:28,479
all cars will be automatic

3969
03:02:28,479 --> 03:02:32,080
and then um and electric obviously um

3970
03:02:32,080 --> 03:02:33,840
so there will still be some gasoline

3971
03:02:33,840 --> 03:02:35,439
cars and some manual cars just like

3972
03:02:35,439 --> 03:02:38,800
there are still some horses

3973
03:02:39,200 --> 03:02:40,319
so

3974
03:02:40,319 --> 03:02:41,680
um all right well thanks everyone for

3975
03:02:41,680 --> 03:02:43,600
coming and i hope you enjoyed a

3976
03:02:43,600 --> 03:02:45,120
presentation and thank you for the great

3977
03:02:45,120 --> 03:02:46,240
questions

3978
03:02:46,240 --> 03:02:55,910
[Applause]

3979
03:02:56,960 --> 03:03:05,700
[Music]

3980
03:03:12,730 --> 03:03:19,920
[Music]

3981
03:03:19,920 --> 03:03:22,000
you

