### üéâ Congratulations üéâ

If you want your model to produce the minimum possible number of false positives, which of the following metrics would you maximize?
(TP means ‚ÄúTrue Positive‚Äù, FN means ‚ÄúFalse Negative‚Äù, FP means ‚ÄúFalse Positive‚Äù, TN means ‚ÄúTrue Negative‚Äù.)

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã –≤–∞—à–∞ –º–æ–¥–µ–ª—å –¥–∞–≤–∞–ª–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π, –∫–∞–∫–æ–π –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –≤—ã –±—ã –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª–∏?

- TN/(TP+FN)
- TP/(TP+FP) , —Ç–æ—á–Ω–æ—Å—Ç—å (precision)
- TP/(TP+FN) , –ø–æ–ª–Ω–æ—Ç–∞ (recall)

+ (TP+TN)/(TP+TN+FP+FN) = (TP+TN)/|Dataset| , [–¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤](https://raw.githubusercontent.com/esokolov/ml-course-hse/d70ea03bcd41b6e2e77c481553cfbfcaf7a81304/2020-fall/lecture-notes/lecture04-linclass.pdf) (accuracy)
- (2P * R)/(P+R) , (F1-score)

–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è –¥–æ–ª—è –æ–±—ä–µ–∫—Ç–æ–≤, –≤—ã–¥–µ–ª–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —è–≤–ª—è–µ—Ç—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏. 
–ü–æ–ª–Ω–æ—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è —á–∞—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –±—ã–ª–∞ –≤—ã–¥–µ–ª–µ–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º.

### coursera
- [bcaffo/courses](https://github.com/bcaffo/courses)
- [Statistical Inference](https://leanpub.com/LittleInferenceBook/read#leanpub-auto-question) [videos](https://www.youtube.com/playlist?list=PLpl-gQkQivXiBmGyzLrUjzsblmQsLtkzJ)

expected values = mean and variance

```python
import  nltk.translate.bleu_score as bleu

# Setting the two different candidate translation that we will compare with two reference translations

reference_translation=['The cat is on the mat.'.split(),
                       'There is a cat on the mat.'.split()
                      ]
candidate_translation_1='the the the mat on the the.'.split()
candidate_translation_2='The cat is on the matrix.'.split()

# Calculating the BLEU score for candidate translation 1

print("BLEU Score: ",bleu.sentence_bleu(reference_translation, candidate_translation_1))
# The hypothesis contains 0 counts of 3-gram overlaps.
# BLEU Score:  6.968148412761692e-155

print("BLEU Score: ",bleu.sentence_bleu(reference_translation, candidate_translation_2))
# BLEU Score:  0.7598356856515925

```
