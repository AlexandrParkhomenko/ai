# 11\. Обнаружение и сегментация

Сегодня мы поговорим о различных типах других задач компьютерного зрения и расскажем о пространственных пикселях внутри ваших изображений. Мы увидим **сегментацию, локализацию, обнаружение**.

При классификации изображений, у нас будет приходить какое-то входное изображение и проходить через какую-то глубокую сверточную сеть. Эта сеть даст нам некоторый вектор признаков, возможно, 4096 измерений в случае AlexNet RGB. Дальше подавать эти признаки на полносвязный слой с 1000 выходами - разными оценками классов. Это, пожалуй, самая простая из возможных задач.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0017.jpg)

## Сегментация

В задаче семантической сегментации мы хотим ввести изображение, а затем вывести решение категории для каждого пикселя в этом изображении. И потом сказать: это кот ходит по полю, он очень милый.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0019.jpg)

Есть одна интересная вещь при семантической сегментации, она не различает экземпляры. На примере справа у нас есть изображение с двумя коровами, где они стоят рядом друг к другу. И когда мы говорим о семантических сегментация мы просто маркируем все пиксели независимо от того, к какой категории относится этот пиксель. Вывод не делает различий между этими двумя коровами. Вместо этого мы просто получаем массу пикселей, которые все помечены как корова.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0021.jpg)

 Cемантическая сегментация может осуществляться посредством классификации. Итак, вы можете использовать идею скользящего окна. Мы берем наше входное изображение и разбиваем его на множество мелких крошечных локальных изображений. В этом примере мы взяли может быть, три обрезанных изображения головы коровы и применили к ним алгоритмы классификации, которые применяли к целым изображениям.

Возможно окно будет супер-супер долго бегать вперед и назад.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0023.jpg)

Поэтому вместо извлечения отдельных участков изображения, мы можем представить себе, что наша сеть станет огромной гигантской стопкой сверточных слоев без полностью связанных слоёв или что-то ещё, поэтому в этом случае у нас просто куча сверточных слоев.

Проблема в тренировочных данных для этого. Это очень дорого, правда. Нам нужно пометить каждый пиксель в этих входных изображениях: нарисовать контуры и заполнить области.

Если вы хотите сделать свертки, которые, возможно, с 64, 128 или 256 каналами для сверточных фильтров, что довольно часто встречается во многих таких сетях, затем запустите эти свертки в высоком разрешении, то будет чрезвычайно затратно в вычислительном отношении и потребуется огромное количество памяти. На практике вы обычно не видите сети с этой архитектурой. Вместо этого вы видите сети, которые что-то ищут. У нас есть понижающая дискретизация.

Одна из стратегий повышения частоты дискретизации выглядит примерно так:

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0027.jpg)

Чтобы уменьшить выборку, мы говорим о среднем объединении. Мы как бы берем пространственное среднее.

### Транспонированная свертка

 Когда вы делаете шаговую свертку с шагом два, это заканчивается понижением дискретизации изображения или карты функций в два раза.
А теперь транспонированная свертка - это как бы противоположное в некотором роде. Наш ввод будет два на два региона, а наш результат будет размером четыре на четыре.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0039.jpg)

Мы делаем транспонированную свертку три на один. Наш фильтр - это всего лишь три числа. Наш ввод - это два числа.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0041.jpg)
_В свертке слева опечатка: Первую матрицу в умножении читать как x, y, z (вместо x)_ 

У этой операции много разных имен в литературе. Иногда её называют деконволюцией. Это плохое имя. Иногда её называют сверткой с дробным шагом.

## Локализация

Следующая задача - это идея классификации плюс локализация. Мы много говорили о классификации изображений, где мы хотим просто присвоить метку категории входному изображению, но иногда вы можете захотеть узнать ещё немного об изображении. Например, присвоив метку **кошка**, вы захотите узнать, где она располагается на изображении и нарисовать ограничительную рамку.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0049.jpg)

У нас будет две функции потери. Это не большая проблема, вы действительно можете обучить сеть делать обе эти вещи одновременно. На практике вы обычно делаете несколько дополнительных гиперпараметров, которые дают вам некоторый вес между этими двумя потерями, поэтому вы получите взвешенную сумму этих двух разных функций потерь. И тогда будут понятные градиенты.

Один из классных примеров - оценка позы человека.

## Обнаружение объектов

Это своего рода основная проблема компьютерного зрения. Мы снова начинаем с некоторого фиксированного набора категорий. И теперь наша задача состоит в том, чтобы с учетом нашего входного изображения, каждый раз, когда на изображении появляется одна из этих категорий, мы хотим обвести её рамкой и предсказать категорию плюс локализацию, потому что может быть разное количество выходов. Вы не знаете заранее, сколько объектов ожидаете найти в каждом изображении.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0055.jpg)

Так, например, на изображении с котом вверху слева есть только один объект, поэтому нам нужно только предсказать четыре числа. 
На изображении посередине трое животных, поэтому нам нужно, чтобы наша сеть угадала 12 чисел, четыре координаты для каждого ограничивающего прямоугольника. 
Или в этом примере много уток, тогда вы хотите, чтобы ваша сеть предсказала целую кучу чисел.

Поэтому сложно думать об обнаружении объектов как о задаче регрессии.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0062.jpg)

Есть такая классная работа, которая называется предложениями по регионам, обычно при этом не используется глубокое обучение. А используется  традиционное компьютерное зрение, региональные сети выдают множество предположений, которые потом проверяются сверточными сетями.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0068.jpg)
_Этот слайд принадлежит Россу Гиршику._

Эта идея назвается **R-CNN**. R обозначает регион.

Подзадача: региональная сеть выдает предположения с различными масштабами и размерами, поэтому нам нужно принять каждое из этих региональных предложений и деформировать их до фиксированного квадратного размера.

Но есть много гиперпараметров темной магии в этом процессе, и это немного непросто. В общем случае тренировка R-CNN идет медленно, у нас около 84 часов, и занимает много дискового пространства, сотни гигабайт.

Другие типы сетей:

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0075.jpg)

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0081.jpg)

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0084.jpg)

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ai/main/Stanford/class/cs231n/ru/images/cs231n_2017_lecture11_page-0085.jpg)

Вопрос в том, сколько данных для обучения вам нужно?

[Microsoft Coco](https://cocodataset.org/) - это примерно 200 000 обучающих изображений. Он имеет 80 категорий.

С оригинальной лекцией можно ознакомиться на [YouTube](https://youtu.be/nDPWywWRIRo).
