1
00:00:05,120 --> 00:00:07,200
на сегодня я очень рад

2
00:00:07,200 --> 00:00:10,320
представить нашего третьего приглашенного спикера

3
00:00:10,320 --> 00:00:13,280
, Маркореллио Ранцато, эм, так он

4
00:00:13,280 --> 00:00:15,040
родом из Италии,

5
00:00:15,040 --> 00:00:18,960
затем работал в Нью-Йорке с молодым Маккуном,

6
00:00:18,960 --> 00:00:21,039
а затем у него есть постдок с Джеффри

7
00:00:21,039 --> 00:00:22,320
Хинтоном, так что он очень

8
00:00:22,320 --> 00:00:24,000
диетический исследователь глубокого обучения

9
00:00:24,000 --> 00:00:26,400
большая часть его

10
00:00:26,400 --> 00:00:29,199
оригинальной работы была в таких областях, как изучение функций

11
00:00:29,199 --> 00:00:29,760


12
00:00:29,760 --> 00:00:32,880
и видение, но за последние несколько лет

13
00:00:32,880 --> 00:00:33,520
он действительно

14
00:00:33,520 --> 00:00:35,920
обратил свой интерес к обработке естественного языка,

15
00:00:35,920 --> 00:00:36,960


16
00:00:36,960 --> 00:00:39,680
и, в частности, в последние несколько лет

17
00:00:39,680 --> 00:00:41,600
он много работал над

18
00:00:41,600 --> 00:00:44,480
изучением машинного перевода в

19
00:00:44,480 --> 00:00:46,079
целом и  конкретный машинный

20
00:00:46,079 --> 00:00:47,120
перевод

21
00:00:47,120 --> 00:00:49,760
для языков, для которых доступно меньше ресурсов

22
00:00:49,760 --> 00:00:50,160
,

23
00:00:50,160 --> 00:00:52,960
поэтому я видел его разговор

24
00:00:52,960 --> 00:00:55,039
по этой теме около шести месяцев назад,

25
00:00:55,039 --> 00:00:58,559
и через него и его команду в facebook

26
00:00:58,559 --> 00:01:00,559
у них действительно есть много захватывающей новой

27
00:01:00,559 --> 00:01:01,199
работы

28
00:01:01,199 --> 00:01:03,280
по способам создания нейронной машины

29
00:01:03,280 --> 00:01:04,239


30
00:01:04,239 --> 00:01:06,240
перевод на новый уровень, и поэтому я надеюсь, что

31
00:01:06,240 --> 00:01:07,760
это будет действительно

32
00:01:07,760 --> 00:01:09,840
отличная возможность для всех увидеть

33
00:01:09,840 --> 00:01:11,680
некоторые из последних и самых захватывающих

34
00:01:11,680 --> 00:01:12,880
технологий  вопросы в вашем

35
00:01:12,880 --> 00:01:15,439
машинном переводе, это своего рода

36
00:01:15,439 --> 00:01:17,200
следующий уровень по сравнению с тем,

37
00:01:17,200 --> 00:01:19,680
о чем мы говорили, и вы, ребята, все выполнили

38
00:01:19,680 --> 00:01:22,000
четвертое и пятое задание для класса,

39
00:01:22,000 --> 00:01:24,240
так что уберите его с Марко Эллиотом,

40
00:01:24,240 --> 00:01:25,840
ладно, спасибо, Крис, что

41
00:01:25,840 --> 00:01:26,720
пригласил меня,

42
00:01:26,720 --> 00:01:30,240
позвольте мне просто  положи мое лицо, я здесь,

43
00:01:30,240 --> 00:01:32,479
привет всем, я собираюсь отключить его сейчас, чтобы

44
00:01:32,479 --> 00:01:34,880
вы могли сосредоточиться на презентации,

45
00:01:34,880 --> 00:01:40,079
так поделитесь,

46
00:01:40,079 --> 00:01:42,320
я надеюсь, вы сможете увидеть мою

47
00:01:42,320 --> 00:01:43,920
презентацию сейчас

48
00:01:43,920 --> 00:01:47,119
хорошо, так что я очень рад, что скажу

49
00:01:47,119 --> 00:01:48,399
вам немного  немного о

50
00:01:48,399 --> 00:01:51,200
машинном переводе с низким уровнем ресурсов, и

51
00:01:51,200 --> 00:01:52,960
давайте начнем с

52
00:01:52,960 --> 00:01:55,759
повторного рассмотрения проблемы машинного перевода,

53
00:01:55,759 --> 00:01:56,960
так

54
00:01:56,960 --> 00:01:58,880
что допустим, что мы хотим переводить

55
00:01:58,880 --> 00:02:01,119
с английского на французский,

56
00:02:01,119 --> 00:02:05,280
и мы начнем с большого

57
00:02:05,280 --> 00:02:07,520
обучающего набора, где у нас есть набор

58
00:02:07,520 --> 00:02:08,720


59
00:02:08,720 --> 00:02:10,720
предложений на английском языке с их соответствующим

60
00:02:10,720 --> 00:02:12,319
переводом на  французский,

61
00:02:12,319 --> 00:02:14,720
и это то, что мы называем параллельным набором данных,

62
00:02:14,720 --> 00:02:15,680


63
00:02:15,680 --> 00:02:17,599
и, в частности, предложения на

64
00:02:17,599 --> 00:02:19,280
английском языке мы называем их

65
00:02:19,280 --> 00:02:21,440
исходными предложениями, а

66
00:02:21,440 --> 00:02:23,760
соответствующие предложения на французском языке - это

67
00:02:23,760 --> 00:02:26,800
то, что мы называем целевым набором данных  ntences,

68
00:02:26,800 --> 00:02:30,000
а теперь проблема обучения

69
00:02:30,000 --> 00:02:33,360
заключается в том, что для данного

70
00:02:33,360 --> 00:02:35,120
предложения на английском языке вы хотите

71
00:02:35,120 --> 00:02:36,720
предсказать соответствующее

72
00:02:36,720 --> 00:02:40,000
предложение на французском языке, и способ, которым мы

73
00:02:40,000 --> 00:02:40,640
это делаем,

74
00:02:40,640 --> 00:02:43,680
заключается в минимизации потери перекрестной энтропии,

75
00:02:43,680 --> 00:02:46,640
которая максимизирует правовую вероятность

76
00:02:46,640 --> 00:02:47,519


77
00:02:47,519 --> 00:02:50,000
эталонного человеческого перевода  учитывая

78
00:02:50,000 --> 00:02:51,840
исходное предложение,

79
00:02:51,840 --> 00:02:54,000
и мы делаем это путем стохастического зернистого

80
00:02:54,000 --> 00:02:55,360
спуска,

81
00:02:55,360 --> 00:02:58,239
используя в качестве архитектуры последовательность для

82
00:02:58,239 --> 00:03:00,239
последовательности с вниманием, которое,

83
00:03:00,239 --> 00:03:03,360
насколько я знаю, вы изучали,

84
00:03:03,360 --> 00:03:06,400
и у вас было домашнее задание несколько недель

85
00:03:06,400 --> 00:03:07,519
назад,

86
00:03:07,519 --> 00:03:10,080
а затем после того, как вы тренируетесь в  на этот

87
00:03:10,080 --> 00:03:11,360
раз

88
00:03:11,360 --> 00:03:14,159
вам дается новое предложение на английском языке,

89
00:03:14,159 --> 00:03:15,440
и вы хотите

90
00:03:15,440 --> 00:03:17,680
произвести соответствующий перевод,

91
00:03:17,680 --> 00:03:19,440
чтобы сделать это,

92
00:03:19,440 --> 00:03:23,440
мы обычно используем метод эвристического

93
00:03:23,440 --> 00:03:26,239
поиска, такой как луч, который пытается

94
00:03:26,239 --> 00:03:27,519


95
00:03:27,519 --> 00:03:30,239
приблизительно найти целевое предложение, которое

96
00:03:30,239 --> 00:03:32,560
максимизирует вероятность закона с

97
00:03:32,560 --> 00:03:37,440
учетом данного источника  предложение,

98
00:03:37,440 --> 00:03:40,159
так что это на высоком уровне, как

99
00:03:40,159 --> 00:03:41,920
работает машинный перевод, и

100
00:03:41,920 --> 00:03:44,239
давайте подумаем о предположениях, которые

101
00:03:44,239 --> 00:03:45,519
мы сделали

102
00:03:45,519 --> 00:03:47,840
Во время этого обсуждения первое

103
00:03:47,840 --> 00:03:49,599
предположение состоит в том, что мы работаем с

104
00:03:49,599 --> 00:03:52,319
двумя достаточно связанными языками, такими как

105
00:03:52,319 --> 00:03:54,319
английский и французский, а второе

106
00:03:54,319 --> 00:03:56,879
предположение, что в нашем

107
00:03:56,879 --> 00:03:59,360
распоряжении имеется большой набор данных параллельных

108
00:03:59,360 --> 00:04:00,799
предложений, потому что здесь мы, по

109
00:04:00,799 --> 00:04:02,480
сути, выполняем,

110
00:04:02,480 --> 00:04:05,280
ох, контролируемые  правильное обучение, и это

111
00:04:05,280 --> 00:04:07,040
прекрасный пример

112
00:04:07,040 --> 00:04:08,319
сквозного обучения

113
00:04:08,319 --> 00:04:10,480
с учителем, но оно зависит от наличия

114
00:04:10,480 --> 00:04:11,439
большого

115
00:04:11,439 --> 00:04:15,760
набора параллельных данных, и поэтому

116
00:04:15,760 --> 00:04:18,000
в мире существует более 6000

117
00:04:18,000 --> 00:04:20,478
языков,

118
00:04:20,478 --> 00:04:24,800
и, разумеется,

119
00:04:24,800 --> 00:04:26,560
большинство из этих языков не  Я принадлежу

120
00:04:26,560 --> 00:04:28,880
к европейской семье,

121
00:04:28,880 --> 00:04:31,680
на которой была сосредоточена большая часть недавних исследований

122
00:04:31,680 --> 00:04:34,240
по машинному переводу,

123
00:04:34,240 --> 00:04:36,800
и даже если вы посмотрите на английский, на

124
00:04:36,800 --> 00:04:37,759
английском говорят

125
00:04:37,759 --> 00:04:40,400
менее пяти процентов населения, поскольку на родных

126
00:04:40,400 --> 00:04:41,199


127
00:04:41,199 --> 00:04:42,800
языках говорят менее пяти процентов

128
00:04:42,800 --> 00:04:45,120
населения мира.

129
00:04:45,120 --> 00:04:48,320
численность населения и т.

130
00:04:48,320 --> 00:04:51,040


131
00:04:51,040 --> 00:04:52,800


132
00:04:52,800 --> 00:04:53,840


133
00:04:53,840 --> 00:04:56,880


134
00:04:56,880 --> 00:04:57,520


135
00:04:57,520 --> 00:05:01,840
Вы обнаружите, что из первых десятков разговорных языков на

136
00:05:01,840 --> 00:05:03,520
это приходится

137
00:05:03,520 --> 00:05:05,840
менее 50 человек в мире,

138
00:05:05,840 --> 00:05:09,360
и теперь, если вы посмотрите на

139
00:05:09,360 --> 00:05:12,639
крайнюю правую часть хвоста,

140
00:05:12,639 --> 00:05:15,039
это языки, для

141
00:05:15,039 --> 00:05:16,479
которых очень мало говорящих и, по

142
00:05:16,479 --> 00:05:18,800
сути, нет оцифрованных

143
00:05:18,800 --> 00:05:20,960
материал данных для вас, чтобы обучить чему-либо, так

144
00:05:20,960 --> 00:05:21,440
что

145
00:05:21,440 --> 00:05:24,240
для тех, кто я думаю, что это почти безнадежно, я

146
00:05:24,240 --> 00:05:25,280
бы сказал,

147
00:05:25,280 --> 00:05:28,639
но в середине этой истории у нас

148
00:05:28,639 --> 00:05:31,120
есть много языков, для которых есть

149
00:05:31,120 --> 00:05:32,000
некоторые

150
00:05:32,000 --> 00:05:35,600
цифровые данные и для которых у нас нет

151
00:05:35,600 --> 00:05:37,039
хороших способов  переводите в

152
00:05:37,039 --> 00:05:39,919
наши дни, если вы думаете о крупных

153
00:05:39,919 --> 00:05:41,759
провайдерах, таких как google

154
00:05:41,759 --> 00:05:44,880
yandex baidu facebook и т.

155
00:05:44,880 --> 00:05:45,520


156
00:05:45,520 --> 00:05:48,400


157
00:05:48,400 --> 00:05:49,280


158
00:05:49,280 --> 00:05:52,639


159
00:05:52,639 --> 00:05:56,000


160
00:05:56,000 --> 00:05:59,440
гм

161
00:05:59,440 --> 00:06:01,520
улучшить машинный перевод

162
00:06:01,520 --> 00:06:03,440
посередине, я думаю, мы могли бы сделать

163
00:06:03,440 --> 00:06:06,560
это было бы очень невозможно, правильно,

164
00:06:06,560 --> 00:06:09,440
но так что происходит, когда мы идем по этому

165
00:06:09,440 --> 00:06:09,919
хвосту,

166
00:06:09,919 --> 00:06:13,199
поэтому происходит то, что количество

167
00:06:13,199 --> 00:06:13,759


168
00:06:13,759 --> 00:06:17,600
данных параллельных данных уменьшается  и

169
00:06:17,600 --> 00:06:19,520
это очень сильно коррелирует с

170
00:06:19,520 --> 00:06:21,120
качеством

171
00:06:21,120 --> 00:06:23,039
систем автоматического машинного перевода,

172
00:06:23,039 --> 00:06:24,800
которые у нас есть, в частности,

173
00:06:24,800 --> 00:06:28,000
как вы можете видеть здесь, в какой-то момент на

174
00:06:28,000 --> 00:06:29,919
самом деле происходит резкое падение

175
00:06:29,919 --> 00:06:32,240
точности вашей системы машинного перевода

176
00:06:32,240 --> 00:06:33,440
,

177
00:06:33,440 --> 00:06:34,560
поэтому

178
00:06:34,560 --> 00:06:36,560
[Музыка]

179
00:06:36,560 --> 00:06:41,280
так что, возможно, начальная

180
00:06:41,280 --> 00:06:44,080
картина,  мы имели в виду, что это немного

181
00:06:44,080 --> 00:06:45,919
другое, поэтому теперь, если мы

182
00:06:45,919 --> 00:06:48,560
возьмем довольно большой исходный язык, такой как

183
00:06:48,560 --> 00:06:50,639
непали, на котором говорят в

184
00:06:50,639 --> 00:06:51,360
Непале,

185
00:06:51,360 --> 00:06:55,520
прекрасной стране к северо-востоку от Индии

186
00:06:55,520 --> 00:06:57,919
с более чем 25 миллионами человек, так что это

187
00:06:57,919 --> 00:06:58,880
не

188
00:06:58,880 --> 00:07:02,319
просто горстка людей в

189
00:07:02,319 --> 00:07:04,000
первую очередь  количество обучающих

190
00:07:04,000 --> 00:07:06,639
данных не так много, как английский французский

191
00:07:06,639 --> 00:07:09,840
намного меньше, и здесь

192
00:07:09,840 --> 00:07:11,039
давайте использовать другое визуальное

193
00:07:11,039 --> 00:07:15,039
представление, поэтому давайте использовать

194
00:07:15,039 --> 00:07:16,880
прямоугольники страха с цветом, который

195
00:07:16,880 --> 00:07:18,319
соответствует

196
00:07:18,319 --> 00:07:20,880
языку, поэтому синий прямоугольник - это

197
00:07:20,880 --> 00:07:22,479
английские данные, а

198
00:07:22,479 --> 00:07:25,599
красный прямоугольник

199
00:07:25,599 --> 00:07:29,039
сейчас на

200
00:07:29,039 --> 00:07:32,160
практике непальские данные параллельный набор данных - это не

201
00:07:32,160 --> 00:07:35,599
просто такая монолитная вещь, потому что

202
00:07:35,599 --> 00:07:36,560
некоторая часть

203
00:07:36,560 --> 00:07:39,759
происходит на английском языке, а некоторые - на

204
00:07:39,759 --> 00:07:42,960
оригинальном  tes на непальском, а теперь давайте

205
00:07:42,960 --> 00:07:44,479
представим

206
00:07:44,479 --> 00:07:48,720
непальские

207
00:07:48,720 --> 00:07:52,400
переводы английских данных с пустым

208
00:07:52,400 --> 00:07:54,879
прямоугольником, где столбец

209
00:07:54,879 --> 00:07:56,800
соответствует языку, и чувствуете ли вы это

210
00:07:56,800 --> 00:07:57,199
или нет,

211
00:07:57,199 --> 00:07:59,120
зависит от того, перевод

212
00:07:59,120 --> 00:08:01,199
ли это так, является ли это человеческим переводом

213
00:08:01,199 --> 00:08:04,240
или

214
00:08:04,400 --> 00:08:07,280
данные, происходящие на языке, поэтому в

215
00:08:07,280 --> 00:08:09,199
этом случае мы берем

216
00:08:09,199 --> 00:08:11,120
данные, которые происходят на английском языке, и

217
00:08:11,120 --> 00:08:15,440
переводим на непальский, поэтому это

218
00:08:15,840 --> 00:08:19,440
пустой красный прямоугольник и то же самое,

219
00:08:19,440 --> 00:08:22,560
когда вы переходите с непальского на английский.

220
00:08:22,560 --> 00:08:25,520


221
00:08:25,520 --> 00:08:26,960
данные, которые происходят из

222
00:08:26,960 --> 00:08:29,280
непальского, могут поступать из

223
00:08:29,280 --> 00:08:30,479
разных доменов,

224
00:08:30,479 --> 00:08:33,279
поэтому здесь, по оси Y, у вас есть

225
00:08:33,279 --> 00:08:34,240
домен, и поэтому

226
00:08:34,240 --> 00:08:37,200
в этом примере я полностью выдумал,

227
00:08:37,200 --> 00:08:40,080
но это довольно

228
00:08:40,080 --> 00:08:41,839
показательно для того, что происходит на практике, у

229
00:08:41,839 --> 00:08:43,120
вас могут быть

230
00:08:43,120 --> 00:08:45,360
английские предложения  могут быть взяты из,

231
00:08:45,360 --> 00:08:46,720
скажем, Библии,

232
00:08:46,720 --> 00:08:48,720
и поэтому непальский здесь перевод

233
00:08:48,720 --> 00:08:50,880
из Библии,

234
00:08:50,880 --> 00:08:54,000
а непальские предложения могут быть

235
00:08:54,000 --> 00:08:58,080
взяты из парламентских данных, хорошо,

236
00:08:58,399 --> 00:09:01,839
так что вы можете  Приветствуйте меня, что

237
00:09:01,839 --> 00:09:03,440
перевод нового предложения

238
00:09:03,440 --> 00:09:06,080
из Библии - не очень

239
00:09:06,080 --> 00:09:07,120
интересная задача,

240
00:09:07,120 --> 00:09:09,200
потому что конвейер представляет собой довольно статичный

241
00:09:09,200 --> 00:09:10,160
набор данных,

242
00:09:10,160 --> 00:09:12,480
и поэтому, возможно, мы хотим переводить данные новостей

243
00:09:12,480 --> 00:09:14,640


244
00:09:14,640 --> 00:09:17,920
, но

245
00:09:17,920 --> 00:09:20,959
на практике у нас нет никаких параллельных

246
00:09:20,959 --> 00:09:21,760
данных

247
00:09:21,760 --> 00:09:24,480
в  новостной домен, возможно, то, что у нас есть,

248
00:09:24,480 --> 00:09:25,040
поэтому то, что мы

249
00:09:25,040 --> 00:09:26,320
действительно хотим сделать в конце, - это

250
00:09:26,320 --> 00:09:29,120
перевести предложения с этого

251
00:09:29,120 --> 00:09:32,320
тестового сайта, который представляет собой английские новости, на

252
00:09:32,320 --> 00:09:33,279
непальский,

253
00:09:33,279 --> 00:09:36,480
но все, что у нас есть в новостной области, - это

254
00:09:36,480 --> 00:09:39,279
не более одноязычные данные как на английском, так

255
00:09:39,279 --> 00:09:40,959
и на непальском языках, поэтому  это

256
00:09:40,959 --> 00:09:44,480
английские предложения, которые совсем не совпадают

257
00:09:44,480 --> 00:09:47,360
с непальскими предложениями

258
00:09:47,360 --> 00:09:47,920
здесь,

259
00:09:47,920 --> 00:09:50,480
просто так случилось, что это были просто данные, которые

260
00:09:50,480 --> 00:09:51,120
вы

261
00:09:51,120 --> 00:09:54,480
получили из новых источников, хорошо, и

262
00:09:54,480 --> 00:09:56,480
это довольно сложная обучающая установка,

263
00:09:56,480 --> 00:09:57,279
потому что у

264
00:09:57,279 --> 00:10:00,480
вас есть немного параллельных

265
00:10:00,480 --> 00:10:02,160
предложений

266
00:10:02,160 --> 00:10:04,560
и э-э  которые находятся в другом домене

267
00:10:04,560 --> 00:10:06,959
из тестового набора,

268
00:10:06,959 --> 00:10:10,160
и все, что у вас есть в

269
00:10:10,160 --> 00:10:10,720
интересующей вас области,

270
00:10:10,720 --> 00:10:14,240
- это одноязычные данные, и

271
00:10:14,240 --> 00:10:18,000
на самом деле у вас может быть

272
00:10:18,000 --> 00:10:21,760
также другая параллель на другом языке,

273
00:10:21,760 --> 00:10:23,040
давайте  скажем хинди,

274
00:10:23,040 --> 00:10:26,320
который принадлежит к той же семье, что и непальский,

275
00:10:26,320 --> 00:10:29,360
но, возможно, это из другой области

276
00:10:29,360 --> 00:10:30,320
, скажем, книги,

277
00:10:30,320 --> 00:10:31,920
и, возможно, у вас также есть одноязычные

278
00:10:31,920 --> 00:10:34,320
данные на хинди, которые также относятся к области книг,

279
00:10:34,320 --> 00:10:36,320


280
00:10:36,320 --> 00:10:39,839
так что на самом деле

281
00:10:39,839 --> 00:10:42,320
вы действительно на практике

282
00:10:42,320 --> 00:10:43,760
обнаруживаете, что  у вас может

283
00:10:43,760 --> 00:10:47,120
быть много языков, на которых вы

284
00:10:47,120 --> 00:10:48,320
могли бы учиться

285
00:10:48,320 --> 00:10:51,680
, и много доменов,

286
00:10:51,680 --> 00:10:54,720
и все, что вы хотите сделать в конце, это

287
00:10:54,720 --> 00:10:56,240
иметь возможность переводить

288
00:10:56,240 --> 00:10:59,279
данные новостей с английского на непальский, но у вас

289
00:10:59,279 --> 00:11:00,000
нет никакого

290
00:11:00,000 --> 00:11:01,760
контроля за этим  у вас нет никаких

291
00:11:01,760 --> 00:11:03,839
данных меток и параллельных данных для того,

292
00:11:03,839 --> 00:11:06,560
что у вас есть набор данных в

293
00:11:06,560 --> 00:11:07,600
разных доменах и

294
00:11:07,600 --> 00:11:09,120
на разных языках, поэтому

295
00:11:09,120 --> 00:11:11,920
вопрос в том, как вы можете использовать

296
00:11:11,920 --> 00:11:15,279
все эти данные для выполнения вашей

297
00:11:15,279 --> 00:11:17,680
исходной задачи перевода

298
00:11:17,680 --> 00:11:20,399
и т.  это мондрианское учебное

299
00:11:20,399 --> 00:11:21,680
исследование,

300
00:11:21,680 --> 00:11:24,720
которое довольно сложно,

301
00:11:24,720 --> 00:11:26,959
и это будет темой

302
00:11:26,959 --> 00:11:28,959
этой лекции,

303
00:11:28,959 --> 00:11:32,320
и поэтому

304
00:11:32,320 --> 00:11:35,920
нет очень четкого определения того, что такое

305
00:11:35,920 --> 00:11:39,120
машинный перевод лорда ресурсов, но

306
00:11:39,120 --> 00:11:41,680
в общих чертах говоря на языке  Бар можно

307
00:11:41,680 --> 00:11:43,279
считать низким ресурсом,

308
00:11:43,279 --> 00:11:45,440
когда количество параллельных предложений в

309
00:11:45,440 --> 00:11:46,399


310
00:11:46,399 --> 00:11:50,000
домене меньше десяти тысяч.

311
00:11:50,000 --> 00:11:54,320


312
00:11:54,320 --> 00:11:57,600


313
00:11:57,600 --> 00:12:00,240


314
00:12:00,240 --> 00:12:02,880


315
00:12:02,880 --> 00:12:04,639


316
00:12:04,639 --> 00:12:06,560
параметры,

317
00:12:06,560 --> 00:12:08,240
и поэтому есть несколько проблем,

318
00:12:08,240 --> 00:12:09,680
есть проблемы, связанные с

319
00:12:09,680 --> 00:12:10,000
данными,

320
00:12:10,000 --> 00:12:12,160
и проблемы, которые относятся к дизайну модели,

321
00:12:12,160 --> 00:12:13,120


322
00:12:13,120 --> 00:12:16,959
поэтому с точки зрения данных очень сложно

323
00:12:16,959 --> 00:12:18,320


324
00:12:18,320 --> 00:12:20,639
получить данные для правильного обучения, очень

325
00:12:20,639 --> 00:12:22,240
сложно понять,

326
00:12:22,240 --> 00:12:24,399
где взять данные  обучать данные, которые

327
00:12:24,399 --> 00:12:25,360
находятся

328
00:12:25,360 --> 00:12:27,360
в домене, похожем на домен, который

329
00:12:27,360 --> 00:12:28,880
вас интересует, в конечном итоге

330
00:12:28,880 --> 00:12:30,560
переводить

331
00:12:30,560 --> 00:12:33,760
э-э, если этого не существует, как получить данные

332
00:12:33,760 --> 00:12:34,079
на

333
00:12:34,079 --> 00:12:37,360
аналогичных языках в других доменах

334
00:12:37,360 --> 00:12:40,079
и даже как получить данные для оценки

335
00:12:40,079 --> 00:12:41,920
вашей системы снова

336
00:12:41,920 --> 00:12:45,279
и снова  со стороны моделирования,

337
00:12:45,279 --> 00:12:47,680
конечно, есть вопрос, как

338
00:12:47,680 --> 00:12:50,000
учиться под присмотром в одиночестве,

339
00:12:50,000 --> 00:12:51,760
по крайней мере, при таком небольшом прямом надзоре,

340
00:12:51,760 --> 00:12:52,560


341
00:12:52,560 --> 00:12:56,800
и как действовать в этой

342
00:12:56,800 --> 00:12:58,800
структуре.  ork, для которого у нас так много

343
00:12:58,800 --> 00:13:02,240
языков и так много доменов,

344
00:13:02,560 --> 00:13:05,519
так что, э-

345
00:13:05,760 --> 00:13:08,720
э, крис упомянул самое

346
00:13:08,720 --> 00:13:09,680
начало,

347
00:13:09,680 --> 00:13:13,519
мой опыт на самом деле не нлп, м-м,

348
00:13:13,519 --> 00:13:16,399
мне всегда было интересно учиться

349
00:13:16,399 --> 00:13:18,480
под присмотром,

350
00:13:18,480 --> 00:13:21,680
и я думаю, что работа с машинным

351
00:13:21,680 --> 00:13:22,880
переводом лордов находится

352
00:13:22,880 --> 00:13:24,959
в  по крайней мере, лично очень уникальная

353
00:13:24,959 --> 00:13:26,399
возможность.

354
00:13:26,399 --> 00:13:28,240
Это очень редкий случай, когда моя

355
00:13:28,240 --> 00:13:29,920
программа исследований согласуется с

356
00:13:29,920 --> 00:13:31,680
приложением,

357
00:13:31,680 --> 00:13:34,720
потому что в

358
00:13:34,720 --> 00:13:36,240
машинном переводе ресурсов у вас не

359
00:13:36,240 --> 00:13:38,399
так много данных уровня, и вам нужно

360
00:13:38,399 --> 00:13:39,199


361
00:13:39,199 --> 00:13:42,000
наилучшим образом использовать вспомогательные задачи и

362
00:13:42,000 --> 00:13:43,040
вспомогательные данные

363
00:13:43,040 --> 00:13:45,920
в  чтобы работать хорошо, и это

364
00:13:45,920 --> 00:13:47,680
общая проблема,

365
00:13:47,680 --> 00:13:50,079
и в то же время машинный перевод

366
00:13:50,079 --> 00:13:50,800
-

367
00:13:50,800 --> 00:13:52,800
это реальное приложение, это то, что, если

368
00:13:52,800 --> 00:13:54,240
мы улучшим, у нас

369
00:13:54,240 --> 00:13:57,680
действительно будет шанс улучшить

370
00:13:57,680 --> 00:14:00,959
э-э, множество приложений

371
00:14:00,959 --> 00:14:04,000
и жизнь многих людей

372
00:14:04,000 --> 00:14:07,440
Итак, на этом я завершаю свое введение

373
00:14:07,440 --> 00:14:08,959
о

374
00:14:08,959 --> 00:14:12,480
машинном переводе лорда ресурсов и

375
00:14:12,480 --> 00:14:14,800
проблемах, с которыми мы сталкиваемся при работе над

376
00:14:14,800 --> 00:14:16,760
этими языками

377
00:14:16,760 --> 00:14:20,000
раньше, и позвольте мне

378
00:14:20,000 --> 00:14:22,959
просто сделать паузу на секунду  Говоря, что

379
00:14:22,959 --> 00:14:24,720
схема акций состояла из

380
00:14:24,720 --> 00:14:28,000
трех столпов, которые в некотором роде

381
00:14:28,000 --> 00:14:29,680


382
00:14:29,680 --> 00:14:32,320
определяют цикл исследования, поэтому первый

383
00:14:32,320 --> 00:14:34,560
столп - это данные,

384
00:14:34,560 --> 00:14:39,120
поэтому я собираюсь рассмотреть,

385
00:14:39,120 --> 00:14:41,199
как мы можем получить данные, в частности, для

386
00:14:41,199 --> 00:14:42,160
оценки,

387
00:14:42,160 --> 00:14:44,720
чтобы данные были предварительным условием для чего-

388
00:14:44,720 --> 00:14:45,760
либо

389
00:14:45,760 --> 00:14:48,000
в нашей жизни как практикующих машинного обучения

390
00:14:48,000 --> 00:14:49,680
,

391
00:14:49,680 --> 00:14:52,240
а затем я собираюсь перейти

392
00:14:52,240 --> 00:14:53,760
к моделированию, поэтому

393
00:14:53,760 --> 00:14:57,519
опишу некоторые алгоритмы для

394
00:14:57,519 --> 00:15:01,440
обучения на языках с ограниченными ресурсами,

395
00:15:01,440 --> 00:15:03,199
и, наконец, я завершу некоторую

396
00:15:03,199 --> 00:15:05,120
работу по

397
00:15:05,120 --> 00:15:07,839
анализу того, что делает модель, когда мы тренируемся на

398
00:15:07,839 --> 00:15:09,360
языки с низким уровнем ресурсов

399
00:15:09,360 --> 00:15:13,440
и на практике, как и на протяжении всей моей

400
00:15:13,440 --> 00:15:16,480
работы здесь, я продолжаю ходить по кругу,

401
00:15:16,480 --> 00:15:16,959
потому что,

402
00:15:16,959 --> 00:15:20,320
когда я выяснил проблемы, которые у нас

403
00:15:20,320 --> 00:15:22,320
есть с данными с моделью,

404
00:15:22,320 --> 00:15:25,040
я делаю карту с набором данных, который лучше

405
00:15:25,040 --> 00:15:26,399
подходит для проблем  что меня

406
00:15:26,399 --> 00:15:27,199
интересует,

407
00:15:27,199 --> 00:15:30,240
а затем я могу вернуться к моделированию,

408
00:15:30,240 --> 00:15:32,639
чтобы улучшить модели

409
00:15:32,639 --> 00:15:33,440
и так далее,

410
00:15:33,440 --> 00:15:36,399
хорошо, и здесь я даю некоторые

411
00:15:36,399 --> 00:15:38,079
ссылки на работы, которые я представляю

412
00:15:38,079 --> 00:15:41,279
не все из  их,

413
00:15:41,279 --> 00:15:44,079
и просто чтобы прояснить, что

414
00:15:44,079 --> 00:15:45,920
это не является хронологическим

415
00:15:45,920 --> 00:15:49,040
обзором, так что это не

416
00:15:49,040 --> 00:15:52,000
обязательно работы, которые внесли определенную

417
00:15:52,000 --> 00:15:52,560
определенную

418
00:15:52,560 --> 00:15:55,839
идею, но это просто, я бы сказал, самые

419
00:15:55,839 --> 00:15:58,480
доступные точки входа по теме

420
00:15:58,480 --> 00:16:00,639
и  затем вы можете перейти к соответствующим разделам работы,

421
00:16:00,639 --> 00:16:03,839
чтобы выяснить, была

422
00:16:03,920 --> 00:16:06,639
ли какая-то основополагающая статья, которая привела

423
00:16:06,639 --> 00:16:07,600
к

424
00:16:07,600 --> 00:16:09,920
этому направлению исследований, и, конечно,

425
00:16:09,920 --> 00:16:11,839
есть немало предвзятости докладчика,

426
00:16:11,839 --> 00:16:13,040
потому что большинство этих

427
00:16:13,040 --> 00:16:16,079
работ были спровоцированы мной,

428
00:16:16,079 --> 00:16:19,519
так что будьте  помня также, что

429
00:16:19,519 --> 00:16:22,560
у вас есть какие-либо вопросы на данный момент у меня

430
00:16:22,560 --> 00:16:24,000
есть быстрый вопрос о

431
00:16:24,000 --> 00:16:25,360
да, я вижу, что первый совет по

432
00:16:25,360 --> 00:16:27,199
модели касается пространства фраз и нейронных сетей

433
00:16:27,199 --> 00:16:27,839
на супер

434
00:16:27,839 --> 00:16:29,440
пустом мне было интересно, могли бы вы поговорить

435
00:16:29,440 --> 00:16:30,880
о разных

436
00:16:30,880 --> 00:16:33,120
подходах к  неконтролируемое обучение,

437
00:16:33,120 --> 00:16:34,639
а также

438
00:16:34,639 --> 00:16:36,480
такие алгоритмы, как перчатка и слово для работы

439
00:16:36,480 --> 00:16:39,839
, возможны на языках с низким уровнем ресурсов.

440
00:16:39,839 --> 00:16:43,759


441
00:16:44,480 --> 00:16:46,800


442
00:16:46,800 --> 00:16:48,320


443
00:16:48,320 --> 00:16:50,880
Архитектура

444
00:16:50,880 --> 00:16:52,079
Я больше говорю об

445
00:16:52,079 --> 00:16:54,880
алгоритмах на самом деле, и поэтому эти

446
00:16:54,880 --> 00:16:57,839
алгоритмы применимы как к

447
00:16:57,839 --> 00:16:59,680
нейронным системам машинного перевода, так и

448
00:16:59,680 --> 00:17:01,199
к системам статистического машинного перевода.

449
00:17:01,199 --> 00:17:03,440


450
00:17:03,440 --> 00:17:06,799
Когда я перейду к этой части, я могу

451
00:17:06,799 --> 00:17:10,160
ответить на ваш вопрос немного

452
00:17:10,160 --> 00:17:11,679
и сказать вам  немного

453
00:17:11,679 --> 00:17:13,919
о различиях между этими

454
00:17:13,919 --> 00:17:14,799
двумя

455
00:17:14,799 --> 00:17:18,799
эм, а затем с точки зрения

456
00:17:18,799 --> 00:17:22,880
эээ методов изучения встраивания слов

457
00:17:22,880 --> 00:17:23,199


458
00:17:23,199 --> 00:17:26,079
и предложений и подшипников, я

459
00:17:26,079 --> 00:17:28,240
очень кратко коснусь этого,

460
00:17:28,240 --> 00:17:31,039
так что в конце лекции я собираюсь

461
00:17:31,039 --> 00:17:31,440
ээ

462
00:17:31,440 --> 00:17:34,160
обратитесь к недавней работе по фильтрации, в

463
00:17:34,160 --> 00:17:34,559
которой

464
00:17:34,559 --> 00:17:39,520
люди используют методы встраивания предложений,

465
00:17:39,520 --> 00:17:42,799
это не глобус, но это что-то

466
00:17:42,799 --> 00:17:46,640
похожее на практике,

467
00:17:46,640 --> 00:17:51,120
для слова и подшипников, ммм

468
00:17:51,120 --> 00:17:54,880
, я бы сказал, что

469
00:17:55,120 --> 00:17:57,200
это предварительное условие для машинного перевода,

470
00:17:57,200 --> 00:17:58,960
потому что если вы можете выровнять

471
00:17:58,960 --> 00:18:01,919
вложения слов  вы изучаете словарь,

472
00:18:01,919 --> 00:18:03,919
а

473
00:18:03,919 --> 00:18:05,520
это примитивный способ машинного

474
00:18:05,520 --> 00:18:07,919
перевода, поэтому мы часто смотрим на

475
00:18:07,919 --> 00:18:08,799
эти вещи

476
00:18:08,799 --> 00:18:12,080
как на хорошую проверку работоспособности

477
00:18:12,080 --> 00:18:15,120
или как на упрощенный машинный перевод  ion,

478
00:18:15,120 --> 00:18:16,080


479
00:18:16,080 --> 00:18:17,919
когда у вас есть справочный словарь,

480
00:18:17,919 --> 00:18:19,360
для которого вы

481
00:18:19,360 --> 00:18:24,080
можете проверить точность вашего выравнивания,

482
00:18:26,640 --> 00:18:31,280
но так что, если вы позволите мне вернуться к вам,

483
00:18:31,280 --> 00:18:34,880
когда мы будем говорить об этом документе, хорошо

484
00:18:34,880 --> 00:18:38,000
, давайте поговорим о данных,

485
00:18:38,000 --> 00:18:41,120
так что давайте вернемся  к нашей

486
00:18:41,120 --> 00:18:43,840
задаче по переводу на английский непальский,

487
00:18:45,840 --> 00:18:49,280
поэтому

488
00:18:49,280 --> 00:18:52,799
есть ресурс под названием

489
00:18:52,799 --> 00:18:56,080
opus, который является очень хорошим, эм, из

490
00:18:56,080 --> 00:18:57,840
которого собрана очень хорошая коллекция

491
00:18:57,840 --> 00:19:00,160
наборов данных, все общедоступные

492
00:19:00,160 --> 00:19:04,000
на многих языках, и

493
00:19:04,000 --> 00:19:06,400
когда вы переходите на этот веб-сайт, на

494
00:19:06,400 --> 00:19:09,440
веб-сайт opus вы найдете это для  английский непальский на

495
00:19:09,440 --> 00:19:12,799
самом деле существует 1 миллион параллельных

496
00:19:12,799 --> 00:19:13,840
предложений, так что,

497
00:19:13,840 --> 00:19:16,240
возможно, я солгал вам, говоря, что

498
00:19:16,240 --> 00:19:19,039
это язык с ограниченными ресурсами, но

499
00:19:19,039 --> 00:19:22,080
если на самом деле, если вы посмотрите на

500
00:19:22,080 --> 00:19:24,320
то, что это за корпорации, вы поймете,

501
00:19:24,320 --> 00:19:25,600
что

502
00:19:25,600 --> 00:19:27,600
почти полмиллиона этих

503
00:19:27,600 --> 00:19:28,960
предложений взяты из

504
00:19:28,960 --> 00:19:32,320
э-э  jw 300 и

505
00:19:32,320 --> 00:19:34,480
это религиозный журнал, а затем у

506
00:19:34,480 --> 00:19:37,760
вас есть 60 000 предложений из Библии,

507
00:19:37,760 --> 00:19:40,080
и их взгляд основан на геноме Эдди Убунту,

508
00:19:40,080 --> 00:19:40,880


509
00:19:40,880 --> 00:19:44,400
так что это материалы, связанные с компьютером,

510
00:19:44,400 --> 00:19:45,120


511
00:19:45,120 --> 00:19:48,160
и так далее  Если вы не заинтересованы в

512
00:19:48,160 --> 00:19:49,440
переводе новых

513
00:19:49,440 --> 00:19:54,640
предложений из Библии, это не

514
00:19:54,880 --> 00:19:58,320
очень полезно, я бы сказал,

515
00:19:58,640 --> 00:20:01,760
и поэтому следует отметить, что все

516
00:20:01,760 --> 00:20:03,600
эти данные происходят с английского, у вас

517
00:20:03,600 --> 00:20:05,840
нет ничего, что происходило бы, во-первых, из непальского,

518
00:20:05,840 --> 00:20:06,960


519
00:20:06,960 --> 00:20:08,799
а во-вторых, если  вас

520
00:20:08,799 --> 00:20:11,360
интересует, скажем, перевод Википедии,

521
00:20:11,360 --> 00:20:14,720
все, что у вас есть, это одноязычные

522
00:20:14,720 --> 00:20:16,720
данные википедии как на английском, так и на непальском и

523
00:20:16,720 --> 00:20:18,640
непальском языках, даже не

524
00:20:18,640 --> 00:20:21,200
очень много, а затем, конечно, вы можете добавить

525
00:20:21,200 --> 00:20:22,480
некоторые одноязычные данные

526
00:20:22,480 --> 00:20:24,320
в другой домен, например, обычный коготь, который

527
00:20:24,320 --> 00:20:27,919
является просто свалкой  Интернет,

528
00:20:27,919 --> 00:20:30,960
но, опять же, перевод с английского

529
00:20:30,960 --> 00:20:32,320
на непальский с использованием

530
00:20:32,320 --> 00:20:35,039
общедоступных данных будет

531
00:20:35,039 --> 00:20:36,559
проблемой, потому что у

532
00:20:36,559 --> 00:20:39,280
вас нет сайта параллельных данных в домене,

533
00:20:39,280 --> 00:20:40,159


534
00:20:40,159 --> 00:20:42,960
хорошо, все, что у вас есть, это в лучшем случае некоторые

535
00:20:42,960 --> 00:20:45,520
одноязычные данные в домене,

536
00:20:45,520 --> 00:20:47,440
но есть еще больший

537
00:20:47,440 --> 00:20:49,919
Проблема заключается в том,

538
00:20:49,919 --> 00:20:53,280
что прямо сейчас нет тестовых данных, поэтому здесь

539
00:20:53,280 --> 00:20:56,000
у нас нет справочных переводов на

540
00:20:56,000 --> 00:20:57,039
непали, чтобы

541
00:20:57,039 --> 00:20:59,039
измерить качество нашей

542
00:20:59,039 --> 00:21:00,799
системы машинного перевода,

543
00:21:00,799 --> 00:21:02,480
и это  большая проблема, потому что если у вас

544
00:21:02,480 --> 00:21:05,520
нет высокого качества

545
00:21:05,520 --> 00:21:08,400
или у вас вообще нет набора тестов,

546
00:21:08,400 --> 00:21:09,760
очень сложно сравнивать

547
00:21:09,760 --> 00:21:12,559
модели, и очень трудно делать

548
00:21:12,559 --> 00:21:14,880
выбор модели для сравнения алгоритмов,

549
00:21:14,880 --> 00:21:18,159
и наша область искалечена, нам

550
00:21:18,159 --> 00:21:21,200
нужен  сильные оценки эм-

551
00:21:21,200 --> 00:21:24,240
эталоны, и это послужило мотивацией для

552
00:21:24,240 --> 00:21:24,960
проекта

553
00:21:24,960 --> 00:21:26,960
под названием flores, который расшифровывается как

554
00:21:26,960 --> 00:21:28,640


555
00:21:28,640 --> 00:21:31,360
эталон оценки ресурсов закона о нехватке ресурсов в facebook для

556
00:21:31,360 --> 00:21:33,600
машинного перевода,

557
00:21:33,600 --> 00:21:37,760
где мы взяли предложения из Википедии

558
00:21:37,760 --> 00:21:39,840
на английском языке и перевели их на

559
00:21:39,840 --> 00:21:41,760
непальский и кинала,

560
00:21:41,760 --> 00:21:45,679
а затем мы взяли википедию,

561
00:21:45,679 --> 00:21:48,400
мы взяли предложения из непальского  wikipedia

562
00:21:48,400 --> 00:21:50,240
и перевел их на английский, а

563
00:21:50,240 --> 00:21:52,080
также из sinaloa wikipedia и перевел

564
00:21:52,080 --> 00:21:52,400
их

565
00:21:52,400 --> 00:21:55,919
на английский, хорошо, так что

566
00:21:55,919 --> 00:21:58,080
вы можете сказать, что это немного скучно,

567
00:21:58,080 --> 00:21:59,039
потому

568
00:21:59,039 --> 00:22:02,080
что в этом сложность,

569
00:22:02,080 --> 00:22:05,280
и расскажите мне о том, что вы знаете трюки, чтобы

570
00:22:05,280 --> 00:22:08,000
улучшить моделирование, но на самом деле вы бы  будьте

571
00:22:08,000 --> 00:22:09,679
удивлены, что этот процесс сбора данных

572
00:22:09,679 --> 00:22:11,440
был

573
00:22:11,440 --> 00:22:14,159
сложнее и интереснее, чем мы

574
00:22:14,159 --> 00:22:15,120
думали,

575
00:22:15,120 --> 00:22:18,720
так что это сложно, потому что очень мало

576
00:22:18,720 --> 00:22:23,280
гриппа  Ent профессиональные переводчики

577
00:22:23,280 --> 00:22:25,200
на эти языки, и это даже не

578
00:22:25,200 --> 00:22:27,760
супер-низкий ресурс,

579
00:22:27,760 --> 00:22:30,799
и так как

580
00:22:30,799 --> 00:22:33,919
мы умерли с агентством переводчиков, и

581
00:22:33,919 --> 00:22:37,280
обычно не хватает людей,

582
00:22:37,280 --> 00:22:39,360
для которых вы можете сделать что-то вроде ab-тестирования,

583
00:22:39,360 --> 00:22:41,760
чтобы проверить перевод одного человека

584
00:22:41,760 --> 00:22:43,600
с другим,

585
00:22:43,600 --> 00:22:46,480
который находится под номером один, номер два, в

586
00:22:46,480 --> 00:22:48,159
целом очень сложно

587
00:22:48,159 --> 00:22:50,400
автоматически оценить качество

588
00:22:50,400 --> 00:22:52,880
перевода, потому что у нас

589
00:22:52,880 --> 00:22:54,559
недостаточно параллельных данных для правильного обучения

590
00:22:54,559 --> 00:22:56,320
системы машинного перевода,

591
00:22:56,320 --> 00:22:59,039
и поэтому нам нужно полагаться на другие методы,

592
00:22:59,039 --> 00:23:00,000


593
00:23:00,000 --> 00:23:01,440
кроме хорошо-  обученная система машинного перевода

594
00:23:01,440 --> 00:23:04,080
для оценки качества,

595
00:23:04,080 --> 00:23:08,159
и поэтому мы построили конвейер, в

596
00:23:08,159 --> 00:23:11,520
котором мы должны были бы отправлять

597
00:23:11,520 --> 00:23:12,400


598
00:23:12,400 --> 00:23:14,559
предложения переводчикам, как только

599
00:23:14,559 --> 00:23:15,760
переводы вернутся,

600
00:23:15,760 --> 00:23:19,360
мы бы сделали несколько проверок, таких как

601
00:23:19,360 --> 00:23:22,640
проверки беглости, используя

602
00:23:22,640 --> 00:23:24,720
языковую модель, которую мы будем проверять на

603
00:23:24,720 --> 00:23:26,400
транслитерацию, чтобы сделать  убедившись, что

604
00:23:26,400 --> 00:23:28,240
предложение не переводится простой

605
00:23:28,240 --> 00:23:30,000
транслитерацией,

606
00:23:30,000 --> 00:23:33,760
мы проверим, что язык

607
00:23:33,760 --> 00:23:36,400
правильный, и поэтому мы  у вас есть

608
00:23:36,400 --> 00:23:38,640
много таких проверок, а затем, если

609
00:23:38,640 --> 00:23:40,400
и, конечно, здесь есть пороги,

610
00:23:40,400 --> 00:23:42,880
которые вам нужно как-то установить,

611
00:23:42,880 --> 00:23:45,600
а затем для тех предложений,

612
00:23:45,600 --> 00:23:46,640
которые не

613
00:23:46,640 --> 00:23:50,720
работают, на этом шаге

614
00:23:50,720 --> 00:23:53,919
мы отправим их обратно на

615
00:23:53,919 --> 00:23:56,320
ретрансляцию, и поэтому после нескольких

616
00:23:56,320 --> 00:23:58,320
итераций  Итак, в конце концов, мы

617
00:23:58,320 --> 00:24:00,000
также проводим оценку с участием человека,

618
00:24:00,000 --> 00:24:04,080
а затем предложения в этом

619
00:24:04,080 --> 00:24:06,240
тесте оценки - это те, которые

620
00:24:06,240 --> 00:24:09,360


621
00:24:09,360 --> 00:24:12,559
прошли все автоматические и человеческие

622
00:24:12,559 --> 00:24:13,200


623
00:24:13,200 --> 00:24:18,320
проверки, а

624
00:24:18,320 --> 00:24:20,159
теперь оказывается, что нет даже

625
00:24:20,159 --> 00:24:22,000
очень хорошей литературы  в котором рассказывается, как

626
00:24:22,000 --> 00:24:22,960
собирать

627
00:24:22,960 --> 00:24:25,200
данные, и, в частности, для языков с ограниченными ресурсами

628
00:24:25,200 --> 00:24:26,400


629
00:24:26,400 --> 00:24:29,200
существует много проблем, связанных с

630
00:24:29,200 --> 00:24:30,960
качеством переводов,

631
00:24:30,960 --> 00:24:33,679
и поэтому мы

632
00:24:33,679 --> 00:24:35,200
думали, что этот проект займет у нас пару месяцев,

633
00:24:35,200 --> 00:24:36,720
но вместо этого нам потребовалось

634
00:24:36,720 --> 00:24:39,919
более шести месяцев гм,

635
00:24:39,919 --> 00:24:43,039
и это говорит о том, что в конечном итоге мы получили

636
00:24:43,039 --> 00:24:45,760
набор для проверки, набор тестов, а также

637
00:24:45,760 --> 00:24:47,279
скрытый тестовый сайт, потому что

638
00:24:47,279 --> 00:24:50,640
мы используем эти данные для конкурса wmt,

639
00:24:50,640 --> 00:24:51,039


640
00:24:51,039 --> 00:24:53,039
и для этого им нужно  ed, чтобы иметь

641
00:24:53,039 --> 00:24:55,120
тестер, который был недоступен для людей,

642
00:24:55,120 --> 00:24:57,840
чтобы убедиться, что люди не

643
00:24:57,840 --> 00:25:00,559
перекрестно проверяли набор тестов,

644
00:25:00,559 --> 00:25:03,919
и вот несколько примеров предложений,

645
00:25:03,919 --> 00:25:04,880
так что это

646
00:25:04,880 --> 00:25:08,400
из предложения из википедии cinahla,

647
00:25:08,400 --> 00:25:10,400
переводящей на английский пару

648
00:25:10,400 --> 00:25:12,240
предложений здесь  и это из английской

649
00:25:12,240 --> 00:25:14,240
википедии, переведенной на кинола, я не

650
00:25:14,240 --> 00:25:15,600
знаю, сколько людей

651
00:25:15,600 --> 00:25:19,440
в аудитории приехали из Шри-Ланки,

652
00:25:19,840 --> 00:25:23,760
которые могли бы оценить эти усилия, но

653
00:25:23,760 --> 00:25:25,279
одна интересная вещь, которую вы

654
00:25:25,279 --> 00:25:27,200
уже можете увидеть, это то, что если вы,

655
00:25:27,200 --> 00:25:28,799
хотя это полностью анекдотично,

656
00:25:28,799 --> 00:25:30,320
потому что это просто  пара предложений

657
00:25:30,320 --> 00:25:31,120
из

658
00:25:31,120 --> 00:25:34,159
личного и английского, вы можете увидеть, что

659
00:25:34,159 --> 00:25:36,480
распределение тем

660
00:25:36,480 --> 00:25:37,279
отличается

661
00:25:37,279 --> 00:25:41,360
, и здесь у вас есть вещи, которые

662
00:25:41,360 --> 00:25:43,600
были бы немного маловероятными в английской

663
00:25:43,600 --> 00:25:46,159
википедии,

664
00:25:46,159 --> 00:25:49,279
и то же самое для непальского английского и

665
00:25:49,279 --> 00:25:52,720
английского непальского, поэтому

666
00:25:52,720 --> 00:25:55,120
у нас есть github  репозиторий, в котором мы

667
00:25:55,120 --> 00:25:56,880
размещаем данные, а также

668
00:25:56,880 --> 00:26:00,320
базовые модели, которые мы обучаем на

669
00:26:00,320 --> 00:26:02,159
общедоступных данных, а затем тестируем их

670
00:26:02,159 --> 00:26:04,559
на эталонном тесте этого этажа,

671
00:26:04,559 --> 00:26:07,360
и на прошлой неделе мы  выпустила еще

672
00:26:07,360 --> 00:26:08,159
пару языков:

673
00:26:08,159 --> 00:26:11,279
английский пушту и английский кхмерский, и

674
00:26:11,279 --> 00:26:11,600


675
00:26:11,600 --> 00:26:14,799
в ближайшие месяцы мы добавляем все больше и больше языков,

676
00:26:14,799 --> 00:26:16,320


677
00:26:16,320 --> 00:26:20,400
поэтому цель этого

678
00:26:20,400 --> 00:26:23,360
раздела - просто сказать, что данные

679
00:26:23,360 --> 00:26:24,400
часто во времени

680
00:26:24,400 --> 00:26:27,360
важнее, чем проектирование модели,

681
00:26:27,360 --> 00:26:29,039
потому что без данных, в частности,

682
00:26:29,039 --> 00:26:31,200
без  Хороший тестовый тест

683
00:26:31,200 --> 00:26:34,400
по существу невозможно провести

684
00:26:34,400 --> 00:26:37,440
исследование в этой области,

685
00:26:37,440 --> 00:26:39,760
и сбор данных не является обзором, это

686
00:26:39,760 --> 00:26:40,720
не

687
00:26:40,720 --> 00:26:44,559
анализ процесса, который вы используете, не

688
00:26:44,559 --> 00:26:48,240
очень хорошо установлен, а

689
00:26:48,240 --> 00:26:52,240
на практике это сложно сделать, и

690
00:26:52,240 --> 00:26:55,279
еще одна вещь, которую нужно подумать извините

691
00:26:55,279 --> 00:26:58,960
состоит в том, чтобы посмотреть на данные, посмотреть на данные,

692
00:26:58,960 --> 00:27:00,159
когда вы их собираете,

693
00:27:00,159 --> 00:27:01,760
а также перед тем, как начать обучение своей

694
00:27:01,760 --> 00:27:04,000
модели, потому что вы можете осознать

695
00:27:04,000 --> 00:27:06,640
некоторые проблемы с качеством

696
00:27:06,640 --> 00:27:07,520
переводов,

697
00:27:07,520 --> 00:27:10,080
если вы говорите на языке, часто

698
00:27:10,080 --> 00:27:10,799
английский находится

699
00:27:10,799 --> 00:27:14,000
на одной стороне, и или вы можете  обнаружите

700
00:27:14,000 --> 00:27:14,880
предубеждения, или

701
00:27:14,880 --> 00:27:17,120
вы можете обнаружить интересные вещи,

702
00:27:17,120 --> 00:27:19,039
поэтому всегда смотрите на данные,

703
00:27:19,039 --> 00:27:22,159
а не просто применяйте свой метод

704
00:27:22,159 --> 00:27:26,880
в виде черного ящика, который завершает  Мое

705
00:27:26,880 --> 00:27:30,000
небольшое обсуждение

706
00:27:30,000 --> 00:27:32,159
части данных, есть ли какие-либо вопросы по

707
00:27:32,159 --> 00:27:33,039
этому

708
00:27:33,039 --> 00:27:34,559
поводу, если вы говорите о построении

709
00:27:34,559 --> 00:27:36,640
языковой модели для языков с низким уровнем ресурсов?

710
00:27:36,640 --> 00:27:39,440


711
00:27:39,440 --> 00:27:40,159


712
00:27:40,159 --> 00:27:43,440


713
00:27:43,440 --> 00:27:46,880


714
00:27:46,880 --> 00:27:49,200


715
00:27:49,200 --> 00:27:51,919
Я точно не помню, что для непали, я думаю, нам пришлось объединить

716
00:27:51,919 --> 00:27:54,159
данные википедии

717
00:27:54,159 --> 00:27:55,440
и общие данные вызовов, потому что

718
00:27:55,440 --> 00:27:57,919
данные википедии были слишком малы,

719
00:27:57,919 --> 00:28:02,000
и мы просто обучаем инграмму на основе подсчета,

720
00:28:02,000 --> 00:28:04,640
а затем базу подсчета и дает вам, что я

721
00:28:04,640 --> 00:28:06,080
не  знаю, если вы изучаете это, но это

722
00:28:06,080 --> 00:28:07,760
дает вам вероятность

723
00:28:07,760 --> 00:28:10,720
одного слова с учетом некоторого фиксированного окна

724
00:28:10,720 --> 00:28:11,919
контекста,

725
00:28:11,919 --> 00:28:14,640
а затем для данного предложения мы

726
00:28:14,640 --> 00:28:15,200
хотели

727
00:28:15,200 --> 00:28:18,720
бы сказать, что это за данное

728
00:28:18,720 --> 00:28:21,440
предложение, вы

729
00:28:21,440 --> 00:28:23,760
вычислите оценку для каждого слова, а

730
00:28:23,760 --> 00:28:25,679
затем  оценка предложения - это просто

731
00:28:25,679 --> 00:28:27,200


732
00:28:27,200 --> 00:28:30,720
средняя оценка

733
00:28:30,720 --> 00:28:32,480
вероятности для всех слов в предложении,

734
00:28:32,480 --> 00:28:34,799
и это даст вам оценку, а затем

735
00:28:34,799 --> 00:28:38,159
у нас будет просто порог для этого,

736
00:28:38,159 --> 00:28:39,200
и поэтому

737
00:28:39,200 --> 00:28:42,799
все предложения, которые будут  d слишком низкая оценка

738
00:28:42,799 --> 00:28:44,799
, которая будет сочтена недостаточно беглой,

739
00:28:44,799 --> 00:28:48,320
будет отправлена за вознаграждение,

740
00:28:48,480 --> 00:28:51,760
но, конечно, всякий раз, когда у вас есть

741
00:28:51,760 --> 00:28:55,120
сущность, когда у вас есть,

742
00:28:55,440 --> 00:28:59,679
вы знаете, что это ненадежно, и

743
00:28:59,679 --> 00:29:02,240
если вы перейдете на языки, ресурсы которых даже

744
00:29:02,240 --> 00:29:04,080
меньше, чем cinahla, тогда у

745
00:29:04,080 --> 00:29:05,520
вас есть  у нас даже нет

746
00:29:05,520 --> 00:29:09,279
действительно внутренних данных, таких как Википедия

747
00:29:09,279 --> 00:29:11,279
не на всех языках, и тогда это

748
00:29:11,279 --> 00:29:13,840
становится еще сложнее

749
00:29:13,840 --> 00:29:17,360
и так часто, поэтому теперь, когда мы

750
00:29:17,360 --> 00:29:20,640
увеличиваем масштаб, мы смотрим на

751
00:29:20,640 --> 00:29:22,559
языковые модели, нейронные языковые модели

752
00:29:22,559 --> 00:29:24,480
, которые обучаются в  многоязычный способ,

753
00:29:24,480 --> 00:29:27,840
и которые точно настроены на небольшом

754
00:29:27,840 --> 00:29:31,039
внутридоменном одноязычном наборе данных,

755
00:29:31,039 --> 00:29:34,240
если он доступен, но да,

756
00:29:34,240 --> 00:29:37,279
также этот шаг не особенно

757
00:29:37,279 --> 00:29:40,399
очевиден, как это сделать, да,

758
00:29:40,399 --> 00:29:43,600
конечно, так что привет, спасибо за

759
00:29:43,600 --> 00:29:45,760
такой потрясающий результат, но я просто

760
00:29:45,760 --> 00:29:46,640
хочу прокомментировать

761
00:29:46,640 --> 00:29:48,480
потому что, как я заметил, что

762
00:29:48,480 --> 00:29:50,000
википедия на самом деле будет иметь

763
00:29:50,000 --> 00:29:51,120
разный контент

764
00:29:51,120 --> 00:29:53,200
на другом языке, который вы выберете, поэтому,

765
00:29:53,200 --> 00:29:54,320
например, у

766
00:29:54,320 --> 00:29:57,200
них будет очень подробное

767
00:29:57,200 --> 00:29:58,399
описание,

768
00:29:58,399 --> 00:30:01,360
например, в основном топи  c, а затем на

769
00:30:01,360 --> 00:30:02,799
других языках, даже

770
00:30:02,799 --> 00:30:04,799
если с таким действительно широко используемым

771
00:30:04,799 --> 00:30:06,720
языком, как китайский, на

772
00:30:06,720 --> 00:30:08,799
самом деле у них будет просто совершенно

773
00:30:08,799 --> 00:30:09,840
другой контент или в

774
00:30:09,840 --> 00:30:14,480
основном упрощенный контент, поэтому я

775
00:30:14,480 --> 00:30:16,640
почти уверен, что это также произойдет

776
00:30:16,640 --> 00:30:19,120
с такими же редко используемыми языками,

777
00:30:19,120 --> 00:30:22,480
так что да, я просто  Я просто думаю,

778
00:30:22,480 --> 00:30:25,039
что, как Википедия, может быть не такой,

779
00:30:25,039 --> 00:30:28,880
как в основном, они могут не быть похожими на

780
00:30:28,880 --> 00:30:31,799
прямую ссылку на

781
00:30:31,799 --> 00:30:33,679
перевод тенденции да

782
00:30:33,679 --> 00:30:35,760
да да, так что это отличный

783
00:30:35,760 --> 00:30:37,279
момент, и это то, что я

784
00:30:37,279 --> 00:30:39,200
собираюсь обсудить более подробно в третьей

785
00:30:39,200 --> 00:30:40,399
части  лекция

786
00:30:40,399 --> 00:30:43,919
и э-э, в некотором смысле,

787
00:30:43,919 --> 00:30:46,880
это проблема перевода,

788
00:30:46,880 --> 00:30:47,600
так что

789
00:30:47,600 --> 00:30:51,279
нам нужно принять тот факт, что контент

790
00:30:51,279 --> 00:30:54,159
, созданный на определенном языке,

791
00:30:54,159 --> 00:30:54,720
может

792
00:30:54,720 --> 00:30:56,320
иметь другое распределение по тематике, чем

793
00:30:56,320 --> 00:30:58,480
контент, созданный на другом

794
00:30:58,480 --> 00:30:59,600
языке,

795
00:30:59,600 --> 00:31:01,679
и то, что вы хотите перевести, является  действительно

796
00:31:01,679 --> 00:31:03,120
контент, который происходит

797
00:31:03,120 --> 00:31:06,159
на исходном языке,

798
00:31:06,159 --> 00:31:08,240
и поэтому вам нужно смириться с этим,

799
00:31:08,240 --> 00:31:09,679


800
00:31:09,679 --> 00:31:12,960
что это то, что так часто бывает в

801
00:31:12,960 --> 00:31:17,679
мм в  в публичных тестах

802
00:31:17,679 --> 00:31:19,279
в литературе вы обнаруживаете, что люди

803
00:31:19,279 --> 00:31:20,720
предполагают, что

804
00:31:20,720 --> 00:31:22,799
корпуса сопоставимы, поэтому все,

805
00:31:22,799 --> 00:31:24,159
что происходит на

806
00:31:24,159 --> 00:31:27,200
английском и, скажем, непальский, по

807
00:31:27,200 --> 00:31:29,200
сути, происходит из одних и тех же

808
00:31:29,200 --> 00:31:31,200
источников, так что это новости, и

809
00:31:31,200 --> 00:31:33,919
все новости говорят об этих схожих

810
00:31:33,919 --> 00:31:34,480
вещах, но

811
00:31:34,480 --> 00:31:36,080
на практике  это неправда, это

812
00:31:36,080 --> 00:31:37,600
неверно для Википедии,

813
00:31:37,600 --> 00:31:40,480
как вы правильно сказали, но это также верно и

814
00:31:40,480 --> 00:31:41,760
для новостей, потому что

815
00:31:41,760 --> 00:31:45,440
если я смотрю местные новости в Непале

816
00:31:45,440 --> 00:31:48,559
и местные новости здесь, это совсем

817
00:31:48,559 --> 00:31:49,039
другое

818
00:31:49,039 --> 00:31:52,320
право, так что это общая проблема, да

819
00:31:52,320 --> 00:31:55,519
, и это имеет  последствия с точки

820
00:31:55,519 --> 00:31:57,519
зрения методов, которые мы собираемся использовать, так

821
00:31:57,519 --> 00:32:01,840
как позже мы обсудим

822
00:32:05,039 --> 00:32:08,159
другие вопросы, или

823
00:32:08,159 --> 00:32:10,880
я не уверен, что мне было ясно, что действительно

824
00:32:10,880 --> 00:32:12,320
трудно

825
00:32:12,320 --> 00:32:17,440
говорить без обратной связи,

826
00:32:17,440 --> 00:32:20,000
пожалуйста, дайте мне знать, если что-

827
00:32:20,000 --> 00:32:21,519
то неясно,

828
00:32:21,519 --> 00:32:23,600
хорошо, давайте  поговорим о моделировании, и

829
00:32:23,600 --> 00:32:24,559
это будет

830
00:32:24,559 --> 00:32:28,320


831
00:32:28,320 --> 00:32:29,760
большая часть нашего времени, на которое мы собираемся проводить большую часть нашего

832
00:32:29,760 --> 00:32:34,080
времени, поэтому помните, что у нас есть эта

833
00:32:34,080 --> 00:32:36,159
забавная диаграмма, где у нас есть домен и

834
00:32:36,159 --> 00:32:37,120
языков, и

835
00:32:37,120 --> 00:32:39,279
это довольно сложная настройка обучения,

836
00:32:39,279 --> 00:32:40,880


837
00:32:40,880 --> 00:32:43,360
и здесь для простоты мы

838
00:32:43,360 --> 00:32:43,919
сосредоточимся

839
00:32:43,919 --> 00:32:49,120
только на английском и непальском языках,

840
00:32:49,200 --> 00:32:51,120
и начнем с самой простой настройки,

841
00:32:51,120 --> 00:32:53,360
когда-либо контролируемого обучения,

842
00:32:53,360 --> 00:32:55,600
предполагая, что все данные находятся в одном

843
00:32:55,600 --> 00:32:57,039
домене,

844
00:32:57,039 --> 00:33:01,279
поэтому, возможно, у вас есть небольшой  торговый сайт

845
00:33:01,440 --> 00:33:04,080
и тестовый набор находится в том же домене,

846
00:33:04,080 --> 00:33:06,080
что и сторона обучения, что и сторона параллельного

847
00:33:06,080 --> 00:33:09,440
обучения. Хорошо, поэтому мы обозначаем

848
00:33:09,440 --> 00:33:12,399
как x исходное предложение, как y - целевое

849
00:33:12,399 --> 00:33:13,039
предложение

850
00:33:13,039 --> 00:33:17,200
d, так что d - это параллельный набор данных,

851
00:33:17,200 --> 00:33:19,519
который правильно собирает все эти пары предложений

852
00:33:19,519 --> 00:33:21,120


853
00:33:21,120 --> 00:33:23,760
Итак, это типичная

854
00:33:23,760 --> 00:33:26,399
структура минимизации эмпирического риска, при которой

855
00:33:26,399 --> 00:33:28,320
вы знаете, что контролируете обучение, в

856
00:33:28,320 --> 00:33:30,159
этом случае вы минимизируете процентную

857
00:33:30,159 --> 00:33:31,360
потерю и хотите

858
00:33:31,360 --> 00:33:33,360
максимизировать вероятность целевого

859
00:33:33,360 --> 00:33:35,600
предложения с учетом исходного предложения,

860
00:33:35,600 --> 00:33:38,000
и поэтому способ визуализировать это  Чтобы сказать,

861
00:33:38,000 --> 00:33:39,120
что

862
00:33:39,120 --> 00:33:42,720
x - это мое английское предложение, он переходит в мой

863
00:33:42,720 --> 00:33:45,679
кодировщик-декодер, систему NT, которая

864
00:33:45,679 --> 00:33:47,360
производит прогноз,

865
00:33:47,360 --> 00:33:49,360
а затем у нас есть потеря, которая измеряет

866
00:33:49,360 --> 00:33:51,120
t  Несоответствие между человеческим

867
00:33:51,120 --> 00:33:52,399
эталоном, о котором

868
00:33:52,399 --> 00:33:54,240
вы знаете, что вы взяли предложение x, которое вы

869
00:33:54,240 --> 00:33:56,159
спросили у своего переводчика, который

870
00:33:56,159 --> 00:33:58,399
дал вам человеческий эталон, и поэтому

871
00:33:58,399 --> 00:33:59,840
потеря перекрестной энтропии измеряет

872
00:33:59,840 --> 00:34:01,440
несоответствие

873
00:34:01,440 --> 00:34:02,960
между предсказанием модели и человеческим

874
00:34:02,960 --> 00:34:05,279
эталоном.

875
00:34:05,279 --> 00:34:08,879


876
00:34:08,879 --> 00:34:12,480
обозначая

877
00:34:12,480 --> 00:34:15,520
прямоугольниками компоненты модели, в этом случае

878
00:34:15,520 --> 00:34:16,960
синее поле - это

879
00:34:16,960 --> 00:34:20,079
кодировщик, процесс представляет собой предложения на английском языке,

880
00:34:20,079 --> 00:34:23,839
а красный прямоугольник - это декодер, который

881
00:34:23,839 --> 00:34:28,000
работает на непальском языке, и

882
00:34:28,000 --> 00:34:30,079
я просто хотел добавить еще одну

883
00:34:30,079 --> 00:34:32,000
вещь: если у вас нет  много

884
00:34:32,000 --> 00:34:32,960
параллельных данных, которые

885
00:34:32,960 --> 00:34:36,079
вам нужно упорядочить, и поэтому вы можете сделать

886
00:34:36,079 --> 00:34:38,560
свадьбу k, что довольно стандартно, поэтому

887
00:34:38,560 --> 00:34:40,879
вы как бы минимизируете

888
00:34:40,879 --> 00:34:43,040
норму l2 параметров, но есть

889
00:34:43,040 --> 00:34:45,119
также другие методы, которые, я думаю,

890
00:34:45,119 --> 00:34:46,800
в классе машинного обучения вы, возможно

891
00:34:46,800 --> 00:34:48,879
, видели как  выпадение, когда вы

892
00:34:48,879 --> 00:34:51,679
устанавливаете на ноль случайным образом скрытые единицы в

893
00:34:51,679 --> 00:34:54,000
вашем кодировщике-декодере, или вы можете выполнить сглаживание меток, в

894
00:34:54,000 --> 00:34:56,239
результате чего вы

895
00:34:56,239 --> 00:35:00,880
потеряете кросс-энтропию вместо того, чтобы на

896
00:35:00,880 --> 00:35:03,520
самом деле должно быть больше  здесь

897
00:35:03,520 --> 00:35:06,320
вместо того, чтобы устанавливать

898
00:35:06,320 --> 00:35:09,760
в качестве цели для правильного слова,

899
00:35:09,760 --> 00:35:10,240


900
00:35:10,240 --> 00:35:11,760
это вероятность по всей последовательности,

901
00:35:11,760 --> 00:35:13,920
которую вы можете разложить на

902
00:35:13,920 --> 00:35:16,880
каждый отдельный мир с помощью правила продукта,

903
00:35:16,880 --> 00:35:18,400


904
00:35:18,400 --> 00:35:21,839
чтобы для каждого вашего слова у вас было

905
00:35:21,839 --> 00:35:25,119
правильное слово, которое вы хотите

906
00:35:25,119 --> 00:35:27,359
извинить каждый раз  шаг, вы хотите

907
00:35:27,359 --> 00:35:28,640
предсказать следующее слово,

908
00:35:28,640 --> 00:35:30,880
и теперь вместо того, чтобы назначать 100

909
00:35:30,880 --> 00:35:32,160


910
00:35:32,160 --> 00:35:35,680
вероятностей следующему слову, вы скажете, что вы назначаете

911
00:35:35,680 --> 00:35:37,760
90 вероятностей, а оставшиеся 10

912
00:35:37,760 --> 00:35:38,720
процентов вы

913
00:35:38,720 --> 00:35:40,640
равномерно распределяете по всем

914
00:35:40,640 --> 00:35:42,320
оставшимся словам, чтобы модель не была

915
00:35:42,320 --> 00:35:44,240
слишком  слишком уверены, так

916
00:35:44,240 --> 00:35:46,000
что комбинации этих двух вещей обычно являются

917
00:35:46,000 --> 00:35:48,160
хорошими

918
00:35:48,160 --> 00:35:51,359
способами упорядочить систему, так что

919
00:35:51,359 --> 00:35:53,119
это простая настройка,

920
00:35:53,119 --> 00:35:55,200
теперь давайте посмотрим, что произойдет, когда у нас

921
00:35:55,200 --> 00:35:57,280
также есть некоторые

922
00:35:57,280 --> 00:36:00,400
одноязычные данные на стороне источника, так что теперь у нас

923
00:36:00,400 --> 00:36:03,440
есть дополнительный набор данных, который имеет только

924
00:36:03,440 --> 00:36:07,200
предложения

925
00:36:07,200 --> 00:36:09,200
в исходном тексте на английском языке, так что в

926
00:36:09,200 --> 00:36:11,040
дополнение к d теперь у нас есть еще,

927
00:36:11,040 --> 00:36:13,839
ммм, одноязычные данные на

928
00:36:13,839 --> 00:36:14,640
стороне источника,

929
00:36:14,640 --> 00:36:19,200
поэтому мы  есть связка осей, поэтому

930
00:36:19,200 --> 00:36:22,880
обычно m намного больше, чем n прямо,

931
00:36:22,880 --> 00:36:26,960
и теперь типичный способ использования

932
00:36:26,960 --> 00:36:28,800
этих данных - моделировать предельное

933
00:36:28,800 --> 00:36:30,640
распределение

934
00:36:30,640 --> 00:36:34,079
данных x справа, и поэтому есть много способов

935
00:36:34,079 --> 00:36:35,440
сделать это,

936
00:36:35,440 --> 00:36:37,680
один способ, который доказал  Чтобы быть довольно

937
00:36:37,680 --> 00:36:38,480
эффективным

938
00:36:38,480 --> 00:36:40,000
в машинном переводе, нужно делать

939
00:36:40,000 --> 00:36:42,160
шумоподавление или кодирование,

940
00:36:42,160 --> 00:36:45,920
и поэтому здесь идея состоит в том, что у

941
00:36:46,240 --> 00:36:48,000
вас есть что-то похожее на то, что у нас

942
00:36:48,000 --> 00:36:49,520
было раньше,

943
00:36:49,520 --> 00:36:52,960
за исключением того, что теперь ввод берется из

944
00:36:52,960 --> 00:36:54,640
этого одноязычного набора данных,

945
00:36:54,640 --> 00:36:58,400
хорошо, и вы добавляете к нему шум,

946
00:36:58,400 --> 00:37:00,000
и я '  m собирается описать

947
00:37:00,000 --> 00:37:01,599
шум за секунду,

948
00:37:01,599 --> 00:37:06,000
а затем задача декодера кодера

949
00:37:06,000 --> 00:37:10,320
состоит в том, чтобы просто уменьшить шум на входе,

950
00:37:10,320 --> 00:37:12,000
а потеря кросс-энтропии измерить

951
00:37:12,000 --> 00:37:14,079
несоответствие

952
00:37:14,079 --> 00:37:16,720
между предсказанием cl и фактическим

953
00:37:16,720 --> 00:37:18,079
чистым вводом,

954
00:37:18,079 --> 00:37:21,760
но теперь обратите внимание, что декодер

955
00:37:21,760 --> 00:37:24,640
это не этот декодер, потому что декодер

956
00:37:24,640 --> 00:37:24,960
теперь

957
00:37:24,960 --> 00:37:27,680
является декодером, который работает на английском языке,

958
00:37:27,680 --> 00:37:31,599
но кодировщик не

959
00:37:31,599 --> 00:37:34,839
кодировщик тот же, что вы видели здесь,

960
00:37:34,839 --> 00:37:37,760
так что снова

961
00:37:37,760 --> 00:37:40,400
функция потерь здесь очень

962
00:37:40,400 --> 00:37:42,320
похожа  до, за исключением того,

963
00:37:42,320 --> 00:37:45,599
что целью является чистый ввод

964
00:37:45,599 --> 00:37:48,640
x, а ввод -

965
00:37:48,640 --> 00:37:52,720
это уведомленная версия x,

966
00:37:52,800 --> 00:37:56,240
поэтому в этом случае мы не предсказываем

967
00:37:56,240 --> 00:37:57,839
что-то непальское, а что-то на

968
00:37:57,839 --> 00:37:58,560
английском языке,

969
00:37:58,560 --> 00:38:01,760
так что это если вы хотите ограничение

970
00:38:01,760 --> 00:38:02,880
этой работы,

971
00:38:02,880 --> 00:38:05,280
но это  полезно, потому что вы в

972
00:38:05,280 --> 00:38:06,160
любом случае

973
00:38:06,160 --> 00:38:09,920
хорошо

974
00:38:09,920 --> 00:38:12,160
моделируете входные предложения и собираетесь

975
00:38:12,160 --> 00:38:14,400
обучить параметры кодировщика, которые

976
00:38:14,400 --> 00:38:15,599
будут

977
00:38:15,599 --> 00:38:18,800
совместно использоваться с вашей контролируемой системой,

978
00:38:18,800 --> 00:38:23,200
чтобы кодировщик совместно использовался между

979
00:38:23,200 --> 00:38:25,200
задачей перевода на параллельных данных

980
00:38:25,200 --> 00:38:26,720


981
00:38:26,720 --> 00:38:29,200
и шумоподавлением  задачи кодирования, поэтому, по

982
00:38:29,200 --> 00:38:30,640
сути, у вас есть кодировщик и два

983
00:38:30,640 --> 00:38:32,720
декодера, один, который работает на непальском языке, один,

984
00:38:32,720 --> 00:38:35,040
который работает на английском языке,

985
00:38:35,040 --> 00:38:38,960
и поэтому

986
00:38:38,960 --> 00:38:41,680
с точки зрения шума, по сути, есть

987
00:38:41,680 --> 00:38:43,440
два типа шума, которые мы

988
00:38:43,440 --> 00:38:44,640
использовали в нашей работе,

989
00:38:44,640 --> 00:38:47,920
другие возможны, но в простейшем

990
00:38:47,920 --> 00:38:49,760
случае  вы можете отбросить

991
00:38:49,760 --> 00:38:52,400
слова или поменять их местами, поэтому предположите, что входное

992
00:38:52,400 --> 00:38:55,119
предложение - это набор денег на коврике,

993
00:38:55,119 --> 00:38:57,920
тогда, если вы меняете слова, вы можете

994
00:38:57,920 --> 00:38:58,960
предоставить ввод,

995
00:38:58,960 --> 00:39:02,320
они разрезают начальный коврик и так h  Прежде

996
00:39:02,320 --> 00:39:04,720
чем кодировщик-декодер должен немного понять

997
00:39:04,720 --> 00:39:05,760


998
00:39:05,760 --> 00:39:07,920
синтаксис и грамматические правила

999
00:39:07,920 --> 00:39:10,160
, чтобы изменить порядок,

1000
00:39:10,160 --> 00:39:12,320
если вы уроните, допустим, вы уроните последнее

1001
00:39:12,320 --> 00:39:13,839
слово кассеты,

1002
00:39:13,839 --> 00:39:16,000
тогда модель должна немного понять

1003
00:39:16,000 --> 00:39:17,599
семантику, потому что ей

1004
00:39:17,599 --> 00:39:19,280
нужно  чтобы назначить

1005
00:39:19,280 --> 00:39:22,400
более высокую вероятность математике прямо сейчас,

1006
00:39:22,400 --> 00:39:25,359
и вы можете видеть, что есть

1007
00:39:25,359 --> 00:39:26,400
немного

1008
00:39:26,400 --> 00:39:28,720
э-э, поэтому здесь есть два гиперпараметра,

1009
00:39:28,720 --> 00:39:30,880
поэтому на

1010
00:39:30,880 --> 00:39:32,800
самом деле есть несколько способов

1011
00:39:32,800 --> 00:39:34,400
использования шума и кодирования, чтобы вы могли использовать

1012
00:39:34,400 --> 00:39:35,119


1013
00:39:35,119 --> 00:39:36,640
кодирование шума как  способ предварительно обучить

1014
00:39:36,640 --> 00:39:38,320
кодировщик,

1015
00:39:38,320 --> 00:39:42,400
или вы можете использовать его в качестве вспомогательных законов,

1016
00:39:42,400 --> 00:39:44,240
когда вы проводите обучение с учителем, чтобы вы

1017
00:39:44,240 --> 00:39:45,440
могли использовать

1018
00:39:45,440 --> 00:39:48,560
этот термин плюс лямбда,

1019
00:39:48,560 --> 00:39:52,480
этот термин хорошо, так что оба способа в порядке,

1020
00:39:52,480 --> 00:39:56,079
и поэтому

1021
00:39:56,079 --> 00:39:58,160
здесь есть очень важный гиперпараметр,

1022
00:39:58,160 --> 00:40:00,079
который  уровень шума, если у вас

1023
00:40:00,079 --> 00:40:00,720


1024
00:40:00,720 --> 00:40:02,880
нет шума или если уровень шума слишком

1025
00:40:02,880 --> 00:40:05,760
низкий, тогда эта задача тривиальна из

1026
00:40:05,760 --> 00:40:08,240
-за внимания, вы можете просто скопировать

1027
00:40:08,240 --> 00:40:09,359
вход,

1028
00:40:09,359 --> 00:40:12,079
и поэтому кодировщику и декодеру не

1029
00:40:12,079 --> 00:40:12,720
нужно учиться

1030
00:40:12,720 --> 00:40:15,920
что-либо, если уровень шума слишком высок

1031
00:40:15,920 --> 00:40:18,640
, вы уничтожаете ввод здесь, поэтому

1032
00:40:18,640 --> 00:40:19,839
кодировщик

1033
00:40:19,839 --> 00:40:22,640
бесполезен, вы просто выполняете языковое моделирование

1034
00:40:22,640 --> 00:40:24,720
с помощью декодера, но помните, что этот

1035
00:40:24,720 --> 00:40:26,079


1036
00:40:26,079 --> 00:40:29,359
декодер не

1037
00:40:29,359 --> 00:40:31,760
используется для перевода, потому что то, что вы

1038
00:40:31,760 --> 00:40:33,200
используете в системе машинного перевода

1039
00:40:33,200 --> 00:40:34,000


1040
00:40:34,000 --> 00:40:36,839
Это поле кодировщика справа от модуля кодировщика,

1041
00:40:36,839 --> 00:40:38,800


1042
00:40:38,800 --> 00:40:42,640
хорошо, поэтому есть другие способы использования

1043
00:40:42,640 --> 00:40:44,720
одноязычных данных на стороне источника

1044
00:40:44,720 --> 00:40:47,040
в дополнение к шумоподавлению кодирования,

1045
00:40:47,040 --> 00:40:48,319
вы также можете

1046
00:40:48,319 --> 00:40:50,960
выполнить самообучение, которое является методом, который

1047
00:40:50,960 --> 00:40:52,400
пришел из 90-х годов,

1048
00:40:52,400 --> 00:40:55,920
если не раньше, и идея  очень

1049
00:40:55,920 --> 00:40:56,560
просто,

1050
00:40:56,560 --> 00:40:59,760
поэтому вы снова берете предложение из

1051
00:40:59,760 --> 00:41:02,319
одноязычного набора данных на стороне источника и

1052
00:41:02,319 --> 00:41:04,160
добавляете к нему шум, а затем у вас есть

1053
00:41:04,160 --> 00:41:06,000
кодировщик-декодер, который

1054
00:41:06,000 --> 00:41:08,880
пытается на этот раз перевести с этого

1055
00:41:08,880 --> 00:41:10,000
шумного ввода,

1056
00:41:10,000 --> 00:41:12,480
хорошо, и теперь, какая

1057
00:41:12,480 --> 00:41:14,160
ссылка дана ссылкой

1058
00:41:14,160 --> 00:41:17,040
стальная версия вашей

1059
00:41:17,040 --> 00:41:18,839
системы машинного перевода,

1060
00:41:18,839 --> 00:41:22,560
хорошо, где ссылка создается

1061
00:41:22,560 --> 00:41:23,680
, скажем, лучом,

1062
00:41:23,680 --> 00:41:27,440
и поэтому потеря перекрестной энтропии

1063
00:41:27,440 --> 00:41:29,280
будет измерять  несоответствие между

1064
00:41:29,280 --> 00:41:30,079
вашим прогнозом

1065
00:41:30,079 --> 00:41:32,960
и тем, что было предсказано на основе

1066
00:41:32,960 --> 00:41:34,480
лестничной версии вашей системы,

1067
00:41:34,480 --> 00:41:37,119
и причина, по которой это работает, заключается в

1068
00:41:37,119 --> 00:41:39,280
том, что когда вы делаете луч,

1069
00:41:39,280 --> 00:41:42,800
вы на самом деле обычно

1070
00:41:43,119 --> 00:41:46,720
производите более качественные

1071
00:41:46,839 --> 00:41:49,839
выходные данные, и поэтому, когда вы сейчас тренируете

1072
00:41:49,839 --> 00:41:52,000
этот декодер кодировщика за счет потери кросс-энтропии,

1073
00:41:52,000 --> 00:41:54,079
вы  мы собираемся изучить

1074
00:41:54,079 --> 00:41:57,119
процесс декодирования, хорошо, и это

1075
00:41:57,119 --> 00:41:58,000
что-то

1076
00:41:58,000 --> 00:42:01,280
хорошее для вас, кроме того,

1077
00:42:01,280 --> 00:42:03,520
когда вы тренируетесь, вы вводите шум,

1078
00:42:03,520 --> 00:42:05,520
и шум регуляризируется, это как бы

1079
00:42:05,520 --> 00:42:06,960


1080
00:42:06,960 --> 00:42:09,280
сглаживает ваше пространство прогнозов, и поэтому, если

1081
00:42:09,280 --> 00:42:11,920
вы прогнозируете правильно  предложение

1082
00:42:11,920 --> 00:42:14,640
теперь также соседние предложения рядом я

1083
00:42:14,640 --> 00:42:15,280
имею в виду,

1084
00:42:15,280 --> 00:42:17,680
что предложения, которые являются похожими фразами или

1085
00:42:17,680 --> 00:42:18,720
которые имеют хорошее

1086
00:42:18,720 --> 00:42:20,880
перекрытие с текущим предложением,

1087
00:42:20,880 --> 00:42:22,160
с

1088
00:42:22,160 --> 00:42:25,200
большей вероятностью будут предсказаны правильно,

1089
00:42:25,200 --> 00:42:26,720
и поэтому у нас есть эта статья, в которой мы

1090
00:42:26,720 --> 00:42:29,119
немного анализируем эти аспекты

1091
00:42:29,119 --> 00:42:30,319
и алгоритм

1092
00:42:30,319 --> 00:42:33,280
очень прост, поэтому сначала вы обучаете

1093
00:42:33,280 --> 00:42:34,960
свою систему машинного перевода на

1094
00:42:34,960 --> 00:42:36,160
параллельных данных,

1095
00:42:36,160 --> 00:42:37,599
а затем повторяете следующий

1096
00:42:37,599 --> 00:42:39,359
процесс, поэтому сначала  вы декодируете свой

1097
00:42:39,359 --> 00:42:40,960
одноязычный набор данных,

1098
00:42:40,960 --> 00:42:43,599
используя вашу текущую

1099
00:42:43,599 --> 00:42:45,040
систему машинного перевода,

1100
00:42:45,040 --> 00:42:48,480
и вы создаете новый параллельный набор

1101
00:42:48,480 --> 00:42:51,119
данных предложений из своего одноязычного

1102
00:42:51,119 --> 00:42:51,680
набора данных,

1103
00:42:51,680 --> 00:42:55,280
извиняясь за

1104
00:42:55,280 --> 00:42:57,440
переводы из вашей текущей системы,

1105
00:42:57,440 --> 00:42:59,200
а затем вы переобучаете модель, которую

1106
00:42:59,200 --> 00:43:02,880
этот pog po y дает x на объединении  ваших

1107
00:43:02,880 --> 00:43:03,680


1108
00:43:03,680 --> 00:43:06,160
исходных параллельных данных плюс этот

1109
00:43:06,160 --> 00:43:07,839
набор вспомогательных данных,

1110
00:43:07,839 --> 00:43:11,200
и здесь у вас есть два гиперпараметра,

1111
00:43:11,200 --> 00:43:12,079
один

1112
00:43:12,079 --> 00:43:14,400
- это уровень шума, а другой

1113
00:43:14,400 --> 00:43:16,480
- гиперпараметры, вес

1114
00:43:16,480 --> 00:43:19,680
этих вспомогательных данных, так что этот набор

1115
00:43:19,680 --> 00:43:20,560
потерь при обучении

1116
00:43:20,560 --> 00:43:24,640
хорошо, теперь

1117
00:43:24,640 --> 00:43:27,520
давайте, на этом мы закончим  как мы можем использовать

1118
00:43:27,520 --> 00:43:29,599
одноязычные данные на стороне источника,

1119
00:43:29,599 --> 00:43:32,160
позвольте мне сказать пару слов о том, как мы можем использовать

1120
00:43:32,160 --> 00:43:34,240
одноязычные данные целевого знака,

1121
00:43:34,240 --> 00:43:35,760
чтобы вы могли использовать целевые

1122
00:43:35,760 --> 00:43:38,240
симонязычные данные для обучения языковой модели,

1123
00:43:38,240 --> 00:43:39,839
а затем обучать систему машинного перевода

1124
00:43:39,839 --> 00:43:40,640


1125
00:43:40,640 --> 00:43:42,319
в остаточном пространстве этого  языковой

1126
00:43:42,319 --> 00:43:44,400
модели, но оказывается, что есть

1127
00:43:44,400 --> 00:43:46,480
гораздо более эффективный способ использовать

1128
00:43:46,480 --> 00:43:48,480
эти данные, и это называется обратным

1129
00:43:48,480 --> 00:43:49,520
переводом,

1130
00:43:49,520 --> 00:43:53,359
поэтому  На уровне gh он работает следующим

1131
00:43:53,359 --> 00:43:55,359
образом: вы берете предложение

1132
00:43:55,359 --> 00:43:58,480
из одноязычного набора данных целевой стороны

1133
00:43:58,480 --> 00:43:59,680
здесь,

1134
00:43:59,680 --> 00:44:03,040
а в параллельном наборе данных вы обучаете

1135
00:44:03,040 --> 00:44:05,280
также обратную систему машинного перевода,

1136
00:44:05,280 --> 00:44:07,200
которая переходит с непальского на английский, хорошо,

1137
00:44:07,200 --> 00:44:10,720
так что теперь у вас есть красный кодировщик,

1138
00:44:10,720 --> 00:44:12,000
который берет непальский

1139
00:44:12,000 --> 00:44:14,880
и синий декодер, который работает в

1140
00:44:14,880 --> 00:44:16,400
английском пространстве, и поэтому

1141
00:44:16,400 --> 00:44:20,000
вы сопоставляете это предложение на английском,

1142
00:44:20,000 --> 00:44:22,160
это предложение пали на английский, и

1143
00:44:22,160 --> 00:44:23,200
теперь это

1144
00:44:23,200 --> 00:44:25,680
может быть неправильный перевод, но

1145
00:44:25,680 --> 00:44:27,200
это шумный

1146
00:44:27,200 --> 00:44:30,000
ввод, который вы подходите к своему декодеру кодировщика,

1147
00:44:30,000 --> 00:44:30,800
который

1148
00:44:30,800 --> 00:44:34,560
вы хотите обучить  правильно, и

1149
00:44:34,560 --> 00:44:37,760
теперь ввод зашумлен, но цель

1150
00:44:37,760 --> 00:44:39,599
здесь чистая, потому что она исходит из

1151
00:44:39,599 --> 00:44:40,640
исходного целевого

1152
00:44:40,640 --> 00:44:43,680
одноязычного набора данных, и поэтому

1153
00:44:43,680 --> 00:44:47,920
это очень мощный алгоритм,

1154
00:44:48,839 --> 00:44:52,079
потому что в

1155
00:44:52,079 --> 00:44:55,119
отличие от обучения ячеек здесь

1156
00:44:55,119 --> 00:44:55,839
цели чистые,

1157
00:44:55,839 --> 00:44:59,200
но ввод немного шумный, и

1158
00:44:59,200 --> 00:44:59,599
это

1159
00:44:59,599 --> 00:45:01,440
обычно намного лучше, чем наличие чистых

1160
00:45:01,440 --> 00:45:03,440
входов, но правильных целей с шумом, потому

1161
00:45:03,440 --> 00:45:05,119
что цели влияют

1162
00:45:05,119 --> 00:45:06,720
практически на все сигналы стрелок, которые

1163
00:45:06,720 --> 00:45:08,319
вы передаете через

1164
00:45:08,319 --> 00:45:11,359
nmt systems,

1165
00:45:11,440 --> 00:45:13,440
и это, и вы можете видеть по переводу,

1166
00:45:13,440 --> 00:45:15,119
- это способ увеличения данных,

1167
00:45:15,119 --> 00:45:19,040
потому что вы создаете шумную

1168
00:45:19,040 --> 00:45:22,079
версию входных данных для данной цели,

1169
00:45:22,079 --> 00:45:25,520
немного как в Vision, где они преуспевают,

1170
00:45:25,839 --> 00:45:27,359
я думаю, это не та

1171
00:45:27,359 --> 00:45:29,440
аудитория, чтобы делать это  аналогия, но если у

1172
00:45:29,440 --> 00:45:31,040
вас есть работа над зрением,

1173
00:45:31,040 --> 00:45:33,839
вы будете масштабировать вращение с различным

1174
00:45:33,839 --> 00:45:35,440
кадрированием, и это немного похоже

1175
00:45:35,440 --> 00:45:37,280
на то, что мы делаем здесь,

1176
00:45:37,280 --> 00:45:40,720
и поэтому алгоритм снова заключается в том, что вы

1177
00:45:40,720 --> 00:45:41,680
тренируете

1178
00:45:41,680 --> 00:45:43,200
магистраль и систему прямого машинного

1179
00:45:43,200 --> 00:45:45,359
перевода на параллельных данных

1180
00:45:45,359 --> 00:45:48,079
и  затем вы используете свою обратную модель для

1181
00:45:48,079 --> 00:45:48,960


1182
00:45:48,960 --> 00:45:51,119
декодирования одноязычного набора данных целевой стороны для

1183
00:45:51,119 --> 00:45:53,599
создания вспомогательного параллельного набора данных,

1184
00:45:53,599 --> 00:45:57,200
а затем

1185
00:45:57,200 --> 00:45:59,760
объединяете два набора данных, исходный набор данных

1186
00:45:59,760 --> 00:46:01,839
и вспомогательный, для

1187
00:46:01,839 --> 00:46:05,520
обучения новой прямой модели. Хорошо,

1188
00:46:05,520 --> 00:46:08,319
конечно, вы можете комбинировать сатрани и

1189
00:46:08,319 --> 00:46:10,560
плохой.  перевод, поэтому, если у вас есть как

1190
00:46:10,560 --> 00:46:12,560
исходный одноязычный набор данных, так и целевое

1191
00:46:12,560 --> 00:46:14,800
мономинг с набором данных,

1192
00:46:14,800 --> 00:46:18,000
вы можете сделать следующее, чтобы вы могли

1193
00:46:18,000 --> 00:46:20,240
использовать параллельные данные для обучения  ward

1194
00:46:20,240 --> 00:46:21,760
и обратная система машинного перевода

1195
00:46:21,760 --> 00:46:22,319
,

1196
00:46:22,319 --> 00:46:25,680
а затем на втором шаге вы можете

1197
00:46:25,680 --> 00:46:28,960
использовать прямую модель для декодирования,

1198
00:46:28,960 --> 00:46:31,280
чтобы перевести одноязычный

1199
00:46:31,280 --> 00:46:32,000
набор данных

1200
00:46:32,000 --> 00:46:35,520
на стороне источника в эти данные, и вы можете

1201
00:46:35,520 --> 00:46:38,319
использовать обратную систему машинного перевода

1202
00:46:38,319 --> 00:46:39,200
для

1203
00:46:39,200 --> 00:46:41,280
перевода целевой simulink с решением

1204
00:46:41,280 --> 00:46:43,920
в эти

1205
00:46:43,920 --> 00:46:47,200
переводы в порядке, а затем вы относитесь к

1206
00:46:47,200 --> 00:46:50,079
этим параллельным предложениям как к реальным данным

1207
00:46:50,079 --> 00:46:52,160
и объединяете их с параллельным

1208
00:46:52,160 --> 00:46:53,040
набором данных,

1209
00:46:53,040 --> 00:46:55,359
и теперь вы переобучаете как прямую, так

1210
00:46:55,359 --> 00:46:58,000
и обратную системы машинного перевода,

1211
00:46:58,000 --> 00:47:00,400
и теперь, пока эти две улучшатся

1212
00:47:00,400 --> 00:47:01,520
, вы можете пойти

1213
00:47:01,520 --> 00:47:03,280
и сделать еще одну итерацию  посредством чего

1214
00:47:03,280 --> 00:47:05,119
вы снова читаете код,

1215
00:47:05,119 --> 00:47:07,280
вы повторно переводите исходный и

1216
00:47:07,280 --> 00:47:09,119
целевой знак на удаленных наборах данных, а затем

1217
00:47:09,119 --> 00:47:10,000
вы идете

1218
00:47:10,000 --> 00:47:13,760
и переобучаете их,

1219
00:47:14,400 --> 00:47:17,200
и это, насколько вы знаете, наиболее

1220
00:47:17,200 --> 00:47:19,440
эффективный способ использовать одноязычные

1221
00:47:19,440 --> 00:47:21,200
данные

1222
00:47:21,200 --> 00:47:25,839
на языках с ограниченными ресурсами в настоящее время

1223
00:47:27,040 --> 00:47:30,000
позвольте мне немного поговорить о том, как мы

1224
00:47:30,000 --> 00:47:30,720
можем проводить

1225
00:47:30,720 --> 00:47:33,200
многоязычное обучение, чтобы в этом случае у нас

1226
00:47:33,200 --> 00:47:35,520
были

1227
00:47:35,680 --> 00:47:37,839
параллельные наборы данных, но на разных

1228
00:47:37,839 --> 00:47:39,280
языковые пары,

1229
00:47:39,280 --> 00:47:42,160
и поэтому у вас есть набор пара-данных для

1230
00:47:42,160 --> 00:47:44,400
английского, непальского, для английского, хинди,

1231
00:47:44,400 --> 00:47:44,800
для

1232
00:47:44,800 --> 00:47:47,200
хинди, английского или непальского хинди, или любого их

1233
00:47:47,200 --> 00:47:49,200
подмножества,

1234
00:47:49,200 --> 00:47:52,880
и это очень просто, поэтому способ

1235
00:47:52,880 --> 00:47:54,960
его работы заключается в том, что у вас есть один

1236
00:47:54,960 --> 00:47:57,359
кодировщик и один  декодер в

1237
00:47:57,359 --> 00:48:00,559
порядке, и вы тренируетесь, контролируя

1238
00:48:00,559 --> 00:48:02,640
обучение,

1239
00:48:02,640 --> 00:48:05,359
единственное изменение, которое необходимо сделать, это

1240
00:48:05,359 --> 00:48:06,079
то, что

1241
00:48:06,079 --> 00:48:08,240
на входе кодировщика вы

1242
00:48:08,240 --> 00:48:09,280
объединяете

1243
00:48:09,280 --> 00:48:12,559
также токен, который указывает язык,

1244
00:48:12,559 --> 00:48:16,079
на который вы хотите переводить, и

1245
00:48:16,079 --> 00:48:18,800
поэтому кодировщик научится обрабатывать

1246
00:48:18,800 --> 00:48:20,240
несколько языков,

1247
00:48:20,240 --> 00:48:24,319
декодер также научится

1248
00:48:24,800 --> 00:48:27,920
создавать несколько языков,

1249
00:48:27,920 --> 00:48:29,920
и он выберет язык на

1250
00:48:29,920 --> 00:48:31,440
основе токена, указанного

1251
00:48:31,440 --> 00:48:34,880
на входе кодировщика, поэтому

1252
00:48:34,880 --> 00:48:36,480
обучение просто сводит к минимуму

1253
00:48:36,480 --> 00:48:38,400
потерю кросс-энтропии для всех параллельных

1254
00:48:38,400 --> 00:48:40,160
наборов данных, которые у вас есть,

1255
00:48:40,160 --> 00:48:44,000
где вы просто добавляете  дополнительный

1256
00:48:44,000 --> 00:48:46,400
токен в исходном предложении, который

1257
00:48:46,400 --> 00:48:47,839
указывает целевой

1258
00:48:47,839 --> 00:48:51,599
язык, который вы хотите перевести,

1259
00:48:52,880 --> 00:48:55,359
и единственное, что я хотел добавить

1260
00:48:55,359 --> 00:48:57,040
, это то, что часто

1261
00:48:57,040 --> 00:49:01,040
он нажимает i  Если вы предварительно обрабатываете данные

1262
00:49:01,040 --> 00:49:04,240
, я не уверен, что вы узнаете о

1263
00:49:04,240 --> 00:49:06,400
двухпартийном кодировании частей предложений, по

1264
00:49:06,400 --> 00:49:07,280
сути, о

1265
00:49:07,280 --> 00:49:10,559
способах сегментации слов на

1266
00:49:10,559 --> 00:49:15,040
слоги или частых инграммах символов,

1267
00:49:15,040 --> 00:49:17,280
и поэтому, если вы объедините эти данные

1268
00:49:17,280 --> 00:49:19,200
, чтобы изучить эти способы сегментирования

1269
00:49:19,200 --> 00:49:20,160
данных, тогда

1270
00:49:20,160 --> 00:49:21,920
также возможно, что для многих

1271
00:49:21,920 --> 00:49:23,520
языков существует значительная

1272
00:49:23,520 --> 00:49:25,359
часть общего словаря,

1273
00:49:25,359 --> 00:49:28,480
и поэтому это также помогает убедиться, что

1274
00:49:28,480 --> 00:49:31,200
вы можете хорошо выполнять перевод

1275
00:49:31,200 --> 00:49:32,880
нескольких языков

1276
00:49:32,880 --> 00:49:37,200
одновременно, и поэтому

1277
00:49:37,200 --> 00:49:40,640
до сих пор я пришел к выводу, что даже

1278
00:49:40,640 --> 00:49:42,400
без эффекта предметной области

1279
00:49:42,400 --> 00:49:44,480
существует множество парадигм обучения, в

1280
00:49:44,480 --> 00:49:46,640
зависимости от имеющихся данных, которые у вас

1281
00:49:46,640 --> 00:49:48,640


1282
00:49:48,640 --> 00:49:52,000
есть априори, очень сложно сказать, какой

1283
00:49:52,000 --> 00:49:54,640
метод работает лучше всего в настоящее время, потому что это

1284
00:49:54,640 --> 00:49:55,839
действительно зависит от

1285
00:49:55,839 --> 00:49:59,119
того, сколько данных у вас есть,

1286
00:49:59,119 --> 00:50:02,079
насколько разные домены и

1287
00:50:02,079 --> 00:50:03,359
какой язык  мощность, с которой вы

1288
00:50:03,359 --> 00:50:04,800
работаете,

1289
00:50:04,800 --> 00:50:07,440
например, домены могут быть очень

1290
00:50:07,440 --> 00:50:08,319
разными, но

1291
00:50:08,319 --> 00:50:11,280
если у вас много данных, возможно, это

1292
00:50:11,280 --> 00:50:14,160
не имеет большого значения

1293
00:50:14,559 --> 00:50:16,800
на практике, у нас есть ключевые ингредиенты  методы

1294
00:50:16,800 --> 00:50:18,480
шумоподавления кодирования

1295
00:50:18,480 --> 00:50:21,200
плохого перевода многоязычное обучение,

1296
00:50:21,200 --> 00:50:22,079
которые

1297
00:50:22,079 --> 00:50:25,520
работают довольно хорошо, и в настоящее

1298
00:50:25,520 --> 00:50:28,480
время область находится на стадии, на которой мы

1299
00:50:28,480 --> 00:50:30,319
пытаемся выяснить, как лучше всего

1300
00:50:30,319 --> 00:50:31,920
их объединить, и прямо сейчас есть

1301
00:50:31,920 --> 00:50:32,960
много того,

1302
00:50:32,960 --> 00:50:35,839
что я бы сказал мастерство э-э, чтобы

1303
00:50:35,839 --> 00:50:38,000
понять  узнайте, как лучше всего их объединить,

1304
00:50:38,000 --> 00:50:42,160
и гм, но, надеюсь, мы сможем найти,

1305
00:50:42,160 --> 00:50:43,680
и я думаю, что есть много усилий,

1306
00:50:43,680 --> 00:50:45,200
чтобы попытаться автоматизировать этот процесс, потому что

1307
00:50:45,200 --> 00:50:46,240
прямо сейчас

1308
00:50:46,240 --> 00:50:48,800
гм, есть много перекрестной проверки, я

1309
00:50:48,800 --> 00:50:49,760
бы сказал, чтобы

1310
00:50:49,760 --> 00:50:52,880
выяснить все эти гиперпараметры

1311
00:50:52,880 --> 00:50:57,440
Итак, открытые проблемы здесь

1312
00:50:57,440 --> 00:51:01,040
связаны с разнообразием

1313
00:51:01,040 --> 00:51:04,960
доменов, имеющих дело с наборами данных, которые

1314
00:51:04,960 --> 00:51:08,160
имеют очень сильно различающееся

1315
00:51:08,160 --> 00:51:10,319
качество перевода, некоторые очень шумные,

1316
00:51:10,319 --> 00:51:12,000
некоторые очень чистые, имеют

1317
00:51:12,000 --> 00:51:14,319
дело с разными с наборами данных

1318
00:51:14,319 --> 00:51:16,000
разного размера

1319
00:51:16,000 --> 00:51:19,440
и очень разными языковыми парами,

1320
00:51:21,280 --> 00:51:24,720
и да  и поэтому я бы сказал, что в

1321
00:51:24,720 --> 00:51:27,280
целом это может показаться нелогичным, но

1322
00:51:27,280 --> 00:51:29,440
работа с машинным переводом с низким уровнем ресурсов

1323
00:51:29,440 --> 00:51:31,359
означает не

1324
00:51:31,359 --> 00:51:34,000
обучение небольших моделей на небольших данных,

1325
00:51:34,000 --> 00:51:35,280
а  На самом деле это означает обучение

1326
00:51:35,280 --> 00:51:37,839
даже более крупных моделей на еще большем количестве данных,

1327
00:51:37,839 --> 00:51:39,280
потому что вам нужно компенсировать

1328
00:51:39,280 --> 00:51:40,559
отсутствие надзора,

1329
00:51:40,559 --> 00:51:42,559
который у вас есть, прямого надзора, который у

1330
00:51:42,559 --> 00:51:44,559
вас

1331
00:51:44,559 --> 00:51:48,000
очень хороший, прежде чем я продолжу, есть ли какие-либо

1332
00:51:48,000 --> 00:51:49,280
вопросы

1333
00:51:49,280 --> 00:51:50,880
эм да у меня только что был быстрый вопрос

1334
00:51:50,880 --> 00:51:52,640
относительно эм в

1335
00:51:52,640 --> 00:51:54,880
В некоторых из предыдущих алгоритмов, которые

1336
00:51:54,880 --> 00:51:56,079
вы

1337
00:51:56,079 --> 00:51:59,839
описали, необходимо ли полностью переобучить, например,

1338
00:51:59,839 --> 00:52:02,240
полностью переобучить модель, или

1339
00:52:02,240 --> 00:52:04,000
есть какой-то способ дополнить

1340
00:52:04,000 --> 00:52:07,040
модель или настроить ее

1341
00:52:07,040 --> 00:52:10,880
на сгенерированном, так

1342
00:52:10,880 --> 00:52:12,800
что на самом деле обычно происходит то, что  что при

1343
00:52:12,800 --> 00:52:14,160
итерации

1344
00:52:14,160 --> 00:52:17,440
вы можете увеличить модель, поэтому,

1345
00:52:17,440 --> 00:52:19,920
когда вы включаете параллельный набор данных,

1346
00:52:19,920 --> 00:52:22,079
обычно это не так много данных, и поэтому вам

1347
00:52:22,079 --> 00:52:23,280
нужно тренироваться в чем-то маленьком,

1348
00:52:23,280 --> 00:52:24,000
иначе вы

1349
00:52:24,000 --> 00:52:27,520
перегреетесь слишком сильно, но как только вы добавите

1350
00:52:27,520 --> 00:52:30,559
одноязычные данные, которые вы

1351
00:52:30,559 --> 00:52:34,400
это 80  набор данных, тогда эта модель

1352
00:52:34,400 --> 00:52:36,079
может быть намного больше, чем исходная

1353
00:52:36,079 --> 00:52:37,520
модель,

1354
00:52:37,520 --> 00:52:40,720
теперь не

1355
00:52:40,720 --> 00:52:44,559
очень очевидно, как

1356
00:52:44,640 --> 00:52:46,559
вы знаете, что инициализируйте большую модель

1357
00:52:46,559 --> 00:52:48,160
из меньшей модели

1358
00:52:48,160 --> 00:52:51,280
, поэтому люди обычно  инициализировать

1359
00:52:51,280 --> 00:52:52,640
из случайного набора

1360
00:52:52,640 --> 00:52:56,880
на следующих итерациях вы можете

1361
00:52:57,680 --> 00:52:59,920
инициализировать из модели на

1362
00:52:59,920 --> 00:53:02,000
предыдущей итерации

1363
00:53:02,000 --> 00:53:03,520
то, что мы обычно обнаруживаем, так это то, что

1364
00:53:03,520 --> 00:53:06,000
случайная инициализация

1365
00:53:06,000 --> 00:53:10,559
обычно также работает

1366
00:53:10,800 --> 00:53:15,040
спасибо спасибо

1367
00:53:15,040 --> 00:53:18,079
хорошо любой другой вопрос,

1368
00:53:18,079 --> 00:53:20,640
когда вы говорите, что вы обычно модель

1369
00:53:20,640 --> 00:53:21,119
учится,

1370
00:53:21,119 --> 00:53:23,440
я был  интересно, вы имеете в виду, что вы

1371
00:53:23,440 --> 00:53:24,720
добавляете э-э,

1372
00:53:24,720 --> 00:53:26,880
больше слоев или больше параметров э-э,

1373
00:53:26,880 --> 00:53:28,480
поскольку модель продолжает обучение

1374
00:53:28,480 --> 00:53:33,520
ой, обычно вы просто

1375
00:53:37,520 --> 00:53:39,839
увеличиваете да, тем больше слоев больше параметра, так

1376
00:53:39,839 --> 00:53:43,360
что шире или глубже

1377
00:53:43,360 --> 00:53:45,119
[Музыка]

1378
00:53:45,119 --> 00:53:48,640
я думаю, обычно

1379
00:53:50,000 --> 00:53:52,240
да, я  не совсем уверен, что есть

1380
00:53:52,240 --> 00:53:53,980
однозначный ответ на этот вопрос, что

1381
00:53:53,980 --> 00:53:55,520
[Музыка],

1382
00:53:55,520 --> 00:53:58,960
как правило, делает кодировщик глубже - это

1383
00:53:58,960 --> 00:54:00,640
хорошо,

1384
00:54:00,640 --> 00:54:02,400
делая декодер глубже,

1385
00:54:02,400 --> 00:54:03,760
вам не очень много

1386
00:54:03,760 --> 00:54:06,960
гм, поэтому обычно мы играем с кодировщиком, я

1387
00:54:06,960 --> 00:54:08,240
бы сказал,

1388
00:54:08,240 --> 00:54:12,480
и гм, но да,

1389
00:54:12,480 --> 00:54:14,160
нет  такая большая разница на

1390
00:54:14,160 --> 00:54:16,800
практике, я бы сказал,

1391
00:54:16,800 --> 00:54:20,720
да, вы можете себе представить, что просто

1392
00:54:20,720 --> 00:54:22,800
удвоите размер вашего скрытого состояния,

1393
00:54:22,800 --> 00:54:25,839
которое будет работать

1394
00:54:26,559 --> 00:54:29,680
нормально, хорошо,

1395
00:54:29,680 --> 00:54:33,440
так что давайте посмотрим, как это, так что я не

1396
00:54:33,440 --> 00:54:35,119
говорил о моделях, но я говорил  об

1397
00:54:35,119 --> 00:54:37,119
алгоритмах вы можете немного превратить эти алгоритмы

1398
00:54:37,119 --> 00:54:37,599
в

1399
00:54:37,599 --> 00:54:39,520
модели и поговорить о совместном

1400
00:54:39,520 --> 00:54:41,920
маржинальном распределении распределения, но,

1401
00:54:41,920 --> 00:54:44,400
на мой взгляд, это просто проще думать в

1402
00:54:44,400 --> 00:54:45,200
терминах

1403
00:54:45,200 --> 00:54:48,799
алгоритмов, потому что также то, как

1404
00:54:48,799 --> 00:54:52,400
мы их реализуем, и поэтому давайте посмотрим, как

1405
00:54:52,400 --> 00:54:53,839
эти алгоритмы могут быть

1406
00:54:53,839 --> 00:54:56,559
помещены  вместе в некоторых интересных тематических

1407
00:54:56,559 --> 00:54:57,200
исследованиях,

1408
00:54:57,200 --> 00:54:59,599
поэтому на самом деле я понимаю, что я действительно

1409
00:54:59,599 --> 00:55:00,720
иду медленно,

1410
00:55:00,720 --> 00:55:03,599
поэтому давайте рассмотрим случай, когда у вас

1411
00:55:03,599 --> 00:55:05,680
есть только одноязычные данные и нет параллельных

1412
00:55:05,680 --> 00:55:06,160
данных,

1413
00:55:06,160 --> 00:55:08,559
поэтому это то, что мы называем неконтролируемым

1414
00:55:08,559 --> 00:55:10,400
машинным переводом,

1415
00:55:10,400 --> 00:55:12,559
поэтому допустим, что у вас есть английский

1416
00:55:12,559 --> 00:55:15,040
и  набор данных на французском языке

1417
00:55:15,040 --> 00:55:17,280
это не типичный вариант использования

1418
00:55:17,280 --> 00:55:18,880
машинного перевода с учителем, но

1419
00:55:18,880 --> 00:55:19,599
именно здесь

1420
00:55:19,599 --> 00:55:22,319
он работает очень хорошо, поэтому давайте сосредоточимся на

1421
00:55:22,319 --> 00:55:24,160
этом сейчас

1422
00:55:24,160 --> 00:55:26,240
, поэтому вы берете предложение из

1423
00:55:26,240 --> 00:55:28,240
целевого исходного набора данных, вы просматриваете

1424
00:55:28,240 --> 00:55:30,240
свой кодировщик-декодер, и вы

1425
00:55:30,240 --> 00:55:32,079
сделать перевод на английский язык, очевидно, у вас

1426
00:55:32,079 --> 00:55:34,079
нет ссылки здесь,

1427
00:55:34,079 --> 00:55:37,920
поэтому вы могли бы приспособить его к

1428
00:55:37,920 --> 00:55:39,599
системе машинного перевода, которая

1429
00:55:39,599 --> 00:55:41,440
с английского на французский,

1430
00:55:41,440 --> 00:55:43,359
так что вы как бы реконструируете свое

1431
00:55:43,359 --> 00:55:45,040
исходное французское предложение, и теперь

1432
00:55:45,040 --> 00:55:45,520
у

1433
00:55:45,520 --> 00:55:48,160
вас есть узкий сигнал для обратного

1434
00:55:48,160 --> 00:55:49,839
распространения через вашу

1435
00:55:49,839 --> 00:55:51,680
систему машинного перевода, вы можете сделать

1436
00:55:51,680 --> 00:55:53,040
то же самое, переходя с

1437
00:55:53,040 --> 00:55:55,839
английского на французский на английский, это

1438
00:55:55,839 --> 00:55:57,200
очень много, что люди  сделали в

1439
00:55:57,200 --> 00:55:57,760
видении,

1440
00:55:57,760 --> 00:55:59,920
они называют это психической согласованностью, вы можете

1441
00:55:59,920 --> 00:56:01,520
видеть это как не кодировщик, где

1442
00:56:01,520 --> 00:56:02,160
промежуточное

1443
00:56:02,160 --> 00:56:05,440
представление, как

1444
00:56:05,680 --> 00:56:09,200
вы знаете, является языком на английском

1445
00:56:09,200 --> 00:56:12,000
языке, проблема в том, что, поскольку это модель

1446
00:56:12,000 --> 00:56:14,319
, не ограничена для создания чего-то,

1447
00:56:14,319 --> 00:56:14,960
что

1448
00:56:14,960 --> 00:56:18,319
является беглым английским предложением  поэтому

1449
00:56:18,319 --> 00:56:19,760
в региональной области люди используют

1450
00:56:19,760 --> 00:56:21,359
состязательное обучение, но

1451
00:56:21,359 --> 00:56:23,680
в nlp это довольно сложно, потому что

1452
00:56:23,680 --> 00:56:26,400
это дискретная последовательность, и поэтому

1453
00:56:26,400 --> 00:56:28,240
для того, чтобы убедиться, что этот декодер

1454
00:56:28,240 --> 00:56:30,160
генерирует английские

1455
00:56:30,160 --> 00:56:32,480
бегло-английские предложения, вы могли бы

1456
00:56:32,480 --> 00:56:33,440
представить, чтобы

1457
00:56:33,440 --> 00:56:35,200
сделать шум и кодирование правильно, чтобы вы

1458
00:56:35,200 --> 00:56:38,000
могли  возьмите, а не вы могли бы взять

1459
00:56:38,000 --> 00:56:39,839
английское предложение nosify,

1460
00:56:39,839 --> 00:56:41,920
пройти через автоматическое кодирование шумоподавителя,

1461
00:56:41,920 --> 00:56:43,920
теперь этот декодер является тем же блоком, что

1462
00:56:43,920 --> 00:56:44,960
Если у вас есть здесь,

1463
00:56:44,960 --> 00:56:46,640
вам придется изучить

1464
00:56:46,640 --> 00:56:49,119
статистику и

1465
00:56:49,119 --> 00:56:52,400
закономерности английского языка,

1466
00:56:52,880 --> 00:56:55,200
проблема в том, что если вы посмотрите на этот

1467
00:56:55,200 --> 00:56:56,400
декодер,

1468
00:56:56,400 --> 00:57:00,240
этот декодер находится в игре с автоматическим кодированием шумов,

1469
00:57:00,240 --> 00:57:01,200


1470
00:57:01,200 --> 00:57:04,319
он работает на выходе этого

1471
00:57:04,319 --> 00:57:07,599
кодировщика, который принимает  английский в качестве входных данных

1472
00:57:07,599 --> 00:57:08,400
здесь

1473
00:57:08,400 --> 00:57:11,040
кодировщик принимает французский в качестве входных данных,

1474
00:57:11,040 --> 00:57:12,720
вполне может быть,

1475
00:57:12,720 --> 00:57:14,799
что представление, созданное этими двумя

1476
00:57:14,799 --> 00:57:15,760
кодировщиками

1477
00:57:15,760 --> 00:57:18,480
, отличается, поэтому этот декодер может

1478
00:57:18,480 --> 00:57:19,839
очень хорошо работать в настройке, но

1479
00:57:19,839 --> 00:57:22,640
не в этой настройке, и поэтому другими способами,

1480
00:57:22,640 --> 00:57:24,160
как можно  мы следим за тем, чтобы

1481
00:57:24,160 --> 00:57:26,960
эти красные и синие блоки

1482
00:57:26,960 --> 00:57:28,400
взаимозаменяемы,

1483
00:57:28,400 --> 00:57:31,040
как мы можем убедиться, что существует хорошая

1484
00:57:31,040 --> 00:57:32,400
модульность,

1485
00:57:32,400 --> 00:57:34,880
и поэтому один из способов сделать это -

1486
00:57:34,880 --> 00:57:36,160
использовать трюк, который мы используем

1487
00:57:36,160 --> 00:57:38,640
для многоязычного обучения, при котором у

1488
00:57:38,640 --> 00:57:40,559
нас есть один кодировщик

1489
00:57:40,559 --> 00:57:43,119
и один декодер  поэтому декодер

1490
00:57:43,119 --> 00:57:44,240
используется на

1491
00:57:44,240 --> 00:57:46,880
французском и английском языках, а кодировщик -

1492
00:57:46,880 --> 00:57:47,599
на

1493
00:57:47,599 --> 00:57:50,480
английском и французском языках, и мы указываем

1494
00:57:50,480 --> 00:57:51,839
целевой язык с

1495
00:57:51,839 --> 00:57:55,440
помощью дополнительного токена на входе

1496
00:57:55,440 --> 00:57:58,480
и частично  icular, если вы изучаете общие биты в

1497
00:57:58,480 --> 00:58:00,640
секунду и если вы разделяете параметры,

1498
00:58:00,640 --> 00:58:02,400
то этот процесс,

1499
00:58:02,400 --> 00:58:04,960
извините, этот процесс действительно работает,

1500
00:58:04,960 --> 00:58:06,079
и у вас

1501
00:58:06,079 --> 00:58:09,520
есть декодер, который хорошо работает

1502
00:58:09,520 --> 00:58:11,680
всякий раз, когда он получает скрытое состояние,

1503
00:58:11,680 --> 00:58:12,640
которое исходит

1504
00:58:12,640 --> 00:58:15,280
от кодировщика, работающего на английском или

1505
00:58:15,280 --> 00:58:16,799
французском языках

1506
00:58:16,799 --> 00:58:19,920
и  так что снова ключевые ингредиенты

1507
00:58:19,920 --> 00:58:21,440
повторяются путем

1508
00:58:21,440 --> 00:58:23,760
кодирования с шумоподавлением перевода и многоязычного

1509
00:58:23,760 --> 00:58:24,720
обучения,

1510
00:58:24,720 --> 00:58:26,640
а для неконтролируемого машинного перевода

1511
00:58:26,640 --> 00:58:28,319
мы делаем

1512
00:58:28,319 --> 00:58:31,280
плохой перевод в онлайн-режиме, в

1513
00:58:31,280 --> 00:58:33,599
результате чего для данной мини-партии

1514
00:58:33,599 --> 00:58:37,359
мы делаем плохой перевод, мы не делаем этого

1515
00:58:37,359 --> 00:58:39,440
с устаревшей версией  модель,

1516
00:58:39,440 --> 00:58:40,640
но вы могли бы сделать

1517
00:58:40,640 --> 00:58:43,760
то, что работает хуже,

1518
00:58:43,760 --> 00:58:46,240
и поэтому, когда вы делаете это с английскими

1519
00:58:46,240 --> 00:58:48,480
друзьями, вы обнаруживаете, что на

1520
00:58:48,480 --> 00:58:50,400
самом деле вы можете получить довольно хорошую

1521
00:58:50,400 --> 00:58:52,559
производительность, синий цвет 30

1522
00:58:52,559 --> 00:58:54,079
обычно дает вам довольно беглые

1523
00:58:54,079 --> 00:58:55,599
переводы, которые

1524
00:58:55,599 --> 00:58:59,520
также адекватны, и если вы сравните это

1525
00:58:59,520 --> 00:59:01,079
к тому, что вы получили с

1526
00:59:01,079 --> 00:59:03,839
контролируемым базовым уровнем, который обучен

1527
00:59:03,839 --> 00:59:06,240
на параллельном наборе данных, вы обнаружите, что

1528
00:59:06,240 --> 00:59:08,880
обучение на 10 миллионах одноязычных

1529
00:59:08,880 --> 00:59:09,920
предложений

1530
00:59:09,920 --> 00:59:11,920
на английском и миллионном французском дает

1531
00:59:11,920 --> 00:59:14,480
вам ту же

1532
00:59:14,480 --> 00:59:16,319
точность перевода, что и обучение

1533
00:59:16,319 --> 00:59:18,079
контролируемой базовой линии, то есть

1534
00:59:18,079 --> 00:59:21,200
эта красная

1535
00:59:21,200 --> 00:59:24,559
кривая, на самом деле эта красная кривая, эта синяя

1536
00:59:24,559 --> 00:59:26,000
кривая, и эта кривая, это

1537
00:59:26,000 --> 00:59:27,680
нейронная версия, это версия на основе фраз

1538
00:59:27,680 --> 00:59:28,960


1539
00:59:28,960 --> 00:59:31,359
с сотнями тысяч параллельных предложений,

1540
00:59:31,359 --> 00:59:32,000
поэтому

1541
00:59:32,000 --> 00:59:35,119
Другими словами, каждая

1542
00:59:35,119 --> 00:59:39,119
пара параллельных предложений эквивалентна

1543
00:59:39,119 --> 00:59:42,400
сотне одноязычных предложений,

1544
00:59:42,400 --> 00:59:44,079
эквивалентных в том смысле, что они дают

1545
00:59:44,079 --> 00:59:46,319
вам систему машинного перевода

1546
00:59:46,319 --> 00:59:49,520
с аналогичной

1547
00:59:49,760 --> 00:59:53,040
точностью, и поэтому

1548
00:59:53,040 --> 00:59:56,000
теперь, чем больше домены разные

1549
00:59:56,000 --> 00:59:57,119
и чем

1550
00:59:57,119 --> 00:59:59,760
больше языки отличаются друг от друга,

1551
00:59:59,760 --> 01:00:01,040


1552
01:00:01,040 --> 01:00:03,520
тем хуже  получает, и поэтому, когда

1553
01:00:03,520 --> 01:00:04,480
вы делаете

1554
01:00:04,480 --> 01:00:06,319
более крупный машинный перевод, это

1555
01:00:06,319 --> 01:00:08,000
крайний случай неконтролируемого машинного

1556
01:00:08,000 --> 01:00:09,440
перевода, вам нужно

1557
01:00:09,440 --> 01:00:11,760
учиться на большом количестве данных, чтобы

1558
01:00:11,760 --> 01:00:13,040
компенсировать

1559
01:00:13,040 --> 01:00:16,720
отсутствие надзора за крысами,

1560
01:00:18,480 --> 01:00:22,480
я, возможно,

1561
01:00:22,480 --> 01:00:26,640
дам вам пример  flores, где

1562
01:00:26,640 --> 01:00:28,720
для flores, как мы видели, не было

1563
01:00:28,720 --> 01:00:30,079


1564
01:00:30,079 --> 01:00:33,280
параллельных данных в домене, были некоторые одноязычные

1565
01:00:33,280 --> 01:00:34,960
данные  это было в домене,

1566
01:00:34,960 --> 01:00:37,200
но не очень много, и было довольно

1567
01:00:37,200 --> 01:00:38,319
много осени

1568
01:00:38,319 --> 01:00:41,599
вне доменных параллельных данных, вы

1569
01:00:41,599 --> 01:00:42,880
помните 1 миллион предложений

1570
01:00:42,880 --> 01:00:46,799
из Библии и ubuntu,

1571
01:00:46,799 --> 01:00:48,559
а затем у нас есть довольно много

1572
01:00:48,559 --> 01:00:51,680
одноязычных данных, которые являются автоматическим доменом,

1573
01:00:51,680 --> 01:00:55,520
и поэтому это  контролируемый базовый уровень

1574
01:00:55,520 --> 01:00:56,960
и неконтролируемый машинный перевод

1575
01:00:56,960 --> 01:00:59,200
здесь вообще не работали, потому что

1576
01:00:59,200 --> 01:01:02,000
очень похоже на то, что уже упоминалось, что

1577
01:01:02,000 --> 01:01:04,480
домены википедии не совсем

1578
01:01:04,480 --> 01:01:07,280
выровнены, и поэтому у этого нет

1579
01:01:07,280 --> 01:01:10,240
неконтролируемого машинного перевода, если вы

1580
01:01:10,240 --> 01:01:10,559
выполняете

1581
01:01:10,559 --> 01:01:12,319
обратный перевод, если вы выполняете итерацию

1582
01:01:12,319 --> 01:01:13,920
переводом, вы  сделать немного лучше,

1583
01:01:13,920 --> 01:01:15,920
чем контролируемая базовая линия,

1584
01:01:15,920 --> 01:01:19,440
что неплохо, но теперь, если вы добавляете

1585
01:01:19,440 --> 01:01:23,040
также параллельные данные на английском хинди, вы делаете

1586
01:01:23,040 --> 01:01:25,040
немного лучше, и теперь также

1587
01:01:25,040 --> 01:01:26,880
работает неконтролируемый машинный перевод,

1588
01:01:26,880 --> 01:01:28,400
он контролируется для

1589
01:01:28,400 --> 01:01:29,760
английского непальский, но у вас есть

1590
01:01:29,760 --> 01:01:32,480
контроль за английским  хинди,

1591
01:01:32,480 --> 01:01:34,240
и поэтому комбинация плохого

1592
01:01:34,240 --> 01:01:37,119
перевода и

1593
01:01:37,119 --> 01:01:39,119
многоязычного обучения здесь является

1594
01:01:39,119 --> 01:01:40,799
выигрышной комбинацией,

1595
01:01:40,799 --> 01:01:43,359
и это то, что мы видим э-

1596
01:01:43,359 --> 01:01:44,799
э  в целом

1597
01:01:44,799 --> 01:01:48,000
хорошо, так что я пропущу результаты по

1598
01:01:48,000 --> 01:01:49,760
английским вермиам на

1599
01:01:49,760 --> 01:01:52,400
самом деле у меня была хорошая демонстрация, но я

1600
01:01:52,400 --> 01:01:56,319
собираюсь показать ее вам позже, если будет время,

1601
01:01:56,960 --> 01:02:00,079
и поэтому, как я уже сказал, у нас есть

1602
01:02:00,079 --> 01:02:03,680
довольно много хороших компонентов, которые мы  прямо сейчас можно

1603
01:02:03,680 --> 01:02:05,440
легко комбинировать,

1604
01:02:05,440 --> 01:02:08,640
исследование посвящено тому, как

1605
01:02:08,640 --> 01:02:10,559
лучше всего их объединить, как лучше всего

1606
01:02:10,559 --> 01:02:12,319
взвесить наборы данных, как лучше всего использовать

1607
01:02:12,319 --> 01:02:15,119
примеры, чтобы

1608
01:02:15,119 --> 01:02:18,000
автоматизировать текущий процесс, основанный на перекрестной проверке,

1609
01:02:18,000 --> 01:02:20,240
я бы сказал,

1610
01:02:20,240 --> 01:02:24,160
и другое сообщение здесь заключается в том, что это

1611
01:02:24,160 --> 01:02:25,920
ресурсная машина  перевод - это проблема с большими

1612
01:02:25,920 --> 01:02:28,799
данными, он требует больших вычислений

1613
01:02:28,799 --> 01:02:31,920
, это довольно большой инженерный подвиг

1614
01:02:31,920 --> 01:02:36,319
, чтобы компенсировать нехватку

1615
01:02:36,319 --> 01:02:39,200
параллельных данных, есть ли по этому поводу какие-либо вопросы,

1616
01:02:39,200 --> 01:02:40,960


1617
01:02:40,960 --> 01:02:42,720
мне просто интересно, когда вы упомянули,

1618
01:02:42,720 --> 01:02:44,720
что параллельность

1619
01:02:44,720 --> 01:02:47,359
видению и согласованность цикла, о которой вы

1620
01:02:47,359 --> 01:02:49,520
упомянули  что мы не можем проводить состязательную

1621
01:02:49,520 --> 01:02:52,559
тренировку, да, и мне просто интересно, можете

1622
01:02:52,559 --> 01:02:54,000
ли вы это высветить, и почему мы

1623
01:02:54,000 --> 01:02:56,160
не можем просто использовать say как

1624
01:02:56,160 --> 01:02:59,760
lstm и выполнять состязательную тренировку

1625
01:02:59,760 --> 01:03:02,240
да да да, так что есть  на самом деле

1626
01:03:02,240 --> 01:03:04,240
куча документов, пытающихся провести

1627
01:03:04,240 --> 01:03:07,359
обучение противников или обучение в

1628
01:03:07,359 --> 01:03:10,400
стиле оружия для

1629
01:03:10,400 --> 01:03:14,079
налоговых сборов, я должен сказать, что

1630
01:03:14,079 --> 01:03:17,280
это довольно активная область исследований,

1631
01:03:17,280 --> 01:03:18,319
я не

1632
01:03:18,319 --> 01:03:20,640
видел очень убедительной демонстрации того, что

1633
01:03:20,640 --> 01:03:23,440
эти методы работают очень хорошо с испытанными

1634
01:03:23,440 --> 01:03:26,400
и  это немного сложно распространять,

1635
01:03:26,400 --> 01:03:27,039
поэтому,

1636
01:03:27,039 --> 01:03:29,039
когда это создает предложение, вам нужно

1637
01:03:29,039 --> 01:03:30,319


1638
01:03:30,319 --> 01:03:32,640
создать предложение, которое вы знаете, и оно

1639
01:03:32,640 --> 01:03:33,599
дискретное,

1640
01:03:33,599 --> 01:03:36,079
и поэтому вы можете распространять его с помощью

1641
01:03:36,079 --> 01:03:38,880
методов подкрепления, которые вы могли бы

1642
01:03:38,880 --> 01:03:42,240
делать много из этих вещей, но по сути

1643
01:03:42,240 --> 01:03:45,920
это просто немного сложно  заставить его работать,

1644
01:03:45,920 --> 01:03:47,760
и он очень привередлив,

1645
01:03:47,760 --> 01:03:51,200
поэтому он может работать с простыми наборами данных, но

1646
01:03:51,200 --> 01:03:52,400
в масштабе

1647
01:03:52,400 --> 01:03:54,240
это очень сложно, поэтому еще

1648
01:03:54,240 --> 01:03:55,760
одно соображение заключается в том, что

1649
01:03:55,760 --> 01:03:57,680
все, что вы делаете, должно работать в

1650
01:03:57,680 --> 01:03:59,200
масштабе, потому что

1651
01:03:59,200 --> 01:04:01,680
снова значение объема

1652
01:04:01,680 --> 01:04:03,200
информации, которое вы получаете от

1653
01:04:03,200 --> 01:04:05,760
одноязычное предложение - это не очень много,

1654
01:04:05,760 --> 01:04:07,440
и теперь, если вы много вычисляете, если у

1655
01:04:07,440 --> 01:04:09,599
вас или если в ваших

1656
01:04:09,599 --> 01:04:12,160
градиентах много шума, например, когда вы пьете с

1657
01:04:12,160 --> 01:04:15,039
тропическим лесом, тогда

1658
01:04:15,039 --> 01:04:18,640
это не гой  нг для работы возможно,

1659
01:04:18,640 --> 01:04:19,039


1660
01:04:19,039 --> 01:04:20,720
что люди придумают способы заставить это

1661
01:04:20,720 --> 01:04:24,000
работать, я не думаю, что

1662
01:04:24,000 --> 01:04:26,400
это закончено в настоящее время, но это может

1663
01:04:26,400 --> 01:04:27,599
быть в будущем,

1664
01:04:27,599 --> 01:04:29,520
поэтому позвольте мне потратить пять минут на

1665
01:04:29,520 --> 01:04:31,039
анализ,

1666
01:04:31,039 --> 01:04:32,799
а затем у вас будут слайды  так что вы

1667
01:04:32,799 --> 01:04:34,480
можете пройтись

1668
01:04:34,480 --> 01:04:38,000
по остальным деталям, так что здесь,

1669
01:04:38,000 --> 01:04:40,559
мы, поэтому отправной точкой является хорошо,

1670
01:04:40,559 --> 01:04:41,359
если бы

1671
01:04:41,359 --> 01:04:43,520
я моделировал машинный перевод с низким уровнем ресурсов

1672
01:04:43,520 --> 01:04:44,880
с помощью языка с высокими ресурсами,

1673
01:04:44,880 --> 01:04:46,640
например с французского на английский,

1674
01:04:46,640 --> 01:04:48,960
допустим, вы берете данные европы, которые у вас есть

1675
01:04:48,960 --> 01:04:51,119
, скажем, 20  000 параллельных предложений и

1676
01:04:51,119 --> 01:04:51,920
сотни тысяч

1677
01:04:51,920 --> 01:04:54,319
языковых целевых предложений, и вы применили

1678
01:04:54,319 --> 01:04:56,000
их переводом, теперь у вас есть очень хорошее

1679
01:04:56,000 --> 01:04:57,119
улучшение,

1680
01:04:57,119 --> 01:05:00,240
если вы зайдете сюда на facebook и

1681
01:05:00,240 --> 01:05:01,359
попробуете это на

1682
01:05:01,359 --> 01:05:04,240
данных facebook, вы обнаружите, что

1683
01:05:04,240 --> 01:05:05,680
улучшение на самом деле

1684
01:05:05,680 --> 01:05:08,960
очень минимальное и относится

1685
01:05:08,960 --> 01:05:10,559
к обсуждению  что у нас было в самом

1686
01:05:10,559 --> 01:05:11,680
начале, что

1687
01:05:11,680 --> 01:05:13,599
то, о чем люди говорят в разных

1688
01:05:13,599 --> 01:05:15,599
частях мира, очень разное,

1689
01:05:15,599 --> 01:05:18,640
и теперь вам нужно, как будто вам

1690
01:05:18,640 --> 01:05:19,520
нужно выровнять

1691
01:05:19,520 --> 01:05:22,480
два облака точек, но  Распределение

1692
01:05:22,480 --> 01:05:23,920
этих двух облаков точек

1693
01:05:23,920 --> 01:05:25,520
очень сильно отличается друг от друга, поэтому

1694
01:05:25,520 --> 01:05:28,079
их очень сложно выровнять,

1695
01:05:28,079 --> 01:05:29,760
и поэтому здесь я привел пример,

1696
01:05:29,760 --> 01:05:31,920
что даже для англоязычных стран,

1697
01:05:31,920 --> 01:05:33,839
если вы посмотрите на

1698
01:05:33,839 --> 01:05:36,960
темы о спорте, у вас есть это

1699
01:05:36,960 --> 01:05:38,720
в Америке.  может больше говорить

1700
01:05:38,720 --> 01:05:40,160
о футболе и

1701
01:05:40,160 --> 01:05:42,799
бейсболе в Великобритании, больше о крикете и футболе,

1702
01:05:42,799 --> 01:05:43,440


1703
01:05:43,440 --> 01:05:46,240
и поэтому для той же темы у вас есть

1704
01:05:46,240 --> 01:05:47,680
разные слова распределения, но у вас

1705
01:05:47,680 --> 01:05:48,480
также есть это

1706
01:05:48,480 --> 01:05:51,520
другое распределение тем,

1707
01:05:51,520 --> 01:05:54,079
и это то, что мы называем несоответствием исходного

1708
01:05:54,079 --> 01:05:55,760
целевого домена, поэтому

1709
01:05:55,760 --> 01:05:57,760
у вас может быть несколько видов несоответствия домена,

1710
01:05:57,760 --> 01:05:59,280
обычно у

1711
01:05:59,280 --> 01:06:01,839
вас есть несоответствие между обучающим

1712
01:06:01,839 --> 01:06:04,480
распределением и тестовым распределением,

1713
01:06:04,480 --> 01:06:06,240
здесь я также говорю о несоответствии

1714
01:06:06,240 --> 01:06:07,680
между исходным

1715
01:06:07,680 --> 01:06:09,760
доменом, исходным языком, исходным

1716
01:06:09,760 --> 01:06:11,359
доменом и целевым доменом,

1717
01:06:11,359 --> 01:06:14,880
хорошо, и поэтому есть  гипотеза о том, что

1718
01:06:14,880 --> 01:06:15,760
это может сделать

1719
01:06:15,760 --> 01:06:17,440
этот перевод менее эффективным, потому что

1720
01:06:17,440 --> 01:06:20,319
даже если вы однажды полностью переведете

1721
01:06:20,319 --> 01:06:22,319
одноязычные данные целевой стороны  вы

1722
01:06:22,319 --> 01:06:23,440
переводите его,

1723
01:06:23,440 --> 01:06:26,880
это будет вне домена

1724
01:06:26,880 --> 01:06:28,559
по отношению к данным, которые вы действительно

1725
01:06:28,559 --> 01:06:30,480
хотите перевести, которые происходят

1726
01:06:30,480 --> 01:06:32,160
в исходном домене,

1727
01:06:32,160 --> 01:06:36,160
и поэтому у нас был очень

1728
01:06:36,160 --> 01:06:38,079
хороший параметр управления для изучения этой

1729
01:06:38,079 --> 01:06:40,480
проблемы,

1730
01:06:40,720 --> 01:06:44,559
где мы создаем синтетический

1731
01:06:44,559 --> 01:06:46,799
набор данных, где источник  домен поступает

1732
01:06:46,799 --> 01:06:49,599
из данных парламента евро, а целевой

1733
01:06:49,599 --> 01:06:51,839
домен - из открытых субтитров,

1734
01:06:51,839 --> 01:06:53,520
которые перемещают подписи,

1735
01:06:53,520 --> 01:06:55,920
и теперь, создав целевой домен

1736
01:06:55,920 --> 01:06:56,880
как смесь

1737
01:06:56,880 --> 01:06:59,680
двух, вы можете точно контролировать степень

1738
01:06:59,680 --> 01:07:00,880


1739
01:07:00,880 --> 01:07:03,200
автономности между исходным и

1740
01:07:03,200 --> 01:07:04,720
целевым доменами

1741
01:07:04,720 --> 01:07:08,079
и варьируя альфа  вы можете изменить это,

1742
01:07:08,079 --> 01:07:09,520
и поэтому основным результатом

1743
01:07:09,520 --> 01:07:13,200
является эта цифра, где альфа измеряет,

1744
01:07:13,200 --> 01:07:14,319


1745
01:07:14,319 --> 01:07:17,440
насколько целевой домен uh похож на

1746
01:07:17,440 --> 01:07:18,720
исходный домен, поэтому, если пять

1747
01:07:18,720 --> 01:07:21,680
равно единице, все они находятся в

1748
01:07:21,680 --> 01:07:22,720
одном домене, если i

1749
01:07:22,720 --> 01:07:24,079
равно нулю, они  совсем другое,

1750
01:07:24,079 --> 01:07:26,160
один - евро по номиналу, а другой - с открытыми

1751
01:07:26,160 --> 01:07:27,440
субтитрами,

1752
01:07:27,440 --> 01:07:30,000
и поэтому оказывается, что в этом экстремальном

1753
01:07:30,000 --> 01:07:31,359
режиме на

1754
01:07:31,359 --> 01:07:33,839
самом деле самообучение, которое представляет собой эту красную

1755
01:07:33,839 --> 01:07:34,720
линию,

1756
01:07:34,720 --> 01:07:38,000
работает лучше, чем плохо  перевод, но по мере

1757
01:07:38,000 --> 01:07:39,599
того, как вы делаете домены все более и более

1758
01:07:39,599 --> 01:07:40,319
похожими

1759
01:07:40,319 --> 01:07:42,640
, перевод намного лучше, чем установка

1760
01:07:42,640 --> 01:07:43,440
обучения,

1761
01:07:43,440 --> 01:07:46,799
и оба они намного лучше, чем

1762
01:07:46,799 --> 01:07:48,319
просто, если бы вы использовали параллельные

1763
01:07:48,319 --> 01:07:50,640
данные,

1764
01:07:50,960 --> 01:07:53,920
так что я пропущу все это, вы можете

1765
01:07:53,920 --> 01:07:54,839
посмотреть  в

1766
01:07:54,839 --> 01:07:58,000
статье и на слайдах

1767
01:07:58,000 --> 01:08:00,079
я хочу сделать вывод, что есть другие

1768
01:08:00,079 --> 01:08:01,839
вещи, о которых я не говорил, например,

1769
01:08:01,839 --> 01:08:03,920
фильтрация, это одна из самых

1770
01:08:03,920 --> 01:08:05,039
захватывающих вещей в

1771
01:08:05,039 --> 01:08:09,200
настоящее время, и идея состоит в том, чтобы, по

1772
01:08:09,200 --> 01:08:11,280
сути, изучить совместное встраиваемое

1773
01:08:11,280 --> 01:08:13,280
пространство для предложений

1774
01:08:13,280 --> 01:08:15,359
, просто обучив  многоязычная

1775
01:08:15,359 --> 01:08:18,080
система на большом количестве общедоступных данных,

1776
01:08:18,080 --> 01:08:20,880
а затем вы используете ее, чтобы выполнить

1777
01:08:20,880 --> 01:08:22,960
поиск ближайшего соседа предложения

1778
01:08:22,960 --> 01:08:23,839
для того,

1779
01:08:23,839 --> 01:08:25,279
что соответствующий перевод был бы

1780
01:08:25,279 --> 01:08:27,198
на других языках,

1781
01:08:27,198 --> 01:08:30,158
и они обнаружили, что они собрали

1782
01:08:30,158 --> 01:08:31,279
большой набор данных,

1783
01:08:31,279 --> 01:08:32,880
и они смогли превзойти

1784
01:08:32,880 --> 01:08:35,279
производительность современной

1785
01:08:35,279 --> 01:08:37,520
системы машинного перевода на языках с высокими

1786
01:08:37,520 --> 01:08:38,799
ресурсами, таких как

1787
01:08:38,799 --> 01:08:42,238
английский, немецкий, английский, русский,

1788
01:08:42,238 --> 01:08:45,198
и идея состоит в том, чтобы использовать гораздо больше данных,

1789
01:08:45,198 --> 01:08:47,120
хотя и шумно.  Вы можете добиться большего успеха, чем

1790
01:08:47,120 --> 01:08:47,759


1791
01:08:47,759 --> 01:08:50,719
использование тщательно подобранного набора данных высокого качества, и это

1792
01:08:50,719 --> 01:08:51,359


1793
01:08:51,359 --> 01:08:54,000
то, что мы видим снова и

1794
01:08:54,000 --> 01:08:55,839
снова, идея состоит в том, что

1795
01:08:55,839 --> 01:08:57,359
нам нужно выяснить, как лучше всего

1796
01:08:57,359 --> 01:08:59,279
объединить, переводя эту

1797
01:08:59,279 --> 01:09:00,880
многоязычную фильтрацию и предварительное обучение

1798
01:09:00,880 --> 01:09:04,158
, чтобы

1799
01:09:04,158 --> 01:09:07,359
получить лучшую комбинацию для решения

1800
01:09:07,359 --> 01:09:09,120
или для улучшения машинного перевода с низким уровнем ресурсов,

1801
01:09:09,120 --> 01:09:10,960
и поэтому

1802
01:09:10,960 --> 01:09:13,439
я просто хочу, может быть, мне следует завершить

1803
01:09:13,439 --> 01:09:14,479
здесь

1804
01:09:14,479 --> 01:09:16,719
э-э, поблагодарив моих сотрудников и

1805
01:09:16,719 --> 01:09:20,399
э-э, сказав вам, что э-э,

1806
01:09:20,399 --> 01:09:22,719
если у вас есть какие-либо вопросы по этой

1807
01:09:22,719 --> 01:09:24,000
лекции, вы всегда можете

1808
01:09:24,000 --> 01:09:26,080
написать мне по электронной почте  напишите мне, я был бы счастлив

1809
01:09:26,080 --> 01:09:28,000
ответить, а также

1810
01:09:28,000 --> 01:09:30,960
в моей лаборатории у нас есть много возможностей

1811
01:09:30,960 --> 01:09:31,359
от

1812
01:09:31,359 --> 01:09:34,000
стажировки до штатных должностей в качестве

1813
01:09:34,000 --> 01:09:36,319
исследователя-исследователя, поэтому,

1814
01:09:36,319 --> 01:09:38,560
если вам интересно или любопытно, просто

1815
01:09:38,560 --> 01:09:39,679
также

1816
01:09:39,679 --> 01:09:43,520
напишите мне  электронная почта хорошо,

1817
01:09:46,319 --> 01:09:49,839
спасибо большое спасибо, Малкольм Элио,

1818
01:09:49,839 --> 01:09:52,238
так что, может быть, есть еще несколько человек

1819
01:09:52,238 --> 01:09:53,040
, у которых могут быть

1820
01:09:53,040 --> 01:09:55,679
вопросы, и вы счастливы остаться еще на

1821
01:09:55,679 --> 01:09:58,800
несколько минут, чтобы задать вопросы,

1822
01:10:01,679 --> 01:10:05,920
счастливы задать вопрос да

1823
01:10:05,920 --> 01:10:08,239
ну хорошо  ау, я хотел бы узнать больше о

1824
01:10:08,239 --> 01:10:09,600
моделях, которые вы использовали на

1825
01:10:09,600 --> 01:10:11,600
самом деле, если вы вернетесь к модели, о которой

1826
01:10:11,600 --> 01:10:12,800
вы впервые говорили,

1827
01:10:12,800 --> 01:10:14,400
говорили прямо перед обратным

1828
01:10:14,400 --> 01:10:16,880
переводом, я хотел понять,

1829
01:10:16,880 --> 01:10:18,880
у вас есть конвейер с английского на

1830
01:10:18,880 --> 01:10:20,960
английский прямо

1831
01:10:20,960 --> 01:10:23,120
в  это один, вы хотите что-то вроде

1832
01:10:23,120 --> 01:10:24,800
вас методы увеличения

1833
01:10:24,800 --> 01:10:26,320
данных, такие как envision, такие как

1834
01:10:26,320 --> 01:10:28,480
отбрасывание слова или переключение

1835
01:10:28,480 --> 01:10:30,320
переключения слов, чтобы иметь возможность сделать

1836
01:10:30,320 --> 01:10:32,239
статус расширенных данных правильным

1837
01:10:32,239 --> 01:10:35,679
, это правильно, поэтому аналогия, которую я сделал

1838
01:10:35,679 --> 01:10:36,159
,

1839
01:10:36,159 --> 01:10:38,960
касается плохого перевода, где да, все эти

1840
01:10:38,960 --> 01:10:40,880
методы  по сути, у

1841
01:10:40,880 --> 01:10:44,480
вас нет x и y, золотых пар x и y,

1842
01:10:44,480 --> 01:10:47,679
и поэтому для тренировки клеток

1843
01:10:47,679 --> 01:10:52,480
вы представляете цель

1844
01:10:52,480 --> 01:10:54,400
для этого перевода, вы фантазируете

1845
01:10:54,400 --> 01:10:55,840
ввод,

1846
01:10:55,840 --> 01:10:57,760
и поэтому вы можете видеть все эти методы

1847
01:10:57,760 --> 01:10:59,360
как способ, в частности, переводом, это

1848
01:10:59,360 --> 01:11:00,560
очень  аналогично

1849
01:11:00,560 --> 01:11:02,239
увеличению данных, которое люди делают в

1850
01:11:02,239 --> 01:11:04,080
зрении, в том смысле, что

1851
01:11:04,080 --> 01:11:07,199
здесь преобразование не

1852
01:11:07,199 --> 01:11:10,000
основано на правилах, оно производится базовой

1853
01:11:10,000 --> 01:11:12,000
системой машинного перевода,

1854
01:11:12,000 --> 01:11:13,840
но имеет ту же цель.

1855
01:11:13,840 --> 01:11:16,960


1856
01:11:16,960 --> 01:11:20,159
Если вы вернетесь

1857
01:11:20,159 --> 01:11:21,199
к предыдущему слайду, когда вы говорите, что вы

1858
01:11:21,199 --> 01:11:22,080
фантазируете

1859
01:11:22,080 --> 01:11:25,199
о цели, то в этом случае у вас будет

1860
01:11:25,199 --> 01:11:27,199
один, на котором вы прогнозируете золотую цель,

1861
01:11:27,199 --> 01:11:29,040
и другой, на котором вы меняете  ввод,

1862
01:11:29,040 --> 01:11:30,320
а затем прогнозировать, что цель состоит в том,

1863
01:11:30,320 --> 01:11:31,440
что

1864
01:11:31,440 --> 01:11:33,920
да, поэтому для набора тренировок способ, которым

1865
01:11:33,920 --> 01:11:35,120
он работает, заключается в том, что

1866
01:11:35,120 --> 01:11:38,320
вы принимаете чистый ввод, который вы передаете

1867
01:11:38,320 --> 01:11:38,640
через

1868
01:11:38,640 --> 01:11:40,480
свою систему машинного перевода на

1869
01:11:40,480 --> 01:11:42,159
предыдущей итерации,

1870
01:11:42,159 --> 01:11:44,719
и вы декодируете с помощью луча или другими

1871
01:11:44,719 --> 01:11:45,760
методами  и у вас

1872
01:11:45,760 --> 01:11:47,760
есть предсказание того, какой должна быть метка,

1873
01:11:47,760 --> 01:11:48,880
и

1874
01:11:48,880 --> 01:11:52,080
что теперь это ваша ссылка,

1875
01:11:52,080 --> 01:11:53,280
но способ обучения вашей

1876
01:11:53,280 --> 01:11:55,199
системы машинного перевода - это зашумление

1877
01:11:55,199 --> 01:11:55,679
ввода,

1878
01:11:55,679 --> 01:11:57,280
чтобы вы добавляли шум к своему вводу, а

1879
01:11:57,280 --> 01:12:00,480
шум - это вы отбрасываете слова, которые вы меняете словами,

1880
01:12:00,480 --> 01:12:03,040
и  затем вы пытаетесь предсказать

1881
01:12:03,040 --> 01:12:03,920
цель

1882
01:12:03,920 --> 01:12:06,159
, о которой мечтаете, и идея состоит в том,

1883
01:12:06,159 --> 01:12:08,239
что две цели должны быть одинаковыми,

1884
01:12:08,239 --> 01:12:10,400
да, поэтому прогноз и эти

1885
01:12:10,400 --> 01:12:11,679
цели,

1886
01:12:11,679 --> 01:12:13,280
когда вы тренируетесь с перекрестной потерей энтропии,

1887
01:12:13,280 --> 01:12:15,280
вы пытаетесь  o свяжите их вместе как

1888
01:12:15,280 --> 01:12:16,239
можно больше,

1889
01:12:16,239 --> 01:12:17,840
ладно, большое спасибо, я с удовольствием отвечу

1890
01:12:17,840 --> 01:12:20,320
на вопрос,

1891
01:12:21,280 --> 01:12:23,920
да, это очень, это один из

1892
01:12:23,920 --> 01:12:25,440
первых

1893
01:12:25,440 --> 01:12:27,600
полууправляемых методов обучения, которые вы найдете в

1894
01:12:27,600 --> 01:12:29,040
сообществе машинного обучения,

1895
01:12:29,040 --> 01:12:30,640
есть много вариантов  из этого,

1896
01:12:30,640 --> 01:12:33,600
где у них, возможно, есть

1897
01:12:33,600 --> 01:12:38,239
сообщество экспертов, которые производят

1898
01:12:38,239 --> 01:12:41,440
этикетку, есть много вариантов

1899
01:12:41,440 --> 01:12:43,360
этого, и

1900
01:12:43,360 --> 01:12:45,440
это имеет большой смысл,

1901
01:12:45,440 --> 01:12:46,800
особенно для

1902
01:12:46,800 --> 01:12:49,600
асимметричных задач, например, если вы делаете конкретное изображение,

1903
01:12:49,600 --> 01:12:50,159


1904
01:12:50,159 --> 01:12:52,640
если вы выполняете классификацию текста, если вы делаете

1905
01:12:52,640 --> 01:12:54,000
резюмирование  тогда

1906
01:12:54,000 --> 01:12:55,360
этот перевод на самом деле

1907
01:12:55,360 --> 01:12:58,080
неприменим, потому что

1908
01:12:58,080 --> 01:13:01,280
вы знаете, если вы перейдете

1909
01:13:01,280 --> 01:13:04,640
от категории ярлыков от категориального ввода к

1910
01:13:04,640 --> 01:13:06,960
целому предложению, это очень сложная

1911
01:13:06,960 --> 01:13:07,920
задача,

1912
01:13:07,920 --> 01:13:09,600
так что перевод работает очень хорошо для

1913
01:13:09,600 --> 01:13:11,840
задач симметрии, таких как

1914
01:13:11,840 --> 01:13:14,640
машинный перевод, но для таких вещей

1915
01:13:14,640 --> 01:13:15,520
которые

1916
01:13:15,520 --> 01:13:18,320
для многих к одному разделу обучения сопоставлению

1917
01:13:18,320 --> 01:13:19,040


1918
01:13:19,040 --> 01:13:20,960
определенно работают лучше, обучение Асада

1919
01:13:20,960 --> 01:13:22,239
хорошо работает

1920
01:13:22,239 --> 01:13:23,920
и в машинном переводе, когда

1921
01:13:23,920 --> 01:13:25,920
есть много  несоответствие домена между

1922
01:13:25,920 --> 01:13:28,000
источником и целью как человек,

1923
01:13:28,000 --> 01:13:31,280
да, так что, к сожалению, эти алгоритмы,

1924
01:13:31,280 --> 01:13:34,320
поэтому трудно сказать в целом,

1925
01:13:34,320 --> 01:13:35,920
что работает лучше всего, потому что это действительно

1926
01:13:35,920 --> 01:13:38,000
зависит от приложения, это действительно

1927
01:13:38,000 --> 01:13:39,360
зависит от типа данных, которые у вас

1928
01:13:39,360 --> 01:13:41,520
есть, есть

1929
01:13:42,560 --> 01:13:44,000
ли у кого-то еще вопрос, который они  я

1930
01:13:44,000 --> 01:13:46,480
бы хотел спросить

1931
01:13:46,480 --> 01:13:48,400
хорошо, похоже, что мы, возможно, не

1932
01:13:48,400 --> 01:13:50,480
получили еще один немедленный вопрос,

1933
01:13:50,480 --> 01:13:52,640
и я думаю, мы дошли до конца

1934
01:13:52,640 --> 01:13:53,760
того времени,

1935
01:13:53,760 --> 01:13:56,640
которое мы должны были сделать, поэтому, возможно, нам

1936
01:13:56,640 --> 01:13:57,679
следует позвонить

1937
01:13:57,679 --> 01:14:00,159
и довести его до  близко, но

1938
01:14:00,159 --> 01:14:01,520
большое спасибо, маркореллио,

1939
01:14:01,520 --> 01:14:03,679
я имею в виду, я надеюсь, что всем это действительно понравилось

1940
01:14:03,679 --> 01:14:04,800
, и я,

1941
01:14:04,800 --> 01:14:06,960
вы знаете, говоря о ком-то, кто

1942
01:14:06,960 --> 01:14:09,120
работал в машинном переводе в течение десяти лет,

1943
01:14:09,120 --> 01:14:10,880
хотя я не так много в последние несколько

1944
01:14:10,880 --> 01:14:11,760
лет

1945
01:14:11,760 --> 01:14:14,800
я имею в виду, что вы знаете, что на самом деле все еще

1946
01:14:14,800 --> 01:14:17,679
кажется  для меня просто удивительно, насколько

1947
01:14:17,679 --> 01:14:18,960
успешно

1948
01:14:18,960 --> 01:14:23,040
вы можете строить вещи с помощью этого um

1949
01:14:23,040 --> 01:14:25,360
building с одноязычными данными и с использованием

1950
01:14:25,360 --> 01:14:26,400


1951
01:14:26,400 --> 01:14:28,320
таких идей, как обратный перевод, я имею в виду,

1952
01:14:28,320 --> 01:14:30,239
это просто невероятно, что это

1953
01:14:30,239 --> 01:14:33,760
обеспечивает такую конкурентоспособную um

1954
01:14:33,760 --> 01:14:36,800
m  Теперь вы

1955
01:14:36,800 --> 01:14:38,400
знаете, что

1956
01:14:38,400 --> 01:14:39,440
это не

1957
01:14:39,440 --> 01:14:41,600
только академические интересы, как вы, возможно,

1958
01:14:41,600 --> 01:14:43,040
поняли, если подумали об этом

1959
01:14:43,040 --> 01:14:43,920
правильно, если у вас

1960
01:14:43,920 --> 01:14:46,480
есть такая компания, как facebook, которая

1961
01:14:46,480 --> 01:14:47,760
действительно может

1962
01:14:47,760 --> 01:14:51,120
хорошо переводить данные на

1963
01:14:51,120 --> 01:14:53,520
домены, которые очень далеки от выходных дней новостей

1964
01:14:53,520 --> 01:14:54,880
или Библии,

1965
01:14:54,880 --> 01:14:57,040
и на языках, которые являются небольшими

1966
01:14:57,040 --> 01:14:58,719
сообществами носителей, на

1967
01:14:58,719 --> 01:15:01,679
самом деле очень важны

1968
01:15:01,679 --> 01:15:02,080
для

1969
01:15:02,080 --> 01:15:05,120
людей, которые являются счастливыми пользователями и

1970
01:15:05,120 --> 01:15:06,080
членами сообществ.

1971
01:15:06,080 --> 01:15:09,040


1972
01:15:09,040 --> 01:15:09,679


1973
01:15:09,679 --> 01:15:11,679
методы довольно щедры, поэтому мы

1974
01:15:11,679 --> 01:15:13,440
применяем их для суммирования

1975
01:15:13,440 --> 01:15:17,040
q и переноса в стиле э-э,

1976
01:15:17,040 --> 01:15:20,880
чтобы вы знали, что это действительно красиво

1977
01:15:20,880 --> 01:15:23,600
, это набор инструментов, которые вы можете использовать

1978
01:15:23,600 --> 01:15:24,000


1979
01:15:24,000 --> 01:15:26,719
во многих местах, и это все, что вы

1980
01:15:26,719 --> 01:15:28,400
знаете, в способе

1981
01:15:28,400 --> 01:15:31,520
выравнивания доменов с небольшим э-э-

1982
01:15:31,520 --> 01:15:34,640
контролем  или переписка так

1983
01:15:34,640 --> 01:15:38,400
что да ладно спасибо большое

1984
01:15:38,400 --> 01:15:47,280
спасибо спасибо до свидания

