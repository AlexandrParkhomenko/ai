1
00:00:05,600 --> 00:00:06,799
ладно

2
00:00:06,799 --> 00:00:08,559
, теперь нам лучше приступить к

3
00:00:08,559 --> 00:00:10,880
лекции, ладно,

4
00:00:10,880 --> 00:00:11,679


5
00:00:11,679 --> 00:00:12,719
у нас

6
00:00:12,719 --> 00:00:15,839
сейчас восьмая неделя, вторая половина четвертой недели,

7
00:00:15,839 --> 00:00:16,720


8
00:00:16,720 --> 00:00:19,119
так что повестка дня сегодня такова, что я в первую

9
00:00:19,119 --> 00:00:20,480
очередь собираюсь

10
00:00:20,480 --> 00:00:23,119
закончить последние части внимания,

11
00:00:23,119 --> 00:00:25,599
которые  Я не говорил об этом в прошлый раз,

12
00:00:25,599 --> 00:00:28,160
но основная тема сегодня - поговорить

13
00:00:28,160 --> 00:00:31,039
о финальных проектах, и

14
00:00:31,039 --> 00:00:33,520
это будет состоять из, э-э, набора разных

15
00:00:33,520 --> 00:00:35,360
вещей: говорить о финальных

16
00:00:35,360 --> 00:00:38,000
проектах и искать темы для исследований, а также

17
00:00:38,000 --> 00:00:40,879
находить данные и проводить исследования.  Я

18
00:00:40,879 --> 00:00:42,960
дам очень краткое введение в

19
00:00:42,960 --> 00:00:45,360
ответы на вопросы, связанные с пониманием прочитанного,

20
00:00:45,360 --> 00:00:47,920
которые являются нашим финальным проектом по умолчанию,

21
00:00:47,920 --> 00:00:50,160
но мы читаем целую лекцию об этом

22
00:00:50,160 --> 00:00:52,320
в начале шестой недели, так что это

23
00:00:52,320 --> 00:00:54,879
просто, чтобы дать вам немного о том

24
00:00:54,879 --> 00:00:56,879
, о чем это, и если вы  подумываете о

25
00:00:56,879 --> 00:00:59,600
выполнении финального проекта по умолчанию, в

26
00:00:59,600 --> 00:01:03,280
некотором смысле, эта лекция также является

27
00:01:03,280 --> 00:01:06,159
редким шансом в этом курсе, ммм, чтобы сделать паузу,

28
00:01:06,159 --> 00:01:08,720
чтобы перевести дух, потому что вы действительно знаете, что

29
00:01:08,720 --> 00:01:09,439


30
00:01:09,439 --> 00:01:12,320
до сих пор у нас был пожарный шланг,

31
00:01:12,320 --> 00:01:15,680
идущий полным потоком вперед, ммм  распыление йо

32
00:01:15,680 --> 00:01:17,439
с новыми фактами, подходами,

33
00:01:17,439 --> 00:01:20,640
алгоритмами, моделями и лингвистическими

34
00:01:20,640 --> 00:01:23,920
вещами, гм, так что это небольшая

35
00:01:23,920 --> 00:01:25,360
передышка, так что

36
00:01:25,360 --> 00:01:27,040
если у вас есть какие-либо вопросы, которые

37
00:01:27,040 --> 00:01:29,600
вы задавали в течение нескольких недель, сегодняшняя

38
00:01:29,600 --> 00:01:31,840
лекция будет хорошим временем, чтобы задать их,

39
00:01:31,840 --> 00:01:34,400
потому что после сегодняшней  лекция на пятой неделе,

40
00:01:34,400 --> 00:01:35,360


41
00:01:35,360 --> 00:01:38,079
мы снова включим пожарный шланг,

42
00:01:38,079 --> 00:01:40,400
и у нас будет много новой информации

43
00:01:40,400 --> 00:01:43,759
о трансформерах и больших предварительно обученных

44
00:01:43,759 --> 00:01:45,680
языковых моделях, которые стали огромной

45
00:01:45,680 --> 00:01:48,799
частью современной нейронной НЛП, как я уже

46
00:01:48,799 --> 00:01:50,880
немного упомянул

47
00:01:50,880 --> 00:01:54,000
позже в этот класс,

48
00:01:54,000 --> 00:01:56,159
хорошо, так что это то место, где мы оставили вещи в

49
00:01:56,159 --> 00:01:58,159
прошлый раз, в основном,

50
00:01:58,159 --> 00:01:58,880


51
00:01:58,880 --> 00:02:01,680
поэтому я бы хотел поговорить

52
00:02:01,680 --> 00:02:04,320
о грубой идее, что то, что мы собираемся

53
00:02:04,320 --> 00:02:07,040
сделать для этой новой модели внимания, - это

54
00:02:07,040 --> 00:02:09,598
то, что мы собираемся использовать кодировщик  справедливость

55
00:02:09,598 --> 00:02:10,720
прежде,

56
00:02:10,720 --> 00:02:14,640
а затем, как только мы запускаем декодер

57
00:02:14,640 --> 00:02:17,599
на каждом временном шаге, мы собираемся

58
00:02:17,599 --> 00:02:19,920
вычислить новое скрытое представление, используя ту

59
00:02:19,920 --> 00:02:23,120
же модель последовательности, что и

60
00:02:23,120 --> 00:02:26,959
раньше, но теперь мы собираемся использовать это

61
00:02:26,959 --> 00:02:30,400
скрытое представление  e декодер, чтобы

62
00:02:30,400 --> 00:02:34,319
посмотреть на кодировщик, и он

63
00:02:34,319 --> 00:02:35,599
будет затем

64
00:02:35,599 --> 00:02:38,640
выработать, соответственно, некоторую

65
00:02:38,640 --> 00:02:41,680
функцию сходства между двумя

66
00:02:41,680 --> 00:02:44,879
скрытыми состояниями и декодировать скрытые состояния,

67
00:02:44,879 --> 00:02:47,440
и на их основе он

68
00:02:47,440 --> 00:02:49,920
будет определять так называемые оценки

69
00:02:49,920 --> 00:02:51,599
внимания, а оценки внимания на самом деле являются

70
00:02:51,599 --> 00:02:54,640
вероятностью  взвешивает um относительно того, насколько ему

71
00:02:54,640 --> 00:02:55,519
нравятся

72
00:02:55,519 --> 00:02:57,760
различные элементы, и на основе этих

73
00:02:57,760 --> 00:03:00,480
оценок внимания мы собираемся

74
00:03:00,480 --> 00:03:04,480
вычислить распределение внимания um,

75
00:03:04,480 --> 00:03:07,120
так что это наше распределение вероятностей,

76
00:03:07,120 --> 00:03:09,840
а затем на основе этого, что мы делаем, это

77
00:03:09,840 --> 00:03:12,640
вычисляем средневзвешенное значение

78
00:03:12,640 --> 00:03:15,760
кодировщика rnn hidden  состояний, взвешенных по

79
00:03:15,760 --> 00:03:18,159
распределению внимания, и это

80
00:03:18,159 --> 00:03:20,319
даст нам новый выходной вектор внимания,

81
00:03:20,319 --> 00:03:22,800
который похож на вектор скрытого

82
00:03:22,800 --> 00:03:26,560
состояния декодера, который является дополнительным

83
00:03:26,560 --> 00:03:28,959
скрытым вектором, и поэтому мы собираемся использовать

84
00:03:28,959 --> 00:03:32,799
их оба, чтобы затем

85
00:03:32,799 --> 00:03:35,360
сгенерировать наш  следующий вывод, который

86
00:03:35,360 --> 00:03:37,519
будет здесь, слово пи в конце

87
00:03:37,519 --> 00:03:38,720
последовательности

88
00:03:38,720 --> 00:03:39,840
um,

89
00:03:39,840 --> 00:03:42,560
так что давайте начнем сейчас, сделав это

90
00:03:42,560 --> 00:03:44,319
с некоторыми уравнениями

91
00:03:44,319 --> 00:03:46,560
um, так что

92
00:03:46,560 --> 00:03:48,720
перед yo  u move on um, здесь хороший

93
00:03:48,720 --> 00:03:50,319
вопрос, извините

94
00:03:50,319 --> 00:03:52,879
, поэтому требуются оба кодировщика и декодера,

95
00:03:52,879 --> 00:03:54,720
а не один и тот

96
00:03:54,720 --> 00:03:58,159
же rnn для обоих, я думаю, да, хорошо, я обращусь к

97
00:03:58,159 --> 00:04:00,560
этому, так

98
00:04:00,560 --> 00:04:02,480
хорошо, возможно, есть еще пара

99
00:04:02,480 --> 00:04:05,200
возможных интерпретаций  для этого, но

100
00:04:05,200 --> 00:04:07,599
я скажу кое-что об этом, чтобы вы знали, что

101
00:04:07,599 --> 00:04:08,480


102
00:04:08,480 --> 00:04:10,799
это основной случай, который мы здесь делали

103
00:04:10,799 --> 00:04:14,480
, это случай машинного перевода,

104
00:04:14,480 --> 00:04:17,358
где у нас есть исходный

105
00:04:17,358 --> 00:04:20,160
кодировщик, который находится на исходном

106
00:04:20,160 --> 00:04:22,960
языке, и мы  получил целевой декодер,

107
00:04:22,960 --> 00:04:26,160
который находится на целевом языке, поэтому, поскольку

108
00:04:26,160 --> 00:04:28,520
эти две вещи

109
00:04:28,520 --> 00:04:30,479
небольшие

110
00:04:30,479 --> 00:04:34,080
с использованием разных языков, имеет

111
00:04:34,080 --> 00:04:36,800
смысл иметь отдельные модели последовательностей с

112
00:04:36,800 --> 00:04:39,520
разными параметрами rnn для каждого из них,

113
00:04:39,520 --> 00:04:42,880
и в этот момент это

114
00:04:42,880 --> 00:04:45,199
просто факт о том, что мы хотим делать

115
00:04:45,199 --> 00:04:48,880
с  машинный перевод, который заключается в том, что

116
00:04:48,880 --> 00:04:51,199
мы на самом деле хотим оглянуться

117
00:04:51,199 --> 00:04:54,400
на источник, чтобы попытаться решить, какие дополнительные

118
00:04:54,400 --> 00:04:57,120
слова добавить в перевод, поэтому

119
00:04:57,120 --> 00:04:59,919
имеет смысл вернуться от

120
00:04:59,919 --> 00:05:02,000
источника к переводу,

121
00:05:02,000 --> 00:05:04,080
но

122
00:05:04,080 --> 00:05:06,240
что вы  Можно спросить, а почему

123
00:05:06,240 --> 00:05:08,720
мы делаем только это, почему бы нам также не

124
00:05:08,720 --> 00:05:12,000
рассмотреть возможность переноса внимания отсюда обратно

125
00:05:12,000 --> 00:05:16,240
в дакоту, и если это, ммм, то, о

126
00:05:16,240 --> 00:05:17,039
чем

127
00:05:17,039 --> 00:05:19,199
вы думаете, это отличное

128
00:05:19,199 --> 00:05:22,160
предложение, и на самом деле очень быстро

129
00:05:22,160 --> 00:05:24,240
после того, как эти модели внимания были

130
00:05:24,240 --> 00:05:26,639
разработаны  это именно то, что люди

131
00:05:26,639 --> 00:05:28,479
начали делать,

132
00:05:28,479 --> 00:05:30,479
они решили, что на самом деле мы могли бы

133
00:05:30,479 --> 00:05:33,039
начать использовать больше форм внимания, и

134
00:05:33,039 --> 00:05:35,600
мы также могли бы использовать напряжение, которое оглядывается

135
00:05:35,600 --> 00:05:38,479
назад в последовательности декодера и которое

136
00:05:38,479 --> 00:05:40,960
часто упоминается как самоудержание,

137
00:05:40,960 --> 00:05:43,520
а самовнимание доказало свою эффективность.  быть

138
00:05:43,520 --> 00:05:46,400
чрезвычайно мощной концепцией мошенничества, и это

139
00:05:46,400 --> 00:05:49,199
действительно приводит

140
00:05:49,199 --> 00:05:51,600
к моделям трансформаторов, которые мы

141
00:05:51,600 --> 00:05:53,280
увидим на следующей неделе.

142
00:05:53,280 --> 00:05:54,560


143
00:05:54,560 --> 00:05:57,280


144
00:05:57,280 --> 00:06:00,160


145
00:06:00,160 --> 00:06:02,080


146
00:06:02,080 --> 00:06:05,600
эта

147
00:06:05,600 --> 00:06:08,800
первоначальная мотивация к переводу, которая была тем,

148
00:06:08,800 --> 00:06:12,240
где было развито внимание, казалось

149
00:06:12,240 --> 00:06:15,680
довольно очевидным, когда мы, когда вы

150
00:06:15,680 --> 00:06:18,479
запускаете декодер rnn

151
00:06:18,479 --> 00:06:19,360
,

152
00:06:19,360 --> 00:06:21,759
в качестве модели условного языка он  получает

153
00:06:21,759 --> 00:06:23,680
некоторую информацию о магазине

154
00:06:23,680 --> 00:06:26,000
в исходном состоянии, тогда казалось

155
00:06:26,000 --> 00:06:28,240
довольно очевидным, что вы теряете много

156
00:06:28,240 --> 00:06:29,520
информации

157
00:06:29,520 --> 00:06:31,360
о деталях того, что было в

158
00:06:31,360 --> 00:06:33,919
четвертом предложении, и поэтому будьте действительно

159
00:06:33,919 --> 00:06:36,000
действительно полезны,

160
00:06:36,000 --> 00:06:38,400
обратите внимание на эту идею, чтобы вы могли непосредственно смотреть  в

161
00:06:38,400 --> 00:06:41,520
то время как вы продолжали перевод

162
00:06:41,520 --> 00:06:43,919
таким образом, немного менее очевидно,

163
00:06:43,919 --> 00:06:47,039
что вам это нужно для декодера rna,

164
00:06:47,039 --> 00:06:48,479
потому что после всей

165
00:06:48,479 --> 00:06:51,280
прошлой недели мы представили эти действительно

166
00:06:51,280 --> 00:06:54,160
умные lstms, и весь

167
00:06:54,160 --> 00:06:56,880
аргумент lstm был на самом деле они довольно

168
00:06:56,880 --> 00:06:59,680
хороши в  ведение истории

169
00:06:59,680 --> 00:07:02,639
последовательности за довольно много периодов времени,

170
00:07:02,639 --> 00:07:06,479
поэтому в той мере, в какой lstm

171
00:07:06,479 --> 00:07:08,639
выполняет идеальную работу, возможно, вам

172
00:07:08,639 --> 00:07:10,319
действительно не нужно самовнимание в

173
00:07:10,319 --> 00:07:13,199
вашем декодере, но на самом деле именно

174
00:07:13,199 --> 00:07:15,840
то, что было показано, - это то, что этот

175
00:07:15,840 --> 00:07:18,800
механизм внимания является  гораздо более эффективный

176
00:07:18,800 --> 00:07:22,080
метод выборочного обращения к

177
00:07:22,080 --> 00:07:24,400
элементам вашего прошлого состояния, и это как

178
00:07:24,400 --> 00:07:26,240
бы более легкий вес, чем

179
00:07:26,240 --> 00:07:28,160
необходимость готовить пара  метров,

180
00:07:28,160 --> 00:07:31,520
что ваш lsdm, так что он передает только

181
00:07:31,520 --> 00:07:34,080
нужную информацию вперед все время, которое

182
00:07:34,080 --> 00:07:36,639
вы предоставили, вы несете только достаточно

183
00:07:36,639 --> 00:07:39,120
информации, чтобы модель знала,

184
00:07:39,120 --> 00:07:40,800
куда оглядываться,

185
00:07:40,800 --> 00:07:42,880
а затем вы можете получить больше

186
00:07:42,880 --> 00:07:44,960
информации из прошлых состояний, когда

187
00:07:44,960 --> 00:07:46,560
захотите, чтобы  на самом деле отличный

188
00:07:46,560 --> 00:07:49,759
подход, но я не буду говорить об этом

189
00:07:49,759 --> 00:07:52,400
больше сейчас, и

190
00:07:52,400 --> 00:07:54,319
на

191
00:07:54,319 --> 00:07:57,639
следующей неделе мы

192
00:07:58,800 --> 00:08:01,840
рассмотрим уравнения, надеюсь, они на

193
00:08:01,840 --> 00:08:04,160
самом деле не покажутся сложными, поэтому у

194
00:08:04,160 --> 00:08:07,280
нас есть скрытые скрытые состояния кодировщика,

195
00:08:07,280 --> 00:08:09,360
которые являются векторами

196
00:08:09,360 --> 00:08:10,639
um

197
00:08:10,639 --> 00:08:13,280
на временном шаге t у нас есть скрытое состояние декодера,

198
00:08:13,280 --> 00:08:15,680
которое также является вектором

199
00:08:15,680 --> 00:08:18,240
измерения скрытого состояния, а затем мы

200
00:08:18,240 --> 00:08:22,080
хотим получить

201
00:08:22,080 --> 00:08:23,120


202
00:08:23,120 --> 00:08:24,960
оценки внимания относительно

203
00:08:24,960 --> 00:08:26,560
того, сколько внимания

204
00:08:26,560 --> 00:08:29,680
он уделяет каждому из скрытых

205
00:08:29,680 --> 00:08:32,479
состояний  кодировщик, и самый простой

206
00:08:32,479 --> 00:08:35,679
способ сделать это - просто

207
00:08:35,679 --> 00:08:38,479
использовать точечные произведения между источником

208
00:08:38,479 --> 00:08:41,519
и извинением, а не источником, скалярные

209
00:08:41,519 --> 00:08:44,159
произведения между скрытым

210
00:08:44,159 --> 00:08:48,080
состоянием s декодера и кодировщиками в состоянии h, поэтому

211
00:08:48,080 --> 00:08:49,839
они дают нам bu  nch чисел, которые

212
00:08:49,839 --> 00:08:52,240
могут быть отрицательными или положительными, но их

213
00:08:52,240 --> 00:08:55,040
внимание оценивается, и поэтому вы знаете,

214
00:08:55,040 --> 00:08:57,440
как мы это делали прямо из первой лекции

215
00:08:57,440 --> 00:09:00,160
с векторами слов, мы затем помещаем их в

216
00:09:00,160 --> 00:09:02,959
мягкое максимальное распределение, а затем мы получаем

217
00:09:02,959 --> 00:09:06,000
распределение вероятностей по временным

218
00:09:06,000 --> 00:09:09,600
шагам  кодировщик в

219
00:09:09,600 --> 00:09:11,600
порядке, теперь у нас есть это распределение вероятностей,

220
00:09:11,600 --> 00:09:15,120
мы можем

221
00:09:15,120 --> 00:09:19,040
построить новый вектор, создав взвешенную сумму

222
00:09:19,040 --> 00:09:22,640
скрытых состояний кодировщика на основе

223
00:09:22,640 --> 00:09:24,480
этих

224
00:09:24,480 --> 00:09:27,360
вероятностей распределения внимания, и это

225
00:09:27,360 --> 00:09:30,080
дает нам

226
00:09:30,800 --> 00:09:33,040
затем использовать это при

227
00:09:33,040 --> 00:09:35,920
генерации выходных данных, которые мы  собираемся объединить

228
00:09:35,920 --> 00:09:38,720
вывод внимания со

229
00:09:38,720 --> 00:09:41,600
скрытым состоянием sp декодера, так что теперь он получил что-

230
00:09:41,600 --> 00:09:44,560
то размером 2h, а затем мы

231
00:09:44,560 --> 00:09:47,279
продолжим, как с моделью без внимания,

232
00:09:47,279 --> 00:09:50,080
мы затем пропустили это через другой запас

233
00:09:50,080 --> 00:09:52,240
max, чтобы сгенерировать распределение вероятностей

234
00:09:52,240 --> 00:09:54,640
выходных слов, а затем

235
00:09:54,640 --> 00:09:56,320
с образцом слова

236
00:09:56,320 --> 00:09:58,160
и,

237
00:09:58,160 --> 00:10:00,399
надеюсь, это довольно

238
00:10:00,399 --> 00:10:02,560
очевидная реализация того, что у нас есть,

239
00:10:02,560 --> 00:10:05,200
поэтому у нас есть векторы с

240
00:10:05,200 --> 00:10:07,760
кодировщиком и  декодер мы получили скалярные

241
00:10:07,760 --> 00:10:09,040
произведения

242
00:10:09,040 --> 00:10:09,760


243
00:10:09,760 --> 00:10:11,680
st с каждым из них

244
00:10:11,680 --> 00:10:14,560
softnext превращает их в вероятность, которую мы

245
00:10:14,560 --> 00:10:16,880
берем средневзвешенное значение

246
00:10:16,880 --> 00:10:19,120
красного цвета, чтобы получить вывод внимания, который мы

247
00:10:19,120 --> 00:10:22,399
объединяем со

248
00:10:22,640 --> 00:10:23,680


249
00:10:23,680 --> 00:10:24,800


250
00:10:24,800 --> 00:10:27,360
скрытым состоянием st декодеров, а затем

251
00:10:27,360 --> 00:10:29,440
пропускаем его через другое программное обеспечение  max, и мы можем

252
00:10:29,440 --> 00:10:32,920
выбрать пи,

253
00:10:35,920 --> 00:10:38,959
ладно, так что

254
00:10:38,959 --> 00:10:41,279
я почти не могу

255
00:10:41,279 --> 00:10:45,360
выделить достаточно внимания, это здорово,

256
00:10:45,360 --> 00:10:48,320
так что самая первая

257
00:10:48,320 --> 00:10:50,640
современная программа нейронного машинного перевода

258
00:10:50,640 --> 00:10:51,760


259
00:10:51,760 --> 00:10:56,399
была сделана в 2014 году в Google,

260
00:10:56,399 --> 00:10:59,279
Илья Сински Брадау, и у них был

261
00:10:59,279 --> 00:11:00,480
простой

262
00:11:00,480 --> 00:11:05,839
кодировщик-декодер для lstms  и с помощью

263
00:11:05,839 --> 00:11:08,959
кучи трюков с очень глубоким lspms, огромным

264
00:11:08,959 --> 00:11:11,440
объемом данных, огромным объемом обучения

265
00:11:11,440 --> 00:11:13,360
другим трюкам, в которые я не хочу

266
00:11:13,360 --> 00:11:15,920
сейчас вдаваться, они действительно смогли получить

267
00:11:15,920 --> 00:11:19,360
хорошие результаты, просто составив

268
00:11:19,360 --> 00:11:22,640
прямой поиск для поиска

269
00:11:22,640 --> 00:11:25,600
новых  система машинного перевода, но очень

270
00:11:25,600 --> 00:11:28,079
скоро после этого, на самом деле, в том же

271
00:11:28,079 --> 00:11:31,680
году группа из

272
00:11:31,680 --> 00:11:33,920


273
00:11:33,920 --> 00:11:37,600
Монреаля, и Джошуа Бенджио представил

274
00:11:37,600 --> 00:11:40,079
последовательность, модель последовательности с вниманием, и это

275
00:11:40,079 --> 00:11:42,880
было просто  Очевидно, лучше, поэтому внимание

276
00:11:42,880 --> 00:11:44,959
значительно улучшает производительность вашего машинного

277
00:11:44,959 --> 00:11:48,000
перевода, и это

278
00:11:48,000 --> 00:11:51,279
имеет смысл, что позволяет

279
00:11:51,279 --> 00:11:53,200
декодеру сосредоточиться на частях исходных

280
00:11:53,200 --> 00:11:56,399
стандартов, поэтому я думаю, что это дает

281
00:11:56,399 --> 00:11:59,120
вам гораздо более похожую на человека модель выполнения

282
00:11:59,120 --> 00:12:01,760
машинного перевода  потому что вы

283
00:12:01,760 --> 00:12:04,240
точно знаете, что сделал бы переводчик,

284
00:12:04,240 --> 00:12:06,079
вы читаете исходное предложение, у вас

285
00:12:06,079 --> 00:12:08,399
есть представление о том, о чем вы начинаете

286
00:12:08,399 --> 00:12:10,000
писать первые пару слов

287
00:12:10,000 --> 00:12:13,440
перевода, а затем

288
00:12:13,440 --> 00:12:15,519
вы оглядываетесь назад, чтобы увидеть,

289
00:12:15,519 --> 00:12:18,480
что именно  он сказал как своего рода

290
00:12:18,480 --> 00:12:20,560
модификаторы существительного для перевода

291
00:12:20,560 --> 00:12:22,480
следующих нескольких слов,

292
00:12:22,480 --> 00:12:24,560
технически люди думают об этом как о

293
00:12:24,560 --> 00:12:27,120
решении проблемы узкого места, потому что

294
00:12:27,120 --> 00:12:30,639
теперь внимание позволяет нам получить полный доступ

295
00:12:30,639 --> 00:12:33,040
ко всему скрытому состоянию источника, и мы

296
00:12:33,040 --> 00:12:35,120
можем получить любую информацию, которая нам нужна,

297
00:12:35,120 --> 00:12:36,959
это не  случай, когда вся

298
00:12:36,959 --> 00:12:39,279
информация должна быть закодирована в окончательном

299
00:12:39,279 --> 00:12:42,079
скрытом состоянии, это также помогает с

300
00:12:42,079 --> 00:12:44,240
проблемой исчезающего градиента, так

301
00:12:44,240 --> 00:12:47,040
что теперь у нас есть ярлыки назад

302
00:12:47,040 --> 00:12:50,880
к каждому скрытому состоянию кодировщика,

303
00:12:50,880 --> 00:12:52,959
и, следовательно, всегда есть короткий

304
00:12:52,959 --> 00:12:55,600
путь для градиентного потока, что значительно

305
00:12:55,600 --> 00:12:59,120
снижает проблему исчезающего градиента.

306
00:12:59,120 --> 00:13:01,920
Наконец, аккуратная вещь заключается в том, что внимание

307
00:13:01,920 --> 00:13:05,440
обеспечивает некоторую эффективную интерпретируемость

308
00:13:05,440 --> 00:13:08,399
для последовательности моделей последовательности, потому что

309
00:13:08,399 --> 00:13:09,360
,

310
00:13:09,360 --> 00:13:11,760
глядя на распределение натяжения  мы

311
00:13:11,760 --> 00:13:14,959
можем видеть, на чем фокусировался декодер,

312
00:13:14,959 --> 00:13:18,160
поэтому мягким вероятностным способом мы

313
00:13:18,160 --> 00:13:20,560
бесплатно получаем через работу

314
00:13:20,560 --> 00:13:24,079
модели мягкое выравнивание того, какие слова

315
00:13:24,079 --> 00:13:27,360
переводят какие слова, поэтому в этом примере

316
00:13:27,360 --> 00:13:29,279
переводится французское предложение,

317
00:13:29,279 --> 00:13:31,839
он ударил меня  с пирогом, где

318
00:13:31,839 --> 00:13:34,000
на французском есть что-то вроде единственного глагола,

319
00:13:34,000 --> 00:13:36,000
который, как я полагаю, в

320
00:13:36,000 --> 00:13:38,639
английском иногда люди в день пи используют

321
00:13:38,639 --> 00:13:40,880
пироги в качестве глаголов, вроде того,

322
00:13:40,880 --> 00:13:43,920
что он меня пидал,

323
00:13:43,920 --> 00:13:46,639
что модель, которую вы знаете, получает этот

324
00:13:46,639 --> 00:13:48,800
угорь  переводится как

325
00:13:48,800 --> 00:13:49,519


326
00:13:49,519 --> 00:13:52,399
он переводится как я и, по сути,

327
00:13:52,399 --> 00:13:55,600
antarte, переводится как

328
00:13:55,600 --> 00:13:56,639
удар пирогом,

329
00:13:56,639 --> 00:13:58,079


330
00:13:58,079 --> 00:13:58,959
так

331
00:13:58,959 --> 00:14:01,120
что удивительно то, что вы знаете,

332
00:14:01,120 --> 00:14:03,440
что модель никогда не была  Когда говорилось о любом из

333
00:14:03,440 --> 00:14:05,920
этих выравниваний, не было явной

334
00:14:05,920 --> 00:14:08,240
отдельной модели, которая пыталась бы изучить

335
00:14:08,240 --> 00:14:10,480
эти выравнивания, поскольку в более ранних

336
00:14:10,480 --> 00:14:13,920
статистических системах, основанных на фразах, мы просто

337
00:14:13,920 --> 00:14:16,160
построили последовательность, секретную модель

338
00:14:16,160 --> 00:14:18,880
с натяжением и сказали, что слышите, как много

339
00:14:18,880 --> 00:14:20,880
переведенных предложений

340
00:14:20,880 --> 00:14:23,279
начинают возвращаться  верните опору и попытайтесь

341
00:14:23,279 --> 00:14:26,160
получить хорошее

342
00:14:26,639 --> 00:14:29,519
использование предложений, и он просто учится

343
00:14:29,519 --> 00:14:32,320
сам, решая, где лучше всего

344
00:14:32,320 --> 00:14:35,199
обращать внимание, что является хорошим

345
00:14:35,199 --> 00:14:37,279
согласованием между исходным и

346
00:14:37,279 --> 00:14:40,240
целевым языками,

347
00:14:43,199 --> 00:14:45,680
хорошо, так

348
00:14:45,680 --> 00:14:47,199
что это основная

349
00:14:47,199 --> 00:14:49,680
идея

350
00:14:49,680 --> 00:14:51,199
внимания,

351
00:14:51,199 --> 00:14:53,680
ммм, я хочу пойти  немного подробнее о

352
00:14:53,680 --> 00:14:56,079
сложности внимания, так как это

353
00:14:56,079 --> 00:14:59,519
настолько важная идея, что

354
00:14:59,519 --> 00:15:01,680
мы многое увидим, поскольку мы продолжим сейчас

355
00:15:01,680 --> 00:15:03,760
с правильным курсом, поэтому

356
00:15:03,760 --> 00:15:06,240
есть несколько вариантов внимания, но

357
00:15:06,240 --> 00:15:08,720
прежде всего вы знаете, что общая

358
00:15:08,720 --> 00:15:13,519
часть, мм, поэтому мы  иметь некоторые значения, некоторые

359
00:15:13,519 --> 00:15:15,920
векторы, которые мы собираемся

360
00:15:15,920 --> 00:15:18,720
использовать в качестве нашей памяти, и у нас есть вектор запроса,

361
00:15:18,720 --> 00:15:22,399
поэтому внимание всегда требует, чтобы

362
00:15:22,399 --> 00:15:26,639
мы вычисляли оценки внимания

363
00:15:26,639 --> 00:15:29,440
и включали  Мы превращаемся в вероятностное

364
00:15:29,440 --> 00:15:32,240
распределение с мягким максимумом,

365
00:15:32,240 --> 00:15:36,480
и мы используем распределение внимания для

366
00:15:36,480 --> 00:15:38,959
вычисления взвешенной

367
00:15:38,959 --> 00:15:41,440
суммы элементов в нашей памяти, что дает

368
00:15:41,440 --> 00:15:44,399
нам вывод внимания,

369
00:15:44,399 --> 00:15:47,120
поэтому основное место, где вы сразу

370
00:15:47,120 --> 00:15:50,399
видите изменение внимания, -

371
00:15:50,399 --> 00:15:52,240
это то, как вы вычисляете эти оценки внимания

372
00:15:52,240 --> 00:15:54,320


373
00:15:54,320 --> 00:15:56,079
Итак, давайте рассмотрим некоторые из способов

374
00:15:56,079 --> 00:15:57,440
, которыми это делается,

375
00:15:57,440 --> 00:16:00,480
поэтому самый простой и очевидный способ сделать

376
00:16:00,480 --> 00:16:03,839
это - сказать, давайте просто возьмем скалярное

377
00:16:03,839 --> 00:16:07,040
произведение между скрытым st,

378
00:16:07,040 --> 00:16:10,160
текущим скрытым состоянием декодера

379
00:16:10,160 --> 00:16:13,600
и всеми векторами здесь um

380
00:16:13,600 --> 00:16:16,160
исходные векторы кодировщика, на которые мы

381
00:16:16,160 --> 00:16:18,880
обращаем внимание, и вы знаете, что

382
00:16:18,880 --> 00:16:21,279
это имеет смысл правильно, это

383
00:16:21,279 --> 00:16:23,920
точечный продукт - наша основная оценка сходства,

384
00:16:23,920 --> 00:16:25,600
но

385
00:16:25,600 --> 00:16:28,160
похоже, что

386
00:16:28,160 --> 00:16:31,600
с этим что-то не так, и вы знаете, что это кажется

387
00:16:31,600 --> 00:16:34,399
неправильным для вас  думать, что

388
00:16:34,399 --> 00:16:37,600
все скрытые состояния источника

389
00:16:37,600 --> 00:16:40,399
и все целевые скрытые состояния

390
00:16:40,399 --> 00:16:41,759


391
00:16:41,759 --> 00:16:44,639
содержат информацию о том, на что обращать внимание,

392
00:16:44,639 --> 00:16:45,360


393
00:16:45,360 --> 00:16:48,320
потому что на самом деле эти скрытые состояния  stms делают

394
00:16:48,320 --> 00:16:51,199
несколько вещей, поэтому

395
00:16:51,199 --> 00:16:53,839
lstms передают информацию в своей

396
00:16:53,839 --> 00:16:56,639
собственной последовательности, чтобы помочь вам узнать

397
00:16:56,639 --> 00:16:58,480
информацию о записях о прошлом, чтобы ее можно было

398
00:16:58,480 --> 00:17:01,519
использовать в будущем, у них есть информация

399
00:17:01,519 --> 00:17:04,000
в скрытом состоянии, чтобы сообщить вам, какой

400
00:17:04,000 --> 00:17:06,959
вывод вы должны сгенерировать следующим

401
00:17:06,959 --> 00:17:09,520
и  возможно, они кодируют некоторую

402
00:17:09,520 --> 00:17:12,000
информацию, которая будет служить своего рода

403
00:17:12,000 --> 00:17:14,880
ключом запроса для извлечения информации

404
00:17:14,880 --> 00:17:18,000
путем внимания из скрытых состояний источника,

405
00:17:18,000 --> 00:17:20,720
поэтому кажется, что, вероятно, мы

406
00:17:20,720 --> 00:17:22,799
хотим использовать только часть информации в

407
00:17:22,799 --> 00:17:26,559
них, чтобы вычислить нашу оценку внимания

408
00:17:26,559 --> 00:17:29,200
и поэтому такой подход

409
00:17:29,200 --> 00:17:32,080
был очень быстро использован в последующей

410
00:17:32,080 --> 00:17:34,160
работе,

411
00:17:34,160 --> 00:17:38,400
поэтому в следующем году, ммм, долго

412
00:17:38,400 --> 00:17:40,880
работая со мной, я изучил эту идею,

413
00:17:40,880 --> 00:17:42,320
которая теперь обычно называется

414
00:17:42,320 --> 00:17:44,559
мультипликативным вниманием, поэтому для

415
00:17:44,559 --> 00:17:46,480
мультипликативного внимания

416
00:17:46,480 --> 00:17:49,440
мы помещаем дополнительную матрицу

417
00:17:49,440 --> 00:17:51,840
в середину нашей точки.  product, так что это

418
00:17:51,840 --> 00:17:54,880
дает нам матрицу изучаемых

419
00:17:54,880 --> 00:17:58,720
параметров, и внутри

420
00:17:58,720 --> 00:18:01,840
этой матрицы мы можем узнать, на какие части s

421
00:18:01,840 --> 00:18:03,919
следует обратить внимание.  на какие части

422
00:18:03,919 --> 00:18:06,320
каждого из них обращать внимание при

423
00:18:06,320 --> 00:18:10,160
вычислении сходства и, следовательно,

424
00:18:10,160 --> 00:18:12,160
оценки внимания

425
00:18:12,160 --> 00:18:15,280
между исходными скрытыми состояниями, а

426
00:18:15,280 --> 00:18:18,160
затем декодировать скрытое состояние um,

427
00:18:18,160 --> 00:18:21,520
чтобы это было хорошо, что в

428
00:18:21,520 --> 00:18:24,160
целом работает намного лучше, но,

429
00:18:24,160 --> 00:18:27,200
возможно, есть проблема  с тем, что вы

430
00:18:27,200 --> 00:18:30,400
знаете, возможно, эта w-матрица имеет слишком много

431
00:18:30,400 --> 00:18:32,960
параметров, которые вы знаете, потому что у нас есть

432
00:18:32,960 --> 00:18:35,039
эти два вектора, которые в простейшем

433
00:18:35,039 --> 00:18:37,039
случае оба имеют одинаковое измерение d,

434
00:18:37,039 --> 00:18:39,520
но они не обязательно должны быть одинаковыми, и

435
00:18:39,520 --> 00:18:41,679
вы знаете, что мы  теперь добавляем d в квадрате

436
00:18:41,679 --> 00:18:44,880
новых параметров для матрицы w, и такое

437
00:18:44,880 --> 00:18:46,960
ощущение, что их слишком много, потому что

438
00:18:46,960 --> 00:18:48,960
вы знаете, возможно, кажется, что у нас

439
00:18:48,960 --> 00:18:51,200
должно быть только около 2d параметров, вы

440
00:18:51,200 --> 00:18:53,440
знаете, один d говорит, сколько внимания уделяется

441
00:18:53,440 --> 00:18:55,520
боли различным частям s  а другой

442
00:18:55,520 --> 00:18:58,080
вопрос, сколько внимания

443
00:18:58,080 --> 00:18:59,520
уделять возрастным группам,

444
00:18:59,520 --> 00:19:01,360
вы знаете, что есть причина для большего,

445
00:19:01,360 --> 00:19:03,760
имея здесь целую матрицу, вы не

446
00:19:03,760 --> 00:19:06,559
только правильно оцениваете элементы

447
00:19:06,559 --> 00:19:09,120
, вы можете иметь

448
00:19:09,120 --> 00:19:12,480
любой элемент бытия  в сочетании с любым

449
00:19:12,480 --> 00:19:15,520
элементом вектора h и увидите, что

450
00:19:15,520 --> 00:19:19,039
это полезная часть вашей оценки сходства,

451
00:19:19,039 --> 00:19:21,840
но есть еще много параметров,

452
00:19:21,840 --> 00:19:25,520
так что немного позже, ну,

453
00:19:27,039 --> 00:19:29,360
может быть, с меньшими

454
00:19:29,360 --> 00:19:32,720
параметрами, поэтому, если у вас есть матрица w, и

455
00:19:32,720 --> 00:19:34,720
вы бы  хотелось бы, чтобы у него было меньше параметров,

456
00:19:34,720 --> 00:19:37,440
очевидная вещь линейной алгебры

457
00:19:37,440 --> 00:19:41,280
- это сказать: хорошо, мы можем смоделировать w как u,

458
00:19:41,280 --> 00:19:42,960
транспонируя v,

459
00:19:42,960 --> 00:19:44,720
где u и v

460
00:19:44,720 --> 00:19:48,240
- тощие матрицы низкого ранга, поэтому мы можем

461
00:19:48,240 --> 00:19:50,240
выбрать некоторое число k

462
00:19:50,240 --> 00:19:52,400
для того, насколько тощими будут эти матрицы

463
00:19:52,400 --> 00:19:54,960
и они могут быть матрицами k, умноженными на

464
00:19:54,960 --> 00:19:55,679
d,

465
00:19:55,679 --> 00:19:58,000
и тогда мы получаем здесь своего

466
00:19:58,000 --> 00:20:00,880
рода матрицу с уменьшенным рангом, и поэтому у

467
00:20:00,880 --> 00:20:04,720
нас есть много, что мы заканчиваем с ad by d

468
00:20:04,720 --> 00:20:07,039
матрицей, но в ней намного меньше параметров,

469
00:20:07,039 --> 00:20:08,320


470
00:20:08,320 --> 00:20:11,520
и поэтому люди исследовали это  и вы знаете,

471
00:20:11,520 --> 00:20:14,480
что в этот момент um, если вы просто сделаете

472
00:20:14,480 --> 00:20:17,200
немного базовой линейной алгебры, то, что у нас

473
00:20:17,200 --> 00:20:20,640
здесь, точно такие же, как

474
00:20:20,640 --> 00:20:23,360
скрытый вектор источника и скрытый вектор декодера

475
00:20:23,360 --> 00:20:26,159
um, и

476
00:20:26,159 --> 00:20:29,280
проецируя каждый из них с линейной проекцией низкого ранга,

477
00:20:29,280 --> 00:20:31,840
а затем беря

478
00:20:31,840 --> 00:20:34,960
скалярный продукт  проекции,

479
00:20:34,960 --> 00:20:37,039
и если вы запомните это уравнение здесь

480
00:20:37,039 --> 00:20:40,799
до следующей лекции во вторник, вы

481
00:20:40,799 --> 00:20:42,960
увидите, что на самом деле это именно то, что

482
00:20:42,960 --> 00:20:46,000
происходит в моделях трансформаторов,

483
00:20:46,000 --> 00:20:47,679
ммм,

484
00:20:47,679 --> 00:20:50,080
но на самом деле ни одна из них не была

485
00:20:50,080 --> 00:20:52,480
первоначальной формой внимания,

486
00:20:52,480 --> 00:20:58,000
предложенной Барнардо, а что теперь?

487
00:20:58,000 --> 00:21:01,120
- это способ, которым мы могли бы

488
00:21:01,120 --> 00:21:04,240
вычислить оценку натяжения, взяв два

489
00:21:04,240 --> 00:21:08,480
вектора, умножив каждый на матрицу,

490
00:21:08,480 --> 00:21:10,720
добавив их, пропустив через них

491
00:21:10,720 --> 00:21:12,640
через функцию tan h,

492
00:21:12,640 --> 00:21:15,039
дающую нам еще один вектор, который мы затем

493
00:21:15,039 --> 00:21:17,760
умножаем на еще один вектор, и

494
00:21:17,760 --> 00:21:20,720
мы теряем вес  так что

495
00:21:20,720 --> 00:21:22,960
в литературе, которая сравнивает гм

496
00:21:22,960 --> 00:21:25,520
дисперсию внимания, это обычно

497
00:21:25,520 --> 00:21:28,080
называют аддитивным вниманием, я

498
00:21:28,080 --> 00:21:29,280
всегда думал

499
00:21:29,280 --> 00:21:32,400
, что это действительно паршивое имя, ну,

500
00:21:32,400 --> 00:21:34,480
по крайней мере, оно никогда не имело для меня смысла,

501
00:21:34,480 --> 00:21:36,720
потому что на самом деле то, что вы здесь делаете, это

502
00:21:36,720 --> 00:21:39,840
то, что  вы используете новый сетевой слой для

503
00:21:39,840 --> 00:21:42,080
расчета оценки внимания, так что он

504
00:21:42,080 --> 00:21:44,559
выглядит точно так же, как слои нейронной сети,

505
00:21:44,559 --> 00:21:46,640
которые мы использовали, когда хотели

506
00:21:46,640 --> 00:21:49,039
c  подсчитать оценки, например, когда мы

507
00:21:49,039 --> 00:21:51,520
делали простой вид сетей с прямой связью

508
00:21:51,520 --> 00:21:53,120
в начале, и мы

509
00:21:53,120 --> 00:21:56,840
хотели подсчитать оценки,

510
00:21:59,440 --> 00:22:03,200
хорошо, в задании четыре, на что вам

511
00:22:03,200 --> 00:22:04,640
стоит взглянуть очень скоро, если вы

512
00:22:04,640 --> 00:22:06,559
еще не посмотрели на это, на самом деле, один

513
00:22:06,559 --> 00:22:08,640
из  в письменных задачах

514
00:22:08,640 --> 00:22:11,200
четвертого задания мы думаем об

515
00:22:11,200 --> 00:22:12,960
этих различных вариантах внимания,

516
00:22:12,960 --> 00:22:15,280


517
00:22:15,280 --> 00:22:16,799
хорошо,

518
00:22:16,799 --> 00:22:19,280
да, я представил эту идею

519
00:22:19,280 --> 00:22:21,360
внимания только

520
00:22:21,360 --> 00:22:24,000
как нечто хорошее для машинного

521
00:22:24,000 --> 00:22:26,799
перевода, которое используется

522
00:22:26,799 --> 00:22:29,120
между исходной и целевой

523
00:22:29,120 --> 00:22:32,080
моделями последовательности, за исключением того случая, когда

524
00:22:32,080 --> 00:22:34,480
когда я пытаюсь ответить на вопрос, но на

525
00:22:34,480 --> 00:22:37,039
самом деле это общий метод глубокого обучения

526
00:22:37,039 --> 00:22:39,440
, поэтому он отлично подходит не только

527
00:22:39,440 --> 00:22:42,640
для этого приложения, вы можете использовать его во

528
00:22:42,640 --> 00:22:45,120
многих архитектурах, а не только в последовательности

529
00:22:45,120 --> 00:22:47,280
последовательностей, и вы можете использовать его для многих

530
00:22:47,280 --> 00:22:50,080
задач, а не только для машинного перевода,

531
00:22:50,080 --> 00:22:54,240
поэтому  каждый раз, когда у вас есть набор

532
00:22:54,240 --> 00:22:57,440
векторных значений, и у вас есть какой-то другой

533
00:22:57,440 --> 00:23:00,159
вектор, который вы можете рассматривать как

534
00:23:00,159 --> 00:23:02,240
внимание запроса как

535
00:23:02,240 --> 00:23:05,120
метод вычисления значения из th  em,

536
00:23:05,120 --> 00:23:07,520
что вы можете заставить запрос обращать внимание

537
00:23:07,520 --> 00:23:10,400
на значения,

538
00:23:12,240 --> 00:23:14,720
и поэтому вы знаете, когда вы думаете об этом

539
00:23:14,720 --> 00:23:18,320
так, что вы можете думать о внимании

540
00:23:18,320 --> 00:23:21,600
как о неком механизме доступа к памяти,

541
00:23:21,600 --> 00:23:24,159
что взвешенная сумма, которую вычисляет внимание,

542
00:23:24,159 --> 00:23:27,520
дает вам своего рода выборочную

543
00:23:27,520 --> 00:23:29,840
сводку некоторых  информации,

544
00:23:29,840 --> 00:23:32,640
содержащейся в значениях, и запрос

545
00:23:32,640 --> 00:23:33,840
сообщает вам, на

546
00:23:33,840 --> 00:23:37,120
какие значения следует обратить внимание,

547
00:23:37,120 --> 00:23:39,919
поэтому, с одной стороны, вы можете сказать, что

548
00:23:39,919 --> 00:23:43,200
это хороший общий метод в любое время, когда у вас

549
00:23:43,200 --> 00:23:45,840
есть целая группа

550
00:23:45,840 --> 00:23:47,919
векторов, и вы хотите получить только один

551
00:23:47,919 --> 00:23:50,080
вектор.  вы знаете, что самое глупое,

552
00:23:50,080 --> 00:23:51,840
что вы можете сделать, - это просто усреднить их

553
00:23:51,840 --> 00:23:53,919
все или сделать

554
00:23:53,919 --> 00:23:56,640
максимальное объединение, взять поэлементный максимум

555
00:23:56,640 --> 00:23:58,880
каждого элемента, но это дает вам гораздо

556
00:23:58,880 --> 00:24:01,039
более гибкий способ объединить их

557
00:24:01,039 --> 00:24:04,640
вместе в один вектор, и поэтому

558
00:24:04,640 --> 00:24:07,279
вы можете думать  он дает

559
00:24:07,279 --> 00:24:10,240
нам операцию, которая больше

560
00:24:10,240 --> 00:24:12,880
похожа на обычный компьютер, и это

561
00:24:12,880 --> 00:24:14,400
доступ к памяти,

562
00:24:14,400 --> 00:24:17,200
поэтому значения, которые мы можем думать, как о

563
00:24:17,200 --> 00:24:19,919
нашем баране,

564
00:24:20,559 --> 00:24:21,520
и

565
00:24:21,520 --> 00:24:22,559
э-э,

566
00:24:22,559 --> 00:24:24,400
как ассоциативная память, верно, у нас

567
00:24:24,400 --> 00:24:27,279
есть  вектор запроса и вектор запроса действуют

568
00:24:27,279 --> 00:24:28,720
как своего рода

569
00:24:28,720 --> 00:24:31,279
указатель ассоциативной памяти, который говорит,

570
00:24:31,279 --> 00:24:34,080
какой вес нужно приложить к различным частям оперативной памяти,

571
00:24:34,080 --> 00:24:36,240
а затем мы пропорционально

572
00:24:36,240 --> 00:24:38,799
извлекаем эти биты вокруг, чтобы получить новое

573
00:24:38,799 --> 00:24:40,799
значение,

574
00:24:40,799 --> 00:24:43,120
еще одна интересная вещь о

575
00:24:43,120 --> 00:24:46,559
внимании, которое я '  Я просто упомяну здесь,

576
00:24:46,559 --> 00:24:48,799
что

577
00:24:48,799 --> 00:24:50,880
вы знаете, что внимание было

578
00:24:50,880 --> 00:24:54,320
действительно новой идеей глубокого обучения

579
00:24:54,320 --> 00:24:56,240
из последнего десятилетия. В середине последнего

580
00:24:56,240 --> 00:24:58,480
десятилетия есть своего рода немного

581
00:24:58,480 --> 00:25:01,039
удручающий факт о глубоком обучении

582
00:25:01,039 --> 00:25:03,679
: многое из того, что было сделано в области глубокого

583
00:25:03,679 --> 00:25:06,400
обучения за последние годы.  на самом деле не было

584
00:25:06,400 --> 00:25:08,880
новых идей, были идеи, которые были

585
00:25:08,880 --> 00:25:11,520
разработаны в 80-х и 90-х годах, просто

586
00:25:11,520 --> 00:25:13,120
люди не могли широко использовать

587
00:25:13,120 --> 00:25:15,600
их тогда, потому что их компьютеры были

588
00:25:15,600 --> 00:25:17,200
слишком малы, а объем данных, которые

589
00:25:17,200 --> 00:25:19,600
у них были, был слишком мал, а они были  они были

590
00:25:19,600 --> 00:25:21,840
изобретены заново в двух

591
00:25:21,840 --> 00:25:24,480
колодцах, но не изобретены заново, но они получили новую жизнь

592
00:25:24,480 --> 00:25:26,720
в 2010-х,

593
00:25:26,720 --> 00:25:29,520
где внимание - это действительно

594
00:25:29,520 --> 00:25:33,600
новая идея из 2010-х, и мы увидим что-

595
00:25:33,600 --> 00:25:35,600
то вроде гм на

596
00:25:35,600 --> 00:25:38,080
следующей неделе  как это потом превращается

597
00:25:38,080 --> 00:25:42,720
в эту огромную идею, которая преобразует nlp,

598
00:25:42,720 --> 00:25:43,679
хорошо,

599
00:25:43,679 --> 00:25:45,360
так что это все, что я хотел сказать о

600
00:25:45,360 --> 00:25:48,320
внимании, а теперь я

601
00:25:48,320 --> 00:25:50,400
хочу продолжить и пойти и поговорить о финальных

602
00:25:50,400 --> 00:25:53,039
проектах и обо всем этом,

603
00:25:53,039 --> 00:25:55,279
так что я хорошо  начни с других

604
00:25:55,279 --> 00:25:57,840
вещей

605
00:25:59,919 --> 00:26:00,720
да

606
00:26:00,720 --> 00:26:02,080
да

607
00:26:02,080 --> 00:26:04,799
ладно так что это быстрое напоминание, так что

608
00:26:04,799 --> 00:26:08,320
вы не забываете, что это их курсовая работа эм,

609
00:26:08,320 --> 00:26:10,080
так что вы

610
00:26:10,080 --> 00:26:11,440
прямо в

611
00:26:11,440 --> 00:26:14,799
середине или в середине, почти на полпути

612
00:26:14,799 --> 00:26:17,279
к выполнению задания, а они

613
00:26:17,279 --> 00:26:19,600
стоят примерно половину  оценка, но другая

614
00:26:19,600 --> 00:26:20,960
половина оценки

615
00:26:20,960 --> 00:26:23,840
получена из последнего проекта, о котором я

616
00:26:23,840 --> 00:26:26,320
собираюсь поговорить сегодня, и который будет

617
00:26:26,320 --> 00:26:28,720
разделен, так что есть проектное

618
00:26:28,720 --> 00:26:30,720
предложение, которое мы раздали

619
00:26:30,720 --> 00:26:32,799
инструкциям на сегодня, стоит пять

620
00:26:32,799 --> 00:26:35,279
процентов, есть  веха, которая стоит

621
00:26:35,279 --> 00:26:37,679
пять процентов в середине,

622
00:26:37,679 --> 00:26:39,360
и в конце есть отчет, который

623
00:26:39,360 --> 00:26:42,000
является большой частью, которая стоит 30 процентов,

624
00:26:42,000 --> 00:26:43,640
а затем мы также хотим иметь

625
00:26:43,640 --> 00:26:45,679
представление о вашем проекте, которое

626
00:26:45,679 --> 00:26:48,720
люди могут легко просматривать, поэтому в

627
00:26:48,720 --> 00:26:50,720
обычные годы, когда есть  В

628
00:26:50,720 --> 00:26:53,039
кампусе мы провели стендовую сессию для

629
00:26:53,039 --> 00:26:54,720
класса, что просто кажется, что мы просто

630
00:26:54,720 --> 00:26:57,279
не можем с пользой делать в нынешнем мире,

631
00:26:57,279 --> 00:26:59,919
мы хотим создать веб-сайт, эм, где

632
00:26:59,919 --> 00:27:01,600
есть своего рода краткие описания

633
00:27:01,600 --> 00:27:02,320
каждого

634
00:27:02,320 --> 00:27:04,480
проекта, какая-то хорошая картина того, что вы ''  я

635
00:27:04,480 --> 00:27:07,120
сделал эм, а затем мы сможем связать ваш

636
00:27:07,120 --> 00:27:09,600
проект с подсветкой, и вы также

637
00:27:09,600 --> 00:27:11,760
получите за это три процента, это, возможно,

638
00:27:11,760 --> 00:27:13,360
просто убедитесь, что вы это сделаете, когда

639
00:27:13,360 --> 00:27:15,679
доходит до этого

640
00:27:15,679 --> 00:27:18,480
эммм, да, так что я должен просто

641
00:27:18,480 --> 00:27:21,200
упомянуть еще раз  поскольку мы идем по

642
00:27:21,200 --> 00:27:23,279
кодексу чести,

643
00:27:23,279 --> 00:27:25,760
который важен также

644
00:27:25,760 --> 00:27:28,240
для финальных проектов, просто чтобы

645
00:27:28,240 --> 00:27:31,440
прояснить это, поэтому для финальных проектов

646
00:27:31,440 --> 00:27:33,600
во многих случаях вы собираетесь использовать

647
00:27:33,600 --> 00:27:35,679
много вещей, которые уже существуют, которые

648
00:27:35,679 --> 00:27:38,559
вы вполне можете использовать  некоторая модель, которую

649
00:27:38,559 --> 00:27:40,399
вы можете просто загрузить из репозитория github

650
00:27:40,399 --> 00:27:43,919
или подобных мест,

651
00:27:43,919 --> 00:27:45,360
вы

652
00:27:45,360 --> 00:27:48,320
вполне можете использовать различные идеи, вы

653
00:27:48,320 --> 00:27:50,960
знаете, что в конечном проекте нормально

654
00:27:50,960 --> 00:27:53,919
использовать любое количество существующих вещей,

655
00:27:53,919 --> 00:27:56,720
но вы должны убедиться,

656
00:27:56,720 --> 00:27:58,559
что вы подтверждаете, что используете  и

657
00:27:58,559 --> 00:28:02,080
задокументируйте это  и с точки зрения оценки

658
00:28:02,080 --> 00:28:04,720
ваших проектов нас будет

659
00:28:04,720 --> 00:28:07,520
интересовать добавленная стоимость с точки

660
00:28:07,520 --> 00:28:10,559
зрения того, что вы сделали, а не то, что вы

661
00:28:10,559 --> 00:28:13,679
можете скачать у других людей,

662
00:28:13,679 --> 00:28:15,600
поэтому для финального проекта у вас могут быть

663
00:28:15,600 --> 00:28:17,600
команды от одного до трех

664
00:28:17,600 --> 00:28:19,039
хм

665
00:28:19,039 --> 00:28:21,679
, почти в каждом случае каждый член

666
00:28:21,679 --> 00:28:24,159
команды получает одинаковую оценку, но мы

667
00:28:24,159 --> 00:28:26,240
просим кратко описать работу,

668
00:28:26,240 --> 00:28:28,480
проделанную каждым товарищем по команде, и, если ясно,

669
00:28:28,480 --> 00:28:30,960
что был какой-то вопиющий

670
00:28:30,960 --> 00:28:34,320
дисбаланс, примерно в одном из ста

671
00:28:34,320 --> 00:28:37,679
случаев, мы  сделайте что-нибудь с этим

672
00:28:37,679 --> 00:28:40,320
хорошо, поэтому для финального проекта у вас, по

673
00:28:40,320 --> 00:28:42,720
сути, есть два варианта: вы можете

674
00:28:42,720 --> 00:28:45,279
либо выполнить наш окончательный проект по умолчанию,

675
00:28:45,279 --> 00:28:48,480
где мы даем вам строительные леса и

676
00:28:48,480 --> 00:28:51,679
сказали, что вы указали в каком-то направлении, либо

677
00:28:51,679 --> 00:28:54,880
вы можете предложить собственный окончательный проект,

678
00:28:54,880 --> 00:28:56,960
который мы  затем необходимо утвердить в качестве

679
00:28:56,960 --> 00:28:59,039
подходящего финального проекта для курса,

680
00:28:59,039 --> 00:29:00,799
и я собираюсь немного рассказать об

681
00:29:00,799 --> 00:29:03,520
обоих в этом классе,

682
00:29:03,520 --> 00:29:06,880
чтобы вы могли работать в группах от одного до трех человек,

683
00:29:06,880 --> 00:29:09,279
если у вас большая команда, мы ожидаем, что

684
00:29:09,279 --> 00:29:10,960
вы сделаете больше

685
00:29:10,960 --> 00:29:13,200
иногда люди используют  один и тот же проект

686
00:29:13,200 --> 00:29:16,480
для нескольких классов um, чтобы он

687
00:29:16,480 --> 00:29:20,000
также мог использовать его, поскольку um

688
00:29:22,399 --> 00:29:24,320
разрешает это, но это вроде того же

689
00:29:24,320 --> 00:29:26,159
общего правила, так что у них есть двое из

690
00:29:26,159 --> 00:29:28,159
вас, и вы используете проект для двух

691
00:29:28,159 --> 00:29:30,080
классов, каждый из которых вроде как

692
00:29:30,080 --> 00:29:32,960
должен  работа должна быть выполнена на четыре человека,

693
00:29:32,960 --> 00:29:35,760
и поэтому мы ожидаем, что вы

694
00:29:35,760 --> 00:29:37,919
знаете проекты, которые

695
00:29:37,919 --> 00:29:39,279
больше, чем

696
00:29:39,279 --> 00:29:41,919
вы знаете, если это всего лишь один из вас, мы

697
00:29:41,919 --> 00:29:44,159
можем быть полностью удовлетворены чем-то

698
00:29:44,159 --> 00:29:46,159
компактным и маленьким, о котором вы знаете, так что это должно

699
00:29:46,159 --> 00:29:49,200
быть сделано  но он может быть компактным и

700
00:29:49,200 --> 00:29:52,080
маленьким, тогда как если вас трое,

701
00:29:52,080 --> 00:29:54,080
мы вроде как чувствуем, что у вас действительно

702
00:29:54,080 --> 00:29:56,880
должно быть достаточно времени, чтобы на самом деле

703
00:29:56,880 --> 00:29:58,559
реализовать вариантную модель, и посмотреть

704
00:29:58,559 --> 00:30:01,520
, работает ли она лучше,

705
00:30:02,240 --> 00:30:04,159
вы можете использовать любую структуру на том языке, на котором

706
00:30:04,159 --> 00:30:06,320
вы хотите  финальный проект,

707
00:30:06,320 --> 00:30:09,039
но на практике в основном люди продолжают

708
00:30:09,039 --> 00:30:12,159
использовать пирог-факел, а затем, наконец, я

709
00:30:12,159 --> 00:30:14,480
должен упомянуть о финальном проекте по умолчанию,

710
00:30:14,480 --> 00:30:16,480
я вернусь к нему через

711
00:30:16,480 --> 00:30:18,799
минуту, но на самом деле в этом году новинка

712
00:30:18,799 --> 00:30:21,840
у нас есть два дополнительных  варианты

713
00:30:21,840 --> 00:30:24,240
финальный проект по умолчанию, и вы можете выбрать

714
00:30:24,240 --> 00:30:26,000
один или другой,

715
00:30:26,000 --> 00:30:26,880


716
00:30:26,880 --> 00:30:29,520
так что для нестандартных финальных проектов я действительно

717
00:30:29,520 --> 00:30:32,080
рад поговорить с людьми о финальных

718
00:30:32,080 --> 00:30:34,480
проектах, но есть эта проблема

719
00:30:34,480 --> 00:30:36,799
, и вам рекомендуется подписаться

720
00:30:36,799 --> 00:30:39,360
на рабочий час  но есть эта

721
00:30:39,360 --> 00:30:42,880
проблема, есть только один из меня, так что

722
00:30:42,880 --> 00:30:46,799
также поощряйте вас поговорить

723
00:30:46,799 --> 00:30:49,520
с дегустаторами о финальных проектах, у многих из

724
00:30:49,520 --> 00:30:51,679
них есть опыт для самых разных

725
00:30:51,679 --> 00:30:53,360
вещей, и мы попытались

726
00:30:53,360 --> 00:30:55,200
обобщить некоторые из того, что у них есть

727
00:30:55,200 --> 00:30:56,559


728
00:30:56,559 --> 00:30:57,519
с

729
00:30:57,519 --> 00:31:00,559
на странице рабочего времени, так что посмотрите на это

730
00:31:00,559 --> 00:31:02,640
и попытайтесь получить некоторые идеи о том, о ком можно было

731
00:31:02,640 --> 00:31:06,320
бы хорошо поговорить, так что

732
00:31:06,320 --> 00:31:09,200
для окончательных проектов

733
00:31:09,200 --> 00:31:11,600
мы позаботимся о том, чтобы у каждого был какой-то

734
00:31:11,600 --> 00:31:14,720
наставник, и наставник может быть либо та,

735
00:31:14,720 --> 00:31:17,440
либо инструктором в этом  класс, или это может

736
00:31:17,440 --> 00:31:20,159
быть кто-то другой, а для

737
00:31:20,159 --> 00:31:22,720
другого варианта - хорошо, вы знаете, есть ли

738
00:31:22,720 --> 00:31:25,200
кто-то, кого вы знаете в Стэнфорде, и есть ли у них

739
00:31:25,200 --> 00:31:27,440
какой-то классный проект, вы знаете,

740
00:31:27,440 --> 00:31:29,760
что это такое, если это что-то, что

741
00:31:29,760 --> 00:31:32,000
вы знаете, и

742
00:31:32,000 --> 00:31:34,640
политология и

743
00:31:34,640 --> 00:31:37,840


744
00:31:37,840 --> 00:31:41,279
Вы можете попросить их стать вашим наставником, или

745
00:31:41,279 --> 00:31:43,519
мы также собрали несколько проектов от

746
00:31:43,519 --> 00:31:46,000
людей из стэнфордской группы и сообщества НЛП,

747
00:31:46,000 --> 00:31:47,760
и мы собираемся

748
00:31:47,760 --> 00:31:50,320
распространить их список, чтобы вы могли

749
00:31:50,320 --> 00:31:52,480
попробовать и  своего рода подписаться на выполнение одного

750
00:31:52,480 --> 00:31:54,159
из этих проектов, и они могут быть

751
00:31:54,159 --> 00:31:58,159
наставниками, поэтому в этом случае другой человек, которого

752
00:31:58,159 --> 00:31:59,840
мы ожидаем, будет наставником, который будет

753
00:31:59,840 --> 00:32:01,360
следить за вашим проектом и

754
00:32:01,360 --> 00:32:02,880
говорить вам, что нужно сделать что-то

755
00:32:02,880 --> 00:32:05,919
разумное, но это один  из тех,

756
00:32:05,919 --> 00:32:07,919
кто будет оценивать

757
00:32:07,919 --> 00:32:11,440
ваши различные работы для класса,

758
00:32:11,440 --> 00:32:14,640
хорошо, так что это подробности о

759
00:32:14,640 --> 00:32:17,120
двух окончательных проектах по умолчанию и

760
00:32:17,120 --> 00:32:19,679
раздаточные материалы для них, их примерно

761
00:32:19,679 --> 00:32:22,080
десять или около того раздаточных страниц для каждого из них

762
00:32:22,080 --> 00:32:24,640
они сейчас в сети, так что

763
00:32:24,640 --> 00:32:26,799
они оба связаны с ответами на вопросы, о

764
00:32:26,799 --> 00:32:28,480
которых я немного упомяну

765
00:32:28,480 --> 00:32:30,159
в конце,

766
00:32:30,159 --> 00:32:33,279
и есть два варианта,

767
00:32:33,279 --> 00:32:34,399
один

768
00:32:34,399 --> 00:32:35,919
для вас, чтобы вы на самом деле

769
00:32:35,919 --> 00:32:39,440
построили архитектуру ответов на вопросы

770
00:32:39,440 --> 00:32:43,279
самостоятельно и  я  описать это как

771
00:32:43,279 --> 00:32:45,440
с нуля, но на самом деле это не с

772
00:32:45,440 --> 00:32:48,000
нуля, потому что мы даем вам базовую

773
00:32:48,000 --> 00:32:49,840
систему ответов на вопросы в стартовом

774
00:32:49,840 --> 00:32:52,399
коде, но вы работаете над тем,

775
00:32:52,399 --> 00:32:54,159
что еще я могу добавить в

776
00:32:54,159 --> 00:32:56,159
модель, как я могу добавить дополнительные

777
00:32:56,159 --> 00:32:58,320
слои  внимание и другие вещи, чтобы

778
00:32:58,320 --> 00:33:02,640
сделать его лучше, используя набор данных отряда,

779
00:33:02,640 --> 00:33:04,080


780
00:33:04,080 --> 00:33:07,600
но одна из вещей, которая произошла в

781
00:33:07,600 --> 00:33:08,720
НЛП,

782
00:33:08,720 --> 00:33:10,640
которая на самом деле является темой занятий на следующей

783
00:33:10,640 --> 00:33:13,200
неделе, а в последние несколько лет в

784
00:33:13,200 --> 00:33:16,640
НЛП произошла настоящая революция в

785
00:33:16,640 --> 00:33:17,760
использовании

786
00:33:17,760 --> 00:33:18,799
больших

787
00:33:18,799 --> 00:33:21,919
предварительно обученных  языковые модели с такими именами,

788
00:33:21,919 --> 00:33:25,200
как рождение роберта и

789
00:33:25,200 --> 00:33:27,360
другие, которые только что были

790
00:33:27,360 --> 00:33:29,360
фантастически хороши для решения

791
00:33:29,360 --> 00:33:33,600
задач естественного языка, поэтому другой выбор

792
00:33:33,600 --> 00:33:37,120
- использовать эти модели, а

793
00:33:37,120 --> 00:33:39,600
затем эффективно модель и

794
00:33:39,600 --> 00:33:42,000
архитектура модели в качестве отправной точки.

795
00:33:42,000 --> 00:33:44,399
для вас, и поэтому мы

796
00:33:44,399 --> 00:33:47,039
надеемся, что люди сосредоточатся на том, как

797
00:33:47,039 --> 00:33:49,600
создать надежную систему ответов на вопросы,

798
00:33:49,600 --> 00:33:51,919
которая работает с разными наборами данных

799
00:33:51,919 --> 00:33:54,640
и доменами, так что огромное  Проблема со

800
00:33:54,640 --> 00:33:58,480
многими моделями nlp заключается в том, что если вы обучаете их,

801
00:33:58,480 --> 00:34:01,440
скажем, данным из Википедии, они отлично работают с

802
00:34:01,440 --> 00:34:04,080
данными из Википедии, но затем, как только вы

803
00:34:04,080 --> 00:34:05,120
попытаетесь

804
00:34:05,120 --> 00:34:07,360
использовать их в чем-то еще, будь то

805
00:34:07,360 --> 00:34:10,480
вопросы поддержки клиентов или веб-

806
00:34:10,480 --> 00:34:13,040
вопросы, их производительность

807
00:34:13,040 --> 00:34:16,239
значительно ухудшится, несмотря на  тот факт,

808
00:34:16,239 --> 00:34:18,480
что человеку кажется, что

809
00:34:18,480 --> 00:34:21,720
вы

810
00:34:21,839 --> 00:34:24,480
отвечаете последним, и

811
00:34:24,480 --> 00:34:26,800
поэтому для создания надежной системы контроля

812
00:34:26,800 --> 00:34:28,639
качества мы собираемся быть своего рода

813
00:34:28,639 --> 00:34:31,440
обучением или тонкой настройкой предварительно обученных

814
00:34:31,440 --> 00:34:35,119
языковых моделей на нескольких наборах данных  и

815
00:34:35,119 --> 00:34:37,359
ваша цель - создать что-то, что

816
00:34:37,359 --> 00:34:40,000
затем будет хорошо работать с разными наборами данных,

817
00:34:40,000 --> 00:34:42,159


818
00:34:42,159 --> 00:34:43,280
хорошо,

819
00:34:43,280 --> 00:34:46,320
поэтому для этой темы с ответами на вопросы

820
00:34:46,320 --> 00:34:47,918
я собираюсь остановиться на несколько минут

821
00:34:47,918 --> 00:34:52,079
в конце, но во вторник шестой

822
00:34:52,079 --> 00:34:53,918
недели вся лекция под вопросом

823
00:34:53,918 --> 00:34:55,440
отвечая, так что там будет много

824
00:34:55,440 --> 00:34:57,200
контента о различных типах

825
00:34:57,200 --> 00:35:00,000
моделей, эм, чтобы действительно ускориться,

826
00:35:00,000 --> 00:35:01,520
хорошие вещи, которые нужно знать, даже если вы не

827
00:35:01,520 --> 00:35:03,599
выполняете финальные проекты по умолчанию, это

828
00:35:03,599 --> 00:35:06,320
основное приложение nlp b  Но еще лучше

829
00:35:06,320 --> 00:35:08,320
знать, делаете ли вы

830
00:35:08,320 --> 00:35:10,560
финальный проект, так что следите за этим, но

831
00:35:10,560 --> 00:35:12,480
просто чтобы дать вам один пример

832
00:35:12,480 --> 00:35:13,599
, у нас есть

833
00:35:13,599 --> 00:35:15,040


834
00:35:15,040 --> 00:35:18,079
проблемы с ответами на вопросы, поэтому ответ на вопрос

835
00:35:18,079 --> 00:35:21,119
берет абзац текста, но я

836
00:35:21,119 --> 00:35:23,839
поставил только одно предложение, чтобы мои слайды были короткими

837
00:35:23,839 --> 00:35:26,480
эм Билл Лакен, усыновленный мексиканской

838
00:35:26,480 --> 00:35:28,240
киноактрисой лука

839
00:35:28,240 --> 00:35:30,720
майорга, выросла в соседнем

840
00:35:30,720 --> 00:35:34,240
городе мадера, и его песня записана в хронику

841
00:35:34,240 --> 00:35:36,960
эм вопрос в том, в каком городе

842
00:35:36,960 --> 00:35:39,040
вырос Билл Айкен это на самом деле не похоже

843
00:35:39,040 --> 00:35:41,680
так сложно, я полагаю, все вы могли

844
00:35:41,680 --> 00:35:43,359
бы сделать это, когда были в шестом

845
00:35:43,359 --> 00:35:45,359
классе в школе, или что-

846
00:35:45,359 --> 00:35:47,359
то в этом роде, ответ должен быть сделан мадейра,

847
00:35:47,359 --> 00:35:50,800
но каким-то образом модель берта Google не

848
00:35:50,800 --> 00:35:53,440
может найти этот ответ ммм, возможно, вы знаете,

849
00:35:53,440 --> 00:35:55,520
что это отчасти потому, что есть лишние вещи

850
00:35:55,520 --> 00:35:57,440
посередине усыновлена мексиканской

851
00:35:57,440 --> 00:35:59,119
киноактрисой,

852
00:35:59,119 --> 00:36:02,000
и поэтому здесь сказано: нет, это предложение

853
00:36:02,000 --> 00:36:04,640
не отвечает на вопрос, так что вы можете

854
00:36:04,640 --> 00:36:07,599
надеяться добиться

855
00:36:07,599 --> 00:36:10,240


856
00:36:10,240 --> 00:36:13,359
большего  он по умолчанию или пользовательский финальный

857
00:36:13,359 --> 00:36:17,280
проект ммм, и вы знаете, что общая

858
00:36:17,280 --> 00:36:20,079
статистика была такова, что примерно половина

859
00:36:20,079 --> 00:36:23,440
людей делает каждый мм, поэтому нет

860
00:36:23,440 --> 00:36:25,920
явного победителя выбора

861
00:36:25,920 --> 00:36:28,720
с точки зрения размышлений о

862
00:36:28,720 --> 00:36:31,599
том, что вы должны выбрать, я имею в виду, я думаю,

863
00:36:31,599 --> 00:36:34,640
что окончательный проект по умолчанию  отлично, если у

864
00:36:34,640 --> 00:36:36,480
вас ограниченный опыт проведения

865
00:36:36,480 --> 00:36:39,119
исследований, если у вас нет четкого

866
00:36:39,119 --> 00:36:41,040
представления о том, что вы хотели бы сделать в качестве

867
00:36:41,040 --> 00:36:43,680
окончательного проекта, если вы думаете, что было

868
00:36:43,680 --> 00:36:46,160
бы хорошо, если бы вы знали руководство и

869
00:36:46,160 --> 00:36:48,720
четкую цель, над которой нужно работать  на самом деле мы

870
00:36:48,720 --> 00:36:50,240
даем вам таблицу лидеров, чтобы вы могли

871
00:36:50,240 --> 00:36:51,920
соревноваться с другими людьми во

872
00:36:51,920 --> 00:36:55,280
время финального проекта, а затем вы должны

873
00:36:55,280 --> 00:36:57,839
выполнить окончательный проект по умолчанию, он дает вам

874
00:36:57,839 --> 00:37:01,680
руководство, выстраивая четкие сообщения о

875
00:37:01,680 --> 00:37:04,800
целях, я имею в виду и, в частности, просто чтобы вроде как

876
00:37:04,800 --> 00:37:08,240
попытаться и дать  Я

877
00:37:08,240 --> 00:37:09,839
имею в виду, что вы знаете,

878
00:37:09,839 --> 00:37:12,720
что факт в том, что каждый год

879
00:37:12,720 --> 00:37:15,359
есть несколько человек, которые делают

880
00:37:15,359 --> 00:37:18,400
нестандартный окончательный проект, и когда мы

881
00:37:18,400 --> 00:37:20,640
оцениваем их, мы смотрим на этот индивидуальный

882
00:37:20,640 --> 00:37:23,520
окончательный проект, и

883
00:37:23,520 --> 00:37:25,839
мы говорим, да, вы знаете, что  s просто выглядит

884
00:37:25,839 --> 00:37:28,079
довольно неубедительно по сравнению с тем, что люди

885
00:37:28,079 --> 00:37:31,599
делают в окончательном проекте по умолчанию, и

886
00:37:31,599 --> 00:37:34,000
это плохое состояние, чтобы быть в правильном состоянии, если

887
00:37:34,000 --> 00:37:36,240
вы делаете собственный конечный проект,

888
00:37:36,240 --> 00:37:38,960
вы хотите иметь что-то вроде четкой вещи,

889
00:37:38,960 --> 00:37:40,800
которую вы продумали.  это

890
00:37:40,800 --> 00:37:43,920
интересно, так что он будет казаться или более

891
00:37:43,920 --> 00:37:45,200
интересным,

892
00:37:45,200 --> 00:37:47,520
чем финальный проект по умолчанию, и если

893
00:37:47,520 --> 00:37:49,280
вы не думаете, что у вас есть такая вещь,

894
00:37:49,280 --> 00:37:50,800
вам на самом деле лучше сделать

895
00:37:50,800 --> 00:37:54,160
финальный проект по умолчанию,

896
00:37:54,320 --> 00:37:56,400
почему вы должны делать собственный финальный

897
00:37:56,400 --> 00:37:57,520
проект

898
00:37:57,520 --> 00:38:00,240
хорошо, если у вас есть какой-то исследовательский проект,

899
00:38:00,240 --> 00:38:01,760
возможно, над чем-то, над чем вы уже

900
00:38:01,760 --> 00:38:04,079
работаете, или, во всяком случае, что-то, что, по

901
00:38:04,079 --> 00:38:06,560
вашему мнению, было бы здорово сделать,

902
00:38:06,560 --> 00:38:08,720
эм, есть два требования к

903
00:38:08,720 --> 00:38:11,359
нашему проекту, он должен по существу

904
00:38:11,359 --> 00:38:14,000
включать человеческий язык, и он должен

905
00:38:14,000 --> 00:38:16,560
по существу задействовать нейронные сети, так

906
00:38:16,560 --> 00:38:18,000
что это не значит, что они должны быть полностью

907
00:38:18,000 --> 00:38:19,760
посвящены этим, если вы хотите сделать проект по языку

908
00:38:19,760 --> 00:38:23,599
и видению, который хорош, ммм, или если

909
00:38:23,599 --> 00:38:26,000
вы хотите сравнить нейронные сети

910
00:38:26,000 --> 00:38:28,560
с другими методами машинного обучения.  с

911
00:38:28,560 --> 00:38:31,040
какой-то проблемой, это нормально, но вы

912
00:38:31,040 --> 00:38:34,000
должны в своем проекте по существу использовать

913
00:38:34,000 --> 00:38:36,320
обе эти вещи,

914
00:38:36,320 --> 00:38:38,079
ага, так что если вы хотите как-то спроектировать

915
00:38:38,079 --> 00:38:39,520
свою собственную вещь и придумать

916
00:38:39,520 --> 00:38:41,760
что-то другое самостоятельно, или просто

917
00:38:41,760 --> 00:38:44,720
вы не делаете  Мне нравится отвечать на вопросы,

918
00:38:44,720 --> 00:38:47,440
или если вы в основном хотите получить больше опыта,

919
00:38:47,440 --> 00:38:49,359
чтобы пройти весь процесс

920
00:38:49,359 --> 00:38:51,359
поиска хорошей исследовательской цели,

921
00:38:51,359 --> 00:38:53,599
найти данные и инструменты для ее изучения,

922
00:38:53,599 --> 00:38:55,760
работая самостоятельно, тогда создание

923
00:38:55,760 --> 00:38:58,000
индивидуального окончательного проекта

924
00:38:58,000 --> 00:39:01,560
- отличный выбор,

925
00:39:01,599 --> 00:39:03,040
хорошо,

926
00:39:03,040 --> 00:39:04,400
либо  Таким образом,

927
00:39:04,400 --> 00:39:08,400
шаги, которые вы выполняете,

928
00:39:08,400 --> 00:39:11,440
следующие, поэтому первое,

929
00:39:11,440 --> 00:39:15,119
что вы перешли к fib 16, - это

930
00:39:15,119 --> 00:39:18,960
написать проектное предложение, которое состоит из

931
00:39:18,960 --> 00:39:21,200
трех

932
00:39:21,920 --> 00:39:23,200
страниц,

933
00:39:23,200 --> 00:39:24,160
чтобы

934
00:39:24,160 --> 00:39:25,119
вы знали,

935
00:39:25,119 --> 00:39:27,599
как некоторые детали менялись в зависимости от

936
00:39:27,599 --> 00:39:30,480
типа проекта  поэтому вам нужно определиться с

937
00:39:30,480 --> 00:39:32,160


938
00:39:32,160 --> 00:39:33,680
темой исследования для вашего

939
00:39:33,680 --> 00:39:35,839
проекта, что довольно легко, если вы

940
00:39:35,839 --> 00:39:38,400
делаете последний проект, это либо a, либо

941
00:39:38,400 --> 00:39:39,839
b,

942
00:39:39,839 --> 00:39:42,880
но затем мы хотим, чтобы вы выбрали одну

943
00:39:42,880 --> 00:39:44,880
исследовательскую работу, которая имеет отношение к вашему

944
00:39:44,880 --> 00:39:46,400
окончательному проекту,

945
00:39:46,400 --> 00:39:48,480
прочтите ее и

946
00:39:48,480 --> 00:39:49,520
затем

947
00:39:49,520 --> 00:39:51,280
узнайте из него кое-что, о чем вы можете

948
00:39:51,280 --> 00:39:52,560
написать,

949
00:39:52,560 --> 00:39:54,960
и мы хотим, чтобы вы написали о своем

950
00:39:54,960 --> 00:39:56,880
плане, о том, что вы собираетесь делать

951
00:39:56,880 --> 00:39:59,599
с окончательным проектом, и это будет включать в себя

952
00:39:59,599 --> 00:40:02,079
описание необходимых вещей, таких как

953
00:40:02,079 --> 00:40:05,520
данные и оценка, и еще раз

954
00:40:05,520 --> 00:40:07,680
это особенно важно для нестандартных финальных

955
00:40:07,680 --> 00:40:08,880
проектов,

956
00:40:08,880 --> 00:40:11,680
может быть очевидным, если вы

957
00:40:11,680 --> 00:40:15,200
делаете финальный проект по умолчанию,

958
00:40:15,200 --> 00:40:17,440
и поэтому обычно, если вы делаете

959
00:40:17,440 --> 00:40:19,359
финальный проект по умолчанию,

960
00:40:19,359 --> 00:40:21,200
это должно быть три пейджера, и если

961
00:40:21,200 --> 00:40:23,040
вы делаете собственный окончательный проект  это

962
00:40:23,040 --> 00:40:24,960
должно быть четыре страницы,

963
00:40:24,960 --> 00:40:26,400
так

964
00:40:26,400 --> 00:40:28,720
что есть две части из них, первая

965
00:40:28,720 --> 00:40:30,720
часть

966
00:40:30,720 --> 00:40:33,200
посвящена бумаге, которую вы читаете, и

967
00:40:33,200 --> 00:40:36,480
эта часть составляет две страницы, поэтому мы представляем

968
00:40:36,480 --> 00:40:38,800
собой более длинную форму инструкций, но мы

969
00:40:38,800 --> 00:40:41,200
хотим, чтобы вы отсортировали  Прочитав и подумав об

970
00:40:41,200 --> 00:40:43,119
этой статье, вы знаете, каков ее новый

971
00:40:43,119 --> 00:40:44,640
вклад

972
00:40:44,640 --> 00:40:46,960
в том, что идея, которую можно было бы

973
00:40:46,960 --> 00:40:49,760
использовать по-другому, есть вещи,

974
00:40:49,760 --> 00:40:52,560
которые действительно не очень хорошо ...

975
00:40:52,560 --> 00:40:54,720


976
00:40:54,720 --> 00:40:57,200
проблема делает ли

977
00:40:57,200 --> 00:40:58,800
это своего рода

978
00:40:58,800 --> 00:41:00,640
предположением, даже если он делал что-то одним

979
00:41:00,640 --> 00:41:02,960
способом, действительно ли он предлагает идеи, которые

980
00:41:02,960 --> 00:41:04,960
действительно могли бы делать что-то другим способом,

981
00:41:04,960 --> 00:41:08,880
который может быть даже лучше, и поэтому

982
00:41:08,880 --> 00:41:10,720
мы хотим, чтобы вы написали это

983
00:41:10,720 --> 00:41:13,119
двухстраничное резюме статьи, которое мы будем

984
00:41:13,119 --> 00:41:15,760
оценивать и  по сути, мы собираемся

985
00:41:15,760 --> 00:41:19,599
оценить это по тому, насколько хорошо вы справляетесь с

986
00:41:19,599 --> 00:41:22,400
размышлениями об анализе и с

987
00:41:22,400 --> 00:41:24,880
критическими комментариями к этой статье,

988
00:41:24,880 --> 00:41:26,800
поэтому вторая половина, которая может быть

989
00:41:26,800 --> 00:41:29,040
длиннее или короче сейчас в зависимости от этого

990
00:41:29,040 --> 00:41:32,319
обычая или по умолчанию,

991
00:41:32,319 --> 00:41:35,520
должна предложить то, что вы  мы собираемся сделать

992
00:41:35,520 --> 00:41:36,319
эм,

993
00:41:36,319 --> 00:41:37,440
и на

994
00:41:37,440 --> 00:41:39,920
самом деле эта часть является формирующей, поэтому

995
00:41:39,920 --> 00:41:42,160
формирующая означает, что мы не собираемся

996
00:41:42,160 --> 00:41:44,319
жестко оценивать ее, мы хотим, чтобы вы ее написали, чтобы мы

997
00:41:44,319 --> 00:41:47,599
могли вам помочь, поэтому мы хотим, чтобы вы как бы обдумали

998
00:41:47,599 --> 00:41:49,599
то, что вы собираетесь

999
00:41:49,599 --> 00:41:52,240
сделать, и у первого есть возможность

1000
00:41:52,240 --> 00:41:55,200
сказать нет, это нереально велико, или

1001
00:41:55,200 --> 00:41:58,240
это звучит недостаточно амбициозно, или

1002
00:41:58,240 --> 00:41:59,920
это не сработает, если вы не

1003
00:41:59,920 --> 00:42:02,160
получите больше данных, чем у вас есть на самом деле, и

1004
00:42:02,160 --> 00:42:04,960
тому подобное, так

1005
00:42:04,960 --> 00:42:07,920
что это в основном только для f  eedback, но

1006
00:42:07,920 --> 00:42:10,880
вы знаете, о чем подумать

1007
00:42:10,880 --> 00:42:13,280
вы знаете о планах проекта, которых

1008
00:42:13,280 --> 00:42:15,440
не хватает, как правило, им просто

1009
00:42:15,440 --> 00:42:18,240
не хватает конкретности в общих

1010
00:42:18,240 --> 00:42:21,119
чертах, которые необходимы для того,

1011
00:42:21,119 --> 00:42:23,680
чтобы иметь возможность сделать хороший финальный проект за короткий

1012
00:42:23,680 --> 00:42:25,839
промежуток времени.  время, поэтому

1013
00:42:25,839 --> 00:42:29,200
вам нужно найти надежные данные или

1014
00:42:29,200 --> 00:42:31,599
иметь реалистичный план, чтобы его можно было

1015
00:42:31,599 --> 00:42:34,240
спланировать реалистичный план, чтобы иметь возможность

1016
00:42:34,240 --> 00:42:36,720
собирать это эм, вам нужно иметь

1017
00:42:36,720 --> 00:42:38,960
реалистичный способ оценки своей

1018
00:42:38,960 --> 00:42:39,920
работы

1019
00:42:39,920 --> 00:42:41,920
вам нужно подумать о том, какие

1020
00:42:41,920 --> 00:42:44,319
виды  экспериментов, которые вы могли бы провести, чтобы

1021
00:42:44,319 --> 00:42:46,400
вы могли показать,

1022
00:42:46,400 --> 00:42:48,720
хорошо или плохо работает ваша модель, и будете как

1023
00:42:48,720 --> 00:42:50,319
бы смотреть, хорошо ли вы выполнили

1024
00:42:50,319 --> 00:42:52,720
эти вещи,

1025
00:42:52,720 --> 00:42:55,280
так что через пару недель после

1026
00:42:55,280 --> 00:42:56,720
этого

1027
00:42:56,720 --> 00:42:59,920
наступит этап проекта, который снова

1028
00:42:59,920 --> 00:43:02,640
от всех  эм, это отчет о прогрессе,

1029
00:43:02,640 --> 00:43:04,560
это опять же просто для того, чтобы помочь

1030
00:43:04,560 --> 00:43:06,880
вам не сбиться с пути, так что вы должны быть

1031
00:43:06,880 --> 00:43:09,839
более чем на полпути, вы должны

1032
00:43:09,839 --> 00:43:11,040
были

1033
00:43:11,040 --> 00:43:13,920
быть в состоянии почти во всех случаях, я расскажу

1034
00:43:13,920 --> 00:43:15,839
об этом больше через минуту.

1035
00:43:15,839 --> 00:43:17,839
почти во всех случаях вы уже должны

1036
00:43:17,839 --> 00:43:20,240
были быть в состоянии реализовать некоторую базовую

1037
00:43:20,240 --> 00:43:22,400
систему и иметь некоторые начальные

1038
00:43:22,400 --> 00:43:24,640
экспериментальные результаты, чтобы показать, что вы знаете, что

1039
00:43:24,640 --> 00:43:26,560
вы все еще работаете над своей основной

1040
00:43:26,560 --> 00:43:28,880
моделью и вам нечего показать, но,

1041
00:43:28,880 --> 00:43:30,960
надеюсь, вы хотя бы сказали

1042
00:43:30,960 --> 00:43:33,280
очевидное простое  базовый уровень, чтобы знать, насколько хорошо

1043
00:43:33,280 --> 00:43:35,280
это работает, - вот эта штука, и я построил ее

1044
00:43:35,280 --> 00:43:37,520
, и у меня есть некоторые цифры, а затем мы

1045
00:43:37,520 --> 00:43:40,079
хотим получить обновленную информацию о том, как вы планируете

1046
00:43:40,079 --> 00:43:42,319
проводить остаток своего времени, и снова, многое из

1047
00:43:42,319 --> 00:43:44,240
этого связано с тем, что мы даем вам больше

1048
00:43:44,240 --> 00:43:46,480
обратная связь относительно того, что лучше всего

1049
00:43:46,480 --> 00:43:47,760
вы могли бы сделать в

1050
00:43:47,760 --> 00:43:50,960
течение последних двух недель занятий,

1051
00:43:50,960 --> 00:43:53,200
а затем, в конце, нужно написать

1052
00:43:53,200 --> 00:43:56,000


1053
00:43:56,000 --> 00:43:57,839
окончательный проект,

1054
00:43:57,839 --> 00:44:00,000
и

1055
00:44:00,079 --> 00:44:00,880
поэтому

1056
00:44:00,880 --> 00:44:02,000


1057
00:44:02,000 --> 00:44:02,800


1058
00:44:02,800 --> 00:44:05,040
вы знаете, что качество вашей рецензии

1059
00:44:05,040 --> 00:44:06,880
действительно действительно  важно для вашей оценки,

1060
00:44:06,880 --> 00:44:08,640
правильно вы знаете, что в целом мы собираемся

1061
00:44:08,640 --> 00:44:11,760
оценить, насколько хорош ваш проект,

1062
00:44:11,760 --> 00:44:15,280
прочитав автора, поэтому убедитесь, что вы

1063
00:44:15,280 --> 00:44:18,960
выделяете достаточно времени, чтобы на самом деле ...

1064
00:44:18,960 --> 00:44:22,400


1065
00:44:22,400 --> 00:44:24,960


1066
00:44:24,960 --> 00:44:27,280
мимо тебя  ars они все

1067
00:44:27,280 --> 00:44:31,839
на сайте cf24n um 2020 был в

1068
00:44:31,839 --> 00:44:33,599
некотором роде беспорядком из-за начала

1069
00:44:33,599 --> 00:44:35,440
пандемии, так что, возможно, вам стоит

1070
00:44:35,440 --> 00:44:38,720
взглянуть на 2019, там есть даже лучшие модели

1071
00:44:38,720 --> 00:44:40,079
того, что вы должны делать

1072
00:44:40,079 --> 00:44:41,359
um, чтобы

1073
00:44:41,359 --> 00:44:43,760
вы знали, что детали различаются, но это  это

1074
00:44:43,760 --> 00:44:45,760
своего рода картина, которую нужно иметь в виду,

1075
00:44:45,760 --> 00:44:46,720
как обычно

1076
00:44:46,720 --> 00:44:49,839
выглядит рецензия, так что вы знаете, что на

1077
00:44:49,839 --> 00:44:52,160
восьми страницах вы хотите иметь абстрактное

1078
00:44:52,160 --> 00:44:54,480
введение в статью, о которой вы хотите

1079
00:44:54,480 --> 00:44:57,119
поговорить, о связанной предыдущей работе,

1080
00:44:57,119 --> 00:44:59,760
которую вы хотите представить.  используя вы

1081
00:44:59,760 --> 00:45:02,079
хотите рассказать о данных, которые вы используете;

1082
00:45:02,079 --> 00:45:04,319
поговорите о своих экспериментах; каковы

1083
00:45:04,319 --> 00:45:07,119
результаты; что вы узнали об этом;

1084
00:45:07,119 --> 00:45:09,119
вы знаете, что детали могут

1085
00:45:09,119 --> 00:45:11,440
отличаться; вы знаете, что в некоторых статьях

1086
00:45:11,440 --> 00:45:13,119
меньше говорится о модели, а

1087
00:45:13,119 --> 00:45:15,040
об экспериментах можно сказать больше.  так что вы можете

1088
00:45:15,040 --> 00:45:16,960
немного перемещать вещи, но

1089
00:45:16,960 --> 00:45:20,319
примерно что-то вроде этого

1090
00:45:20,400 --> 00:45:21,440
хорошо,

1091
00:45:21,440 --> 00:45:22,240
так что

1092
00:45:22,240 --> 00:45:23,200


1093
00:45:23,200 --> 00:45:25,040
я теперь хочу продолжить и сказать

1094
00:45:25,040 --> 00:45:28,160
немного об исследованиях и практических вещах,

1095
00:45:28,160 --> 00:45:30,160
которые нам нужно

1096
00:45:30,160 --> 00:45:32,880
сделать многие из этих вещей актуальны для

1097
00:45:32,880 --> 00:45:35,680
всех в  любой  оцените есть вещи

1098
00:45:35,680 --> 00:45:38,000
, о которых вы должны немного знать,

1099
00:45:38,000 --> 00:45:40,560
поэтому самый первый - это

1100
00:45:40,560 --> 00:45:42,720
поиск тем для исследований, которые в некотором роде

1101
00:45:42,720 --> 00:45:45,359
особенно важны

1102
00:45:45,359 --> 00:45:47,760
для нестандартных финальных проектов.

1103
00:45:47,760 --> 00:45:49,119


1104
00:45:49,119 --> 00:45:52,000


1105
00:45:52,000 --> 00:45:54,000


1106
00:45:54,000 --> 00:45:57,040
исследовательский проект, одним из способов которого является изучение

1107
00:45:57,040 --> 00:45:58,240


1108
00:45:58,240 --> 00:46:01,040
предметной области, в котором вы начинаете

1109
00:46:01,040 --> 00:46:03,839
с интересующей вас проблемы,

1110
00:46:03,839 --> 00:46:06,560
например, как я могу построить достойный

1111
00:46:06,560 --> 00:46:08,160
чероки для английской

1112
00:46:08,160 --> 00:46:10,640
системы машинного перевода, и вы работаете над

1113
00:46:10,640 --> 00:46:13,359
поиском способов сделать это лучше,

1114
00:46:13,359 --> 00:46:16,720
чем люди  в настоящее время знают, как решать

1115
00:46:16,720 --> 00:46:19,040
или понимать проблему лучше, чем это

1116
00:46:19,040 --> 00:46:21,359
понимают в настоящее время люди, а

1117
00:46:21,359 --> 00:46:23,359
другой способ - использовать методологический

1118
00:46:23,359 --> 00:46:26,720
подход, при котором вы начинаете с какого-либо

1119
00:46:26,720 --> 00:46:29,040
метода или подхода, представляющего интерес, а затем

1120
00:46:29,040 --> 00:46:31,280
вы разрабатываете хорошие способы расширить или

1121
00:46:31,280 --> 00:46:34,079
улучшить его или  новые способы его применения, и, по

1122
00:46:34,079 --> 00:46:36,560
сути, вы делаете

1123
00:46:36,560 --> 00:46:38,319
один из них,

1124
00:46:38,319 --> 00:46:41,200
так что существуют разные

1125
00:46:41,200 --> 00:46:43,760
типы проектов, которые вы можете выполнять.

1126
00:46:43,760 --> 00:46:46,400
Это не исчерпывающий список, но большинство

1127
00:46:46,400 --> 00:46:49,040
проектов  попадают в одну из этих

1128
00:46:49,040 --> 00:46:52,560
корзин очень неравномерно,

1129
00:46:52,560 --> 00:46:53,839


1130
00:46:53,839 --> 00:46:56,640
поэтому наиболее распространенным типом является то, что вы находите какое-

1131
00:46:56,640 --> 00:46:59,920
либо интересное приложение или задачу и

1132
00:46:59,920 --> 00:47:03,200
изучаете, как подойти к ней и решить ее,

1133
00:47:03,200 --> 00:47:05,680
насколько это возможно, часто используя

1134
00:47:05,680 --> 00:47:07,760
существующие модели и пробуя различные

1135
00:47:07,760 --> 00:47:10,960
варианты и  подобные вещи второй

1136
00:47:10,960 --> 00:47:11,920
тип

1137
00:47:11,920 --> 00:47:14,960
- вы можете взять относительно сложную

1138
00:47:14,960 --> 00:47:17,440
нейронную архитектуру, то есть она должна быть

1139
00:47:17,440 --> 00:47:19,839
чем-то более сложным, чем мы создали

1140
00:47:19,839 --> 00:47:23,440
для заданий с первого по пятый, вы

1141
00:47:23,440 --> 00:47:25,280
реализуете это

1142
00:47:25,280 --> 00:47:27,920
и получаете что-то, что работает с некоторыми

1143
00:47:27,920 --> 00:47:29,760
данными,

1144
00:47:29,760 --> 00:47:31,839
и вы знаете, если я  делаете что-то

1145
00:47:31,839 --> 00:47:33,760
довольно сложное, это нормально, просто

1146
00:47:33,760 --> 00:47:37,520
реализовать это и заставить работать,

1147
00:47:37,520 --> 00:47:39,200
но вы знаете, есть ли какой-то способ, чтобы

1148
00:47:39,200 --> 00:47:41,040
вы могли настроить это и попробовать сделать

1149
00:47:41,040 --> 00:47:42,559
что-то другое и посмотреть,

1150
00:47:42,559 --> 00:47:44,880
сделает ли это еще лучше или, может быть, станет

1151
00:47:44,880 --> 00:47:46,559
хуже, и  вы можете проводить эксперименты в

1152
00:47:46,559 --> 00:47:50,000
любом случае, это вроде даже лучше,

1153
00:47:50,000 --> 00:47:52,160
есть другие виды

1154
00:47:52,160 --> 00:47:54,800
проектов, которые вы можете делать, так что другой

1155
00:47:54,800 --> 00:47:57,760
вид проекта - это проект анализа, так что вы

1156
00:47:57,760 --> 00:48:00,319
можете выбрать какой-то режим  Это существующая

1157
00:48:00,319 --> 00:48:03,440
модель, и вы можете ткнуть в нее и

1158
00:48:03,440 --> 00:48:06,400
узнать кое-что о том, что она знает, чтобы вы

1159
00:48:06,400 --> 00:48:08,720
могли взять что угодно, даже такое простое, как

1160
00:48:08,720 --> 00:48:11,599
векторы слов, и тыкать в них, и вы

1161
00:48:11,599 --> 00:48:13,520
можете узнать такие вещи, как хорошо, насколько

1162
00:48:13,520 --> 00:48:15,440
эти векторы слов знают о слове

1163
00:48:15,440 --> 00:48:16,559


1164
00:48:16,559 --> 00:48:18,720
хорошо чувствует иногда одно и то же слово одновременно является и

1165
00:48:18,720 --> 00:48:21,440
существительным, и глаголом, можете ли вы сказать,

1166
00:48:21,440 --> 00:48:23,440
можете ли вы получить эти

1167
00:48:23,440 --> 00:48:25,680
разные сходства из векторов слов,

1168
00:48:25,680 --> 00:48:28,400
так что аналитические проекты

1169
00:48:28,400 --> 00:48:31,359
совершенно прекрасны, часто интересны, а

1170
00:48:31,359 --> 00:48:34,079
затем из этих пяти раз самый

1171
00:48:34,079 --> 00:48:36,480
редкий проект  у нас была пара

1172
00:48:36,480 --> 00:48:38,480
теоретических проектов,

1173
00:48:38,480 --> 00:48:40,160
так что вы знаете, что есть много интересной

1174
00:48:40,160 --> 00:48:42,240
теории глубокого обучения:

1175
00:48:42,240 --> 00:48:44,880
как эти вещи работают, почему и

1176
00:48:44,880 --> 00:48:46,480
что нужно сделать, чтобы они работали

1177
00:48:46,480 --> 00:48:47,839
лучше,

1178
00:48:47,839 --> 00:48:50,640
и чтобы вы могли работать над получением

1179
00:48:50,640 --> 00:48:54,079
любого  какое-то нетривиальное свойство или

1180
00:48:54,079 --> 00:48:59,119
понимание модели глубокого обучения

1181
00:48:59,200 --> 00:49:00,640
здесь - это просто пара

1182
00:49:00,640 --> 00:49:03,200
примеров некоторых проектов

1183
00:49:03,200 --> 00:49:06,240
из прошлых лет с 224 end просто дает

1184
00:49:06,240 --> 00:49:08,880
вам пару примеров таких вещей,

1185
00:49:08,880 --> 00:49:10,079
поэтому

1186
00:49:10,079 --> 00:49:12,000
глубокая поэзия

1187
00:49:12,000 --> 00:49:13,359
это создавало

1188
00:49:13,359 --> 00:49:15,920
шекспировские

1189
00:49:15,920 --> 00:49:18,160
сонеты гм, так что способ его

1190
00:49:18,160 --> 00:49:21,119
создания был связан со списком кланов

1191
00:49:21,119 --> 00:49:22,240


1192
00:49:22,240 --> 00:49:25,200
и с чем работать сейчас

1193
00:49:25,200 --> 00:49:26,559
для

1194
00:49:26,559 --> 00:49:28,240
машинного перевода, но у него были

1195
00:49:28,240 --> 00:49:29,920
интересные отличия, потому что если вы

1196
00:49:29,920 --> 00:49:32,000
хотели сгенерировать поэзию, вам нужно

1197
00:49:32,000 --> 00:49:34,640
знать о метрической структуре  и рифмуются,

1198
00:49:34,640 --> 00:49:36,720
и поэтому они работают над тем, как добавить

1199
00:49:36,720 --> 00:49:40,319
компоненты в модель, которая могла бы это сделать.

1200
00:49:40,319 --> 00:49:42,640
Вот кто-то, кто

1201
00:49:42,640 --> 00:49:45,440
реализовал более сложную новую модель, так

1202
00:49:45,440 --> 00:49:47,680
что в deepmind была работа, эм-

1203
00:49:47,680 --> 00:49:51,359
м-м, и пыталась создать

1204
00:49:51,359 --> 00:49:53,119
компьютеры общего назначения в качестве нейронных

1205
00:49:53,119 --> 00:49:54,960
архитектур.  и есть, прежде всего,

1206
00:49:54,960 --> 00:49:57,040
нейронные машины Тьюринга, а затем

1207
00:49:57,040 --> 00:49:58,720
последующая

1208
00:49:58,720 --> 00:50:00,400
модель, называемая дифференциальным

1209
00:50:00,400 --> 00:50:02,319
нейронным компьютером с мячом,

1210
00:50:02,319 --> 00:50:04,640
и они еще не выпустили код этой системы с

1211
00:50:04,640 --> 00:50:08,640
открытым исходным кодом, поэтому Кэрол решила,

1212
00:50:08,640 --> 00:50:11,040
что она собирается

1213
00:50:11,040 --> 00:50:13,040
повторно реализовать дифференциальные нейронные

1214
00:50:13,040 --> 00:50:15,359
компьютеры и  Заставить их работать, это

1215
00:50:15,359 --> 00:50:17,599
была очень опасная идея,

1216
00:50:17,599 --> 00:50:19,359
потому что мы были на 10 неделе

1217
00:50:19,359 --> 00:50:21,680
занятий, а она все еще не пошла на

1218
00:50:21,680 --> 00:50:24,000
работать вообще, но, к счастью,

1219
00:50:24,000 --> 00:50:26,400
она собрала это в последний момент

1220
00:50:26,400 --> 00:50:28,720
и на самом деле заставила свою модель работать, и

1221
00:50:28,720 --> 00:50:30,640
смогла запустить ее и получить результаты по

1222
00:50:30,640 --> 00:50:32,400
некоторым проблемам, которые глубокие умы

1223
00:50:32,400 --> 00:50:36,079
также показали результаты, и поэтому она

1224
00:50:36,079 --> 00:50:37,520
вытащила кролика  из шляпы и

1225
00:50:37,520 --> 00:50:39,920
имел огромный успех, и мы были очень

1226
00:50:39,920 --> 00:50:42,960
впечатлены тем, что ей удалось это сделать.

1227
00:50:42,960 --> 00:50:43,839


1228
00:50:43,839 --> 00:50:46,400
Вот так иногда финальные

1229
00:50:46,400 --> 00:50:49,280
проекты превращались в статьи. А вот последний

1230
00:50:49,280 --> 00:50:52,000
проект, который

1231
00:50:52,000 --> 00:50:54,800
стал статьей, опубликованной на ведущей

1232
00:50:54,800 --> 00:50:56,480
конференции по машинному обучению.

1233
00:50:56,480 --> 00:50:59,119
лет назад, это из 2017

1234
00:50:59,119 --> 00:51:01,760
года. На самом деле у него есть пара довольно

1235
00:51:01,760 --> 00:51:04,240
простых идей, но вы знаете, что есть

1236
00:51:04,240 --> 00:51:06,480
идеи, которые в то время люди не

1237
00:51:06,480 --> 00:51:10,160
использовали, и эти два человека доказали свою эффективность

1238
00:51:10,160 --> 00:51:12,800
и улучшили вещи, и они

1239
00:51:12,800 --> 00:51:14,480
получили из этого доклад конференции, так что  Я

1240
00:51:14,480 --> 00:51:16,720
просто упомяну один из них сейчас,

1241
00:51:16,720 --> 00:51:19,119
поэтому, если вы думаете о наших текущих

1242
00:51:19,119 --> 00:51:22,400
языковых моделях нейронных сетей, у них есть

1243
00:51:22,400 --> 00:51:23,359


1244
00:51:23,359 --> 00:51:26,160
как слова, так и кодирование в

1245
00:51:26,160 --> 00:51:28,960
распределенные векторы, теперь на другом конце

1246
00:51:28,960 --> 00:51:32,720
вы знаете матрицу softmax  x в основном

1247
00:51:32,720 --> 00:51:36,160
скрывает внутри него, как и для наших

1248
00:51:36,160 --> 00:51:39,680
векторов слов, вектор слов для каждого слова, а

1249
00:51:39,680 --> 00:51:41,599
затем вы как бы решаете

1250
00:51:41,599 --> 00:51:43,280
вероятности генерации разных

1251
00:51:43,280 --> 00:51:47,520
слов на основе сходства между

1252
00:51:47,520 --> 00:51:49,599


1253
00:51:49,599 --> 00:51:52,079
вектором запроса в каждом из этих слов, поэтому

1254
00:51:52,079 --> 00:51:54,720
их идея была  послушайте, возможно, мы

1255
00:51:54,720 --> 00:51:57,440
действительно смогли бы построить лучшие языковые модели,

1256
00:51:57,440 --> 00:51:59,760
если бы мы связали вместе матрицу встраивания слов

1257
00:51:59,760 --> 00:52:00,960


1258
00:52:00,960 --> 00:52:01,920


1259
00:52:01,920 --> 00:52:04,559
и матрицу, используемую для проецирования

1260
00:52:04,559 --> 00:52:08,240
вывода rnn um, и на самом деле они показали, что

1261
00:52:08,240 --> 00:52:10,720
вы можете получить значительный выигрыш,

1262
00:52:10,720 --> 00:52:14,559
сделав это, и теперь вы знаете

1263
00:52:14,559 --> 00:52:16,240
это в основном теперь становится

1264
00:52:16,240 --> 00:52:18,160
стандартом, если вы хотите создать

1265
00:52:18,160 --> 00:52:19,200
сильные

1266
00:52:19,200 --> 00:52:20,960
новые языковые модели, которые вы хотите

1267
00:52:20,960 --> 00:52:22,720
связать эти два набора параметров

1268
00:52:22,720 --> 00:52:24,800
вместе, так что это было довольно круто,

1269
00:52:24,800 --> 00:52:26,160


1270
00:52:26,160 --> 00:52:29,680
вот еще один проект system z, так что

1271
00:52:29,680 --> 00:52:31,760
я упомяну об этом еще раз позже  но вы

1272
00:52:31,760 --> 00:52:33,040
знаете, что кое-что людей

1273
00:52:33,040 --> 00:52:35,520
интересовало, как можно сжать

1274
00:52:35,520 --> 00:52:38,480
нейронные сети и сделать их маленькими, чтобы

1275
00:52:38,480 --> 00:52:41,200
вы могли запускать их на

1276
00:52:41,200 --> 00:52:44,240
обычном ноутбуке или меньшем

1277
00:52:44,240 --> 00:52:47,440
устройстве, таком как мобильный компьютер.  отточить, и

1278
00:52:47,440 --> 00:52:51,280
эти люди работали над тем,

1279
00:52:51,280 --> 00:52:54,000
как вы могли бы провести

1280
00:52:54,000 --> 00:52:56,319
квантование нейронных сетей на один или

1281
00:52:56,319 --> 00:52:59,520
два бита на параметр и при этом получить

1282
00:52:59,520 --> 00:53:02,880
хорошие результаты, так что это своего рода

1283
00:53:02,880 --> 00:53:05,680
пример использования нейронных сетей

1284
00:53:05,680 --> 00:53:08,000
и человеческого языка.  своего рода способ

1285
00:53:08,000 --> 00:53:09,599
, которым вы могли бы сказать, что это

1286
00:53:09,599 --> 00:53:12,160
вообще не связано с человеческим языком, потому

1287
00:53:12,160 --> 00:53:14,079
что это действительно касалось квантования ваших

1288
00:53:14,079 --> 00:53:16,240
сетей, но вы точно знаете, где мы

1289
00:53:16,240 --> 00:53:18,720
проводим черту, мы говорим, что вам будет

1290
00:53:18,720 --> 00:53:21,280
разрешено это сделать, предоставив задачу

1291
00:53:21,280 --> 00:53:22,160
что

1292
00:53:22,160 --> 00:53:24,480
ваша задача и модель, которые вы используете для

1293
00:53:24,480 --> 00:53:27,760
демонстрации успеха или неудачи, являются

1294
00:53:27,760 --> 00:53:32,160
задачей естественного языка, и поэтому они выполнили

1295
00:53:32,160 --> 00:53:35,040
как задачи схожести слов, так и

1296
00:53:35,040 --> 00:53:37,440
задачи с ответами на вопросы, чтобы узнать, как долго

1297
00:53:37,440 --> 00:53:40,160
система работала после

1298
00:53:40,160 --> 00:53:43,839
сжатия с помощью квантования.

1299
00:53:43,920 --> 00:53:44,720


1300
00:53:44,720 --> 00:53:47,040
хорошее место для

1301
00:53:47,040 --> 00:53:50,240
проекта, если у вас нет хорошей идеи,

1302
00:53:50,240 --> 00:53:53,359
одно место - это как бы взглянуть на недавние

1303
00:53:53,359 --> 00:53:55,680
статьи, поэтому для большинства статей по нлп они

1304
00:53:55,680 --> 00:53:58,640
появляются в антологии acl.

1305
00:53:58,640 --> 00:54:01,839
g конференций um

1306
00:54:01,839 --> 00:54:04,960
большинство прошлых 224 n проектов находятся на

1307
00:54:04,960 --> 00:54:07,200
сайте класса вы можете просмотреть их

1308
00:54:07,200 --> 00:54:10,480
там есть только общие серверы archive.org,

1309
00:54:10,480 --> 00:54:12,079


1310
00:54:12,079 --> 00:54:14,319
но, возможно, еще лучше

1311
00:54:14,319 --> 00:54:16,720
найти интересную проблему в мире,

1312
00:54:16,720 --> 00:54:20,000
так как вариант, экономист,

1313
00:54:20,000 --> 00:54:21,119


1314
00:54:21,119 --> 00:54:22,839
пожалуйста,

1315
00:54:22,839 --> 00:54:25,839
сейчас, и он написал эту классную статью, которую я

1316
00:54:25,839 --> 00:54:28,000
часто рекомендую приходить

1317
00:54:28,000 --> 00:54:30,880
к студентам, о том, как построить экономическую

1318
00:54:30,880 --> 00:54:33,599
модель в свободное время, и эта статья

1319
00:54:33,599 --> 00:54:35,520
на самом деле не об экономических моделях, а

1320
00:54:35,520 --> 00:54:40,240
о том, как проводить исследования и о том, что он

1321
00:54:40,240 --> 00:54:43,040
говорит прямо на  В начале

1322
00:54:43,040 --> 00:54:44,799
раздела один статьи называется «

1323
00:54:44,799 --> 00:54:46,400


1324
00:54:46,400 --> 00:54:49,760
Получение идей», и он пишет, гм, но где взять идеи

1325
00:54:49,760 --> 00:54:51,200
- вот вопрос, который

1326
00:54:51,200 --> 00:54:52,880
большинство аспирантов убеждены в

1327
00:54:52,880 --> 00:54:55,119
том, что способ получения идей - это читать

1328
00:54:55,119 --> 00:54:57,839
журнальные статьи, но, по моему опыту,

1329
00:54:57,839 --> 00:54:59,520
журналы на самом деле не очень  хороший

1330
00:54:59,520 --> 00:55:02,000
источник оригинальных идей, вы можете

1331
00:55:02,000 --> 00:55:04,319
многое почерпнуть из журнальных статей. Понимание

1332
00:55:04,319 --> 00:55:07,359
техники, даже верное, но в

1333
00:55:07,359 --> 00:55:09,440
большинстве случаев вы получите только

1334
00:55:09,440 --> 00:55:12,880
чьи-то идеи.

1335
00:55:12,880 --> 00:55:13,839


1336
00:55:13,839 --> 00:55:16,079
Более того, о лучших способах получения

1337
00:55:16,079 --> 00:55:18,160
идей, размышляя о проблемах в

1338
00:55:18,160 --> 00:55:20,640
мире,

1339
00:55:20,640 --> 00:55:23,119
так что для архива это огромное

1340
00:55:23,119 --> 00:55:25,680
хранилище документов, в котором трудно

1341
00:55:25,680 --> 00:55:28,160
ориентироваться ... Есть различные инструменты, которые

1342
00:55:28,160 --> 00:55:30,319
могут облегчить навигацию, один из

1343
00:55:30,319 --> 00:55:33,280
них - это архиватор работоспособности,

1344
00:55:33,280 --> 00:55:35,760
который является  веб-сайт, который был написан

1345
00:55:35,760 --> 00:55:38,559
Андреем Кэпати, который был оригинальным

1346
00:55:38,559 --> 00:55:40,839
человеком, который создал и преподавал

1347
00:55:40,839 --> 00:55:44,880
курс cs231 n, все еще неплохо

1348
00:55:44,880 --> 00:55:45,920
использовать

1349
00:55:45,920 --> 00:55:46,720
ммм, в nlp um

1350
00:55:46,720 --> 00:55:48,720
есть много списков лидеров для

1351
00:55:48,720 --> 00:55:52,319
разных задач, так что место, где вы

1352
00:55:52,319 --> 00:55:56,240
можете найти задачи и поработать над ними

1353
00:55:56,240 --> 00:55:58,880
смотрит на списки лидеров, так что документы

1354
00:55:58,880 --> 00:56:01,760
с кодом и прогрессом nlp - это два хороших

1355
00:56:01,760 --> 00:56:04,000
общих источника списков лидеров,

1356
00:56:04,000 --> 00:56:06,319
есть также много более

1357
00:56:06,319 --> 00:56:09,440
специализированных для конкретных задач, которые

1358
00:56:09,440 --> 00:56:13,359
я хотел, затем для исследовательских тем,

1359
00:56:13,359 --> 00:56:16,319
этот материал, эти следующие четыре слайда

1360
00:56:16,319 --> 00:56:19,520
совершенно новые для  в этом году я хотел

1361
00:56:19,520 --> 00:56:23,359
просто сказать несколько слов о

1362
00:56:23,359 --> 00:56:24,079


1363
00:56:24,079 --> 00:56:27,599
том забавном, несколько другом времени,

1364
00:56:27,599 --> 00:56:28,799
в котором мы находимся,

1365
00:56:28,799 --> 00:56:31,440
где есть что-то вроде старого глубокого обучения

1366
00:56:31,440 --> 00:56:32,559
НЛП

1367
00:56:32,559 --> 00:56:35,520
и новое глубокое обучение nlp,

1368
00:56:35,520 --> 00:56:37,839
поэтому в первые дни возрождения глубокого

1369
00:56:37,839 --> 00:56:40,640
обучения, которое я назову с 2010 по

1370
00:56:40,640 --> 00:56:44,480
2018 год, потому что 2010-й год я начал

1371
00:56:44,480 --> 00:56:47,200
заниматься глубоким обучением для nlp,

1372
00:56:47,200 --> 00:56:48,960
большая часть работы

1373
00:56:48,960 --> 00:56:51,440
заключалась в определении и изучении лучших

1374
00:56:51,440 --> 00:56:54,240
архитектур глубокого обучения,

1375
00:56:54,240 --> 00:56:56,880
поэтому типичный  бумага была вы знаете, что я могу

1376
00:56:56,880 --> 00:56:59,839
улучшить систему резюмирования, но

1377
00:56:59,839 --> 00:57:02,319
не только используя вид внимания, который

1378
00:57:02,319 --> 00:57:04,160
я только что объяснил, но я мог бы добавить

1379
00:57:04,160 --> 00:57:06,400
дополнительный вид внимания, который я буду использовать

1380
00:57:06,400 --> 00:57:08,640
в качестве механизма копирования, поэтому я сделаю

1381
00:57:08,640 --> 00:57:11,119
дополнительные вычисления внимания к

1382
00:57:11,119 --> 00:57:12,880
выработать

1383
00:57:12,880 --> 00:57:16,720
исходные слова, которые я мог бы дословно скопировать

1384
00:57:16,720 --> 00:57:18,640
в вывод, вместо того, чтобы

1385
00:57:18,640 --> 00:57:20,400
восстанавливать их с помощью стандартного

1386
00:57:20,400 --> 00:57:22,799
типа softmax, это всего лишь один

1387
00:57:22,799 --> 00:57:24,799
из миллионов примеров, но вы меняете

1388
00:57:24,799 --> 00:57:27,359
архитектуру модели и

1389
00:57:27,359 --> 00:57:30,559
улучшаете ее, вы знаете, что это то, что

1390
00:57:30,559 --> 00:57:35,280
много хороших проектов cs224n um тоже сделал

1391
00:57:35,280 --> 00:57:37,359
и, в частности, вы знаете

1392
00:57:37,359 --> 00:57:38,160
для

1393
00:57:38,160 --> 00:57:40,640
одной ветви финального проекта по умолчанию

1394
00:57:40,640 --> 00:57:41,839
тот, где вы начинаете с

1395
00:57:41,839 --> 00:57:44,799
ответа на вопрос базовой линии  система

1396
00:57:44,799 --> 00:57:48,000
гм и разработать способы сделать ее лучше

1397
00:57:48,000 --> 00:57:51,040
, добавив больше нейронной архитектуры, по

1398
00:57:51,040 --> 00:57:53,599
сути, она делает это,

1399
00:57:53,599 --> 00:57:54,799


1400
00:57:54,799 --> 00:57:57,760
но на самом деле, если вы посмотрите

1401
00:57:57,760 --> 00:57:58,880


1402
00:57:58,880 --> 00:58:01,680
на мир исследований последних двух

1403
00:58:01,680 --> 00:58:02,799
лет,

1404
00:58:02,799 --> 00:58:05,280
печальная правда в том,

1405
00:58:05,280 --> 00:58:07,440
что подход мертв, нет,

1406
00:58:07,440 --> 00:58:10,160
он на самом деле не мертв  Я имею в виду, что это слишком

1407
00:58:10,160 --> 00:58:11,280
сильно,

1408
00:58:11,280 --> 00:58:12,319
ммм,

1409
00:58:12,319 --> 00:58:13,200


1410
00:58:13,200 --> 00:58:14,640
но теперь это

1411
00:58:14,640 --> 00:58:18,000
намного труднее и реже,

1412
00:58:18,000 --> 00:58:21,119
если вы посмотрите на последние три

1413
00:58:21,119 --> 00:58:23,440
года НЛП,

1414
00:58:23,440 --> 00:58:24,960
и это верно

1415
00:58:24,960 --> 00:58:27,839
как для людей, которые внедряют

1416
00:58:27,839 --> 00:58:31,599
производственные системы НЛП в компаниях, так

1417
00:58:31,599 --> 00:58:34,559
и для людей, которые делают  исследования в

1418
00:58:34,559 --> 00:58:36,480
nlp,

1419
00:58:36,480 --> 00:58:40,000
что большая часть работы больше похожа на это

1420
00:58:40,000 --> 00:58:42,000
есть эти огромные,

1421
00:58:42,000 --> 00:58:43,760
чрезвычайно хорошие

1422
00:58:43,760 --> 00:58:48,000
большие предварительно обученные языковые модели bert gpt

1423
00:58:48,000 --> 00:58:52,720
2 roberta excel net t5

1424
00:58:52,720 --> 00:58:55,680
они существуют в Интернете, и вы можете

1425
00:58:55,680 --> 00:58:57,599
загрузить их

1426
00:58:57,599 --> 00:59:00,640
с помощью одной команды python, и они дают

1427
00:59:00,640 --> 00:59:04,160
вам отличную основу  для выполнения большинства

1428
00:59:04,160 --> 00:59:05,920
задач nlp мы узнаем о них все на следующей

1429
00:59:05,920 --> 00:59:09,040
неделе, так что вы на самом деле не

1430
00:59:09,040 --> 00:59:10,880
начинаете с нуля, чтобы найти свою

1431
00:59:10,880 --> 00:59:13,200
собственную архитектуру модели и играть с

1432
00:59:13,200 --> 00:59:15,520
вариантами, которые вы говорите, я g  о том, чтобы

1433
00:59:15,520 --> 00:59:18,839
использовать роберту для

1434
00:59:21,920 --> 00:59:24,240
дальнейшей тонкой настройки ее для вашей задачи,

1435
00:59:24,240 --> 00:59:27,040
выполняя адаптацию домена

1436
00:59:27,040 --> 00:59:29,520
и тому подобное,

1437
00:59:29,520 --> 00:59:31,760
так что вы знаете, что

1438
00:59:31,760 --> 00:59:34,280
это очень быстро для

1439
00:59:34,280 --> 00:59:37,920
2021 nlp для всех ваших практических

1440
00:59:37,920 --> 00:59:40,640
проектов и потребностей отрасли, это в

1441
00:59:40,640 --> 00:59:42,799
основном формула, которую вы,

1442
00:59:42,799 --> 00:59:45,440
вероятно, должны  используйте um, есть эта

1443
00:59:45,440 --> 00:59:48,400
невероятно отличная библиотека от компании,

1444
00:59:48,400 --> 00:59:51,359
обнимая лицо um вы устанавливаете ее pip

1445
00:59:51,359 --> 00:59:54,079
install transformers, а затем это дает

1446
00:59:54,079 --> 00:59:56,000
вам отличную реализацию

1447
00:59:56,000 --> 00:59:58,319
трансформаторов, о которых мы узнаем на следующей неделе,

1448
00:59:58,319 --> 01:00:00,240
а затем эффективно то, что вы делаете,

1449
01:00:00,240 --> 01:00:02,559
похоже на мой код ниже um  этот

1450
01:00:02,559 --> 01:00:04,960
код не совсем запускается, в нем отсутствуют некоторые

1451
01:00:04,960 --> 01:00:07,040
части, если вы попробуете, но вы знаете,

1452
01:00:07,040 --> 01:00:10,559
какие части вы загружаете большую

1453
01:00:10,559 --> 01:00:13,200
предварительно обученную языковую модель, поэтому здесь я

1454
01:00:13,200 --> 01:00:16,720
загружаю модель корпуса для дня рождения с солнцем

1455
01:00:16,720 --> 01:00:18,880
, оказывается, эти модели  у всех шляп

1456
01:00:18,880 --> 01:00:20,960
есть особые токенизаторы, о которых вы тоже услышите

1457
01:00:20,960 --> 01:00:23,119
на следующей неделе, поэтому мы

1458
01:00:23,119 --> 01:00:26,559
возьмем для него токенизатор, а затем

1459
01:00:26,559 --> 01:00:29,520
мы исправим его для наших задач, например, может быть, я

1460
01:00:29,520 --> 01:00:32,319
буду работать  с юридическими данными, поэтому я

1461
01:00:32,319 --> 01:00:34,000
хочу взять общую модель и

1462
01:00:34,000 --> 01:00:36,000
настроить ее, чтобы лучше понимать юридические данные,

1463
01:00:36,000 --> 01:00:38,640
а затем у меня есть кое-что, что я

1464
01:00:38,640 --> 01:00:40,160
хочу сделать,

1465
01:00:40,160 --> 01:00:43,280
например, ответить на вопрос или, возможно, здесь,

1466
01:00:43,280 --> 01:00:44,880
где я использую bert для классификации последовательности,

1467
01:00:44,880 --> 01:00:47,359
возможно,  Задача, которую я хочу

1468
01:00:47,359 --> 01:00:49,680
сделать, - это пометить

1469
01:00:49,680 --> 01:00:54,000
упоминания разделов юридического кода, поэтому на

1470
01:00:54,000 --> 01:00:55,680
этом этапе

1471
01:00:55,680 --> 01:00:57,920
я собираюсь выполнить

1472
01:00:57,920 --> 01:01:00,400
точную настройку для этой конкретной

1473
01:01:00,400 --> 01:01:04,319
задачи, а затем запустить эту задачу,

1474
01:01:04,319 --> 01:01:06,960
и вот что мы делаем,

1475
01:01:06,960 --> 01:01:08,559
и  мы просто как бы

1476
01:01:08,559 --> 01:01:11,119
делаем что-то поверх уже существующей

1477
01:01:11,119 --> 01:01:12,319
модели,

1478
01:01:12,319 --> 01:01:15,520
поэтому сейчас много интересного - это

1479
01:01:15,520 --> 01:01:18,960
проблемы, которые работают в этом мире или вокруг него

1480
01:01:18,960 --> 01:01:21,839
,

1481
01:01:21,839 --> 01:01:22,960
так

1482
01:01:22,960 --> 01:01:25,520
что вы могли бы подумать об

1483
01:01:25,520 --> 01:01:28,079
этом и посмотреть на недавние статьи и

1484
01:01:28,079 --> 01:01:29,680
прочее.  что можно было бы сделать с этим

1485
01:01:29,680 --> 01:01:31,839
миром хорошо, один из них, и это

1486
01:01:31,839 --> 01:01:34,960
другая половина финального проекта по умолчанию

1487
01:01:34,960 --> 01:01:37,680
, у нас все еще есть проблема

1488
01:01:37,680 --> 01:01:39,839
устойчивости к сдвигу домена, что эти

1489
01:01:39,839 --> 01:01:42,799
модели обычно обучаются на одном

1490
01:01:42,799 --> 01:01:45,440
типе текста, но мы часто хотим использовать  это для

1491
01:01:45,440 --> 01:01:48,319
разных типов текста, включая

1492
01:01:48,319 --> 01:01:50,000
Когда вы говорите о проблемах или конкретных приложениях, вы часто говорите об

1493
01:01:50,000 --> 01:01:52,400


1494
01:01:52,400 --> 01:01:54,720
их предметах, но у

1495
01:01:54,720 --> 01:01:57,599
вас мало данных, как вы можете сделать это хорошо,

1496
01:01:57,599 --> 01:01:59,520


1497
01:01:59,520 --> 01:02:01,200
если у вас есть одна из этих больших моделей,

1498
01:02:01,200 --> 01:02:03,760
в некотором смысле они хороши, но

1499
01:02:03,760 --> 01:02:07,359
они на самом деле, вы знаете, надежны, что они

1500
01:02:07,359 --> 01:02:10,160
работают для всех разных вещей

1501
01:02:10,160 --> 01:02:12,400
в пространстве, над которым вы бы хотели, чтобы они работали, поэтому

1502
01:02:12,400 --> 01:02:14,079
вас интересует не только базовая

1503
01:02:14,079 --> 01:02:16,160
точность, но и надежность, поэтому этот

1504
01:02:16,160 --> 01:02:17,760
тренажерный зал

1505
01:02:17,760 --> 01:02:20,799
был недавно объявлен проектом,

1506
01:02:20,799 --> 01:02:23,280
эм  аспирантка в Стэнфорде, нынешняя

1507
01:02:23,280 --> 01:02:25,599
девушка, на самом деле она проверяет

1508
01:02:25,599 --> 01:02:28,160
надежность моделей НЛП, и у них есть

1509
01:02:28,160 --> 01:02:30,400
кое-что, встроенное в нее, но есть

1510
01:02:30,400 --> 01:02:32,160
много вещей, которые не встроены в нее,

1511
01:02:32,160 --> 01:02:34,240
если кто-то захочет решить

1512
01:02:34,240 --> 01:02:37,359
какую-то проблему НЛП, будь то

1513
01:02:37,359 --> 01:02:39,119
анализ зависимостей или что-то еще, например,

1514
01:02:39,119 --> 01:02:42,240
обобщение и построение

1515
01:02:42,240 --> 01:02:43,760
тестов на устойчивость для него, что может быть

1516
01:02:43,760 --> 01:02:46,079
интересно сделать ммм

1517
01:02:46,079 --> 01:02:48,880
вы знаете множество других вещей, которые вы можете

1518
01:02:48,880 --> 01:02:51,920
посмотреть на проблемы, ммм, есть ли предвзятость,

1519
01:02:51,920 --> 01:02:54,480
встроенная в эту модель  Как вы можете

1520
01:02:54,480 --> 01:02:57,200
объяснить, что они делают? Как

1521
01:02:57,200 --> 01:02:59,039
вы можете использовать увеличение данных?

1522
01:02:59,039 --> 01:03:00,880
Было проделано огромное количество работы по

1523
01:03:00,880 --> 01:03:03,599
использованию увеличения данных для улучшения ресурсов модели в

1524
01:03:03,599 --> 01:03:05,359


1525
01:03:05,359 --> 01:03:08,640
самых разных областях,

1526
01:03:08,640 --> 01:03:11,760
я просто упомяну две другие вещи,

1527
01:03:11,760 --> 01:03:13,760
а затем я  продолжайте,

1528
01:03:13,760 --> 01:03:16,960
так что была проделана тонна работы по масштабированию

1529
01:03:16,960 --> 01:03:19,039
моделей вверх и вниз,

1530
01:03:19,039 --> 01:03:22,880
поэтому эти большие предварительно обученные языковые

1531
01:03:22,880 --> 01:03:25,520
модели уже велики,

1532
01:03:25,520 --> 01:03:28,160
поэтому факт в том

1533
01:03:28,160 --> 01:03:30,319
, что время и

1534
01:03:30,319 --> 01:03:33,680
ресурсы, которые у вас есть в 224n, просто невозможно

1535
01:03:33,680 --> 01:03:36,160
подумать  Я собираюсь строить

1536
01:03:36,160 --> 01:03:37,839
самостоятельно, э-

1537
01:03:37,839 --> 01:03:38,640


1538
01:03:38,640 --> 01:03:41,440
э, предварительно обученные модели, все, что вы можете сделать, это

1539
01:03:41,440 --> 01:03:45,440
использовать те, которые уже существуют, но вы знаете,

1540
01:03:45,440 --> 01:03:48,240
с другой стороны, люди действительно

1541
01:03:48,240 --> 01:03:50,480
заинтересованы в том, можете ли вы

1542
01:03:50,480 --> 01:03:53,119
создавать очень маленькие модели, которые все еще работают

1543
01:03:53,119 --> 01:03:55,520
довольно хорошо  и, как вы знаете, есть

1544
01:03:55,520 --> 01:03:57,839
много примеров, но на самом деле один из них, который был

1545
01:03:57,839 --> 01:04:00,799
недавно сделан для ответов на вопросы, заключался в

1546
01:04:00,799 --> 01:04:03,119
том, что

1547
01:04:03,119 --> 01:04:04,799
на последнем европейском мероприятии проводилось соревнование по запеканию, которое называлось

1548
01:04:04,799 --> 01:04:08,000
эффективным качеством качества, и одним из разделов

1549
01:04:08,000 --> 01:04:08,880
этого

1550
01:04:08,880 --> 01:04:11,119
конкурса было

1551
01:04:11,119 --> 01:04:14,319
вы можете создать производительную

1552
01:04:14,319 --> 01:04:17,359
систему ответов на вопросы, которая будет работать

1553
01:04:17,359 --> 01:04:20,920
в 500

1554
01:04:21,039 --> 01:04:22,240
, и вы знаете, что на самом деле это

1555
01:04:22,240 --> 01:04:24,000
разумная вещь, которую вы могли бы

1556
01:04:24,000 --> 01:04:27,440
попробовать для окончательного проекта. Еще одна

1557
01:04:27,440 --> 01:04:30,000
вещь, которая очень интересовала людей, - это

1558
01:04:30,000 --> 01:04:31,839
желание изучить

1559
01:04:31,839 --> 01:04:35,839
более продвинутые возможности обучения.

1560
01:04:35,839 --> 01:04:38,280
в нейронных сетях такие идеи, как

1561
01:04:38,280 --> 01:04:40,000
композиционность, систематическое

1562
01:04:40,000 --> 01:04:42,880
обобщение, быстрое обучение, такое как

1563
01:04:42,880 --> 01:04:45,920
мета-обучение, и много времени

1564
01:04:45,920 --> 01:04:48,319
люди исследовали их

1565
01:04:48,319 --> 01:04:50,799
в небольших областях, поэтому вот несколько

1566
01:04:50,799 --> 01:04:53,920
примеров, которые вы можете посмотреть на детское ai и

1567
01:04:53,920 --> 01:04:56,319
g-сканирование, чтобы они могли быть своего рода

1568
01:04:56,319 --> 01:04:58,960
интересные места, в которых вы можете поискать

1569
01:04:58,960 --> 01:05:01,920
итоговый проект,

1570
01:05:02,000 --> 01:05:05,119
хорошо, другие вещи, которые нужно знать быстро,

1571
01:05:05,119 --> 01:05:07,599
наверное, я не могу полностью просмотреть все

1572
01:05:07,599 --> 01:05:09,599
эти слайды, а некоторые из них вы можете

1573
01:05:09,599 --> 01:05:11,760
просто взять домой и посмотреть,

1574
01:05:11,760 --> 01:05:15,119
вам нужны данные,

1575
01:05:15,119 --> 01:05:17,039
теперь нам это действительно нравится  если люди чувствуют,

1576
01:05:17,039 --> 01:05:19,839
что могут собирать свои собственные данные, а

1577
01:05:19,839 --> 01:05:21,520
иногда это хороший способ собрать

1578
01:05:21,520 --> 01:05:23,440
ваши собственные данные

1579
01:05:23,440 --> 01:05:25,599
, но вы знаете, что

1580
01:05:25,599 --> 01:05:27,680
в реальности много времени

1581
01:05:27,680 --> 01:05:29,599
Самый простой способ быстро начать

1582
01:05:29,599 --> 01:05:31,359
окончательный проект, когда у вас всего несколько

1583
01:05:31,359 --> 01:05:33,920
недель, - это использовать существующий набор данных,

1584
01:05:33,920 --> 01:05:36,799
и есть много уже существующих

1585
01:05:36,799 --> 01:05:39,760
наборов данных, поэтому есть данные из

1586
01:05:39,760 --> 01:05:42,240
консорциума лингвистических данных, которые являются

1587
01:05:42,240 --> 01:05:44,400
лицензированными данными  у нас есть лицензии в

1588
01:05:44,400 --> 01:05:45,839
Стэнфорде, вы можете просмотреть их

1589
01:05:45,839 --> 01:05:47,520
каталог и найти все, что у

1590
01:05:47,520 --> 01:05:49,920
них есть. Есть веб-сайты с большим

1591
01:05:49,920 --> 01:05:52,000
количеством данных, поэтому, если вы хотите выполнять

1592
01:05:52,000 --> 01:05:54,640
задачи машинного перевода, вы можете найти много

1593
01:05:54,640 --> 01:05:58,000
данных машинного перевода на этом разборе зависимостей этого веб-сайта,

1594
01:05:58,000 --> 01:06:00,640
если вы  очень заинтересованы в

1595
01:06:00,640 --> 01:06:03,280
назначении трех объемов данных на

1596
01:06:03,280 --> 01:06:05,760
веб-сайте универсальных зависимостей.

1597
01:06:05,760 --> 01:06:08,000
Сейчас существует несколько

1598
01:06:08,000 --> 01:06:10,079
веб-сайтов, которые собирают множество

1599
01:06:10,079 --> 01:06:12,720
наборов данных, поэтому «обнимающее лицо» также

1600
01:06:12,720 --> 01:06:14,400
недавно фактически анонсировало наборы данных «обнимающее лицо»,

1601
01:06:14,400 --> 01:06:16,799
которые являются своего рода индексом

1602
01:06:16,799 --> 01:06:19,119
наборов данных и  документы с кодом у

1603
01:06:19,119 --> 01:06:21,280
людей также есть документы с наборами данных кода,

1604
01:06:21,280 --> 01:06:24,160
так что вы можете посмотреть на них, эм,

1605
01:06:24,160 --> 01:06:27,200
их гораздо больше,

1606
01:06:27,200 --> 01:06:28,000
да,

1607
01:06:28,000 --> 01:06:28,960


1608
01:06:28,960 --> 01:06:30,480
вот просто

1609
01:06:30,480 --> 01:06:34,319
краткое

1610
01:06:34,319 --> 01:06:37,359
изложение мыслей о повторном  поисковый

1611
01:06:37,359 --> 01:06:40,400
проект, чтобы вы знали, что это всего лишь один

1612
01:06:40,400 --> 01:06:42,839
пример. Предположим, вы думаете о

1613
01:06:42,839 --> 01:06:45,039
суммировании, так что это своего рода переход

1614
01:06:45,039 --> 01:06:47,039
от более длинного фрагмента текста к его краткому

1615
01:06:47,039 --> 01:06:49,520
изложению, чтобы вы знали, что

1616
01:06:49,520 --> 01:06:52,480
вам нужно сделать, чтобы вы знали, что найти

1617
01:06:52,480 --> 01:06:55,039
набор данных  и, вероятно, проще

1618
01:06:55,039 --> 01:06:56,960
всего будет использовать

1619
01:06:56,960 --> 01:06:59,359
существующий набор данных текстового резюмирования, который вы

1620
01:06:59,359 --> 01:07:01,680
можете найти несколько в Интернете, но вы знаете,

1621
01:07:01,680 --> 01:07:03,039
что именно здесь вы можете придумать

1622
01:07:03,039 --> 01:07:05,359
интересные способы создания своих собственных данных,

1623
01:07:05,359 --> 01:07:07,200
чтобы вы могли заметить,

1624
01:07:07,200 --> 01:07:08,880
если бы  Посмотрите на твиттер, что

1625
01:07:08,880 --> 01:07:10,559
журналисты часто продвигают свои собственные

1626
01:07:10,559 --> 01:07:13,280
истории в

1627
01:07:13,280 --> 01:07:16,960
своей газете или на телеканале,

1628
01:07:16,960 --> 01:07:18,960
публикуя твит, и это

1629
01:07:18,960 --> 01:07:21,039
вроде как найденные данные, которые представляют собой своего рода

1630
01:07:21,039 --> 01:07:22,960
резюме, не могли бы вы собрать некоторые из

1631
01:07:22,960 --> 01:07:25,119
них и попытаться изучить  для создания

1632
01:07:25,119 --> 01:07:28,319
твитов для новой истории

1633
01:07:28,319 --> 01:07:29,280
эм,

1634
01:07:29,280 --> 01:07:32,240
поэтому я немного скажу о гигиене набора данных,

1635
01:07:32,240 --> 01:07:34,160
вы хотите быть осторожными при работе

1636
01:07:34,160 --> 01:07:36,319
, чтобы у вас были

1637
01:07:36,319 --> 01:07:38,319
обученные наборы и наборы тестов, я скажу, что

1638
01:07:38,319 --> 01:07:40,240
через минуту вам нужно немного времени  y, чтобы

1639
01:07:40,240 --> 01:07:43,039
оценить, хорошо ли вы делаете это

1640
01:07:43,039 --> 01:07:45,119
при построении моделей, и вам в значительной степени

1641
01:07:45,119 --> 01:07:47,760
нужна метрика автоматической оценки,

1642
01:07:47,760 --> 01:07:49,920
даже если человеческая оценка

1643
01:07:49,920 --> 01:07:51,760
хороша, поскольку вы хотите обучить кучу

1644
01:07:51,760 --> 01:07:53,920
моделей и посмотреть, лучше или хуже

1645
01:07:53,920 --> 01:07:55,920
вы обычно хотите  автоматическая метрика,

1646
01:07:55,920 --> 01:07:57,839
которая полуприлична,

1647
01:07:57,839 --> 01:07:59,839
вы должны убедиться, что у вас есть какая-

1648
01:07:59,839 --> 01:08:02,240
то базовая линия,

1649
01:08:02,240 --> 01:08:04,240
которую вы хотите иметь некоторое представление о

1650
01:08:04,240 --> 01:08:05,920
том, все ли у вас хорошо, и поэтому

1651
01:08:05,920 --> 01:08:08,400
обычно вы сначала хотите реализовать

1652
01:08:08,400 --> 01:08:10,480
некоторую простую модель, такую как логистическая

1653
01:08:10,480 --> 01:08:12,240
регрессия или

1654
01:08:12,240 --> 01:08:14,400
просто усреднение  векторы слов или что-то в этом роде,

1655
01:08:14,400 --> 01:08:16,479
и посмотрите, насколько хорошо это работает, потому что тогда

1656
01:08:16,479 --> 01:08:18,000
вы знаете, что если у вас не получается лучше, чем

1657
01:08:18,000 --> 01:08:19,679
это, на самом деле вы вообще не добиваетесь

1658
01:08:19,679 --> 01:08:22,000
никакого прогресса,

1659
01:08:22,000 --> 01:08:23,759
тогда вам следует реализовать какую-то новую сетевую

1660
01:08:23,759 --> 01:08:25,520
модель и посмотреть, сможете ли вы,

1661
01:08:25,520 --> 01:08:27,198
что, по вашему мнению, может быть  хорошо, и посмотрите,

1662
01:08:27,198 --> 01:08:29,759
сможете ли вы заставить это работать, а

1663
01:08:29,759 --> 01:08:31,279
это работает хорошо,

1664
01:08:31,279 --> 01:08:32,080


1665
01:08:32,080 --> 01:08:34,319
убедитесь, что вы продолжаете смотреть на свои данные,

1666
01:08:34,319 --> 01:08:36,158
чтобы увидеть, какие ошибки вы делаете,

1667
01:08:36,158 --> 01:08:37,600
и подумать о том, как вы могли бы

1668
01:08:37,600 --> 01:08:40,479
изменить эти  Модель, чтобы избежать их,

1669
01:08:40,479 --> 01:08:42,960
и затем, надеюсь, у вас будет время

1670
01:08:42,960 --> 01:08:45,040
опробовать некоторые варианты модели и посмотреть

1671
01:08:45,040 --> 01:08:47,520
, лучше они или хуже, и тогда это

1672
01:08:47,520 --> 01:08:51,040
поможет в создании хорошего проекта,

1673
01:08:51,040 --> 01:08:55,359
да, так быстро, что я называю здесь

1674
01:08:55,359 --> 01:08:58,238
горшками с данными  эм, так

1675
01:08:58,238 --> 01:09:00,880
много общедоступных наборов данных имеют

1676
01:09:00,880 --> 01:09:03,120
структуру, в которой они обучаются разработке и

1677
01:09:03,120 --> 01:09:04,960
тестированию,

1678
01:09:04,960 --> 01:09:07,600
и идея состоит в том, что вы храните свои тестовые

1679
01:09:07,600 --> 01:09:11,040
данные до конца, и вы

1680
01:09:11,040 --> 01:09:13,679
выполняете тестовые прогоны только тогда, когда разработка

1681
01:09:13,679 --> 01:09:18,319
завершена или, по крайней мере, почти завершена,

1682
01:09:18,319 --> 01:09:21,319
и

1683
01:09:21,600 --> 01:09:24,238
тренируетесь на  данные поезда, и вы

1684
01:09:24,238 --> 01:09:26,719
оцениваете данные разработчика, иногда вам нужно

1685
01:09:26,719 --> 01:09:28,640
еще больше наборов данных, иногда вы

1686
01:09:28,640 --> 01:09:30,719
хотите выполнить настройку гиперпараметров, и вам

1687
01:09:30,719 --> 01:09:33,279
может потребоваться поезд, набор настроек, набор настроек, набор разработчика

1688
01:09:33,279 --> 01:09:36,880
и набор тестов, если набор данных

1689
01:09:36,880 --> 01:09:39,120
не  не приходит предварительно разделенным, или в нем

1690
01:09:39,120 --> 01:09:42,479
недостаточно частей, это своего рода ваша

1691
01:09:42,479 --> 01:09:45,839
работа - решить, как разрезать его на части

1692
01:09:45,839 --> 01:09:49,198
и заставить все работать, и причина, по

1693
01:09:49,198 --> 01:09:51,279
которой вам нужно это сделать,

1694
01:09:51,279 --> 01:09:52,960


1695
01:09:52,960 --> 01:09:55,199
в

1696
01:09:56,239 --> 01:09:58,800
том, что необходимо иметь  эти

1697
01:09:58,800 --> 01:10:00,840
различные наборы, чтобы получить

1698
01:10:00,840 --> 01:10:04,159
реалистичные измерения pe  На

1699
01:10:04,159 --> 01:10:07,840
самом деле в идеале вы фактически

1700
01:10:07,840 --> 01:10:10,480
тестируете тестовый набор только один раз

1701
01:10:10,480 --> 01:10:13,760
и, во всяком случае, очень мало раз, поэтому, если

1702
01:10:13,760 --> 01:10:15,440
вы выполняете финальный проект по умолчанию,

1703
01:10:15,440 --> 01:10:18,000
мы ограничиваем вас тремя запусками на тестовом

1704
01:10:18,000 --> 01:10:20,800
наборе, так что запомните это и сохраните свои три

1705
01:10:20,800 --> 01:10:24,640
запуска  И причина, по которой мы это делаем, заключается в

1706
01:10:24,640 --> 01:10:27,360
том, что если вы как бы смешиваете и злоупотребляете

1707
01:10:27,360 --> 01:10:30,159
этими наборами данных, результаты просто становятся

1708
01:10:30,159 --> 01:10:33,600
недействительными, поэтому вы знаете, что когда вы хорошо тренируетесь на

1709
01:10:33,600 --> 01:10:35,760
данных, вы всегда строите модель,

1710
01:10:35,760 --> 01:10:37,760
которая хорошо работает с данными обучения, так что это

1711
01:10:37,760 --> 01:10:41,040
не интересно  ну и хорошо, если вы хотите

1712
01:10:41,040 --> 01:10:43,760
настроить гиперпараметры, если вы настроите их

1713
01:10:43,760 --> 01:10:46,560
на наборе данных обучения, вы не получите

1714
01:10:46,560 --> 01:10:48,719
для них хороших допустимых значений, потому

1715
01:10:48,719 --> 01:10:51,120
что они не настроены на хорошие значения для

1716
01:10:51,120 --> 01:10:52,960
чего-то, что будет работать с другими

1717
01:10:52,960 --> 01:10:54,719
тестовыми данными,

1718
01:10:54,719 --> 01:10:58,159
кроме самых тонких  отчасти вы знаете,

1719
01:10:58,159 --> 01:11:00,320
я думаю, что многие люди начинают

1720
01:11:00,320 --> 01:11:02,400
думать, что нет ничего плохого в том, чтобы просто

1721
01:11:02,400 --> 01:11:06,480
продолжать тестирование на тестовом наборе каждый раз, когда

1722
01:11:06,480 --> 01:11:09,040
вы знаете, попробуйте какой-то вариант ммм, я

1723
01:11:09,040 --> 01:11:10,960
просто посмотрю, как это происходит на тестовом наборе

1724
01:11:10,960 --> 01:11:12,800
это действительно убедительная вещь  что вы

1725
01:11:12,800 --> 01:11:15,199
хотите поступить правильно вы изменили свою модель

1726
01:11:15,199 --> 01:11:16,880
вы хотели бы знать, повысился ли

1727
01:11:16,880 --> 01:11:19,679
результат на тестовом наборе эм,

1728
01:11:19,679 --> 01:11:23,199
но вы знаете, что правда в том, что если вы

1729
01:11:23,199 --> 01:11:24,880
это сделаете,

1730
01:11:24,880 --> 01:11:27,679
вы обманываете, потому что то, что вы делаете,

1731
01:11:27,679 --> 01:11:30,239
это вы  Вы как бы медленно тренируетесь на

1732
01:11:30,239 --> 01:11:32,800
тестовом наборе, потому что вы сохраняете каждое изменение,

1733
01:11:32,800 --> 01:11:35,120
которое помогает в тестовом наборе, и вы

1734
01:11:35,120 --> 01:11:38,000
отбрасываете каждое изменение, которое не помогает

1735
01:11:38,000 --> 01:11:40,560
на тестовом наборе или делает его хуже, и поэтому

1736
01:11:40,560 --> 01:11:42,800
вы изучаете тест  набор и

1737
01:11:42,800 --> 01:11:45,199
то, что случается случайно, для работы на

1738
01:11:45,199 --> 01:11:46,640
этом конкретном

1739
01:11:46,640 --> 01:11:48,800
наборе тестов, так что вы эффективно медленно

1740
01:11:48,800 --> 01:11:51,679
тренируетесь на наборе тестов и получаете

1741
01:11:51,679 --> 01:11:54,480
необъективно нереалистично высокие

1742
01:11:54,480 --> 01:11:57,440
уровни производительности.

1743
01:11:57,440 --> 01:12:00,400


1744
01:12:00,719 --> 01:12:02,239


1745
01:12:02,239 --> 01:12:03,360


1746
01:12:03,360 --> 01:12:04,800


1747
01:12:04,800 --> 01:12:08,000
больше слайдов о нейронных

1748
01:12:08,000 --> 01:12:11,679
сетях, которые, я думаю, я сейчас просто

1749
01:12:11,679 --> 01:12:12,480
пропущу,

1750
01:12:12,480 --> 01:12:15,520
но я думаю, что в

1751
01:12:15,520 --> 01:12:19,120
целом они полезны, чтобы их увидеть,

1752
01:12:19,120 --> 01:12:22,000
может быть, я просто

1753
01:12:22,000 --> 01:12:25,199
упомяну этот,

1754
01:12:25,520 --> 01:12:28,480
так что для финальных проектов вы '  гораздо

1755
01:12:28,480 --> 01:12:31,840
больше в одиночку, и вы должны

1756
01:12:31,840 --> 01:12:34,880
решить для себя, как  заставьте вашу

1757
01:12:34,880 --> 01:12:37,920
новую сеть работать,

1758
01:12:37,920 --> 01:12:38,880


1759
01:12:38,880 --> 01:12:40,400
поэтому первое,

1760
01:12:40,400 --> 01:12:42,480
что вы хотите начать с позитивного

1761
01:12:42,480 --> 01:12:44,640
отношения, вы знаете, эти нейронные сети

1762
01:12:44,640 --> 01:12:46,719
потрясающие, они действительно хотят научиться, они

1763
01:12:46,719 --> 01:12:48,400
хотят найти любой шаблон, который они могут

1764
01:12:48,400 --> 01:12:50,560
где угодно, в данных, которые

1765
01:12:50,560 --> 01:12:53,040
они действительно просто делают, что это в их

1766
01:12:53,040 --> 01:12:56,080
ДНК, поэтому, если ваша нейронная сеть не

1767
01:12:56,080 --> 01:12:58,640
обучается, это означает, что вы делаете что-то

1768
01:12:58,640 --> 01:13:00,880
не так, что мешает ей успешно обучаться,

1769
01:13:00,880 --> 01:13:02,640


1770
01:13:02,640 --> 01:13:04,880
но вы знаете, что в этот момент существует

1771
01:13:04,880 --> 01:13:08,080
мрачная реальность, эм, есть все виды вещей, из-за

1772
01:13:08,080 --> 01:13:10,880
которых нейронные сети вообще не

1773
01:13:10,880 --> 01:13:12,320
обучаются

1774
01:13:12,320 --> 01:13:14,560
или более распространенный случай, на самом деле, они как

1775
01:13:14,560 --> 01:13:17,280
бы немного узнают, что они не

1776
01:13:17,280 --> 01:13:19,840
очень хорошо учатся, вы знаете, что

1777
01:13:19,840 --> 01:13:22,239
в коде, который вы разделяете, есть ошибки, из-

1778
01:13:22,239 --> 01:13:23,760
за неправильной вещи

1779
01:13:23,760 --> 01:13:25,760
вам не хватает некоторых соединений в вашей

1780
01:13:25,760 --> 01:13:28,719
сети, поэтому нет информации  перетекает

1781
01:13:28,719 --> 01:13:31,199
из одного места в другое,

1782
01:13:31,199 --> 01:13:32,960
вы неправильно рассчитываете градиенты

1783
01:13:32,960 --> 01:13:35,120
в каком-то слое, есть множество

1784
01:13:35,120 --> 01:13:36,719
вещей, которые могут

1785
01:13:36,719 --> 01:13:38,400
пойти не

1786
01:13:38,400 --> 01:13:40,880
так, поэтому вам нужно затем решить, как их найти

1787
01:13:40,880 --> 01:13:43,440
и исправить, и правда в том, что  при этой

1788
01:13:43,440 --> 01:13:46,400
отладке и настройке часто может

1789
01:13:46,400 --> 01:13:49,199
потребоваться больше времени, чем я собираюсь

1790
01:13:49,199 --> 01:13:51,280
реализовать модель, поэтому с точки зрения

1791
01:13:51,280 --> 01:13:52,960
размышлений о том, сколько вы могли бы пройти,

1792
01:13:52,960 --> 01:13:55,520
вы должны думать хорошо, я

1793
01:13:55,520 --> 01:13:57,760
закодировал свою модель, что не означает, что

1794
01:13:57,760 --> 01:14:01,440
вам 75, это довольно часто, это

1795
01:14:01,440 --> 01:14:03,840
означает, что вам всего 20,

1796
01:14:03,840 --> 01:14:05,600
и еще много работы,

1797
01:14:05,600 --> 01:14:09,280
чтобы заставить все работать

1798
01:14:09,360 --> 01:14:11,520
нормально,

1799
01:14:11,520 --> 01:14:14,239
поэтому в последние минуты я просто хочу

1800
01:14:14,239 --> 01:14:18,480
сказать несколько минут

1801
01:14:20,239 --> 01:14:22,640
о последнем проекте, так что  у нас есть некоторое представление

1802
01:14:22,640 --> 01:14:24,800
о том, что это такое как

1803
01:14:24,800 --> 01:14:27,800
проблема

1804
01:14:28,719 --> 01:14:30,640
nlp, хорошо, поэтому проблема

1805
01:14:30,640 --> 01:14:31,440


1806
01:14:31,440 --> 01:14:34,000
чаще всего называется ответами

1807
01:14:34,000 --> 01:14:36,719
на вопросы по документам, но на самом деле то,

1808
01:14:36,719 --> 01:14:39,280
что мы делаем, возможно, лучше

1809
01:14:39,280 --> 01:14:42,000
назвать пониманием прочитанного,

1810
01:14:42,000 --> 01:14:45,520
и поэтому идея этого  что вы

1811
01:14:45,520 --> 01:14:49,280
действительно хотите иметь возможность отвечать на вопросы

1812
01:14:49,280 --> 01:14:52,000
на основе документов,

1813
01:14:52,000 --> 01:14:55,199
так что вот пример вопроса, кто

1814
01:14:55,199 --> 01:14:58,000
был третьим премьер-министром Австралии,

1815
01:14:58,000 --> 01:15:00,080
и вы знаете, когда-то, если

1816
01:15:00,080 --> 01:15:03,440
вы набирали вопрос в google,

1817
01:15:03,440 --> 01:15:05,760
все, что у вас было, это веб-поиск, и это

1818
01:15:05,760 --> 01:15:09,520
вернул вам список страниц с

1819
01:15:09,520 --> 01:15:11,920
подразумеваемым обещанием, что некоторые из тех,

1820
01:15:11,920 --> 01:15:13,840
что находятся в самом верху, вероятно, имеют

1821
01:15:13,840 --> 01:15:15,520
ответ на вопрос,

1822
01:15:15,520 --> 01:15:17,840
но если вы сделаете это сейчас,

1823
01:15:17,840 --> 01:15:20,239
он вернет вам ответ,

1824
01:15:20,239 --> 01:15:22,560
и вот ответ Джон Кристиан

1825
01:15:22,560 --> 01:15:23,679
Ватсон

1826
01:15:23,679 --> 01:15:26,800
и важные  нужно понимать,

1827
01:15:26,800 --> 01:15:29,360
что этот вид избранного фрагмента, который, как вы

1828
01:15:29,360 --> 01:15:31,679
знаете, в Google есть 101 или, может быть,

1829
01:15:31,679 --> 01:15:34,159
тысяча разных частей внутри него,

1830
01:15:34,159 --> 01:15:36,800
но вы знаете, что этот избранный фрагмент не

1831
01:15:36,800 --> 01:15:39,840
исходит из структурированных данных графа знаний Google,

1832
01:15:39,840 --> 01:15:42,800
он поступает прямо

1833
01:15:42,800 --> 01:15:45,600
с веб-страницы, где

1834
01:15:45,600 --> 01:15:48,800
какая-то часть поисковой системы Google

1835
01:15:48,800 --> 01:15:51,199
действительно прочитала эту веб-страницу и

1836
01:15:51,199 --> 01:15:54,400
решила, какой будет ответ,

1837
01:15:54,400 --> 01:15:57,199
поэтому для такой системы самый

1838
01:15:57,199 --> 01:15:59,760
простой способ сделать это -

1839
01:15:59,760 --> 01:16:02,000
сначала у вас есть две части, у вас есть система веб-поиска

1840
01:16:02,000 --> 01:16:04,800
, которая находит страницу, которая, вероятно,

1841
01:16:04,800 --> 01:16:07,120
есть ответ, а затем у вас есть

1842
01:16:07,120 --> 01:16:09,440
система понимания прочитанного, которая

1843
01:16:09,440 --> 01:16:12,800
фактически просматривает текст и

1844
01:16:12,800 --> 01:16:16,400
работает, чтобы извлечь ответ, и поэтому

1845
01:16:16,400 --> 01:16:19,360
она просматривает этот фрагмент текста, и

1846
01:16:19,360 --> 01:16:21,679
это отправлено  Энс говорит, что был австралийским

1847
01:16:21,679 --> 01:16:23,600
политиком, который был третьим премьер-

1848
01:16:23,600 --> 01:16:25,760
министром Австралии, вот что я

1849
01:16:25,760 --> 01:16:27,840
прошу, и немного другое слово

1850
01:16:27,840 --> 01:16:30,640
в третьем премьер-министре Австралии.

1851
01:16:30,640 --> 01:16:33,120


1852
01:16:33,120 --> 01:16:35,199


1853
01:16:35,199 --> 01:16:38,239
мы хотим

1854
01:16:38,239 --> 01:16:41,360
встроить в окончательный проект по умолчанию

1855
01:16:41,360 --> 01:16:44,159
системы, которые выполняют эту вторую часть,

1856
01:16:44,159 --> 01:16:45,120


1857
01:16:45,120 --> 01:16:48,719
учитывая фрагмент текста и вопрос, на который они могут

1858
01:16:48,719 --> 01:16:51,120
дать ответ, и поэтому общая

1859
01:16:51,120 --> 01:16:54,080
мотивация того, почему это важно, заключается в том,

1860
01:16:54,080 --> 01:16:57,040
что у нас есть огромные

1861
01:16:57,040 --> 01:16:59,840
коллекции полнотекстовых документов  что вы

1862
01:16:59,840 --> 01:17:02,400
знаете, просто сказав, что вот список,

1863
01:17:02,400 --> 01:17:04,960
возможно, релевантных документов, он имеет ограниченное

1864
01:17:04,960 --> 01:17:07,840
использование, что мы действительно предпочли бы получить

1865
01:17:07,840 --> 01:17:10,320
ответы на наши вопросы, и вы знаете,

1866
01:17:10,320 --> 01:17:12,880
что это правда в целом, но вы знаете, что это

1867
01:17:12,880 --> 01:17:14,960
особенно верно, если вы используете свой

1868
01:17:14,960 --> 01:17:17,120
телефон  пытаться искать информацию,

1869
01:17:17,120 --> 01:17:18,400
а не сидеть перед

1870
01:17:18,400 --> 01:17:22,000
27-дюймовым монитором, это особенно актуально, если

1871
01:17:22,000 --> 01:17:24,719
вы используете устройство виртуального помощника,

1872
01:17:24,719 --> 01:17:28,320
такое как alexa или google assis

1873
01:17:28,320 --> 01:17:31,040
Так что это проблема

1874
01:17:31,040 --> 01:17:33,199
, над которой работали над

1875
01:17:33,199 --> 01:17:34,239


1876
01:17:34,239 --> 01:17:35,920
пониманием прочитанного или ответами на вопросы,

1877
01:17:35,920 --> 01:17:38,640
и поэтому набор данных отряда

1878
01:17:38,640 --> 01:17:41,440
, созданный Пранавом Раджем Паркером и

1879
01:17:41,440 --> 01:17:43,199
Перси Ляном,

1880
01:17:43,199 --> 01:17:45,760
состоит из отрывков, взятых из

1881
01:17:45,760 --> 01:17:49,600
Википедии, и вопросов, какая команда выиграла

1882
01:17:49,600 --> 01:17:52,239
Суперкубок 50 и что вы  должны

1883
01:17:52,239 --> 01:17:54,000
быть в состоянии сделать, прочитать этот

1884
01:17:54,000 --> 01:17:56,560
отрывок

1885
01:17:57,280 --> 01:18:00,080
и сказать, ага, ответ -

1886
01:18:00,080 --> 01:18:02,400
denver broncos

1887
01:18:02,400 --> 01:18:05,120
um, и поэтому существует сотня тысяч

1888
01:18:05,120 --> 01:18:08,560
таких примеров, и поэтому

1889
01:18:08,560 --> 01:18:12,640
ответ всегда принимается просто как отрезок

1890
01:18:12,640 --> 01:18:14,080
отрывка, и на него ссылаются  как

1891
01:18:14,080 --> 01:18:16,480
извлекающий ответ на вопрос

1892
01:18:16,480 --> 01:18:19,920
, чтобы собрать эти данные, что было

1893
01:18:19,920 --> 01:18:23,760
сделано: людям показали отрывки, которые

1894
01:18:23,760 --> 01:18:25,760
задавали несколько вопросов, точно так же, как

1895
01:18:25,760 --> 01:18:27,840
понимание прочитанного в школе, возможно,

1896
01:18:27,840 --> 01:18:30,239
немного более простые вопросы,

1897
01:18:30,239 --> 01:18:32,560
и им было предложено выбрать диапазон,

1898
01:18:32,560 --> 01:18:34,480
который ответил бы на него,

1899
01:18:34,480 --> 01:18:37,600
и вы знаете, как в этих  примеры показывают,

1900
01:18:37,600 --> 01:18:40,640
что они показали это трем людям,

1901
01:18:40,640 --> 01:18:42,719
и они не всегда выбирали точно

1902
01:18:42,719 --> 01:18:45,199
такой же интервал, потому что есть некоторая

1903
01:18:45,199 --> 01:18:47,360
неопределенность относительно того, сколько  слова, которые нужно

1904
01:18:47,360 --> 01:18:51,199
включить, но примерно они отвечают

1905
01:18:51,199 --> 01:18:53,679
на вопрос таким образом,

1906
01:18:53,679 --> 01:18:56,880
и поэтому у нас есть меры оценки,

1907
01:18:56,880 --> 01:18:59,840
и поэтому есть две меры оценки,

1908
01:18:59,840 --> 01:19:02,640
одна из которых точно соответствует, возвращает ли вы

1909
01:19:02,640 --> 01:19:05,199
именно то, что вернул один из людей,

1910
01:19:05,199 --> 01:19:07,440
а другой - f1  мера,

1911
01:19:07,440 --> 01:19:08,480
которая является

1912
01:19:08,480 --> 01:19:09,360
um

1913
01:19:09,360 --> 01:19:12,400
- это перекрывающиеся слова вашего диапазона для

1914
01:19:12,400 --> 01:19:14,640
одного из людей, примерно,

1915
01:19:14,640 --> 01:19:15,600


1916
01:19:15,600 --> 01:19:19,840
поэтому для приседания

1917
01:19:20,640 --> 01:19:23,199
инициалы всегда были вопросом, мы собираемся сделать

1918
01:19:23,199 --> 01:19:28,080
отряд 2.0, который немного

1919
01:19:28,080 --> 01:19:30,000
сложнее, потому что они делают это

1920
01:19:30,000 --> 01:19:32,320
немного  немного сложнее, что на некоторые

1921
01:19:32,320 --> 01:19:35,840
вопросы нет ответов в тексте, так что

1922
01:19:35,840 --> 01:19:38,000
вот отрывок о Чингисхане,

1923
01:19:38,000 --> 01:19:41,280
и вопрос в том,

1924
01:19:41,280 --> 01:19:44,400
когда Чингисхан убил великого хана,

1925
01:19:44,400 --> 01:19:48,840
и хорошо, если мы как бы

1926
01:19:48,840 --> 01:19:51,679
прочитаем этот текст в начале этого Чингисхана

1927
01:19:51,679 --> 01:19:54,320
и гм

1928
01:19:54,320 --> 01:19:57,120
говорят о разных ханах, и

1929
01:19:57,120 --> 01:19:59,280
здесь внизу человек, который стал великим

1930
01:19:59,280 --> 01:20:02,560
ханом в 1251 году, но рыжий хан не

1931
01:20:02,560 --> 01:20:04,960
убивал великого хана, это вообще не говорит об этом,

1932
01:20:04,960 --> 01:20:07,360
но вы знаете, что на

1933
01:20:07,360 --> 01:20:10,000
самом деле это микрософт  t nlmet, это

1934
01:20:10,000 --> 01:20:12,960
еще одна сильная система ответов на вопросы,

1935
01:20:12,960 --> 01:20:16,639
и если вы зададите этот вопрос, он

1936
01:20:16,639 --> 01:20:20,000
скажет 12 34. Так что реальность такова, что многие

1937
01:20:20,000 --> 01:20:22,880
из этих моделей, мм, эффективно

1938
01:20:22,880 --> 01:20:25,280
эвристически ведут себя, как хорошо,

1939
01:20:25,280 --> 01:20:28,000
это просит год, позвольте мне посмотреть  в

1940
01:20:28,000 --> 01:20:30,000
течение года в этом отрывке это близкое

1941
01:20:30,000 --> 01:20:32,560
обсуждение Чингисхана

1942
01:20:32,560 --> 01:20:35,040
и, возможно, его ослабления чем-то похоже

1943
01:20:35,040 --> 01:20:37,679
на убийство, я собираюсь угадать 12 34, и

1944
01:20:37,679 --> 01:20:39,120
это вроде неправильной вещи

1945
01:20:39,120 --> 01:20:41,360
здесь, так что это хороший

1946
01:20:41,360 --> 01:20:43,600
тест надежности для моделей с ответами на вопросы  Так

1947
01:20:43,600 --> 01:20:45,840
что это интересная дополнительная проблема, на которую стоит обратить

1948
01:20:45,840 --> 01:20:46,880
внимание,

1949
01:20:46,880 --> 01:20:47,840
ладно,

1950
01:20:47,840 --> 01:20:50,320
я собираюсь на этом остановиться на сегодня,

1951
01:20:50,320 --> 01:20:54,360
удачи в ваших проектах

