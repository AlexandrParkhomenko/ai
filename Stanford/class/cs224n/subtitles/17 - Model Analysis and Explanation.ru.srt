1
00:00:05,359 --> 00:00:09,360
добро пожаловать на лекцию cs224n,

2
00:00:09,360 --> 00:00:11,200
седьмая

3
00:00:11,200 --> 00:00:12,160
подростковая

4
00:00:12,160 --> 00:00:14,920
модель, анализ и объяснение,

5
00:00:14,920 --> 00:00:18,240
хорошо, посмотри на нас, мы здесь,

6
00:00:18,240 --> 00:00:19,840
давай начнем с

7
00:00:19,840 --> 00:00:23,519
логистики курса, мы обновили

8
00:00:23,519 --> 00:00:26,320
политику в отношении реакции на гостевую лекцию. Все

9
00:00:26,320 --> 00:00:29,840
они должны пройти в пятницу.

10
00:00:29,840 --> 00:00:32,640
23:59, вы не можете использовать поздние дни для этого

11
00:00:32,640 --> 00:00:34,559
, так что, пожалуйста, пусть мужчины

12
00:00:34,559 --> 00:00:36,640
смотрят лекции, они классные

13
00:00:36,640 --> 00:00:39,840
лекции,

14
00:00:39,840 --> 00:00:41,360


15
00:00:41,360 --> 00:00:43,520
они классные гости  должны быть

16
00:00:43,520 --> 00:00:45,920
представлены до пятницы,

17
00:00:45,920 --> 00:00:48,879
ну ладно, итоговые проекты помните,

18
00:00:48,879 --> 00:00:51,440
что срок сдачи -

19
00:00:51,440 --> 00:00:55,039
вторник, вторник, 16:30, 16 марта,

20
00:00:55,039 --> 00:00:55,920
и

21
00:00:55,920 --> 00:00:58,800
позвольте мне подчеркнуть, что есть жесткий

22
00:00:58,800 --> 00:01:03,280
крайний срок в три дня с

23
00:01:03,280 --> 00:01:04,879
пятницы, которые

24
00:01:04,879 --> 00:01:07,040
мы не будем принимать  из-за дополнительных

25
00:01:07,040 --> 00:01:08,479
баллов от

26
00:01:08,479 --> 00:01:10,640
заданий, извините, окончательные проекты

27
00:01:10,640 --> 00:01:12,400
, которые представлены после

28
00:01:12,400 --> 00:01:15,280
крайнего срока 4 30 в пятницу,

29
00:01:15,280 --> 00:01:17,119
нам нужно получить эти оценки и получить

30
00:01:17,119 --> 00:01:19,680
оценки, так

31
00:01:19,680 --> 00:01:22,000
что это конец девятой недели, наша неделя

32
00:01:22,000 --> 00:01:23,040
10 - это

33
00:01:23,040 --> 00:01:25,119
действительно лекции, которые

34
00:01:25,119 --> 00:01:26,960
мы читаем  ты  помогите в окончательном проекте,

35
00:01:26,960 --> 00:01:28,320
так что это действительно последняя неделя

36
00:01:28,320 --> 00:01:30,560
лекций, спасибо за всю вашу тяжелую работу

37
00:01:30,560 --> 00:01:33,280
и за то, что задавали классные вопросы на

38
00:01:33,280 --> 00:01:35,600
лекциях, в рабочее время и в редакции,

39
00:01:35,600 --> 00:01:37,759
и давайте перейдем к этому, так

40
00:01:37,759 --> 00:01:40,720
что сегодня мы перейдем к  поговорим об одном из моих

41
00:01:40,720 --> 00:01:43,280
любимых предметов в обработке естественного языка,

42
00:01:43,280 --> 00:01:45,439
это анализ моделей и

43
00:01:45,439 --> 00:01:47,920
объяснение эм, так что сначала мы собираемся

44
00:01:47,920 --> 00:01:50,399
заняться тем, что я люблю делать, что мотивирует,

45
00:01:50,399 --> 00:01:52,159
почему мы вообще хотим поговорить на эту тему,

46
00:01:52,159 --> 00:01:54,079


47
00:01:54,079 --> 00:01:56,320
мы поговорим о том, откуда вы знаете  мы можем

48
00:01:56,320 --> 00:01:58,240
взглянуть на модель на разных уровнях

49
00:01:58,240 --> 00:01:59,840
абстракции, чтобы выполнить на ней различные

50
00:01:59,840 --> 00:02:01,840
виды анализа.

51
00:02:01,840 --> 00:02:03,600
Мы поговорим о наборах оценок вне домена,

52
00:02:03,600 --> 00:02:06,320
так что это будет

53
00:02:06,320 --> 00:02:09,520
знакомо надежным специалистам по контролю качества, а

54
00:02:09,520 --> 00:02:10,318


55
00:02:10,318 --> 00:02:12,959
затем мы поговорим о  э-э, вроде

56
00:02:12,959 --> 00:02:15,200
попытки выяснить для данного примера,

57
00:02:15,200 --> 00:02:17,120
почему он принял решение, что он

58
00:02:17,120 --> 00:02:19,280
принял какой-то ввод, он произвел какой-то вывод,

59
00:02:19,280 --> 00:02:20,560
можем ли мы придумать какое-то

60
00:02:20,560 --> 00:02:23,280
интерпретируемое объяснение для этого,

61
00:02:23,280 --> 00:02:25,840
и э-э, тогда

62
00:02:25,840 --> 00:02:26,959
мы посмотрим на собственно

63
00:02:26,959 --> 00:02:29,360
представлять  модели, так что

64
00:02:29,360 --> 00:02:30,879
это своего рода скрытые состояния

65
00:02:30,879 --> 00:02:33,040
, которые строятся векторами, которые вы знаете на

66
00:02:33,040 --> 00:02:34,800
протяжении всей обработки модели,

67
00:02:34,800 --> 00:02:37,040
пытаются выяснить, можем ли мы понять

68
00:02:37,040 --> 00:02:38,720
некоторые из представлений и

69
00:02:38,720 --> 00:02:41,200
механизмов, которые выполняет модель,

70
00:02:41,200 --> 00:02:42,959
а затем мы  на самом деле возвращаемся к

71
00:02:42,959 --> 00:02:45,120
одному из видов состояний по умолчанию

72
00:02:45,120 --> 00:02:46,720
, в которых мы были в этом курсе,

73
00:02:46,720 --> 00:02:47,680
который

74
00:02:47,680 --> 00:02:49,519
пытается вам узнать, посмотрите на улучшения модели,

75
00:02:49,519 --> 00:02:51,280
удаляя вещи из моделей,

76
00:02:51,280 --> 00:02:53,680
видя, как это работает, и соотносите это

77
00:02:53,680 --> 00:02:55,599
с анализом, который мы  Делая на этой

78
00:02:55,599 --> 00:02:57,440
лекции, покажу, что не

79
00:02:57,440 --> 00:02:58,800
все так уж и иначе,

80
00:02:58,800 --> 00:03:00,720
ну ладно,

81
00:03:00,720 --> 00:03:02,640


82
00:03:02,640 --> 00:03:05,680
если вы не видели этот xkcd, а теперь у вас

83
00:03:05,680 --> 00:03:07,920
есть, и это одно из моих любимых

84
00:03:07,920 --> 00:03:11,040
слов, я собираюсь сказать все слова, так что человек

85
00:03:11,040 --> 00:03:13,280
a говорит, что это  ваша система машинного обучения

86
00:03:13,280 --> 00:03:15,920
человек b говорит, что да, вы вливаете

87
00:03:15,920 --> 00:03:18,159
данные в эту большую кучу линейной

88
00:03:18,159 --> 00:03:20,159
алгебры, а затем собираете ответы

89
00:03:20,159 --> 00:03:21,360
с другой стороны

90
00:03:21,360 --> 00:03:24,159
человек а что, если ответы неправильные,

91
00:03:24,159 --> 00:03:26,239
а человек b просто перемешивает кучу, пока

92
00:03:26,239 --> 00:03:28,319
они не начнут искать ri  ght,

93
00:03:28,319 --> 00:03:30,640
и мне кажется, что в худшем случае глубокое

94
00:03:30,640 --> 00:03:32,159
обучение может казаться таким.

95
00:03:32,159 --> 00:03:34,159


96
00:03:34,159 --> 00:03:35,920


97
00:03:35,920 --> 00:03:37,760


98
00:03:37,760 --> 00:03:39,200


99
00:03:39,200 --> 00:03:41,360
это не работает для других, и

100
00:03:41,360 --> 00:03:42,959
вы знаете, какие изменения мы вносим в наши

101
00:03:42,959 --> 00:03:44,640
модели,

102
00:03:44,640 --> 00:03:46,159
вы знаете, что они основаны на интуиции, но

103
00:03:46,159 --> 00:03:48,159
часто вы знаете, каковы правила, которые

104
00:03:48,159 --> 00:03:50,000
вам говорят, вы знаете всех в рабочее время,

105
00:03:50,000 --> 00:03:51,360
например, иногда вам просто нужно попробовать

106
00:03:51,360 --> 00:03:52,640
это и увидеть  Если это сработает,

107
00:03:52,640 --> 00:03:55,360
потому что очень сложно сказать, что

108
00:03:55,360 --> 00:03:57,599
очень-очень

109
00:03:57,599 --> 00:04:00,560
сложно понять наши модели на каком-либо

110
00:04:00,560 --> 00:04:02,560
уровне, и поэтому сегодня мы рассмотрим

111
00:04:02,560 --> 00:04:04,480
несколько способов, чтобы попытаться найти

112
00:04:04,480 --> 00:04:06,080


113
00:04:06,080 --> 00:04:09,280
здесь небольшие кусочки понимания  и там так эээ,

114
00:04:09,280 --> 00:04:11,599
помимо того, что вы знаете, что

115
00:04:11,599 --> 00:04:13,519
важно, потому что в следующем

116
00:04:13,519 --> 00:04:14,640
комиксе

117
00:04:14,640 --> 00:04:16,160
kcd, почему мы должны заботиться о том, какие наши

118
00:04:16,160 --> 00:04:18,320
модели понимают наши модели,

119
00:04:18,320 --> 00:04:20,399
первое, что мы хотим знать,

120
00:04:20,399 --> 00:04:23,520
что делают наши модели,

121
00:04:23,520 --> 00:04:24,479
так что

122
00:04:24,479 --> 00:04:27,120
здесь у вас есть черный  ящик

123
00:04:27,120 --> 00:04:29,199
черный ящик f  Объединения - это своего рода

124
00:04:29,199 --> 00:04:30,800
идея о том, что вы не можете изучить их и

125
00:04:30,800 --> 00:04:33,199
интерпретировать то, что они делают, у

126
00:04:33,199 --> 00:04:35,840
вас есть входное предложение, а затем

127
00:04:35,840 --> 00:04:37,520
некоторый прогноз вывода,

128
00:04:37,520 --> 00:04:40,240
возможно, этот черный ящик на самом деле ваш,

129
00:04:40,240 --> 00:04:43,040
ваш последний проект, модель, и она получает

130
00:04:43,040 --> 00:04:45,840
некоторую точность

131
00:04:45,840 --> 00:04:47,280
Теперь

132
00:04:47,280 --> 00:04:49,199
мы суммируем наши модели, и в ваших

133
00:04:49,199 --> 00:04:50,639
окончательных проектах вы суммируете свою

134
00:04:50,639 --> 00:04:53,600
модель с помощью одного или

135
00:04:53,600 --> 00:04:56,320
нескольких сводных показателей точности, или оценки f1,

136
00:04:56,320 --> 00:04:58,639
или блюзкора, или чего-то еще,

137
00:04:58,639 --> 00:04:59,680
но

138
00:04:59,680 --> 00:05:01,360
это большая модель, которую нужно объяснить с

139
00:05:01,360 --> 00:05:04,000
помощью небольшого количества  метрики, так что

140
00:05:04,000 --> 00:05:06,320
они узнают, почему они добиваются успеха и

141
00:05:06,320 --> 00:05:08,240
почему они терпят неудачу?

142
00:05:08,240 --> 00:05:09,840
Какая еще одна мотивация, поэтому мы хотим,

143
00:05:09,840 --> 00:05:11,759
мы хотим знать, что наши модели

144
00:05:11,759 --> 00:05:14,400
делают хорошо, но, может быть, это

145
00:05:14,400 --> 00:05:15,919
потому, что мы хотим иметь возможность сделать

146
00:05:15,919 --> 00:05:18,639
модель завтрашнего дня такой  сегодня,

147
00:05:18,639 --> 00:05:20,240
когда вы создаете модели в

148
00:05:20,240 --> 00:05:22,560
этом классе в компании, которую знаете, вы

149
00:05:22,560 --> 00:05:24,639
начинаете с какого-то рецепта, который,

150
00:05:24,639 --> 00:05:25,600
как

151
00:05:25,600 --> 00:05:27,440
известно, работает либо в компании, либо

152
00:05:27,440 --> 00:05:28,960
потому, что у вас есть опыт в этом

153
00:05:28,960 --> 00:05:31,360
классе, а это не п  erfect right он

154
00:05:31,360 --> 00:05:33,280
делает ошибки, вы смотрите на ошибки,

155
00:05:33,280 --> 00:05:35,520
а затем со временем вы знаете, что берете

156
00:05:35,520 --> 00:05:36,639
то, что работает,

157
00:05:36,639 --> 00:05:37,759
возможно,

158
00:05:37,759 --> 00:05:39,520
а затем вы обнаруживаете, что нужно изменить, так

159
00:05:39,520 --> 00:05:41,280
что кажется, что, может быть, вы знаете, что добавление

160
00:05:41,280 --> 00:05:43,680
еще одного слоя к модели помогло, и,

161
00:05:43,680 --> 00:05:45,759
может быть, это хорошая настройка

162
00:05:45,759 --> 00:05:48,720
производительность модели

163
00:05:48,720 --> 00:05:52,240
улучшается и

164
00:05:52,240 --> 00:05:54,160


165
00:05:54,160 --> 00:05:56,319


166
00:05:56,319 --> 00:05:59,360


167
00:05:59,360 --> 00:06:01,280


168
00:06:01,280 --> 00:06:03,039


169
00:06:03,039 --> 00:06:05,840
т.д.  что мы можем лучше

170
00:06:05,840 --> 00:06:08,479
оценивать ситуацию, когда мы нуждаемся в больших

171
00:06:08,479 --> 00:06:10,560
скачках, когда нам нужны серьезные изменения, потому

172
00:06:10,560 --> 00:06:12,400
что есть проблемы, которые мы решаем

173
00:06:12,400 --> 00:06:14,240
с помощью нашего постепенного прогресса,

174
00:06:14,240 --> 00:06:16,479
и мы не очень

175
00:06:16,479 --> 00:06:19,199
хорошо продвигаемся, поэтому мы хотим  Сделайте модель завтрашнего дня

176
00:06:19,199 --> 00:06:22,160
еще одну вещь, которая, я думаю, очень

177
00:06:22,160 --> 00:06:24,400
связана с

178
00:06:24,400 --> 00:06:26,400
этой областью анализа и как бы является ее частью и больше, чем эта

179
00:06:26,400 --> 00:06:28,319
область анализа.

180
00:06:28,319 --> 00:06:30,639


181
00:06:30,639 --> 00:06:33,759
es solver, который вы

182
00:06:33,759 --> 00:06:35,199
знаете от гм,

183
00:06:35,199 --> 00:06:36,960
от перчатки

184
00:06:36,960 --> 00:06:38,880
или слова до спины, это от

185
00:06:38,880 --> 00:06:41,759
первого задания, и вы даете ему аналогию, которую

186
00:06:41,759 --> 00:06:43,600
удалось компьютерному программисту, поскольку

187
00:06:43,600 --> 00:06:46,000
женщине два года, и он дает вам выходную

188
00:06:46,000 --> 00:06:47,919
домохозяйку, это реальный пример

189
00:06:47,919 --> 00:06:49,840
из статьи ниже эм

190
00:06:49,840 --> 00:06:50,639


191
00:06:50,639 --> 00:06:53,759
ты должен быть как вау, ну

192
00:06:53,759 --> 00:06:55,440
я рад, что знаю, что сейчас, и, конечно,

193
00:06:55,440 --> 00:06:56,800
ты видел

194
00:06:56,800 --> 00:06:59,919
лекцию Юлии Светковой на

195
00:06:59,919 --> 00:07:02,080
прошлой неделе, ты сказал: вау, я рад,

196
00:07:02,080 --> 00:07:03,840
что знаю это сейчас, и это огромная

197
00:07:03,840 --> 00:07:05,759
проблема, что использовала модель  в своем

198
00:07:05,759 --> 00:07:07,840
решении, какие предубеждения он извлекает из

199
00:07:07,840 --> 00:07:10,319
данных и, возможно, делает его еще хуже,

200
00:07:10,319 --> 00:07:11,120
так

201
00:07:11,120 --> 00:07:12,560
что это то, что вы также можете

202
00:07:12,560 --> 00:07:14,080
делать с анализом модели, помимо

203
00:07:14,080 --> 00:07:16,560
улучшения моделей в соответствии с какой-то

204
00:07:16,560 --> 00:07:18,319
сводной метрикой

205
00:07:18,319 --> 00:07:21,039
, а затем еще кое-что, чего мы не делаем

206
00:07:21,039 --> 00:07:22,720
просто хочу создать модель завтрашнего дня, и

207
00:07:22,720 --> 00:07:23,919
это то, что я считаю очень

208
00:07:23,919 --> 00:07:26,639
важным, мы,

209
00:07:26,639 --> 00:07:28,000
вы знаете,

210
00:07:28,000 --> 00:07:29,759
мы не просто хотим смотреть на эту временную

211
00:07:29,759 --> 00:07:32,880
шкалу, мы хотим сказать, что будет через 10 15 25

212
00:07:32,880 --> 00:07:34,800
лет, какие вещи

213
00:07:34,800 --> 00:07:37,440
мы будем  делать тебе  знать, каковы пределы

214
00:07:37,440 --> 00:07:39,440
того, что может быть изучено с помощью предварительного обучения языковой модели,

215
00:07:39,440 --> 00:07:40,880


216
00:07:40,880 --> 00:07:42,080
какая модель

217
00:07:42,080 --> 00:07:43,680
заменит преобразователь,

218
00:07:43,680 --> 00:07:45,039
какая модель заменит эту

219
00:07:45,039 --> 00:07:46,080
модель,

220
00:07:46,080 --> 00:07:47,840
что затрудняет глубокое обучение,

221
00:07:47,840 --> 00:07:49,759
что мы как бы атакуем снова и

222
00:07:49,759 --> 00:07:51,199
снова  снова и не добившись

223
00:07:51,199 --> 00:07:53,599
значительного прогресса в том, что нейронные

224
00:07:53,599 --> 00:07:54,960
модели говорят нам о языке,

225
00:07:54,960 --> 00:07:56,160
потенциально есть люди, которые в

226
00:07:56,160 --> 00:07:58,479
первую очередь заинтересованы в

227
00:07:58,479 --> 00:08:00,879
лучшем понимании языка с помощью нейронных сетей.

228
00:08:00,879 --> 00:08:02,720
Круто

229
00:08:02,720 --> 00:08:04,000
,

230
00:08:04,000 --> 00:08:06,240
как наши модели влияют на людей,

231
00:08:06,240 --> 00:08:08,319
передающих власть между группами

232
00:08:08,319 --> 00:08:11,039
людей, правительствами и т. д.

233
00:08:11,039 --> 00:08:13,440
отличный тип анализа того, что нельзя

234
00:08:13,440 --> 00:08:14,960
выучить с помощью предварительной подготовки языковой модели,

235
00:08:14,960 --> 00:08:16,400
так что это своего рода дополнительный

236
00:08:16,400 --> 00:08:18,879
вопрос, если вы как бы подошли

237
00:08:18,879 --> 00:08:20,639
к краю того, что вы можете изучить с помощью

238
00:08:20,639 --> 00:08:22,400
предварительной подготовки языковой модели, есть ли

239
00:08:22,400 --> 00:08:24,160
что-то, что нам нужно в целом  сдвиг парадигмы

240
00:08:24,160 --> 00:08:26,400
,

241
00:08:26,400 --> 00:08:28,000
чтобы добиться успеха,

242
00:08:28,000 --> 00:08:30,479
так что все это, я имею в виду, вы знаете, подпадает

243
00:08:30,479 --> 00:08:32,719
под какую-то категорию попыток реального

244
00:08:32,719 --> 00:08:34,240
Мы глубоко понимаем наши модели и их

245
00:08:34,240 --> 00:08:36,399
возможности,

246
00:08:36,399 --> 00:08:37,200
и

247
00:08:37,200 --> 00:08:38,799
здесь есть много разных методов,

248
00:08:38,799 --> 00:08:41,039
которые мы рассмотрим сегодня, и одна вещь,

249
00:08:41,039 --> 00:08:42,559
которую я хочу, чтобы вы вынесли из этого, это

250
00:08:42,559 --> 00:08:44,250
то, что они все

251
00:08:44,250 --> 00:08:45,440
[Аплодисменты]

252
00:08:45,440 --> 00:08:47,440
они все собираются  скажите нам

253
00:08:47,440 --> 00:08:49,519
какой-то аспект модели, проясните какую-

254
00:08:49,519 --> 00:08:51,600
то интуицию или что-то в этом роде, но ни один

255
00:08:51,600 --> 00:08:54,160
из них не скажет, ага, я

256
00:08:54,160 --> 00:08:56,160
действительно понимаю 100 о том, что эта

257
00:08:56,160 --> 00:08:58,080
модель делает сейчас эм, так что они

258
00:08:58,080 --> 00:09:00,000
собираются обеспечить некоторую ясность, но никогда полную

259
00:09:00,000 --> 00:09:01,760
ясность  и

260
00:09:01,760 --> 00:09:04,240
один из способов, если вы пытаетесь решить, как

261
00:09:04,240 --> 00:09:06,800
вы хотите лучше понимать свою модель,

262
00:09:06,800 --> 00:09:08,080
я думаю, вам следует начать с

263
00:09:08,080 --> 00:09:09,839
размышлений о том, на каком уровне

264
00:09:09,839 --> 00:09:12,080
абстракции я хочу смотреть на

265
00:09:12,080 --> 00:09:14,720
свою модель,

266
00:09:14,720 --> 00:09:17,120
так что своего рода очень высокий  абстракция уровня

267
00:09:17,120 --> 00:09:20,080
предположим, что вы обучили, что знаете модель qa

268
00:09:20,080 --> 00:09:22,320
для оценки вероятностей

269
00:09:22,320 --> 00:09:24,560
начальных и конечных индексов, и вы знаете, что в

270
00:09:24,560 --> 00:09:26,160
проблеме понимания прочитанного, или вы

271
00:09:26,160 --> 00:09:28,240
обучили языковую модель, которая присваивает

272
00:09:28,240 --> 00:09:30,480
вероятности словам в контексте, вы

273
00:09:30,480 --> 00:09:32,880
можете просто посмотреть  в модели в качестве этого

274
00:09:32,880 --> 00:09:34,560
объекта, так что это просто распределение вероятностей,

275
00:09:34,560 --> 00:09:37,519
определенное вашей моделью,

276
00:09:37,519 --> 00:09:39,279
вы не изучаете его дальше,

277
00:09:39,279 --> 00:09:41,040
чем тот факт, что вы можете вроде как дать

278
00:09:41,040 --> 00:09:42,640
ему входные данные и посмотреть, какие выходные данные он

279
00:09:42,640 --> 00:09:44,800
предоставляет,

280
00:09:44,800 --> 00:09:46,320
так

281
00:09:46,320 --> 00:09:48,399
что даже кого не волнует,  это нейронная

282
00:09:48,399 --> 00:09:50,800
сеть, это может быть что угодно,

283
00:09:50,800 --> 00:09:52,080
но это способ понять ее

284
00:09:52,080 --> 00:09:53,120
поведение

285
00:09:53,120 --> 00:09:54,720
другой уровень абстракции, на который вы

286
00:09:54,720 --> 00:09:56,320
можете взглянуть, вы можете копнуть немного глубже,

287
00:09:56,320 --> 00:09:58,720
вы можете хорошо сказать, я знаю, что моя сеть

288
00:09:58,720 --> 00:10:00,640
представляет собой набор слоев, которые как бы

289
00:10:00,640 --> 00:10:02,240
сложены  друг над другом у вас есть

290
00:10:02,240 --> 00:10:05,120
своего рода, может быть, ваш кодировщик-преобразователь

291
00:10:05,120 --> 00:10:07,120
с вашим однослойным, двухслойным, трехуровневым

292
00:10:07,120 --> 00:10:08,800
слоем, вы можете попытаться увидеть, что он делает,

293
00:10:08,800 --> 00:10:11,600
когда он проникает глубже в слои,

294
00:10:11,600 --> 00:10:13,360
поэтому, возможно, ваша нейронная модель представляет собой

295
00:10:13,360 --> 00:10:15,600
последовательность этих векторных представлений  Третий

296
00:10:15,600 --> 00:10:18,399
вариант своеобразной специфичности - посмотреть,

297
00:10:18,399 --> 00:10:21,200
как вы знаете столько деталей,

298
00:10:21,200 --> 00:10:22,880
насколько это возможно, у вас есть эти параметры,

299
00:10:22,880 --> 00:10:24,079
у вас есть связи

300
00:10:24,079 --> 00:10:26,000
в графе вычислений,

301
00:10:26,000 --> 00:10:27,760
так что теперь вы вроде как tr  вы хотите удалить

302
00:10:27,760 --> 00:10:30,079
всю возможную абстракцию и

303
00:10:30,079 --> 00:10:32,240
рассмотреть как можно больше деталей, и

304
00:10:32,240 --> 00:10:33,600
все три таких способа

305
00:10:33,600 --> 00:10:34,959
взгляда на вашу модель и выполнения

306
00:10:34,959 --> 00:10:36,079
анализа

307
00:10:36,079 --> 00:10:38,320
будут полезны и фактически будут

308
00:10:38,320 --> 00:10:40,079
медленно перемещаться

309
00:10:40,079 --> 00:10:42,560
от одного к двум.  до трех, пока мы

310
00:10:42,560 --> 00:10:45,279
проходим эту лекцию,

311
00:10:45,440 --> 00:10:46,880
хорошо,

312
00:10:46,880 --> 00:10:48,399
поэтому мы на самом деле еще не говорили о каких-либо

313
00:10:48,399 --> 00:10:50,240
анализах,

314
00:10:50,240 --> 00:10:52,480
так что мы собираемся начать

315
00:10:52,480 --> 00:10:55,279
с этого сейчас,

316
00:10:55,279 --> 00:10:57,200
и мы начинаем своего рода

317
00:10:57,200 --> 00:10:59,360
тестирование поведения нашей модели,

318
00:10:59,360 --> 00:11:01,920
так что  мы хотим увидеть, будет ли моя модель

319
00:11:01,920 --> 00:11:03,680
работать хорошо, я имею в виду, что естественно

320
00:11:03,680 --> 00:11:06,079
спросить, как она ведет себя на

321
00:11:06,079 --> 00:11:08,160
некоторых на каком-то

322
00:11:08,160 --> 00:11:09,440
тестовом наборе

323
00:11:09,440 --> 00:11:11,680
правильно, и поэтому нас на самом деле не

324
00:11:11,680 --> 00:11:13,680
заботят механизмы, но почему она

325
00:11:13,680 --> 00:11:16,000
выполняет это с помощью чего  метод, он

326
00:11:16,000 --> 00:11:17,920
принимает свое решение, вместо этого мы просто

327
00:11:17,920 --> 00:11:19,839
заинтересованы в некоторой абстракции более высокого

328
00:11:19,839 --> 00:11:21,360
уровня,

329
00:11:21,360 --> 00:11:23,440
например, работает ли он так, как я хочу,

330
00:11:23,440 --> 00:11:26,720
поэтому давайте

331
00:11:26,720 --> 00:11:28,959
возьмем оценку нашей модели, которую мы

332
00:11:28,959 --> 00:11:31,519
уже делаем, и вроде  переделать это

333
00:11:31,519 --> 00:11:33,839
в рамках анализа, так что вы

334
00:11:33,839 --> 00:11:36,079
обучили свою модель на некоторых образцах

335
00:11:36,079 --> 00:11:37,600
из некоторого дистрибутива, чтобы у вас были

336
00:11:37,600 --> 00:11:40,320
какие-то пары входных выходов,

337
00:11:40,320 --> 00:11:42,320
так как модель ведет себя на выборках

338
00:11:42,320 --> 00:11:44,000
из того же дистрибутива, это

339
00:11:44,000 --> 00:11:46,959
простой вопрос, и это вроде как

340
00:11:46,959 --> 00:11:48,160
вы знаете, что это известно, поскольку вы знаете

341
00:11:48,160 --> 00:11:50,399
точность в домене, или

342
00:11:50,399 --> 00:11:52,399
вы можете сказать, что образцы являются iid, и это

343
00:11:52,399 --> 00:11:53,920
то, что вы тестируете, и это

344
00:11:53,920 --> 00:11:54,800
именно

345
00:11:54,800 --> 00:11:56,160
то, что мы делали все время,

346
00:11:56,160 --> 00:11:58,079
это точность вашего набора тестов или f1 или

347
00:11:58,079 --> 00:11:59,839
синий счет,

348
00:11:59,839 --> 00:12:02,160
и вы знаете, что

349
00:12:02,160 --> 00:12:04,560
у вас есть модель с некоторой точностью,

350
00:12:04,560 --> 00:12:05,440
и,

351
00:12:05,440 --> 00:12:07,120
возможно, она лучше, чем какая-то модель с

352
00:12:07,120 --> 00:12:08,800
некоторой другой точностью на этом тестовом наборе,

353
00:12:08,800 --> 00:12:10,000
правильно, так что это то, что вы делаете, когда

354
00:12:10,000 --> 00:12:11,279
повторяете свои модели в своем

355
00:12:11,279 --> 00:12:14,320
финальный проект, как

356
00:12:14,320 --> 00:12:16,320
вы говорите, хорошо, что вы знаете на моем тестовом наборе, о

357
00:12:16,320 --> 00:12:17,920
котором я решил

358
00:12:17,920 --> 00:12:20,480
позаботиться сейчас. Модель A работает лучше, они оба

359
00:12:20,480 --> 00:12:21,920
кажутся довольно хорошими,

360
00:12:21,920 --> 00:12:24,000
и поэтому, возможно, я выберу модель A, чтобы продолжить

361
00:12:24,000 --> 00:12:25,680
работу, может быть, я  выберу, если

362
00:12:25,680 --> 00:12:28,320
ты что-то вкладываешь в  производство

363
00:12:28,320 --> 00:12:30,320
гм, но помните, что вы знаете

364
00:12:30,320 --> 00:12:33,120
эту идею, что это всего лишь одно число, чтобы

365
00:12:33,120 --> 00:12:36,240
резюмировать очень сложную систему, а этого

366
00:12:36,240 --> 00:12:37,839
будет недостаточно, чтобы сказать вам,

367
00:12:37,839 --> 00:12:39,600
как она будет работать в самых

368
00:12:39,600 --> 00:12:42,079
разных настройках,

369
00:12:42,079 --> 00:12:44,240
хорошо, так что мы были  Делая это, это

370
00:12:44,240 --> 00:12:46,720
оценка модели как анализ модели.

371
00:12:46,720 --> 00:12:48,399


372
00:12:48,399 --> 00:12:51,680
Теперь мы собираемся сказать, что, если мы

373
00:12:51,680 --> 00:12:53,839
не тестируем точно тот же тип

374
00:12:53,839 --> 00:12:56,160
данных, на котором мы обучались,

375
00:12:56,160 --> 00:12:58,399
поэтому теперь мы спрашиваем, узнала ли модель

376
00:12:58,399 --> 00:13:00,399
что-то такое, что она может  своего рода

377
00:13:00,399 --> 00:13:03,120
экстраполировать или выполнять, как я хочу,

378
00:13:03,120 --> 00:13:04,480
на данных, которые выглядят немного

379
00:13:04,480 --> 00:13:05,920
иначе, чем те, на которых они были обучены,

380
00:13:05,920 --> 00:13:07,200
и мы собираемся взять пример

381
00:13:07,200 --> 00:13:09,600
вывода на естественном языке, чтобы

382
00:13:09,600 --> 00:13:11,360
вспомнить задачу вывода на естественном языке,

383
00:13:11,360 --> 00:13:13,040
и это  через набор данных multi-nli,

384
00:13:13,040 --> 00:13:14,320
который мы просто извлекаем из нашего

385
00:13:14,320 --> 00:13:15,440
определения, у

386
00:13:15,440 --> 00:13:16,800
вас есть предпосылка, которую

387
00:13:16,800 --> 00:13:18,880
он повернул и увидел, что Джон спит в своей

388
00:13:18,880 --> 00:13:21,600
полушатнице, и у вас есть гипотеза, которую

389
00:13:21,600 --> 00:13:23,760
он видел, что Джон спал,

390
00:13:23,760 --> 00:13:26,399
а затем вы даете их модели,

391
00:13:26,399 --> 00:13:27,839
и это  это  модель, которая у нас была раньше

392
00:13:27,839 --> 00:13:29,920
, имеет хорошую точность, и эта

393
00:13:29,920 --> 00:13:33,120
модель должна сказать,

394
00:13:33,120 --> 00:13:35,360
подразумевается ли гипотеза

395
00:13:35,360 --> 00:13:38,160
предположением или противоречит ей, так что она

396
00:13:38,160 --> 00:13:40,320
может противоречить, возможно, если гипотеза состоит в том,

397
00:13:40,320 --> 00:13:42,560
что вы знаете, что Джон проснулся,

398
00:13:42,560 --> 00:13:44,160
например, или он видел  Джон не спал,

399
00:13:44,160 --> 00:13:46,480
возможно, это было бы нейтральным противоречием,

400
00:13:46,480 --> 00:13:48,399
если бы что-то и то и другое могло быть истинным

401
00:13:48,399 --> 00:13:50,399
одновременно, так сказать, а затем

402
00:13:50,399 --> 00:13:51,839
следствием в этом случае, вы знаете,

403
00:13:51,839 --> 00:13:53,440
кажется, что они говорят, что вы знаете,

404
00:13:53,440 --> 00:13:55,760
что посылка подразумевает гипотезу

405
00:13:55,760 --> 00:13:57,279
и так  эм, вы знаете,

406
00:13:57,279 --> 00:13:59,040
вы бы сказали, что, вероятно, это даст

407
00:13:59,040 --> 00:14:00,560
правильный ответ, так как

408
00:14:00,560 --> 00:14:02,480
точность модели составляет 95

409
00:14:02,480 --> 00:14:05,600
95 случаев, когда она получает правильный ответ

410
00:14:05,600 --> 00:14:07,920
эм, и мы собираемся углубиться в

411
00:14:07,920 --> 00:14:09,519
это, а

412
00:14:09,519 --> 00:14:12,160
что, если модель не  делать то, что, по нашему

413
00:14:12,160 --> 00:14:14,480
мнению, мы хотим, чтобы он

414
00:14:14,480 --> 00:14:16,560
выполнял логический вывод на естественном языке,

415
00:14:16,560 --> 00:14:19,040
поэтому в таком наборе данных, как multi-nli,

416
00:14:19,040 --> 00:14:20,800
авторы, собравшие набор данных, будут

417
00:14:20,800 --> 00:14:21,680


418
00:14:21,680 --> 00:14:24,160
просить людей выполнить задачу, и вы

419
00:14:24,160 --> 00:14:26,240
знаете, что получили точность, которая  достижения людей

420
00:14:26,240 --> 00:14:28,720
и модели в настоящее время

421
00:14:28,720 --> 00:14:30,720
достигают точности, сравнимой с теми,

422
00:14:30,720 --> 00:14:33,839
которые достигают люди,

423
00:14:33,839 --> 00:14:36,480
поначалу это звучит великолепно,

424
00:14:36,480 --> 00:14:37,199
но,

425
00:14:37,199 --> 00:14:38,959
как мы увидим, это не то же самое, что на

426
00:14:38,959 --> 00:14:42,320
самом деле выполнять задачу в более

427
00:14:42,320 --> 00:14:45,120
широком смысле правильным образом,

428
00:14:45,120 --> 00:14:46,399
так что, если модели  не делая

429
00:14:46,399 --> 00:14:49,120
что-то умное эффективно,

430
00:14:49,120 --> 00:14:52,560
мы собираемся использовать диагностический тестовый

431
00:14:52,560 --> 00:14:54,639
набор тщательно построенных примеров, которые

432
00:14:54,639 --> 00:14:56,160
кажутся вещами, которые модель должна

433
00:14:56,160 --> 00:14:57,440
уметь делать

434
00:14:57,440 --> 00:15:01,199
для проверки определенного навыка или способности,

435
00:15:01,199 --> 00:15:03,600
в этом случае мы будем использовать Ханса, так что Ханс -

436
00:15:03,600 --> 00:15:05,199
это  эвристический анализ для анализа

437
00:15:05,199 --> 00:15:06,240


438
00:15:06,240 --> 00:15:08,160
набора данных систем, и

439
00:15:08,160 --> 00:15:10,160
он предназначен для того, чтобы взять системы, которые делают

440
00:15:10,160 --> 00:15:12,399
логический вывод на естественном языке, и проверить

441
00:15:12,399 --> 00:15:13,920
, используют ли они какую-то простую

442
00:15:13,920 --> 00:15:15,920
синтаксическую эвристику,

443
00:15:15,920 --> 00:15:17,360
что у нас будет в каждом из этих случаев,

444
00:15:17,360 --> 00:15:19,920
у нас будет некоторая эвристика, о которой

445
00:15:19,920 --> 00:15:21,120
мы поговорим  определение, мы

446
00:15:21,120 --> 00:15:22,800
получим пример, поэтому первое, что нужно сделать, это

447
00:15:22,800 --> 00:15:25,920
лексическое перекрытие,

448
00:15:25,920 --> 00:15:28,720
чтобы модель могла сделать то же самое, когда она

449
00:15:28,720 --> 00:15:30,240
предполагает, что предпосылка влечет за собой все

450
00:15:30,240 --> 00:15:32,000
гипотезы, построенные из слов в t  он

451
00:15:32,000 --> 00:15:35,759
предположил, что в этом примере у вас есть

452
00:15:35,759 --> 00:15:38,560
предположение, что врачу заплатил

453
00:15:38,560 --> 00:15:40,639
актер,

454
00:15:40,639 --> 00:15:42,720
а затем гипотеза заключается в том, что врач

455
00:15:42,720 --> 00:15:44,399
заплатил актеру, и вы заметите, что

456
00:15:44,399 --> 00:15:47,040
здесь жирным шрифтом выделено согласие врача, а затем

457
00:15:47,040 --> 00:15:49,519
оплата, а затем актер

458
00:15:49,519 --> 00:15:51,680
прав и  поэтому, если вы используете

459
00:15:51,680 --> 00:15:53,360
эту эвристику, вы подумаете, что

460
00:15:53,360 --> 00:15:54,959
врачу заплатил актер, подразумевает, что

461
00:15:54,959 --> 00:15:56,800
доктор заплатил актеру, что,

462
00:15:56,800 --> 00:15:58,480
конечно, не подразумевает этого,

463
00:15:58,480 --> 00:16:00,720
и поэтому вы знаете, что можете ожидать от модели, которую

464
00:16:00,720 --> 00:16:02,000
вы хотите, чтобы модель могла это сделать

465
00:16:02,000 --> 00:16:03,440
это несколько просто,

466
00:16:03,440 --> 00:16:04,880
но если он использует эту эвристику, то

467
00:16:04,880 --> 00:16:07,759
этот пример не будет правильным, а

468
00:16:07,759 --> 00:16:11,279
затем - подпоследовательность, эвристика, поэтому

469
00:16:11,279 --> 00:16:12,560
здесь,

470
00:16:12,560 --> 00:16:14,399
в предположении, если модель предполагает,

471
00:16:14,399 --> 00:16:15,759
что посылка влечет за собой все ее

472
00:16:15,759 --> 00:16:17,839
смежные подпоследовательности, она

473
00:16:17,839 --> 00:16:20,320
также ошибется  Итак, в этом

474
00:16:20,320 --> 00:16:23,040
примере врач рядом с актером танцевал

475
00:16:23,040 --> 00:16:25,120
, это предпосылка, гипотеза, что

476
00:16:25,120 --> 00:16:27,199
актер танцевал сейчас, это простая

477
00:16:27,199 --> 00:16:29,600
синтаксическая вещь, которую доктор

478
00:16:29,600 --> 00:16:31,519
танцует рядом с актером, это

479
00:16:31,519 --> 00:16:33,680
предложная фраза,

480
00:16:33,680 --> 00:16:35,519
и поэтому модель  как бы использует эту

481
00:16:35,519 --> 00:16:37,199
эвристику, о, посмотрите, танец актера, который

482
00:16:37,199 --> 00:16:39,600
влечет за собой потрясающую подпоследовательность, тогда

483
00:16:39,600 --> 00:16:42,160
он тоже ошибается, а

484
00:16:42,160 --> 00:16:43,759


485
00:16:43,759 --> 00:16:45,120
вот еще один, который очень похож на

486
00:16:45,120 --> 00:16:48,720
подпоследовательность, но

487
00:16:48,720 --> 00:16:50,000
если модель думает, что посылка

488
00:16:50,000 --> 00:16:51,360
влечет за собой все

489
00:16:51,360 --> 00:16:53,199
полные поддеревья, так что это похоже на своего

490
00:16:53,199 --> 00:16:56,320
рода полностью сформированные фразы, так что художник

491
00:16:56,320 --> 00:16:59,440
спал здесь, это полностью сформированное

492
00:16:59,440 --> 00:17:01,199
вроде поддерева, если художник спал,

493
00:17:01,199 --> 00:17:03,759
актер побежал, а затем это предпосылка

494
00:17:03,759 --> 00:17:06,000
, влечет ли это гипотеза, что актер

495
00:17:06,000 --> 00:17:07,199
спал

496
00:17:07,199 --> 00:17:08,000
э-

497
00:17:08,000 --> 00:17:09,119


498
00:17:09,119 --> 00:17:11,199
э, извините  художник спал, что не

499
00:17:11,199 --> 00:17:12,400
влечет за собой этого, потому что это

500
00:17:12,400 --> 00:17:14,319
условно

501
00:17:14,319 --> 00:17:16,079
хорошо, я только остановлюсь здесь, чтобы

502
00:17:16,079 --> 00:17:17,599
задать несколько вопросов, прежде чем я

503
00:17:17,599 --> 00:17:20,319
перейду к тому, чтобы посмотреть, как эти модели делают

504
00:17:20,319 --> 00:17:23,679
кого-то неясным в отношении

505
00:17:23,679 --> 00:17:25,919
того, как проводится такая оценка

506
00:17:25,919 --> 00:17:28,919


507
00:17:33,200 --> 00:17:35,760
нету ладно

508
00:17:37,360 --> 00:17:39,600
круто ладно

509
00:17:39,600 --> 00:17:41,200
ладно  гм,

510
00:17:41,200 --> 00:17:43,120
так как модели работают, это своего

511
00:17:43,120 --> 00:17:46,480
рода вопрос часа, что мы будем

512
00:17:46,480 --> 00:17:48,160
делать, э-э,

513
00:17:48,160 --> 00:17:49,200
вы знаете, мы рассмотрим эти результаты

514
00:17:49,200 --> 00:17:50,880
из той же статьи, которая действительно

515
00:17:50,880 --> 00:17:53,280
выпустила набор данных, поэтому они взяли для  У вас

516
00:17:53,280 --> 00:17:56,240
сильные мультианализирующие модели

517
00:17:56,240 --> 00:17:57,760
со следующей точностью, так что

518
00:17:57,760 --> 00:18:00,000
здесь точность составляет что-то между 60,

519
00:18:00,000 --> 00:18:01,760
а вы знаете, что 80, что-то, что здесь 80 процентов,

520
00:18:01,760 --> 00:18:04,559
лучше всего работает хорошо

521
00:18:04,559 --> 00:18:06,000
и гм

522
00:18:06,000 --> 00:18:08,160
в области прямо в той первой

523
00:18:08,160 --> 00:18:10,559
настройке, о которой мы говорили.

524
00:18:10,559 --> 00:18:13,679
получить эту разумную точность,

525
00:18:13,679 --> 00:18:14,960
и

526
00:18:14,960 --> 00:18:16,480
это вроде того, что мы говорили раньше

527
00:18:16,480 --> 00:18:19,679
о том, что он выглядит довольно хорошо,

528
00:18:19,679 --> 00:18:23,440
и когда мы оцениваем на hans

529
00:18:23,440 --> 00:18:25,600
в этой настройке здесь,

530
00:18:25,600 --> 00:18:28,240
у нас есть примеры, когда эвристика, о которой мы

531
00:18:28,240 --> 00:18:29,440
говорили,

532
00:18:29,440 --> 00:18:31,360
действительно работает, поэтому, если модель

533
00:18:31,360 --> 00:18:33,840
использует эвристику, она будет  сделайте это правильно,

534
00:18:33,840 --> 00:18:35,200
и он получит

535
00:18:35,200 --> 00:18:38,400
очень высокую точность, а затем,

536
00:18:38,400 --> 00:18:40,559
если мы оценим модель в настройках,

537
00:18:40,559 --> 00:18:42,160
где, если она использует эвристику, она

538
00:18:42,160 --> 00:18:44,080
ошибается в примерах,

539
00:18:44,080 --> 00:18:44,960


540
00:18:44,960 --> 00:18:47,280
вы знаете, может быть, Берт работает как эпсилон

541
00:18:47,280 --> 00:18:49,120
лучше, чем некоторые другие вещи здесь,

542
00:18:49,120 --> 00:18:51,760
но это э-э, это  это совсем

543
00:18:51,760 --> 00:18:54,559
другая история, хорошо, и вы видели те

544
00:18:54,559 --> 00:18:56,720
примеры, которые не являются

545
00:18:56,720 --> 00:18:59,679
сложными в нашем собственном

546
00:18:59,679 --> 00:19:03,360
представлении о сложности,

547
00:19:03,360 --> 00:19:05,360
и поэтому это как бы

548
00:19:05,360 --> 00:19:08,240
кажется очевидным.  неисправность системы

549
00:19:08,240 --> 00:19:10,559
теперь вы можете сказать, что хорошо, может быть,

550
00:19:10,559 --> 00:19:13,039
в обучающих данных не

551
00:19:13,039 --> 00:19:14,720
было никаких подобных явлений,

552
00:19:14,720 --> 00:19:16,960
поэтому модель не могла научиться, эээ, не

553
00:19:16,960 --> 00:19:18,559
делать этого, и это своего рода

554
00:19:18,559 --> 00:19:20,640
разумный аргумент  за исключением того, что вы знаете, что

555
00:19:20,640 --> 00:19:22,640
Bert предварительно обучен на кучу

556
00:19:22,640 --> 00:19:24,720
языковых текстов, поэтому вы можете надеяться,

557
00:19:24,720 --> 00:19:26,080
что вы можете надеяться, что это будет

558
00:19:26,080 --> 00:19:28,320
лучше,

559
00:19:28,480 --> 00:19:29,360


560
00:19:29,360 --> 00:19:36,000
так что мы увидели, что пример um-моделей

561
00:19:36,240 --> 00:19:38,720
хорошо работает на примерах,

562
00:19:38,720 --> 00:19:40,320
подобных тем, которые были  тренировались, а

563
00:19:40,320 --> 00:19:42,400
затем совсем не очень хорошо работали на

564
00:19:42,400 --> 00:19:45,440
примерах, которые кажутся разумными, но которые,

565
00:19:45,440 --> 00:19:46,400


566
00:19:46,400 --> 00:19:47,280
в

567
00:19:47,280 --> 00:19:49,919
некотором роде, немного сложны.

568
00:19:49,919 --> 00:19:52,640


569
00:19:52,640 --> 00:19:54,080


570
00:19:54,080 --> 00:19:55,679
в другом направлении, поэтому мы

571
00:19:55,679 --> 00:19:57,679
собираемся выяснить, что означает

572
00:19:57,679 --> 00:19:59,919
попытка понять лингвистические

573
00:19:59,919 --> 00:20:01,919
свойства наших моделей. Делает это так, чтобы

574
00:20:01,919 --> 00:20:03,760
вопрос синтаксической эвристики был одним из вопросов для

575
00:20:03,760 --> 00:20:05,600
логического вывода на естественном языке, но можем ли мы

576
00:20:05,600 --> 00:20:08,559
как бы проверить, как модели реагируют на

577
00:20:08,559 --> 00:20:10,640
Мы считаем, что определенные вещи являются своего рода правильными

578
00:20:10,640 --> 00:20:11,840
или неправильными в

579
00:20:11,840 --> 00:20:14,159
качестве языковых моделей,

580
00:20:14,159 --> 00:20:16,000
и первый способ, которым мы это сделаем, -

581
00:20:16,000 --> 00:20:17,919
это спросить, как мы думаем о

582
00:20:17,919 --> 00:20:20,720
том, что люди считают хорошим

583
00:20:20,720 --> 00:20:22,799
языком, как мы оцениваем

584
00:20:22,799 --> 00:20:24,080
их

585
00:20:24,080 --> 00:20:26,559
предпочтения  о языке

586
00:20:26,559 --> 00:20:29,039
и один ответ - это минимальные пары, а

587
00:20:29,039 --> 00:20:30,640
идея минимальной пары состоит в том, что у вас

588
00:20:30,640 --> 00:20:33,679
есть одно предложение, которое хорошо звучит

589
00:20:33,679 --> 00:20:35,919
для говорящего, поэтому это предложение -

590
00:20:35,919 --> 00:20:39,440
шеф-повар, который приготовил пиццу, здесь

591
00:20:39,440 --> 00:20:41,360
это называется, это приемлемое предложение,

592
00:20:41,360 --> 00:20:44,640
по крайней мере, для  я эм а затем с небольшим

593
00:20:44,640 --> 00:20:47,520
изменением минимальное изменение эээ

594
00:20:47,520 --> 00:20:49,520
предложение больше не устраивает

595
00:20:49,520 --> 00:20:51,600
говорящего, поэтому шеф-повар, который готовил пиццу

596
00:20:51,600 --> 00:20:53,280
, здесь,

597
00:20:53,280 --> 00:20:54,880
и эм,

598
00:20:54,880 --> 00:20:56,559


599
00:20:56,559 --> 00:20:58,320
это должно быть

600
00:20:58,320 --> 00:21:01,120
глагол

601
00:21:01,120 --> 00:21:03,039
в настоящем времени в английском языке, глаголы в настоящем времени согласны по

602
00:21:03,039 --> 00:21:05,120
количеству с  их предмет, э-э, когда

603
00:21:05,120 --> 00:21:08,640
они от третьего лица, так что шеф-повар пиццы хорошо,

604
00:21:08,640 --> 00:21:10,480


605
00:21:10,480 --> 00:21:12,000
и э-

606
00:21:12,000 --> 00:21:14,400
э, это довольно обычная

607
00:21:14,400 --> 00:21:16,000
вещь, которая не нравится большинству людей, это

608
00:21:16,000 --> 00:21:18,480
неверно спряженный глагол,

609
00:21:18,480 --> 00:21:20,960
и поэтому синтаксис здесь выглядит так, как будто у

610
00:21:20,960 --> 00:21:23,120
вас есть повар  сделал пиццу,

611
00:21:23,120 --> 00:21:25,919
а затем эта дуга соглашения и

612
00:21:25,919 --> 00:21:29,280
число требует, что слово здесь

613
00:21:29,280 --> 00:21:32,240
должно быть в единственном числе, а не во множественном числе,

614
00:21:32,240 --> 00:21:34,000
несмотря на то, что есть эта ver

615
00:21:34,000 --> 00:21:36,559
this существительное pizzas, которое во множественном числе

616
00:21:36,559 --> 00:21:39,280
ближе, линейно возвращается к

617
00:21:39,280 --> 00:21:41,280
разбору зависимостей мы  назад, хорошо,

618
00:21:41,280 --> 00:21:43,840
а как это выглядит в

619
00:21:43,840 --> 00:21:46,559
древовидной структуре? Хорошо, вы знаете,

620
00:21:46,559 --> 00:21:50,400
шеф-повар, и они прикреплены к дереву, а

621
00:21:50,400 --> 00:21:51,520


622
00:21:51,520 --> 00:21:54,080
вы знаете, что тема шеф-повара - это

623
00:21:54,080 --> 00:21:56,799
пицца, здесь, в этом поддереве,

624
00:21:56,799 --> 00:21:59,200
и так что субъект-глагол  отношения

625
00:21:59,200 --> 00:22:02,480
имеют такого рода согласование,

626
00:22:02,480 --> 00:22:04,720
так что это довольно простое и

627
00:22:04,720 --> 00:22:06,559
интересное свойство языка, которое

628
00:22:06,559 --> 00:22:09,120
также отражает синтаксическую

629
00:22:09,120 --> 00:22:11,200
иерархическую структуру языка, поэтому

630
00:22:11,200 --> 00:22:12,320
мы тренировали эти языковые

631
00:22:12,320 --> 00:22:14,000
модели, выбирая из них, видя, что

632
00:22:14,000 --> 00:22:16,000
они становятся интересными  вещи, и они,

633
00:22:16,000 --> 00:22:17,840
как правило, создают синтаксический

634
00:22:17,840 --> 00:22:19,200
контент,

635
00:22:19,200 --> 00:22:21,919
но действительно ли он понимает или ведет

636
00:22:21,919 --> 00:22:24,400
себя так, как будто понимает эту идею

637
00:22:24,400 --> 00:22:26,640
согласия в более широком смысле, и делает ли это своего

638
00:22:26,640 --> 00:22:28,640
рода  синтаксис правильный, чтобы он

639
00:22:28,640 --> 00:22:30,799
соответствовал подлежащим и

640
00:22:30,799 --> 00:22:33,840
глаголам, но языковые модели не могут точно сказать нам

641
00:22:33,840 --> 00:22:35,440
, считают ли они

642
00:22:35,440 --> 00:22:37,360
предложение хорошим или плохим, они просто говорят

643
00:22:37,360 --> 00:22:40,640
нам вероятность предложения э-э, э-

644
00:22:40,640 --> 00:22:42,640
э, до того, как мы приняли приемлемое и

645
00:22:42,640 --> 00:22:44,240
неприемлемо, это то, что мы получаем от

646
00:22:44,240 --> 00:22:47,120
людей, а аналог языковых моделей

647
00:22:47,120 --> 00:22:48,720
просто присваивает более высокую

648
00:22:48,720 --> 00:22:50,960
вероятность приемлемому предложению

649
00:22:50,960 --> 00:22:52,480
в минимальной паре, так что у вас

650
00:22:52,480 --> 00:22:55,360
есть вероятность в соответствии с моделью,

651
00:22:55,360 --> 00:22:57,360
что шеф-повар, который сделал пиццу,

652
00:22:57,360 --> 00:22:59,919
здесь и  тогда у вас есть вероятность в

653
00:22:59,919 --> 00:23:01,440
соответствии с моделью горничных, которые

654
00:23:01,440 --> 00:23:04,000
готовили пиццу, и вы хотите, чтобы

655
00:23:04,000 --> 00:23:07,840
эта вероятность здесь была выше,

656
00:23:07,840 --> 00:23:09,919
и если это так, то это вроде как

657
00:23:09,919 --> 00:23:11,919
простой способ проверить, правильно ли и просто ли модель

658
00:23:11,919 --> 00:23:12,799
вроде

659
00:23:12,799 --> 00:23:15,360
дала все правильно.

660
00:23:15,360 --> 00:23:16,559


661
00:23:16,559 --> 00:23:18,480
как и в случае с hans,

662
00:23:18,480 --> 00:23:20,320
мы можем разработать тестовый набор с очень

663
00:23:20,320 --> 00:23:22,640
тщательно подобранными свойствами, так что

664
00:23:22,640 --> 00:23:25,679
большинство предложений в английском языке не имеют

665
00:23:25,679 --> 00:23:28,000
ужасно сложной

666
00:23:28,000 --> 00:23:30,000
структуры согласования субъект-глагол с

667
00:23:30,000 --> 00:23:32,240
большим количеством слов в  середина, как пицца,

668
00:23:32,240 --> 00:23:34,080
которая усложнит задачу, поэтому,

669
00:23:34,080 --> 00:23:38,480
если я скажу, что вы знаете, что собака бежит, как

670
00:23:38,480 --> 00:23:40,640
бы никак не ошибиться, потому

671
00:23:40,640 --> 00:23:42,000
что

672
00:23:42,000 --> 00:23:45,200
нет, этот индекс очень простой, эм, поэтому мы

673
00:23:45,200 --> 00:23:46,880
можем создавать

674
00:23:46,880 --> 00:23:49,840
или искать предложения, в которых есть

675
00:23:49,840 --> 00:23:52,320
это те вещи, которые в предложении называются аттракторами,

676
00:23:52,320 --> 00:23:54,480
поэтому пицца - это

677
00:23:54,480 --> 00:23:57,120
аттрактор, потому что модель может быть

678
00:23:57,120 --> 00:23:59,760
привлечена к множеству здесь и

679
00:23:59,760 --> 00:24:02,799
получить неправильное спряжение,

680
00:24:02,799 --> 00:24:04,240
поэтому это наш вопрос, могут ли языковые

681
00:24:04,240 --> 00:24:06,480
модели как бы в общем случае обрабатывать

682
00:24:06,480 --> 00:24:09,200
эти примеры с аттракторами, чтобы мы могли

683
00:24:09,200 --> 00:24:11,440
брать примеры  с нулевыми аттракторами посмотрите,

684
00:24:11,440 --> 00:24:13,039
правильно ли дает модель минимальную оценку пар,

685
00:24:13,039 --> 00:24:15,360
мы можем взять примеры

686
00:24:15,360 --> 00:24:17,039
с одним аттрактором,

687
00:24:17,039 --> 00:24:19,279
двумя аттракторами, вы можете увидеть, как люди

688
00:24:19,279 --> 00:24:20,640
все еще разумно понимают эти

689
00:24:20,640 --> 00:24:22,320
предложения, правильно повар, который

690
00:24:22,320 --> 00:24:24,720
готовил пиццу и готовил ингредиенты, это все

691
00:24:24,720 --> 00:24:26,320
еще шеф-повар, который  есть,

692
00:24:26,320 --> 00:24:28,480
и тогда вы знаете, что он

693
00:24:28,480 --> 00:24:30,400
становится все реже, очевидно, но у вас может

694
00:24:30,400 --> 00:24:32,480
быть все больше и больше аттракторов

695
00:24:32,480 --> 00:24:34,080
, поэтому теперь мы создали этот набор тестов

696
00:24:34,080 --> 00:24:35,840
это предназначено для оценки этого очень

697
00:24:35,840 --> 00:24:38,320
специфического лингвистического феномена,

698
00:24:38,320 --> 00:24:43,039
так что в этой статье мы

699
00:24:43,039 --> 00:24:44,559
соглашаемся, что все обучили языковую модель lcm на

700
00:24:44,559 --> 00:24:46,400
подмножестве википедии

701
00:24:46,400 --> 00:24:49,600
еще в 2018 году, и они оценивают ее как

702
00:24:49,600 --> 00:24:51,360
бы в этих сегментах, которые

703
00:24:51,360 --> 00:24:53,039
указаны в статье

704
00:24:53,039 --> 00:24:54,960
of

705
00:24:54,960 --> 00:24:56,559
under введенный предметный глагол согласуется

706
00:24:56,559 --> 00:24:57,679
с uh

707
00:24:57,679 --> 00:25:02,240
в поле nlp, по крайней мере, недавно,

708
00:25:02,240 --> 00:25:04,640
и они оценивают его в сегментах на

709
00:25:04,640 --> 00:25:07,120
основе количества аттракторов, и поэтому

710
00:25:07,120 --> 00:25:08,799
в этой таблице здесь вы

711
00:25:08,799 --> 00:25:09,600
увидите,

712
00:25:09,600 --> 00:25:10,320


713
00:25:10,320 --> 00:25:12,080
что числа представляют собой своего рода процент от

714
00:25:12,080 --> 00:25:14,159
раз, когда вам присваивается более высокая

715
00:25:14,159 --> 00:25:17,440
вероятность правильного

716
00:25:17,440 --> 00:25:19,520
предложения в минимальной паре,

717
00:25:19,520 --> 00:25:20,880
поэтому, если вы просто выполняете случайный или

718
00:25:20,880 --> 00:25:23,200
основной класс, вы получаете эти ошибки ой,

719
00:25:23,200 --> 00:25:24,799
извините, это процент раз, когда

720
00:25:24,799 --> 00:25:26,240
вы ошиблись,

721
00:25:26,240 --> 00:25:28,960
извините за это, поэтому чем ниже, тем лучше

722
00:25:28,960 --> 00:25:31,679
гм, и поэтому без аттракторов вы получаете

723
00:25:31,679 --> 00:25:34,400
очень низкий уровень ошибок, так что это 1,3

724
00:25:34,400 --> 00:25:37,919
коэффициент ошибок с 350-мерным lstm

725
00:25:37,919 --> 00:25:38,880
ммм,

726
00:25:38,880 --> 00:25:40,640
а вы знаете, с одним

727
00:25:40,640 --> 00:25:43,039
аттрактором ваш коэффициент ошибок выше, но

728
00:25:43,039 --> 00:25:45,520
ac  в действительности люди начинают получать ошибки с

729
00:25:45,520 --> 00:25:47,600
большим количеством аттракторов, так что нулевые

730
00:25:47,600 --> 00:25:49,919
аттракторы - это просто.

731
00:25:49,919 --> 00:25:51,919


732
00:25:51,919 --> 00:25:53,600


733
00:25:53,600 --> 00:25:56,480


734
00:25:56,480 --> 00:25:58,320


735
00:25:58,320 --> 00:26:00,960
четыре аттрактора, которые

736
00:26:00,960 --> 00:26:02,320
пытаются придумать пример в вашей голове,

737
00:26:02,320 --> 00:26:03,520
например, повар

738
00:26:03,520 --> 00:26:06,400
приготовил пиццу и вынул мусор, который, как

739
00:26:06,400 --> 00:26:07,760
вы знаете, должен быть таким длинным

740
00:26:07,760 --> 00:26:09,760
предложением, и скорость передачи определенно

741
00:26:09,760 --> 00:26:12,640
выше, поэтому становится сложнее,

742
00:26:12,640 --> 00:26:15,200
но все равно  относительно низко,

743
00:26:15,200 --> 00:26:16,799
и поэтому даже на этих очень сложных примерах

744
00:26:16,799 --> 00:26:18,400
модели на самом деле выполняют

745
00:26:18,400 --> 00:26:21,200
согласование чисел подлежащих глаголов относительно хорошо.

746
00:26:21,200 --> 00:26:22,840


747
00:26:22,840 --> 00:26:24,880


748
00:26:24,880 --> 00:26:27,919


749
00:26:27,919 --> 00:26:29,679


750
00:26:29,679 --> 00:26:31,520


751
00:26:31,520 --> 00:26:32,880
думаю, на самом деле

752
00:26:32,880 --> 00:26:34,799
ошибки довольно интересны,

753
00:26:34,799 --> 00:26:36,880
поэтому вот предложение: корабль,

754
00:26:36,880 --> 00:26:38,720
который управляет игроком,

755
00:26:38,720 --> 00:26:41,200
имеет очень высокую скорость,

756
00:26:41,200 --> 00:26:43,200
теперь эта модель думала, что это было менее

757
00:26:43,200 --> 00:26:46,159
вероятно, чем sh  ip, что

758
00:26:46,159 --> 00:26:50,640
приводы плеера имеют очень высокую скорость,

759
00:26:50,880 --> 00:26:51,679
моя

760
00:26:51,679 --> 00:26:55,200
гипотеза права заключается в том, что он как бы неправильно

761
00:26:55,200 --> 00:26:58,559
анализирует диски как существительное во множественном числе,

762
00:26:58,559 --> 00:27:00,559
например, это своего рода

763
00:27:00,559 --> 00:27:01,840
сложная конструкция, я думаю,

764
00:27:01,840 --> 00:27:04,320
это довольно

765
00:27:04,320 --> 00:27:06,559


766
00:27:06,559 --> 00:27:09,200
интересно  ввод также довольно длинный.

767
00:27:09,200 --> 00:27:12,640


768
00:27:12,640 --> 00:27:15,360


769
00:27:15,360 --> 00:27:17,600


770
00:27:17,600 --> 00:27:21,360


771
00:27:21,360 --> 00:27:22,720


772
00:27:22,720 --> 00:27:24,640


773
00:27:24,640 --> 00:27:27,200
это относится к

774
00:27:27,200 --> 00:27:29,679
такого рода

775
00:27:29,679 --> 00:27:31,760
пяти абзацам как к пяти

776
00:27:31,760 --> 00:27:33,600
фактическим абзацам, а не

777
00:27:33,600 --> 00:27:36,159
к одной единице длины,

778
00:27:36,159 --> 00:27:37,360
описывающей ведущую роль,

779
00:27:37,360 --> 00:27:40,080
увлекательно,

780
00:27:40,480 --> 00:27:42,399
хорошо,

781
00:27:42,399 --> 00:27:44,720


782
00:27:45,120 --> 00:27:49,080
может быть, снова вопросы,

783
00:27:52,320 --> 00:27:53,360


784
00:27:53,360 --> 00:27:55,919
так что, я думаю, есть пара,

785
00:27:55,919 --> 00:27:59,039
можем ли мы провести аналогичный эвристический анализ

786
00:27:59,039 --> 00:28:01,120
для других задач, таких как  как классификация qa

787
00:28:01,120 --> 00:28:03,840


788
00:28:05,600 --> 00:28:07,520
да эм

789
00:28:07,520 --> 00:28:09,840
так да я думаю, что легче сделать

790
00:28:09,840 --> 00:28:11,279
такой анализ,

791
00:28:11,279 --> 00:28:12,399


792
00:28:12,399 --> 00:28:15,760
как анализ стиля Ханса, с эм

793
00:28:15,760 --> 00:28:18,159
с ответом на вопрос эм

794
00:28:18,159 --> 00:28:21,120
и другие виды задач, потому что

795
00:28:21,120 --> 00:28:23,919
вы можете построить примеры, которые

796
00:28:23,919 --> 00:28:25,440
точно так же, как

797
00:28:25,440 --> 00:28:26,320


798
00:28:26,320 --> 00:28:28,840
вы знаете, имеют эти

799
00:28:28,840 --> 00:28:30,270
эвристики мм

800
00:28:30,270 --> 00:28:32,000
[Музыка]

801
00:28:32,000 --> 00:28:34,320
а затем ответ зависят

802
00:28:34,320 --> 00:28:36,880
от синтаксиса или нет, вы знаете, что фактическая

803
00:28:36,880 --> 00:28:39,360
вероятность одного

804
00:28:39,360 --> 00:28:40,640
предложения выше, чем другого,

805
00:28:40,640 --> 00:28:41,919
конечно  это своего рода

806
00:28:41,919 --> 00:28:44,640
вещь, зависящая от языковой модели, но идея о том, что вы

807
00:28:44,640 --> 00:28:46,320
можете вроде как

808
00:28:46,320 --> 00:28:49,279
разработать своего рода индивидуальные наборы тестов для

809
00:28:49,279 --> 00:28:52,159
различных задач,

810
00:28:52,159 --> 00:28:54,480
я думаю, это очень и очень общий характер, и

811
00:28:54,480 --> 00:28:56,559
я думаю, что на самом деле это

812
00:28:56,559 --> 00:28:59,360
довольно интересно,

813
00:28:59,360 --> 00:29:00,880
да, поэтому

814
00:29:00,880 --> 00:29:02,720
я выиграл  я продолжу, но я думаю,

815
00:29:02,720 --> 00:29:04,880
что ответ - просто да,

816
00:29:04,880 --> 00:29:06,480
так что есть еще один,

817
00:29:06,480 --> 00:29:08,799
ммм, как вы знаете, где найти эти

818
00:29:08,799 --> 00:29:10,799
случаи сбоя, может быть, сейчас подходящее

819
00:29:10,799 --> 00:29:14,240
время для рекламы классов лингвистики,

820
00:29:14,240 --> 00:29:15,919
извините,

821
00:29:15,919 --> 00:29:18,080
вы все еще очень тихо здесь

822
00:29:18,080 --> 00:29:19,600
как вы находите, что

823
00:29:19,600 --> 00:29:21,279
откуда вы знаете, где искать эти

824
00:29:21,279 --> 00:29:23,120
случаи отказов

825
00:29:23,120 --> 00:29:24,880
о, интересно, да, как мы узнаем, где

826
00:29:24,880 --> 00:29:26,880
искать случаи отказов

827
00:29:26,880 --> 00:29:29,200
, это хороший вопрос я имею в виду, я думаю, я

828
00:29:29,200 --> 00:29:31,520
согласен с крисом, что на самом деле

829
00:29:31,520 --> 00:29:34,559
вы  знаю, что думать о том, что

830
00:29:34,559 --> 00:29:35,520


831
00:29:35,520 --> 00:29:38,080
интересно в языковых вещах, - это

832
00:29:38,080 --> 00:29:40,480
один из способов сделать это, я имею в виду те

833
00:29:40,480 --> 00:29:43,360
эвристики, которые мы видели

834
00:29:43,360 --> 00:29:46,559
в нашей языковой модели, извините в наших nli-

835
00:29:46,559 --> 00:29:49,200
моделях с hans,

836
00:29:49,200 --> 00:29:53,039
вы можете представить, что они,

837
00:29:53,360 --> 00:29:55,760
если бы модель была сортировкой  игнорировать факты

838
00:29:55,760 --> 00:29:57,760
о языке и как бы просто использовать

839
00:29:57,760 --> 00:29:59,600
этот грубый набор слов с

840
00:29:59,600 --> 00:30:02,880
некоторой дополнительной магией, тогда это будет хорошо,

841
00:30:02,880 --> 00:30:05,360
примерно так же плохо, как здесь, и

842
00:30:05,360 --> 00:30:08,720
такого рода идеи о том, что

843
00:30:08,720 --> 00:30:09,679
вы

844
00:30:09,679 --> 00:30:11,760
понимаете, что это утверждение, если

845
00:30:11,760 --> 00:30:13,440
художник проспал  актер не

846
00:30:13,440 --> 00:30:15,600
подразумевает, что художник спал, - это

847
00:30:15,600 --> 00:30:17,840
то, что, может быть, вы

848
00:30:17,840 --> 00:30:19,679
придумаете самостоятельно, но вы также потратите время

849
00:30:19,679 --> 00:30:22,640
на размышления и размышления над

850
00:30:22,640 --> 00:30:25,360
общими мыслями в э-э, вы знаете

851
00:30:25,360 --> 00:30:29,440
учебные программы по лингвистике как  ну так

852
00:30:31,440 --> 00:30:34,720
что-нибудь еще крис

853
00:30:34,840 --> 00:30:37,840
ум, так что там

854
00:30:37,840 --> 00:30:40,480
также хорошо, я думаю, кто-то также

855
00:30:40,480 --> 00:30:42,080
сказал, что я думаю, что это вроде

856
00:30:42,080 --> 00:30:45,200
примера промежуточных глаголов или промежуточного

857
00:30:45,200 --> 00:30:47,760
существительного, извините, но данные, так что

858
00:30:47,760 --> 00:30:49,600
набор данных, вероятно, я  Включает

859
00:30:49,600 --> 00:30:52,960
ошибки с более высокими аттракторами.

860
00:30:52,960 --> 00:30:55,440


861
00:30:55,440 --> 00:30:57,360


862
00:30:57,360 --> 00:30:59,760


863
00:30:59,760 --> 00:31:02,880


864
00:31:02,880 --> 00:31:05,679


865
00:31:05,679 --> 00:31:08,000


866
00:31:08,000 --> 00:31:10,080


867
00:31:10,080 --> 00:31:12,080
придумываю это, но

868
00:31:12,080 --> 00:31:13,600
я так думаю,

869
00:31:13,600 --> 00:31:14,880
но да, было бы интересно на

870
00:31:14,880 --> 00:31:16,640
самом деле пройти этот набор тестов и

871
00:31:16,640 --> 00:31:19,200
посмотреть,

872
00:31:19,200 --> 00:31:21,039
сколько ошибок делает действительно сильная

873
00:31:21,039 --> 00:31:23,440
модель, на самом деле из-за

874
00:31:23,440 --> 00:31:25,039
того, что наблюдаемая форма

875
00:31:25,039 --> 00:31:29,799
неверна, я был бы супер  любопытно,

876
00:31:33,519 --> 00:31:34,559
хорошо,

877
00:31:34,559 --> 00:31:36,000
следует ли мне двигаться дальше,

878
00:31:36,000 --> 00:31:36,799
да,

879
00:31:36,799 --> 00:31:39,799
отлично,

880
00:31:47,760 --> 00:31:48,720
хорошо,

881
00:31:48,720 --> 00:31:50,320


882
00:31:50,320 --> 00:31:53,440
так что, каково это, что мы чувствуем,

883
00:31:53,440 --> 00:31:55,519
когда строим такого

884
00:31:55,519 --> 00:31:58,080
рода небольшие тщательно продуманные наборы тестов

885
00:31:58,080 --> 00:32:00,880
для различных явлений, ну, это

886
00:32:00,880 --> 00:32:03,440
похоже на модульное тестирование

887
00:32:03,440 --> 00:32:07,440
и в  Фактически, идея такого рода была

888
00:32:09,120 --> 00:32:10,880
выдвинута на первый план, можно

889
00:32:10,880 --> 00:32:12,720
сказать, в

890
00:32:12,720 --> 00:32:14,720
модульных тестах nlp, но для этих нейронных

891
00:32:14,720 --> 00:32:18,080
сетей nlp и, в частности, статья,

892
00:32:18,080 --> 00:32:19,440
которую я сижу внизу,

893
00:32:19,440 --> 00:32:21,840
предполагает, что это  минимальная функция минимальный

894
00:32:21,840 --> 00:32:23,919
тест функциональности вам нужен небольшой

895
00:32:23,919 --> 00:32:26,320
набор тестов, нацеленный на конкретное поведение,

896
00:32:26,320 --> 00:32:28,320
которое должно звучать как некоторые из

897
00:32:28,320 --> 00:32:29,840
вещей, о которых мы уже

898
00:32:29,840 --> 00:32:32,159
говорили, но в этом случае

899
00:32:32,159 --> 00:32:34,559
мы собираемся получить еще более конкретную,

900
00:32:34,559 --> 00:32:37,039
так что вот  в одном тестовом примере у нас

901
00:32:37,039 --> 00:32:38,159


902
00:32:38,159 --> 00:32:40,080
будет ожидаемая метка, что на самом деле было

903
00:32:40,080 --> 00:32:42,399
предсказано, прошла ли модель этот

904
00:32:42,399 --> 00:32:43,600
модульный тест,

905
00:32:43,600 --> 00:32:45,600
и метки будут, это

906
00:32:45,600 --> 00:32:48,159
будет анализ настроений, поэтому

907
00:32:48,159 --> 00:32:50,159
отрицательная метка положительная метка или нейтральный

908
00:32:50,159 --> 00:32:52,080
или три варианта

909
00:32:52,080 --> 00:32:54,320
и модульный тест будет состоять

910
00:32:54,320 --> 00:32:56,880
просто из предложений, которые следуют этому

911
00:32:56,880 --> 00:33:00,320
шаблону, затем отрицание положительного

912
00:33:00,320 --> 00:33:02,559
глагола, а затем вещь,

913
00:33:02,559 --> 00:33:05,840
поэтому, если вы отрицаете положительный глагол,

914
00:33:05,840 --> 00:33:08,159
значит, что вы отрицательный глагол правильно, и

915
00:33:08,159 --> 00:33:09,760
вот пример, я не могу сказать, что я

916
00:33:09,760 --> 00:33:12,080
рекомендовать еду ожидаемая этикетка

917
00:33:12,080 --> 00:33:14,159
отрицательная ответ, который предоставила модель,

918
00:33:14,159 --> 00:33:15,360
и это я думаю, что

919
00:33:15,360 --> 00:33:16,799
коммерческая

920
00:33:16,799 --> 00:33:19,279
система анализа настроений была приостановлена,

921
00:33:19,279 --> 00:33:21,840
поэтому она предсказала положительный результат, а затем я

922
00:33:21,840 --> 00:33:24,799
не  Мне нравится полет, ожидаемый

923
00:33:24,799 --> 00:33:26,320
ярлык был отрицательным, а затем

924
00:33:26,320 --> 00:33:29,679
предсказанный ответ был нейтральным,

925
00:33:29,679 --> 00:33:31,200
и эта

926
00:33:31,200 --> 00:33:32,640
система анализа коммерческих

927
00:33:32,640 --> 00:33:34,799


928
00:33:34,799 --> 00:33:36,080
настроений хорошо

929
00:33:36,080 --> 00:33:38,880


930
00:33:38,880 --> 00:33:42,000
себя зарекомендовала.

931
00:33:42,000 --> 00:33:44,320
предоставить систему

932
00:33:44,320 --> 00:33:46,640
, у которой была эта структура для

933
00:33:46,640 --> 00:33:49,600
создания тестовых примеров для моделей nlp, два

934
00:33:49,600 --> 00:33:52,080
инженера-специалиста, работающие над этими продуктами,

935
00:33:52,080 --> 00:33:52,880
э

936
00:33:52,880 --> 00:33:55,440
-э, дайте им этот интерфейс, и они на

937
00:33:55,440 --> 00:33:56,240


938
00:33:56,240 --> 00:33:57,360
самом деле

939
00:33:57,360 --> 00:33:58,960
найдут ошибки, которые, как

940
00:33:58,960 --> 00:34:01,279
вы знаете, ошибки являются категориями с высоким уровнем

941
00:34:01,279 --> 00:34:03,039
ошибок, правильно находят ошибки в их  модели,

942
00:34:03,039 --> 00:34:04,960
которые они затем могли бы попытаться найти

943
00:34:04,960 --> 00:34:07,679
и исправить, и что это был своего рода

944
00:34:07,679 --> 00:34:09,520
эффективный способ попытаться найти вещи,

945
00:34:09,520 --> 00:34:11,839
которые были простыми и все же неправильными в

946
00:34:11,839 --> 00:34:13,440
том, что должно быть

947
00:34:13,440 --> 00:34:16,159
довольно сложными нейронными системами,

948
00:34:16,159 --> 00:34:18,399
так что мне это очень нравится, и

949
00:34:18,399 --> 00:34:20,560
это своего рода  хороший способ подумать более

950
00:34:20,560 --> 00:34:21,520
конкретно о том, какие

951
00:34:21,520 --> 00:34:24,560
возможности у нас в виде точных

952
00:34:24,560 --> 00:34:27,119
терминов наших моделей,

953
00:34:27,119 --> 00:34:29,280
и все вместе теперь вы видели

954
00:34:29,280 --> 00:34:31,359
проблемы с

955
00:34:31,359 --> 00:34:33,199
логическим выводом на естественном языке, которые

956
00:34:33,199 --> 00:34:34,639
вы видели, языковые модели на самом деле

957
00:34:34,639 --> 00:34:36,239
довольно хорошо

958
00:34:36,239 --> 00:34:38,719
справляются с задачей языкового моделирования, но затем вы видите, что

959
00:34:38,719 --> 00:34:40,879
вы только что видели пример коммерческой

960
00:34:40,879 --> 00:34:42,879
системы анализа настроений, которая вроде как должна

961
00:34:42,879 --> 00:34:46,399
работать лучше и не работает, и это происходит

962
00:34:46,399 --> 00:34:48,480
на самом деле, я думаю, широкий и

963
00:34:48,480 --> 00:34:51,839
важный вывод, который, э-э,

964
00:34:51,839 --> 00:34:53,280
если вы получите высокую точность на

965
00:34:53,280 --> 00:34:54,800
тестовом наборе в домене,

966
00:34:54,800 --> 00:34:58,320
вам не гарантируется высокая точность

967
00:34:58,320 --> 00:35:00,960
даже в том, что вы можете считать

968
00:35:00,960 --> 00:35:05,359
разумным вне оценки домена, и

969
00:35:05,359 --> 00:35:08,000
жизнь всегда вне домена

970
00:35:08,000 --> 00:35:09,119
и если вы создаете систему, которая

971
00:35:09,119 --> 00:35:10,079
будет

972
00:35:10,079 --> 00:35:11,839
предоставлена пользователям,

973
00:35:11,839 --> 00:35:13,359
она немедленно выходит из домена, по

974
00:35:13,359 --> 00:35:15,280
крайней мере потому, что она обучена тексту,

975
00:35:15,280 --> 00:35:16,960
который теперь старше, чем то,

976
00:35:16,960 --> 00:35:19,119
что сейчас говорят пользователи, так что это

977
00:35:19,119 --> 00:35:20,880
действительно очень важный вывод, что

978
00:35:20,880 --> 00:35:23,359
ваш вид  эталонной точности - это

979
00:35:23,359 --> 00:35:25,440
единое число, которое не гарантирует

980
00:35:25,440 --> 00:35:27,200
хорошую производительность по широкому кругу

981
00:35:27,200 --> 00:35:29,920
вопросов, и с точки зрения того, что делают наши нейронные

982
00:35:29,920 --> 00:35:32,320
сети, с одной стороны,

983
00:35:32,320 --> 00:35:34,320
Подумайте об этом, так это то, что модели, похоже,

984
00:35:34,320 --> 00:35:36,400
изучают набор данных, подходящий для

985
00:35:36,400 --> 00:35:37,839
мелкозернистой

986
00:35:37,839 --> 00:35:39,839
эвристики и статистики, которые

987
00:35:39,839 --> 00:35:40,880
помогают ему

988
00:35:40,880 --> 00:35:43,520
соответствовать этому одному набору данных, в отличие от

989
00:35:43,520 --> 00:35:45,440
изучения задач, чтобы люди могли выполнять

990
00:35:45,440 --> 00:35:47,119
логический вывод на естественном языке, если вы

991
00:35:47,119 --> 00:35:49,920
им дадите  примеры из любого набора данных, который

992
00:35:49,920 --> 00:35:51,119
вы знаете, как только вы скажете им, как

993
00:35:51,119 --> 00:35:53,599
выполнять задачу, они в целом будут

994
00:35:53,599 --> 00:35:55,119
сильны в этом,

995
00:35:55,119 --> 00:35:57,520
но вы берете свою

996
00:35:57,520 --> 00:36:00,240
модель mli и тестируете ее на hans, и она дает

997
00:36:00,240 --> 00:36:02,400
вам знать все, что было ниже случайной

998
00:36:02,400 --> 00:36:03,839
точности  это не то,

999
00:36:03,839 --> 00:36:05,839
что вы хотите видеть, поэтому он определенно

1000
00:36:05,839 --> 00:36:07,440
хорошо изучает набор данных, потому что

1001
00:36:07,440 --> 00:36:10,560
точность в предметной области высока,

1002
00:36:10,560 --> 00:36:12,400
но наши модели,

1003
00:36:12,400 --> 00:36:14,240
похоже, не

1004
00:36:14,240 --> 00:36:16,400
часто изучают такие

1005
00:36:16,400 --> 00:36:18,480
механизмы, которые мы хотели бы, чтобы они

1006
00:36:18,480 --> 00:36:19,359
изучали на

1007
00:36:19,359 --> 00:36:22,160
прошлой неделе.  слышали о языковых моделях

1008
00:36:22,160 --> 00:36:23,599
и своего рода неявных знаниях, которые

1009
00:36:23,599 --> 00:36:25,040
они кодируют о мире через

1010
00:36:25,040 --> 00:36:27,200
предварительное обучение, и

1011
00:36:27,200 --> 00:36:28,720
одним из способов, которые мы искали, взаимодействовать

1012
00:36:28,720 --> 00:36:30,320
с языковыми моделями, было

1013
00:36:30,320 --> 00:36:31,920
предоставление им  шумно,

1014
00:36:31,920 --> 00:36:34,560
как будто Данте родился в маске,

1015
00:36:34,560 --> 00:36:35,839
а затем посмотреть, дает ли это высокая

1016
00:36:35,839 --> 00:36:38,480
вероятность правильного продолжения,

1017
00:36:38,480 --> 00:36:41,520
что требует от вас доступа к знаниям

1018
00:36:41,520 --> 00:36:44,079
о том, где родился Данте, и на

1019
00:36:44,079 --> 00:36:46,240
прошлой неделе мы не формулировали это таким образом, но это

1020
00:36:46,240 --> 00:36:47,839
вписывается в набор поведенческих исследований

1021
00:36:47,839 --> 00:36:49,680
то, что мы сделали до сих пор, это

1022
00:36:49,680 --> 00:36:51,599
особый вид ввода, который

1023
00:36:51,599 --> 00:36:54,079
вы можете попросить об этом для нескольких типов

1024
00:36:54,079 --> 00:36:55,920
нескольких людей, вы могли бы поменять данте

1025
00:36:55,920 --> 00:36:58,079
на других людей, которые поменяли местами рожденных,

1026
00:36:58,079 --> 00:36:59,599
потому что

1027
00:36:59,599 --> 00:37:01,920
я не знаю, умерли или что-то в этом роде, а

1028
00:37:01,920 --> 00:37:03,040
затем  вы можете быть,

1029
00:37:03,040 --> 00:37:05,920
они снова похожи на наборы тестов, и так

1030
00:37:05,920 --> 00:37:08,320
что все связано нормально, так что я не буду

1031
00:37:08,320 --> 00:37:10,320
слишком углубляться в знание

1032
00:37:10,320 --> 00:37:11,920
языковых моделей с точки зрения мировых

1033
00:37:11,920 --> 00:37:13,440
знаний, потому что

1034
00:37:13,440 --> 00:37:15,280
мы это кое-что рассмотрели, но вы знаете, когда

1035
00:37:15,280 --> 00:37:16,480
вы  думаете о способах

1036
00:37:16,480 --> 00:37:19,599
взаимодействия с вашими моделями,

1037
00:37:19,599 --> 00:37:21,119
такого рода поведенческие исследования могут быть

1038
00:37:21,119 --> 00:37:22,480
очень общими,

1039
00:37:22,480 --> 00:37:24,720
хотя помните, что мы все еще находимся на этом

1040
00:37:24,720 --> 00:37:27,040
самом высоком уровне абстракции, где

1041
00:37:27,040 --> 00:37:28,560
мы просто смотрим на распределения вероятностей

1042
00:37:28,560 --> 00:37:31,760
, которые определены

1043
00:37:32,160 --> 00:37:33,280
все в порядке,

1044
00:37:33,280 --> 00:37:35,520
так что теперь мы перейдем к этому, поэтому мы как бы

1045
00:37:35,520 --> 00:37:37,680
посмотрели на понимание в

1046
00:37:37,680 --> 00:37:39,119
мелкозернистых областях, что на самом деле делает наша модель,

1047
00:37:39,119 --> 00:37:40,960


1048
00:37:40,960 --> 00:37:44,079
а как насчет того, почему для

1049
00:37:44,079 --> 00:37:46,480
отдельных входных данных получается

1050
00:37:46,480 --> 00:37:48,640
правильный или неправильный ответ?  а затем есть

1051
00:37:48,640 --> 00:37:51,280
изменения во входных данных, которые выглядят хорошо для

1052
00:37:51,280 --> 00:37:54,320
людей, но на самом деле заставляют модели

1053
00:37:54,320 --> 00:37:57,760
работать плохо, поэтому одно исследование, на которое я люблю

1054
00:37:57,760 --> 00:38:00,480
ссылаться, действительно возвращает

1055
00:38:00,480 --> 00:38:02,839
нас к нашей первоначальной мотивации использования

1056
00:38:02,839 --> 00:38:05,599
сетей lstm вместо простых

1057
00:38:05,599 --> 00:38:07,040
рекуррентных нейронных сетей  состоял в том, что они

1058
00:38:07,040 --> 00:38:09,440
могли использовать длинный контекст,

1059
00:38:09,440 --> 00:38:10,320
поэтому,

1060
00:38:10,320 --> 00:38:13,359
например, как долго ваша

1061
00:38:13,359 --> 00:38:16,800
долговременная память и идея

1062
00:38:16,800 --> 00:38:20,560
Kindle Kindlewell вообще в 2018 году заключалась в

1063
00:38:20,560 --> 00:38:23,599
перемешивании или удалении контекстов, которые находятся

1064
00:38:23,599 --> 00:38:26,800
дальше, чем некоторые k слов,

1065
00:38:26,800 --> 00:38:29,040
изменяя k,

1066
00:38:29,040 --> 00:38:30,320
и

1067
00:38:30,320 --> 00:38:32,720
если точность, если если  предсказательная

1068
00:38:32,720 --> 00:38:34,320
способность вашей языковой модели

1069
00:38:34,320 --> 00:38:37,119
право на недоумение не изменится, как только вы

1070
00:38:37,119 --> 00:38:38,880
это сделаете, это означает, что модель на

1071
00:38:38,880 --> 00:38:40,960
самом деле не использовала этот контекст, я думаю, что

1072
00:38:40,960 --> 00:38:43,119
это так круто, поэтому

1073
00:38:43,119 --> 00:38:46,000
по оси x мы получили, как далеко

1074
00:38:46,000 --> 00:38:47,280
от t  Слово, которое вы пытаетесь

1075
00:38:47,280 --> 00:38:49,680
предсказать, действительно ли вы

1076
00:38:49,680 --> 00:38:52,079
искажаете перетасовку или удаляете что-

1077
00:38:52,079 --> 00:38:54,240
то из последовательности, а затем по

1078
00:38:54,240 --> 00:38:57,359
оси Y - увеличение потерь, поэтому,

1079
00:38:57,359 --> 00:39:00,320
если увеличение потерь равно нулю,

1080
00:39:00,320 --> 00:39:02,000
это означает, что модель

1081
00:39:02,000 --> 00:39:03,760
была  не использовать то, что вы только что

1082
00:39:03,760 --> 00:39:06,160
удалили, потому что, если бы он использовал его,

1083
00:39:06,160 --> 00:39:08,240
без него теперь было бы хуже, и

1084
00:39:08,240 --> 00:39:11,119
поэтому, если вы перемешаете синюю линию

1085
00:39:11,119 --> 00:39:13,280
здесь, если вы перемешаете историю, которая

1086
00:39:13,280 --> 00:39:16,079
дальше от 50 слов, модель

1087
00:39:16,079 --> 00:39:18,560
даже не  обратите внимание,

1088
00:39:18,560 --> 00:39:20,400
я думаю, что это действительно интересно, он

1089
00:39:20,400 --> 00:39:22,720
говорит все, что после 50 слов этой

1090
00:39:22,720 --> 00:39:24,400
языковой модели lstm

1091
00:39:24,400 --> 00:39:25,920
вы могли бы дать ему в случайном порядке,

1092
00:39:25,920 --> 00:39:27,520
и он бы не заметил,

1093
00:39:27,520 --> 00:39:28,400


1094
00:39:28,400 --> 00:39:30,240
а затем два он говорит, что если вы

1095
00:39:30,240 --> 00:39:31,920
ближе, чем это на самом деле

1096
00:39:31,920 --> 00:39:34,079
использование порядка слов, это довольно

1097
00:39:34,079 --> 00:39:35,760
длинная память, это действительно

1098
00:39:35,760 --> 00:39:37,280
интересно, а затем, если вы действительно

1099
00:39:37,280 --> 00:39:39,520
полностью удалите слова,

1100
00:39:39,520 --> 00:39:42,160
которые у вас есть, вы можете как бы заметить, что

1101
00:39:42,160 --> 00:39:45,520
слова отсутствуют на расстоянии до 200 слов,

1102
00:39:45,520 --> 00:39:46,880
поэтому вы не знаете порядок  э-э, что вас

1103
00:39:46,880 --> 00:39:48,240
не волнует порядок, в котором они находятся,

1104
00:39:48,240 --> 00:39:49,680
но вас волнует, находятся ли они там или

1105
00:39:49,680 --> 00:39:51,599
нет, и поэтому

1106
00:39:51,599 --> 00:39:53,920
это оценка того, хорошо ли lstms имеют

1107
00:39:53,920 --> 00:39:55,839
долгосрочную память хорошо, что, по крайней

1108
00:39:55,839 --> 00:39:58,320
мере, эффективно не более 200

1109
00:39:58,320 --> 00:39:59,119


1110
00:39:59,119 --> 00:40:00,560
слова памяти,

1111
00:40:00,560 --> 00:40:02,079
но также не менее

1112
00:40:02,079 --> 00:40:03,200


1113
00:40:03,200 --> 00:40:05,760
очень круто,

1114
00:40:05,760 --> 00:40:06,800


1115
00:40:06,800 --> 00:40:08,640
так что это похоже на общее исследование для

1116
00:40:08,640 --> 00:40:10,640
одной модели, о

1117
00:40:10,640 --> 00:40:13,040
котором говорится, это своего рода среднее поведение

1118
00:40:13,040 --> 00:40:14,800
по широкому кругу примеров, но мы

1119
00:40:14,800 --> 00:40:16,400
хотим поговорить об индивидуальных

1120
00:40:16,400 --> 00:40:18,000
прогнозах для отдельных входных данных, поэтому

1121
00:40:18,000 --> 00:40:20,720
Давайте поговорим об этом, так что

1122
00:40:20,720 --> 00:40:23,520
один из способов интерпретации, почему моя

1123
00:40:23,520 --> 00:40:26,000
модель приняла это решение, которое очень популярно,

1124
00:40:26,000 --> 00:40:28,319
- это для единственного примера, какие

1125
00:40:28,319 --> 00:40:31,200
части входных данных на самом деле привели к решению,

1126
00:40:31,200 --> 00:40:33,359
и именно здесь мы вступаем с

1127
00:40:33,359 --> 00:40:35,920
картами значимости, чтобы карта значимости

1128
00:40:35,920 --> 00:40:38,079
обеспечивала  оценка для каждого слова,

1129
00:40:38,079 --> 00:40:39,680
указывающая на его важность для прогноза модели,

1130
00:40:39,680 --> 00:40:43,359
так что у вас есть что-то вроде

1131
00:40:43,359 --> 00:40:45,520
bert здесь у вас есть bert bert

1132
00:40:45,520 --> 00:40:47,440
делает прогноз для этой

1133
00:40:47,440 --> 00:40:49,520
маски маска поспешила в отделение неотложной помощи, чтобы

1134
00:40:49,520 --> 00:40:51,520
увидеть своего пациента

1135
00:40:51,520 --> 00:40:54,079
ока  y и так далее, и предсказания, которые

1136
00:40:54,079 --> 00:40:57,440
делает модель, относятся к 47, это

1137
00:40:57,440 --> 00:40:58,880
будет медсестра, которая здесь в

1138
00:40:58,880 --> 00:41:00,400
маске,

1139
00:41:00,400 --> 00:41:02,319
или, может быть, женщина, врач,

1140
00:41:02,319 --> 00:41:04,400
мать или девочка, в порядке,

1141
00:41:04,400 --> 00:41:05,839
а затем карта значимости

1142
00:41:05,839 --> 00:41:08,160
визуализируется здесь оранжевым цветом в соответствии с

1143
00:41:08,160 --> 00:41:10,160
этим  метод заметности, называемый простыми

1144
00:41:10,160 --> 00:41:13,119
градиентами, который мы получим в чрезвычайной ситуации,

1145
00:41:13,119 --> 00:41:14,319
ее

1146
00:41:14,319 --> 00:41:16,079
и токен сеп,

1147
00:41:16,079 --> 00:41:17,599
давайте пока не будем беспокоиться о токене шага,

1148
00:41:17,599 --> 00:41:20,480
но чрезвычайная ситуация в ней - это, по-

1149
00:41:20,480 --> 00:41:22,079
видимому, важные слова, и дополнительный

1150
00:41:22,079 --> 00:41:23,760
токен появляется в каждом предложении, поэтому я

1151
00:41:23,760 --> 00:41:26,800
не  Итак, эти двое

1152
00:41:26,800 --> 00:41:28,160
вместе

1153
00:41:28,160 --> 00:41:29,520
соответствуют этому методу, что

1154
00:41:29,520 --> 00:41:30,880
важно для модели, чтобы сделать это

1155
00:41:30,880 --> 00:41:33,200
предсказание замаскированным,

1156
00:41:33,200 --> 00:41:35,200
и вы можете видеть, что знаете, возможно, некоторые

1157
00:41:35,200 --> 00:41:38,000
статистические смещения и т. д., которые подбираются

1158
00:41:38,000 --> 00:41:39,760
в предсказаниях, а затем

1159
00:41:39,760 --> 00:41:42,960
наносятся на  предложение, и это

1160
00:41:42,960 --> 00:41:44,319
хорошо, похоже, что это действительно помогает

1161
00:41:44,319 --> 00:41:46,960
интерпретируемости ммм,

1162
00:41:46,960 --> 00:41:48,960
и ммм,

1163
00:41:48,960 --> 00:41:50,880
да, я думаю, что это своего рода

1164
00:41:50,880 --> 00:41:52,880
очень полезный инструмент, и на самом деле это

1165
00:41:52,880 --> 00:41:56,319
часть демонстрации от alan nl  эээ, который

1166
00:41:56,319 --> 00:41:58,960
позволяет вам делать это

1167
00:41:58,960 --> 00:42:00,960
эээээ сам для любого предложения, которое вы

1168
00:42:00,960 --> 00:42:04,000
хотите.

1169
00:42:04,000 --> 00:42:05,760


1170
00:42:05,760 --> 00:42:07,440


1171
00:42:07,440 --> 00:42:09,119
очень простой

1172
00:42:09,119 --> 00:42:10,960
и проработайте, почему это имеет

1173
00:42:10,960 --> 00:42:12,560
смысл,

1174
00:42:12,560 --> 00:42:13,440


1175
00:42:13,440 --> 00:42:15,839
так что проблема в том, как правильно определить

1176
00:42:15,839 --> 00:42:17,040
важность,

1177
00:42:17,040 --> 00:42:18,480
что значит быть важным

1178
00:42:18,480 --> 00:42:21,040
для прогноза модели, и вот

1179
00:42:21,040 --> 00:42:22,480
один из способов думать об этом, это

1180
00:42:22,480 --> 00:42:24,560
называется простым градиентом  метод эм, давайте

1181
00:42:24,560 --> 00:42:26,160
получим немного формальности, у вас есть слова от x1 до

1182
00:42:26,160 --> 00:42:27,760
xn,

1183
00:42:27,760 --> 00:42:29,359
хорошо, а затем у вас есть оценка модели

1184
00:42:29,359 --> 00:42:31,599
для данного выходного класса, так что, возможно, у вас

1185
00:42:31,599 --> 00:42:32,400
есть

1186
00:42:32,400 --> 00:42:34,319
в примере березы каждый выходной класс

1187
00:42:34,319 --> 00:42:36,160
был каждым выходным словом, которое вы могли

1188
00:42:36,160 --> 00:42:37,920
возможно, предскажите

1189
00:42:37,920 --> 00:42:40,480
um, а затем вы берете

1190
00:42:40,480 --> 00:42:42,640
норму градиента оценки

1191
00:42:42,640 --> 00:42:44,960
по каждому слову, хорошо, поэтому

1192
00:42:44,960 --> 00:42:47,040
мы говорим,

1193
00:42:47,040 --> 00:42:48,240
что оценка

1194
00:42:48,240 --> 00:42:49,920
правильная, это своего рода ненормализованная

1195
00:42:49,920 --> 00:42:51,200
вероятность

1196
00:42:51,200 --> 00:42:52,560


1197
00:42:52,560 --> 00:42:54,960
для этого класса,

1198
00:42:54,960 --> 00:42:56,560
хорошо, поэтому у вас есть  один класс, который вы

1199
00:42:56,560 --> 00:42:58,240
берете  оценка это похоже на то, насколько вероятно, что

1200
00:42:58,240 --> 00:43:00,560
это еще не нормализовано тем, насколько вероятно,

1201
00:43:00,560 --> 00:43:03,200
что все остальное представляет собой своего рода градиент,

1202
00:43:03,200 --> 00:43:05,200
насколько он изменится,

1203
00:43:05,200 --> 00:43:06,960
если я немного сдвину его в том

1204
00:43:06,960 --> 00:43:08,560
или ином направлении, а затем вы

1205
00:43:08,560 --> 00:43:10,800
возьмете норму, чтобы получить скаляр из  вектор,

1206
00:43:10,800 --> 00:43:12,880
так что это выглядит так, так заметность

1207
00:43:12,880 --> 00:43:13,920
слова i у

1208
00:43:13,920 --> 00:43:16,400
вас есть полосы нормы на внешнем

1209
00:43:16,400 --> 00:43:18,720
градиенте относительно xi,

1210
00:43:18,720 --> 00:43:20,880
так что если я немного изменю

1211
00:43:20,880 --> 00:43:22,640
локально xi,

1212
00:43:22,640 --> 00:43:24,720
насколько изменится моя оценка

1213
00:43:24,720 --> 00:43:27,280
um, поэтому идея состоит в том, что высокий градиент

1214
00:43:27,280 --> 00:43:29,440
Норма означает, что, если бы я изменил его

1215
00:43:29,440 --> 00:43:32,000
локально, я бы сильно повлиял на оценку, и

1216
00:43:32,000 --> 00:43:33,359
это означает, что это было очень важно для

1217
00:43:33,359 --> 00:43:35,280
решения, давайте немного визуализируем это,

1218
00:43:35,280 --> 00:43:37,280
поэтому

1219
00:43:37,280 --> 00:43:40,480
здесь, по оси Y, у нас есть потеря,

1220
00:43:40,480 --> 00:43:41,920
просто потеря  модель, извините, это должна

1221
00:43:41,920 --> 00:43:43,040
быть оценка,

1222
00:43:43,040 --> 00:43:44,960
она должна быть оценкой, и по оси X

1223
00:43:44,960 --> 00:43:46,720
у вас есть пространство для слов, а

1224
00:43:46,720 --> 00:43:49,359
пространство для слов похоже на своего рода

1225
00:43:49,359 --> 00:43:51,040


1226
00:43:51,040 --> 00:43:53,200
уплощение способности перемещать вложение вашего слова

1227
00:43:53,200 --> 00:43:55,200
в тысячумерном пространстве, которое я только что

1228
00:43:55,200 --> 00:43:57,599
нарисовал  это здесь в одном измерении,

1229
00:43:57,599 --> 00:43:58,640


1230
00:43:58,640 --> 00:44:00,880
а теперь высокий s  Вы можете

1231
00:44:00,880 --> 00:44:03,040
видеть, что взаимосвязь между

1232
00:44:03,040 --> 00:44:05,599
тем, что должно быть оценено, и перемещением

1233
00:44:05,599 --> 00:44:07,359
слова в пространстве слов, вы немного перемещаете его

1234
00:44:07,359 --> 00:44:10,319
по оси x, и оценка

1235
00:44:10,319 --> 00:44:11,839
сильно

1236
00:44:11,839 --> 00:44:14,800
меняется

1237
00:44:14,800 --> 00:44:18,000
переместите слово локально, и

1238
00:44:18,000 --> 00:44:20,240
оценка не изменится,

1239
00:44:20,240 --> 00:44:21,119
так что это интерпретатор,

1240
00:44:21,119 --> 00:44:22,640
интерпретация

1241
00:44:22,640 --> 00:44:24,560
означает, что фактическая, как вы знаете,

1242
00:44:24,560 --> 00:44:26,480
идентичность этого слова не была так

1243
00:44:26,480 --> 00:44:27,920
важна для предсказания, потому что я

1244
00:44:27,920 --> 00:44:29,599
мог бы изменить ее, и оценка не была

1245
00:44:29,599 --> 00:44:31,280
бы  Теперь не изменилось,

1246
00:44:31,280 --> 00:44:33,760
почему существует больше методов, чем этот,

1247
00:44:33,760 --> 00:44:35,520
потому что я честно читаю, что я был

1248
00:44:35,520 --> 00:44:37,520
таким, как будто это звучит потрясающе, звучит

1249
00:44:37,520 --> 00:44:39,839
великолепно, вы знаете, что

1250
00:44:39,839 --> 00:44:43,040
с этим методом есть много проблем

1251
00:44:43,280 --> 00:44:44,640
и много способов их

1252
00:44:44,640 --> 00:44:46,480
обойти  у них есть одна проблема,

1253
00:44:46,480 --> 00:44:48,240
это не идеально,

1254
00:44:48,240 --> 00:44:50,800
потому что, может быть, ваше линейное

1255
00:44:50,800 --> 00:44:52,640
приближение, которое дает

1256
00:44:52,640 --> 00:44:56,640
вам градиент, выполняется только очень и очень локально,

1257
00:44:56,640 --> 00:45:00,400
так что здесь градиент равен нулю, так что это

1258
00:45:00,400 --> 00:45:02,720
слово с низкой значимостью быть  Потому что в

1259
00:45:02,720 --> 00:45:05,040
нижней части этой параболы, но если бы я

1260
00:45:05,040 --> 00:45:06,560
немного сдвинулся в любом

1261
00:45:06,560 --> 00:45:09,839
направлении, счет хотел бы вырасти

1262
00:45:09,839 --> 00:45:11,520
правильно, так что это не важное слово,

1263
00:45:11,520 --> 00:45:13,119
как кажется

1264
00:45:13,119 --> 00:45:15,760
важным быть прямо здесь,

1265
00:45:15,760 --> 00:45:18,160
а не где-либо еще, даже своего рода

1266
00:45:18,160 --> 00:45:19,280
рядом

1267
00:45:19,280 --> 00:45:21,920
, чтобы оценка не росла,

1268
00:45:21,920 --> 00:45:23,760
поэтому метод простых градиентов

1269
00:45:23,760 --> 00:45:25,599
не улавливает это, потому что он просто смотрит

1270
00:45:25,599 --> 00:45:27,920
на градиент, который является нулевым прямо

1271
00:45:27,920 --> 00:45:29,599
здесь,

1272
00:45:29,599 --> 00:45:30,800
хорошо,

1273
00:45:30,800 --> 00:45:32,640
но если вы хотите изучить больше,

1274
00:45:32,640 --> 00:45:34,160
есть куча разных  методы

1275
00:45:34,160 --> 00:45:36,319
, которые вроде как применяются в этих документах,

1276
00:45:36,319 --> 00:45:39,119
и, вы знаете, я думаю, что есть

1277
00:45:39,119 --> 00:45:42,319
хороший инструмент для набора инструментов,

1278
00:45:42,400 --> 00:45:44,400
хорошо, так

1279
00:45:44,400 --> 00:45:46,160
что это один из способов объяснить

1280
00:45:46,160 --> 00:45:48,000
предсказание, и

1281
00:45:48,000 --> 00:45:48,960


1282
00:45:48,960 --> 00:45:51,200
вы знаете, есть некоторые проблемы, например,

1283
00:45:51,200 --> 00:45:53,599
почему оцениваются отдельные слова, а не

1284
00:45:53,599 --> 00:45:55,440
наоборот  на фразы или что-то в

1285
00:45:55,440 --> 00:45:57,760
этом роде, а пока мы собираемся

1286
00:45:57,760 --> 00:46:00,560
перейти к другому типу объяснений,

1287
00:46:00,560 --> 00:46:04,079
и я проверю время, хорошо, круто, на

1288
00:46:04,079 --> 00:46:05,920
самом деле, да, позвольте мне на

1289
00:46:05,920 --> 00:46:09,200
секунду приостановить любые вопросы по этому поводу

1290
00:46:10,240 --> 00:46:12,480
ах,

1291
00:46:12,480 --> 00:46:14,720
я имею в виду  ранее было несколько

1292
00:46:14,720 --> 00:46:15,920
вопросов,

1293
00:46:15,920 --> 00:46:18,640
один из них: что вы думаете о

1294
00:46:18,640 --> 00:46:20,079
том, что вы думаете о том, является ли

1295
00:46:20,079 --> 00:46:21,599
рассмотрение весов внимания

1296
00:46:21,599 --> 00:46:23,760
методологически строгим способом

1297
00:46:23,760 --> 00:46:25,359
определения важности, которую

1298
00:46:25,359 --> 00:46:28,319
модель придает определенным токенам?

1299
00:46:28,319 --> 00:46:30,000
в

1300
00:46:30,000 --> 00:46:31,760
литературе

1301
00:46:31,760 --> 00:46:33,119
,

1302
00:46:33,119 --> 00:46:35,280
это отличный вопрос, и я, вероятно

1303
00:46:35,280 --> 00:46:37,200
, не буду вдаваться в подробности этого вопроса,

1304
00:46:37,200 --> 00:46:37,920


1305
00:46:37,920 --> 00:46:39,839
если бы у нас была вторая лекция

1306
00:46:39,839 --> 00:46:41,760
по этому поводу, я на самом деле предоставлю некоторый

1307
00:46:41,760 --> 00:46:43,839
анализ внимания и скажу вам, что они

1308
00:46:43,839 --> 00:46:46,400
интересны, а затем  Я как бы

1309
00:46:46,400 --> 00:46:48,720
немного скажу о ...

1310
00:46:48,720 --> 00:46:50,240
эээ,

1311
00:46:50,240 --> 00:46:51,280
вы знаете,

1312
00:46:51,280 --> 00:46:52,960
почему они могут быть интересными, не

1313
00:46:52,960 --> 00:46:54,839
будучи своего рода,

1314
00:46:54,839 --> 00:46:56,720
может быть,

1315
00:46:56,720 --> 00:46:58,400


1316
00:46:58,400 --> 00:47:02,319
своего рода концом анализа того,

1317
00:47:02,319 --> 00:47:03,760
где информация течет в

1318
00:47:03,760 --> 00:47:06,160
трансформаторе, например, эм, я думаю, что

1319
00:47:06,160 --> 00:47:07,599
дебаты - это

1320
00:47:07,599 --> 00:47:09,440
то, к чему нам нужно будет обратиться

1321
00:47:09,440 --> 00:47:12,240
в течение гораздо более длительного периода времени, но посмотрите

1322
00:47:12,240 --> 00:47:13,359
на слайды, которые я показываю, о

1323
00:47:13,359 --> 00:47:15,599
внимании и предостережениях, которые я предоставляю,

1324
00:47:15,599 --> 00:47:17,680
и дайте мне знать, если это отвечает на y

1325
00:47:17,680 --> 00:47:18,800
сначала наш вопрос, потому что у нас есть довольно

1326
00:47:18,800 --> 00:47:20,720
много слайдов, и если нет, пожалуйста,

1327
00:47:20,720 --> 00:47:22,880
спросите еще раз, и мы сможем поболтать

1328
00:47:22,880 --> 00:47:24,880
об этом,

1329
00:47:24,880 --> 00:47:27,040
и, возможно, у вас все получится,

1330
00:47:27,040 --> 00:47:29,760
хорошо, так что

1331
00:47:29,760 --> 00:47:31,200
я думаю, что это действительно

1332
00:47:31,200 --> 00:47:32,800
увлекательный вопрос, который также дает  был

1333
00:47:32,800 --> 00:47:35,040
важен для ввода,

1334
00:47:35,040 --> 00:47:36,800
но на самом деле даже более

1335
00:47:36,800 --> 00:47:39,680
прямым способом, я мог бы просто сохранить

1336
00:47:39,680 --> 00:47:41,920
некоторую минимальную часть ввода и получить

1337
00:47:41,920 --> 00:47:43,839
тот же ответ, так что вот пример

1338
00:47:43,839 --> 00:47:45,359
от команды, у

1339
00:47:45,359 --> 00:47:47,680
вас есть этот отрывок в 1899 году, Джон Джейкоб

1340
00:47:47,680 --> 00:47:50,079
Эштон iv вложил 100  000

1341
00:47:50,079 --> 00:47:51,760
для Tesla, хорошо,

1342
00:47:51,760 --> 00:47:53,040
и тогда ответ, который

1343
00:47:53,040 --> 00:47:54,400
предсказывается моделью,

1344
00:47:54,400 --> 00:47:55,760
всегда будет синим в этих примерах

1345
00:47:55,760 --> 00:47:58,160
экспериментов Колорадо-Спрингс, так что у вас

1346
00:47:58,160 --> 00:47:59,680
есть этот отрывок,

1347
00:47:59,680 --> 00:48:02,319
и вопрос в том, на что Tesla потратила

1348
00:48:02,319 --> 00:48:03,920
деньги Astr, поэтому

1349
00:48:03,920 --> 00:48:05,119
предсказание  Это эксперименты в Колорадо-Спрингс,

1350
00:48:05,119 --> 00:48:07,440
модель получает

1351
00:48:07,440 --> 00:48:10,880
правильный ответ, что приятно, и мы

1352
00:48:10,880 --> 00:48:12,319
хотели бы думать, что это потому, что она выполняет

1353
00:48:12,319 --> 00:48:14,640
какое-то понимание прочитанного,

1354
00:48:14,640 --> 00:48:16,319
но вот проблема,

1355
00:48:16,319 --> 00:48:18,559
которая оказывается на основе t  его увлекательная

1356
00:48:18,559 --> 00:48:19,599
статья

1357
00:48:19,599 --> 00:48:21,359
о том, что если вы просто наберете, сократите

1358
00:48:21,359 --> 00:48:23,040
вопрос до

1359
00:48:23,040 --> 00:48:25,200


1360
00:48:25,200 --> 00:48:27,839
того, получили ли вы на самом деле то же самое,

1361
00:48:27,839 --> 00:48:30,079
вы на самом деле получите точно такой же ответ,

1362
00:48:30,079 --> 00:48:32,960
и на самом деле с исходным

1363
00:48:32,960 --> 00:48:35,200
вопросом модель имела своего рода уверенность 0,78, что

1364
00:48:35,200 --> 00:48:36,960
вы знаете вероятность в этом

1365
00:48:36,960 --> 00:48:39,760
ответе, и э-э, с  с сокращенным

1366
00:48:39,760 --> 00:48:41,680
вопросом

1367
00:48:41,680 --> 00:48:44,800
вы получили еще большую уверенность, и что,

1368
00:48:44,800 --> 00:48:46,800
если вы дадите человеку это, они не

1369
00:48:46,800 --> 00:48:48,240
смогут понять, о чем вы

1370
00:48:48,240 --> 00:48:50,079
пытаетесь спросить, так что кажется, что

1371
00:48:50,079 --> 00:48:53,119
некоторые вещи идут очень шатко

1372
00:48:53,119 --> 00:48:55,119
вот еще вот  вот что-то

1373
00:48:55,119 --> 00:48:57,040
вроде очень высокого обзора

1374
00:48:57,040 --> 00:48:59,119
метода,

1375
00:48:59,119 --> 00:49:00,640
на самом деле он действительно ссылается на нашу входную

1376
00:49:00,640 --> 00:49:02,160
продажу и те же методы, которые хорошо

1377
00:49:02,160 --> 00:49:04,640
связаны, так что вы итеративно

1378
00:49:04,640 --> 00:49:06,240
удаляете

1379
00:49:06,240 --> 00:49:09,040
несущественные или неважные слова, так что

1380
00:49:09,040 --> 00:49:10,559
вот квест вот отрывок, снова

1381
00:49:10,559 --> 00:49:14,319
говорящий о футболе  Я думаю, да,

1382
00:49:14,319 --> 00:49:17,599
и ох, хорошо, хорошо, так что вопрос

1383
00:49:17,599 --> 00:49:19,040
в том, где бронко тренировались

1384
00:49:19,040 --> 00:49:20,880
на суперкубке, как предсказал

1385
00:49:20,880 --> 00:49:22,880
Стэнфордский университет,

1386
00:49:22,880 --> 00:49:23,920


1387
00:49:23,920 --> 00:49:26,960
и это правильно  ct, так что снова кажется приятным,

1388
00:49:26,960 --> 00:49:29,359
и теперь мы на самом деле не собираемся, чтобы

1389
00:49:29,359 --> 00:49:31,200
вы знали, что модель неверна, мы

1390
00:49:31,200 --> 00:49:32,319
просто собираемся сказать,

1391
00:49:32,319 --> 00:49:33,280


1392
00:49:33,280 --> 00:49:35,680
как я могу изменить этот вопрос

1393
00:49:35,680 --> 00:49:37,040
, чтобы я все равно получил правильный ответ,

1394
00:49:37,040 --> 00:49:39,040
поэтому я собираюсь  удалите слово, которое было

1395
00:49:39,040 --> 00:49:40,880
наименее важным в соответствии с методом заметности,

1396
00:49:40,880 --> 00:49:42,880
так что теперь именно там, где уже проходила

1397
00:49:42,880 --> 00:49:44,880
практика для суперкубка,

1398
00:49:44,880 --> 00:49:46,559
это вроде как неотразимо,

1399
00:49:46,559 --> 00:49:48,480
потому что у вас есть две тренировочные команды,

1400
00:49:48,480 --> 00:49:49,839
вы даже не знаете, о какой из них

1401
00:49:49,839 --> 00:49:52,000
спрашиваете  Итак, почему модель все еще

1402
00:49:52,000 --> 00:49:53,680
думает, что она настолько уверена в Стэнфордском

1403
00:49:53,680 --> 00:49:55,680
университете, не имеет смысла, но вы можете

1404
00:49:55,680 --> 00:49:57,760
просто продолжать,

1405
00:49:57,760 --> 00:49:58,800


1406
00:49:58,800 --> 00:50:02,400
и теперь вы знаете, я думаю, что

1407
00:50:02,400 --> 00:50:04,400
здесь модель перестает быть уверенной

1408
00:50:04,400 --> 00:50:07,119
в ответе Стэнфордского университета,

1409
00:50:07,119 --> 00:50:08,960
но вы знаете,

1410
00:50:08,960 --> 00:50:10,559
я думаю, что это действительно интересно, просто

1411
00:50:10,559 --> 00:50:11,760
чтобы показать, что

1412
00:50:11,760 --> 00:50:13,280
если модель способна делать это с

1413
00:50:13,280 --> 00:50:15,680
очень высокой степенью уверенности,

1414
00:50:15,680 --> 00:50:18,480
она не отражает неопределенность, которая

1415
00:50:18,480 --> 00:50:20,559
действительно должна присутствовать, потому

1416
00:50:20,559 --> 00:50:23,280
что вы даже не можете знать, о чем спрашиваете,

1417
00:50:23,280 --> 00:50:25,359
хорошо, так что было важно дать этот

1418
00:50:25,359 --> 00:50:27,520
ответ  ну,

1419
00:50:27,520 --> 00:50:29,599
по крайней мере, эта часть, эти части были

1420
00:50:29,599 --> 00:50:31,119
важны, потому что вы могли сохранить только

1421
00:50:31,119 --> 00:50:32,960
эти части и получить такой же увлекательный ответ,

1422
00:50:32,960 --> 00:50:34,960


1423
00:50:34,960 --> 00:50:37,920
ну ладно, так что это своего рода конец,

1424
00:50:37,920 --> 00:50:41,760
по общему признанию, краткого раздела, посвященного

1425
00:50:41,760 --> 00:50:44,480
размышлениям о методах важности ввода

1426
00:50:44,480 --> 00:50:45,599
и подобных вещах, теперь мы '  мы собираемся

1427
00:50:45,599 --> 00:50:47,760
поговорить о том, чтобы на самом деле ломать модели и

1428
00:50:47,760 --> 00:50:50,800
понимать модели, ломая их,

1429
00:50:50,800 --> 00:50:53,440
хорошо, круто, так что, если у нас есть отрывок

1430
00:50:53,440 --> 00:50:54,880
здесь, Пейтон Мэннинг стал первым

1431
00:50:54,880 --> 00:50:56,000
квотербеком

1432
00:50:56,000 --> 00:50:56,410
ммм

1433
00:50:56,410 --> 00:50:57,920
[Музыка]

1434
00:50:57,920 --> 00:51:00,480
что-то суперкубок в возрасте 39 лет после рекорда,

1435
00:51:00,480 --> 00:51:02,880
установленного Джоном Элвэем.

1436
00:51:02,880 --> 00:51:04,319
отвечая на вопрос, у нас есть этот

1437
00:51:04,319 --> 00:51:05,839
вопрос, как звали

1438
00:51:05,839 --> 00:51:08,319
квотербека, которому было 38 лет в суперкубке,

1439
00:51:08,319 --> 00:51:12,160
прогноз верен, выглядит хорошо, сейчас

1440
00:51:12,160 --> 00:51:13,440
мы не собираемся менять вопрос,

1441
00:51:13,440 --> 00:51:16,079
чтобы попытаться сделать вопрос

1442
00:51:16,079 --> 00:51:17,599
бессмысленным, пока  сохраняя тот же

1443
00:51:17,599 --> 00:51:20,160
ответ, вместо этого мы собираемся изменить

1444
00:51:20,160 --> 00:51:21,280
отрывок

1445
00:51:21,280 --> 00:51:22,400


1446
00:51:22,400 --> 00:51:24,079
, добавив предложение в конце, которое

1447
00:51:24,079 --> 00:51:25,920
действительно никого не должно отвлекать. это

1448
00:51:25,920 --> 00:51:28,079
квотербек, известный квотербек  у Джеффа Дина, которого

1449
00:51:28,079 --> 00:51:30,800
вы знаете, была футболка под номером 37 в

1450
00:51:30,800 --> 00:51:32,559
чаше чемпионов, так что это просто не имеет

1451
00:51:32,559 --> 00:51:34,559
отношения к этому,

1452
00:51:34,559 --> 00:51:37,119
но теперь предсказание - джефф Дин, э-э,

1453
00:51:37,119 --> 00:51:41,599
для нашей красивой модели QA, э-э, и это

1454
00:51:41,599 --> 00:51:43,280
также показывает, что

1455
00:51:43,280 --> 00:51:45,760
э-э, кажется, может быть это  например,

1456
00:51:45,760 --> 00:51:48,000
предвзятость в конце отрывка относительно того,

1457
00:51:48,000 --> 00:51:50,079
где должен быть ответ, например, и поэтому

1458
00:51:50,079 --> 00:51:52,079
не это - состязательный

1459
00:51:52,079 --> 00:51:54,240
пример, когда мы перевернули прогноз

1460
00:51:54,240 --> 00:51:56,000
, добавив что-то безобидное для

1461
00:51:56,000 --> 00:51:57,119
людей,

1462
00:51:57,119 --> 00:51:58,800
и так что-то вроде выноса более высокого

1463
00:51:58,800 --> 00:52:01,280
уровня, как о  похоже, что модель qa,

1464
00:52:01,280 --> 00:52:03,359
которая у нас была, казалась хорошей, она на

1465
00:52:03,359 --> 00:52:05,200
самом деле не выполняет qa так, как мы хотим

1466
00:52:05,200 --> 00:52:06,960
, даже несмотря на то, что с

1467
00:52:06,960 --> 00:52:09,839
точностью до предметной области это было хорошо,

1468
00:52:09,839 --> 00:52:13,200
а вот еще один пример, так что у вас

1469
00:52:13,200 --> 00:52:16,000
есть этот абзац

1470
00:52:16,000 --> 00:52:17,520
с вопросом, что  был

1471
00:52:17,520 --> 00:52:20,240
результатом этой огласки. Ответ заключается в

1472
00:52:20,240 --> 00:52:22,720
повышенном внимании к неправомерному поведению учителей.

1473
00:52:22,720 --> 00:52:24,880


1474
00:52:24,880 --> 00:52:27,119


1475
00:52:27,119 --> 00:52:28,319


1476
00:52:28,319 --> 00:52:29,480


1477
00:52:29,480 --> 00:52:32,079


1478
00:52:32,079 --> 00:52:34,720
предсказание модели, так что сначала,

1479
00:52:34,720 --> 00:52:36,880
что ха, и теперь у вас есть этот тип,

1480
00:52:36,880 --> 00:52:39,440
просто результат этой огласки

1481
00:52:39,440 --> 00:52:42,319
ответ меняется на неправомерное поведение учителя,

1482
00:52:42,319 --> 00:52:44,640
вероятно, человек проигнорирует эту

1483
00:52:44,640 --> 00:52:47,040
опечатку или что-то в этом роде и ответит правильный

1484
00:52:47,040 --> 00:52:49,359
ответ, и тогда это действительно

1485
00:52:49,359 --> 00:52:51,359
чокнутый  спрашивать, каков был

1486
00:52:51,359 --> 00:52:53,760
результат этой огласки, если вы спрашиваете,

1487
00:52:53,760 --> 00:52:56,480
каков был результат этой огласки,

1488
00:52:56,480 --> 00:52:59,200
ответ также меняется,

1489
00:52:59,200 --> 00:53:00,480
и

1490
00:53:00,480 --> 00:53:02,400
это авторы называют это семантически

1491
00:53:02,400 --> 00:53:04,880
эквивалентным

1492
00:53:04,880 --> 00:53:07,920


1493
00:53:07,920 --> 00:53:10,880
противником.  эта модель qa ломает ее

1494
00:53:10,880 --> 00:53:12,800
довольно часто,

1495
00:53:12,800 --> 00:53:14,960
и поэтому снова, когда вы возвращаетесь и как бы

1496
00:53:14,960 --> 00:53:16,040


1497
00:53:16,040 --> 00:53:18,720
переделываете, как построить свою модель,

1498
00:53:18,720 --> 00:53:20,000
вы будете думать об этих

1499
00:53:20,000 --> 00:53:21,520
вещах, а не только о какой-то средней

1500
00:53:21,520 --> 00:53:23,040
точности,

1501
00:53:23,040 --> 00:53:25,920
так

1502
00:53:26,000 --> 00:53:28,000
что это вроде как говорит о шуме  наши

1503
00:53:28,000 --> 00:53:30,880
модели устойчивы к шуму на входе

1504
00:53:30,880 --> 00:53:32,319
наши люди устойчивы к шуму, есть еще

1505
00:53:32,319 --> 00:53:34,480
один вопрос, который мы можем задать, и поэтому вы

1506
00:53:34,480 --> 00:53:37,520
можете как бы перейти к этому популярному

1507
00:53:37,520 --> 00:53:40,079
типу мемов, распространяемых по интерьеру.  net

1508
00:53:40,079 --> 00:53:43,119
время от времени, когда все

1509
00:53:43,119 --> 00:53:44,960
буквы в этих словах зашифрованы, вы говорите,

1510
00:53:44,960 --> 00:53:47,280
согласно исследованию э-э

1511
00:53:47,280 --> 00:53:49,440
или в кембриджском университете, не имеет

1512
00:53:49,440 --> 00:53:51,119
значения, в каком порядке буквы в

1513
00:53:51,119 --> 00:53:54,000
слове правильные, и поэтому кажется, что вы

1514
00:53:54,000 --> 00:53:54,960
знаете,

1515
00:53:54,960 --> 00:53:57,520
я думаю  я проделал довольно хорошую работу там,

1516
00:53:57,520 --> 00:53:59,599
кажется, правильно, мы получили этот шум,

1517
00:53:59,599 --> 00:54:01,839
это особый вид шума, и мы можем быть

1518
00:54:01,839 --> 00:54:04,400
устойчивыми, как люди, к чтению и

1519
00:54:04,400 --> 00:54:06,400
обработке языка, на

1520
00:54:06,400 --> 00:54:08,400
самом деле без особых

1521
00:54:08,400 --> 00:54:11,119
трудностей, так что, возможно, это то,

1522
00:54:11,119 --> 00:54:12,880
что мы могли бы захотеть  наши модели также должны быть

1523
00:54:12,880 --> 00:54:15,119
надежными,

1524
00:54:15,119 --> 00:54:16,160
и

1525
00:54:16,160 --> 00:54:19,280
это очень практично, так как шум

1526
00:54:19,280 --> 00:54:21,520
является частью всех входных данных nlp-систем

1527
00:54:21,520 --> 00:54:24,240
в любое время, просто не существует такой

1528
00:54:24,240 --> 00:54:26,400
эффективной вещи, как, например, наличие у вас знакомых

1529
00:54:26,400 --> 00:54:28,640
пользователей и отсутствие

1530
00:54:28,640 --> 00:54:30,400
шума um,

1531
00:54:30,400 --> 00:54:31,839
и поэтому есть исследование  это было

1532
00:54:31,839 --> 00:54:34,079
выполнено на некоторых известных вам популярных

1533
00:54:34,079 --> 00:54:36,319
моделях машинного перевода, где вы

1534
00:54:36,319 --> 00:54:39,119
тренируете модели машинного перевода с французского,

1535
00:54:39,119 --> 00:54:42,079
немецкого и чешского, я думаю, все на английский,

1536
00:54:42,079 --> 00:54:43,839
и вы получаете синие оценки, эти синие

1537
00:54:43,839 --> 00:54:45,599
оценки будут выглядеть  намного лучше, чем

1538
00:54:45,599 --> 00:54:47,359
те, что в вашем Simon 4, потому что гораздо

1539
00:54:47,359 --> 00:54:49,280
больше обучающих данных. Идея состоит в том, что это на

1540
00:54:49,280 --> 00:54:50,960
самом деле довольно сильные

1541
00:54:50,960 --> 00:54:52,880
системы машинного перевода,

1542
00:54:52,880 --> 00:54:56,000
и теперь они находятся в области чистого текста,

1543
00:54:56,000 --> 00:54:58,799
если вы добавляете замену символов, как те,

1544
00:54:58,799 --> 00:55:01,359
которые мы видели в, вы знаете в этом  в этом

1545
00:55:01,359 --> 00:55:03,599
предложении о

1546
00:55:03,599 --> 00:55:07,520
Кембридже синие оценки имеют довольно резкое погружение,

1547
00:55:07,520 --> 00:55:09,440
не очень хорошо,

1548
00:55:09,440 --> 00:55:12,400
и даже если вы возьмете несколько

1549
00:55:12,400 --> 00:55:14,720
более естественный вид

1550
00:55:14,720 --> 00:55:16,880
распределения шума опечаток,

1551
00:55:16,880 --> 00:55:18,720
вы увидите, что вы все еще понимаете,

1552
00:55:18,720 --> 00:55:22,079
что 20-ие

1553
00:55:22,079 --> 00:55:23,760
да очень высоко

1554
00:55:23,760 --> 00:55:26,240
падает синим цветом из-за простого

1555
00:55:26,240 --> 00:55:27,680
естественного шума,

1556
00:55:27,680 --> 00:55:29,200
и, возможно, вы вернетесь и

1557
00:55:29,200 --> 00:55:30,799
переобучите модель на большем количестве типов шума, а

1558
00:55:30,799 --> 00:55:32,640
затем вы спросите, если я сделаю это,

1559
00:55:32,640 --> 00:55:34,960
устойчиво ли оно даже к различным видам шума,

1560
00:55:34,960 --> 00:55:36,160
это те вопросы, которые будут

1561
00:55:36,160 --> 00:55:37,680
чтобы быть действительно важным, и

1562
00:55:37,680 --> 00:55:39,119
важно знать, что вы можете

1563
00:55:39,119 --> 00:55:41,359
очень легко сломать свою модель, чтобы

1564
00:55:41,359 --> 00:55:43,040
затем вы могли пойти и попытаться сделать ее более

1565
00:55:43,040 --> 00:55:45,119
надежной,

1566
00:55:45,119 --> 00:55:49,119
ладно, теперь давайте посмотрим

1567
00:55:49,119 --> 00:55:50,319
20 минут

1568
00:55:50,319 --> 00:55:52,880
ах немного

1569
00:55:52,880 --> 00:55:55,359
а теперь мы собираемся

1570
00:55:55,359 --> 00:55:56,960
я догадываюсь  да,

1571
00:55:56,960 --> 00:55:58,880
да, так что теперь мы собираемся взглянуть на

1572
00:55:58,880 --> 00:56:01,359
репрезентации наших нейронных сетей, о которых

1573
00:56:01,359 --> 00:56:02,640
мы говорили, об их

1574
00:56:02,640 --> 00:56:04,880
поведении, а затем можем ли мы как-

1575
00:56:04,880 --> 00:56:07,920
то изменить или выяснить причины

1576
00:56:07,920 --> 00:56:10,319
их поведения. Теперь мы

1577
00:56:10,319 --> 00:56:12,880
перейдем к менее абстракционному

1578
00:56:12,880 --> 00:56:14,960
взгляду.  больше на реальных векторных

1579
00:56:14,960 --> 00:56:16,400
представлениях, которые строятся

1580
00:56:16,400 --> 00:56:18,400
моделями, и мы можем ответить по

1581
00:56:18,400 --> 00:56:20,240


1582
00:56:20,240 --> 00:56:21,680
крайней мере на вопросы другого типа, чем в других

1583
00:56:21,680 --> 00:56:24,000
исследованиях,

1584
00:56:24,000 --> 00:56:26,160
первое, что связано с

1585
00:56:26,160 --> 00:56:28,400
вопросом, который был задан о внимании,

1586
00:56:28,400 --> 00:56:31,119
который заключается в том, что некоторые

1587
00:56:31,119 --> 00:56:33,520
компоненты моделирования  поддаются проверке

1588
00:56:33,520 --> 00:56:35,280
сейчас, это предложение, которое я выбрал

1589
00:56:35,280 --> 00:56:37,119
довольно осторожно, потому что в

1590
00:56:37,119 --> 00:56:39,200
части этого обсуждения правильно,

1591
00:56:39,200 --> 00:56:41,839
являются ли они интерпретируемыми компонентами, которые

1592
00:56:41,839 --> 00:56:44,319
мы увидим, но они поддаются

1593
00:56:44,319 --> 00:56:46,799
проверке следующим образом:

1594
00:56:46,799 --> 00:56:48,400
вы можете хорошо визуализировать их и

1595
00:56:48,400 --> 00:56:50,319
сопоставить их  легко с различными

1596
00:56:50,319 --> 00:56:51,520
свойствами,

1597
00:56:51,520 --> 00:56:53,200
так что предположим, что у вас есть головы в

1598
00:56:53,200 --> 00:56:55,359
зале, это из действительно

1599
00:56:55,359 --> 00:56:58,000
хорошего исследования, которое было проведено здесь,

1600
00:56:58,000 --> 00:56:58,799
где

1601
00:56:58,799 --> 00:57:00,640
вы смотрите на i  ntention Head of Burt, и

1602
00:57:00,640 --> 00:57:01,839
вы говорите,

1603
00:57:01,839 --> 00:57:03,599
что знаете, что в большинстве предложений у этой

1604
00:57:03,599 --> 00:57:05,760
внимательной головы была одна, которая, кажется, выполняет

1605
00:57:05,760 --> 00:57:08,319
такого рода глобальную агрегацию,

1606
00:57:08,319 --> 00:57:10,319
простая операция делает это

1607
00:57:10,319 --> 00:57:13,920
довольно последовательно, это круто, гм, это хорошо

1608
00:57:13,920 --> 00:57:15,760
интерпретируемо,

1609
00:57:15,760 --> 00:57:17,440


1610
00:57:17,440 --> 00:57:19,839
может быть, правильно, так что это первый слой,

1611
00:57:19,839 --> 00:57:22,079
который  означает, что это найденное

1612
00:57:22,079 --> 00:57:24,799
слово неконтекстуализировано,

1613
00:57:24,799 --> 00:57:27,359
а затем, вы знаете, но на более глубоких

1614
00:57:27,359 --> 00:57:30,960
уровнях проблема в том, что, как только вы

1615
00:57:30,960 --> 00:57:33,200
делаете несколько раундов внимания, у вас есть

1616
00:57:33,200 --> 00:57:35,920
информация, смешивающаяся и перетекающая между

1617
00:57:35,920 --> 00:57:38,319
словами, и как вы точно знаете, какую

1618
00:57:38,319 --> 00:57:40,160
информацию вы?  повторное объединение того, чем вы

1619
00:57:40,160 --> 00:57:42,960
занимаетесь, даже если это немного сложно

1620
00:57:42,960 --> 00:57:44,400
сказать,

1621
00:57:44,400 --> 00:57:47,520
и методы выделения более прямо как

1622
00:57:47,520 --> 00:57:50,079
бы оценивают важность моделей, но

1623
00:57:50,079 --> 00:57:51,839
все же интересно увидеть,

1624
00:57:51,839 --> 00:57:53,760
с какой-то местной механистической точки

1625
00:57:53,760 --> 00:57:55,280
зрения, какие вещи используются

1626
00:57:55,280 --> 00:57:57,040


1627
00:57:57,040 --> 00:57:59,680
Итак, давайте возьмем еще один пример, некоторые

1628
00:57:59,680 --> 00:58:01,760
главы внимания, кажется, выполняют простые

1629
00:58:01,760 --> 00:58:03,200
операции, поэтому у вас есть глобальная

1630
00:58:03,200 --> 00:58:05,359
агрегация здесь, которую мы уже видели, как

1631
00:58:05,359 --> 00:58:07,839
другие  em, чтобы довольно активно следить

1632
00:58:07,839 --> 00:58:10,640
за следующим токеном, крутой следующий токен -

1633
00:58:10,640 --> 00:58:12,960
отличный сигнал, что некоторые руководители

1634
00:58:12,960 --> 00:58:14,480
обращают внимание на токен sep,

1635
00:58:14,480 --> 00:58:16,880
так что здесь вы уделяете внимание sep, а

1636
00:58:16,880 --> 00:58:18,880
затем, может быть, некоторые уделяют внимание периодам, может быть

1637
00:58:18,880 --> 00:58:20,640
,

1638
00:58:20,640 --> 00:58:22,160
вы знаете, что разделение предложений вместе

1639
00:58:22,160 --> 00:58:23,839
и тому подобное  это не то, что

1640
00:58:23,839 --> 00:58:25,520
трудно сделать, но вещи, которые некоторые

1641
00:58:25,520 --> 00:58:27,280
головы внимания, кажется, довольно надежно

1642
00:58:27,280 --> 00:58:29,040
выполняют

1643
00:58:29,040 --> 00:58:30,400


1644
00:58:30,400 --> 00:58:32,240
сейчас снова, хотя глубоко в сети,

1645
00:58:32,240 --> 00:58:33,680
что на самом деле представлено в этот

1646
00:58:33,680 --> 00:58:35,200
период на

1647
00:58:35,200 --> 00:58:37,520
уровне 11,

1648
00:58:37,520 --> 00:58:41,200
немного неясно, немного неясно, хорошо,

1649
00:58:41,200 --> 00:58:42,400
поэтому

1650
00:58:42,400 --> 00:58:43,920
некоторые головы, хотя и связаны  с

1651
00:58:43,920 --> 00:58:45,839
действительно интересными лингвистическими свойствами,

1652
00:58:45,839 --> 00:58:48,319
так что эта глава на самом деле занимается

1653
00:58:48,319 --> 00:58:50,640
модификаторами существительных, так что у вас есть этот

1654
00:58:50,640 --> 00:58:52,079
сложный

1655
00:58:52,079 --> 00:58:53,440
язык

1656
00:58:53,440 --> 00:58:55,359
в огромном новом

1657
00:58:55,359 --> 00:58:56,720
законе,

1658
00:58:56,720 --> 00:58:59,839
верно, что довольно увлекательно,

1659
00:58:59,839 --> 00:59:01,839
даже если модель не похожа на то,

1660
00:59:01,839 --> 00:59:04,160
чтобы делать это как причинный механизм для

1661
00:59:04,160 --> 00:59:06,480
синтаксиса, обязательно  Тот факт, что эти

1662
00:59:06,480 --> 00:59:08,559
вещи так сильно коррелируют, на самом деле

1663
00:59:08,559 --> 00:59:10,799
довольно круто, и поэтому во

1664
00:59:10,799 --> 00:59:12,640
всех этих исследованиях у нас есть своего рода  n

1665
00:59:12,640 --> 00:59:14,240
приблизительная интерпретация и

1666
00:59:14,240 --> 00:59:16,319
количественный анализ,

1667
00:59:16,319 --> 00:59:18,880
связанный, например, позволяющий нам рассуждать

1668
00:59:18,880 --> 00:59:21,520
об очень сложном поведении модели

1669
00:59:21,520 --> 00:59:23,119
, все они являются приближениями, но

1670
00:59:23,119 --> 00:59:24,799
они определенно интересны. Еще

1671
00:59:24,799 --> 00:59:26,640
один пример - это совместная ссылка, поэтому

1672
00:59:26,640 --> 00:59:29,839
мы видели некоторую работу по совместной работе.  ref ссылка и

1673
00:59:29,839 --> 00:59:32,240
эм, кажется, эта голова довольно

1674
00:59:32,240 --> 00:59:35,440
хорошо справляется с фактическим сопоставлением

1675
00:59:35,440 --> 00:59:38,799
со-референтных сущностей, они в красных

1676
00:59:38,799 --> 00:59:42,319
переговорах, переговоры она ее, и это

1677
00:59:42,319 --> 00:59:44,000
не очевидно, как это сделать, это

1678
00:59:44,000 --> 00:59:46,640
сложная задача, и поэтому она делает, чтобы вы

1679
00:59:46,640 --> 00:59:48,720
знали  с некоторым процентом времени

1680
00:59:48,720 --> 00:59:49,839
um,

1681
00:59:49,839 --> 00:59:51,440
и снова это своего рода соединение очень

1682
00:59:51,440 --> 00:59:53,680
сложного поведения модели с

1683
00:59:53,680 --> 00:59:54,720
uh

1684
00:59:54,720 --> 00:59:57,280
с такими интерпретируемыми

1685
00:59:57,280 --> 01:00:00,160
сводками коррелирующих uh свойств.В

1686
01:00:00,160 --> 01:00:01,760
других случаях у вас могут быть отдельные

1687
01:00:01,760 --> 01:00:03,200
скрытые единицы, которые поддаются

1688
01:00:03,200 --> 01:00:04,400
интерпретации,

1689
01:00:04,400 --> 01:00:05,680
так что

1690
01:00:05,680 --> 01:00:08,000
здесь у вас есть персонаж  уровень

1691
01:00:08,000 --> 01:00:10,160
языковой модели lstm

1692
01:00:10,160 --> 01:00:12,319
каждая строка здесь представляет собой предложение, если вы не можете

1693
01:00:12,319 --> 01:00:14,079
его прочитать, это нормально,

1694
01:00:14,079 --> 01:00:15,359
интерпретация, которую вы должны принять, заключается в

1695
01:00:15,359 --> 01:00:17,680
том, что когда мы идем в одиночестве  g предложение, которое этот

1696
01:00:17,680 --> 01:00:20,480
единый блок меняется от

1697
01:00:20,480 --> 01:00:22,480
очень отрицательного к очень положительному или от очень

1698
01:00:22,480 --> 01:00:24,720
положительного к очень отрицательному, я действительно не

1699
01:00:24,720 --> 01:00:26,240
помню,

1700
01:00:26,240 --> 01:00:28,000
но вы знаете, что отслеживание положения

1701
01:00:28,000 --> 01:00:29,920
в строке,

1702
01:00:29,920 --> 01:00:32,000
так что это просто единица линейного положения и

1703
01:00:32,000 --> 01:00:32,799


1704
01:00:32,799 --> 01:00:34,640
довольно надежно работает  Итак, во всех

1705
01:00:34,640 --> 01:00:36,400
этих предложениях,

1706
01:00:36,400 --> 01:00:38,559
так что это из хорошего

1707
01:00:38,559 --> 01:00:41,760
исследования визуализации еще в 2016 году,

1708
01:00:41,760 --> 01:00:43,920
вот еще одна ячейка из той же

1709
01:00:43,920 --> 01:00:45,920
языковой модели lstm, которая вроде как

1710
01:00:45,920 --> 01:00:47,440
включается

1711
01:00:47,440 --> 01:00:49,920
внутри кавычек, вот цитата,

1712
01:00:49,920 --> 01:00:51,440
и она включается хорошо, так что я думаю  это

1713
01:00:51,440 --> 01:00:52,960
положительно в синей

1714
01:00:52,960 --> 01:00:55,359
конечной цитате здесь,

1715
01:00:55,359 --> 01:00:57,040
а затем отрицательно,

1716
01:00:57,040 --> 01:00:59,440
здесь вы начинаете без кавычек,

1717
01:00:59,440 --> 01:01:02,240
отрицательно в красном, видите цитату,

1718
01:01:02,240 --> 01:01:04,640
а затем синий кажется снова очень

1719
01:01:04,640 --> 01:01:06,720
интерпретируемым, также потенциально очень

1720
01:01:06,720 --> 01:01:08,079
полезной функцией, о которой следует помнить, и

1721
01:01:08,079 --> 01:01:10,079
это всего лишь отдельная единица в  lstm, на

1722
01:01:10,079 --> 01:01:11,760
который вы можете просто взглянуть и увидеть, что

1723
01:01:11,760 --> 01:01:15,760
он делает это очень, очень интересно,

1724
01:01:17,520 --> 01:01:19,280
даже дальше, и это на

1725
01:01:19,280 --> 01:01:22,720
самом деле исследование некоторых

1726
01:01:22,720 --> 01:01:26,000
исследователей искусственного интеллекта и нейробиологии, хорошо,

1727
01:01:26,000 --> 01:01:27,680
мы видели, что  t lstms были хороши в

1728
01:01:27,680 --> 01:01:30,000
согласовании количества подлежащих глаголов um можем ли мы

1729
01:01:30,000 --> 01:01:31,839
выяснить механизмы, с помощью которых lstm

1730
01:01:31,839 --> 01:01:33,359
решает задачу, можем ли мы действительно получить

1731
01:01:33,359 --> 01:01:35,520
некоторое представление об этом, и, таким образом, у нас есть

1732
01:01:35,520 --> 01:01:37,520


1733
01:01:37,520 --> 01:01:39,359
языковая модель на уровне слов,

1734
01:01:39,359 --> 01:01:40,720
которая будет  немного маленькое, но у вас есть

1735
01:01:40,720 --> 01:01:43,200
фраза, которую мальчик нежно и любезно

1736
01:01:43,200 --> 01:01:45,280
приветствует,

1737
01:01:45,280 --> 01:01:47,680
и эта ячейка, которая отслеживается здесь,

1738
01:01:47,680 --> 01:01:50,400
так что это отдельная скрытая единица ммм в одном

1739
01:01:50,400 --> 01:01:53,440
измерении, на самом деле после того, как она

1740
01:01:53,440 --> 01:01:56,720
видит мальчика, она вроде начинает подниматься

1741
01:01:56,720 --> 01:01:59,599
выше, а затем снижается  к

1742
01:01:59,599 --> 01:02:02,160
чему-то очень маленькому, как только он видит приветствие,

1743
01:02:02,160 --> 01:02:04,559
и эта ячейка, кажется, эффективно коррелирует

1744
01:02:04,559 --> 01:02:07,119
с областью действия экземпляра согласования числа подлежащих глаголов,

1745
01:02:07,119 --> 01:02:08,400


1746
01:02:08,400 --> 01:02:10,400
поэтому здесь мальчик,

1747
01:02:10,400 --> 01:02:12,160
который наблюдает за собакой, которая смотрит на

1748
01:02:12,160 --> 01:02:13,680
кошку, приветствует,

1749
01:02:13,680 --> 01:02:16,400
у вас эта ячейка снова остается высокой,

1750
01:02:16,400 --> 01:02:18,799
сохраняя объем  темы, пока не

1751
01:02:18,799 --> 01:02:21,680
поприветствует, и в этот момент он останавливается,

1752
01:02:21,680 --> 01:02:24,000
что позволяет ему это делать, возможно, некоторые

1753
01:02:24,000 --> 01:02:25,839
сложные другие

1754
01:02:25,839 --> 01:02:27,760
динамики в сети, но это все еще

1755
01:02:27,760 --> 01:02:30,559
захватывающая, я думаю, понимание

1756
01:02:30,559 --> 01:02:34,760
эм и да  ах, это просто вы знаете нейрон

1757
01:02:34,760 --> 01:02:38,480
1150 в этом lstm,

1758
01:02:38,480 --> 01:02:39,680


1759
01:02:39,680 --> 01:02:41,920
так что это вроде всех наблюдательных

1760
01:02:41,920 --> 01:02:44,880
исследований, которые вы могли бы провести

1761
01:02:45,280 --> 01:02:47,039
, выбрав отдельные

1762
01:02:47,039 --> 01:02:49,039
компоненты модели, которые вы можете как бы просто взять

1763
01:02:49,039 --> 01:02:50,160
каждый из них

1764
01:02:50,160 --> 01:02:51,200
и

1765
01:02:51,200 --> 01:02:55,440
сопоставить их с некоторым поведением, теперь

1766
01:02:55,520 --> 01:02:56,960
мы  Мы рассмотрим общий класс методов,

1767
01:02:56,960 --> 01:02:58,240
называемых зондированием, с

1768
01:02:58,240 --> 01:03:01,760
помощью которых мы все еще как бы используем контролируемые

1769
01:03:01,760 --> 01:03:03,440
знания, такие

1770
01:03:03,440 --> 01:03:05,599
как знание типа

1771
01:03:05,599 --> 01:03:07,200
совместной ссылки, которую мы ищем, но

1772
01:03:07,200 --> 01:03:08,720
вместо того, чтобы видеть, коррелирует ли она с

1773
01:03:08,720 --> 01:03:09,680
чем-то, что можно сразу

1774
01:03:09,680 --> 01:03:12,480
интерпретировать как

1775
01:03:12,480 --> 01:03:14,480
Мы собираемся

1776
01:03:14,480 --> 01:03:16,640
изучить векторные представления модели

1777
01:03:16,640 --> 01:03:18,400
и посмотреть, могут ли эти свойства быть

1778
01:03:18,400 --> 01:03:21,119
прочитаны какой-нибудь простой функцией,

1779
01:03:21,119 --> 01:03:23,920
чтобы сказать: ах, возможно, это свойство было

1780
01:03:23,920 --> 01:03:26,240
очень легко доступно моей нейронной

1781
01:03:26,240 --> 01:03:28,640
сети, поэтому давайте углубимся в это,

1782
01:03:28,640 --> 01:03:30,640
чтобы  Общая парадигма состоит в том, что у вас

1783
01:03:30,640 --> 01:03:33,359
есть языковые данные, которые передаются в какой-то

1784
01:03:33,359 --> 01:03:35,359
большой предварительно обученный преобразователь с

1785
01:03:35,359 --> 01:03:37,599
тонкой настройкой, и вы получаете самые современные

1786
01:03:37,599 --> 01:03:40,400
результаты, ну, газировка означает современное состояние.  искусство

1787
01:03:40,400 --> 01:03:41,839
правильно, и поэтому вопрос

1788
01:03:41,839 --> 01:03:45,280
о методологии зондирования такой, как если бы

1789
01:03:45,280 --> 01:03:46,880
он предоставлял эти языковые представления общего назначения,

1790
01:03:46,880 --> 01:03:49,760
вы знаете,

1791
01:03:49,760 --> 01:03:51,119
что он на самом деле кодирует в

1792
01:03:51,119 --> 01:03:52,160
языке,

1793
01:03:52,160 --> 01:03:53,200
например,

1794
01:03:53,200 --> 01:03:54,799
можем ли мы количественно оценить это можем ли мы

1795
01:03:54,799 --> 01:03:56,079
выяснить, какие вещи

1796
01:03:56,079 --> 01:03:57,440
изучаются о языке  что нам,

1797
01:03:57,440 --> 01:04:00,319
похоже, теперь не нужно это рассказывать,

1798
01:04:00,319 --> 01:04:03,039
и у вас может быть что-то

1799
01:04:03,039 --> 01:04:06,240
вроде предложения, например, я записываю запись,

1800
01:04:06,240 --> 01:04:08,079
которая представляет собой интересное предложение, и вы

1801
01:04:08,079 --> 01:04:11,039
вставляете ее в свою модель трансформатора

1802
01:04:11,039 --> 01:04:12,480
с ее вложениями слов

1803
01:04:12,480 --> 01:04:14,559
в начале, может быть,  несколько слоев

1804
01:04:14,559 --> 01:04:16,559
самовнимания и прочее, и вы делаете

1805
01:04:16,559 --> 01:04:19,039
некоторые прогнозы, и теперь нашими объектами

1806
01:04:19,039 --> 01:04:20,880
исследования будут эти промежуточные

1807
01:04:20,880 --> 01:04:22,160
слои,

1808
01:04:22,160 --> 01:04:24,240
так что это вектор на

1809
01:04:24,240 --> 01:04:26,880
слово или подслово для каждого слоя,

1810
01:04:26,880 --> 01:04:28,720
и вопрос в том, можем ли мы использовать

1811
01:04:28,720 --> 01:04:30,720
эти лингвистические  свойства, такие как

1812
01:04:30,720 --> 01:04:33,039
синтаксический анализ зависимостей, который у нас был еще

1813
01:04:33,039 --> 01:04:35,440
в начале курса, чтобы

1814
01:04:35,440 --> 01:04:38,400
понять, что-то вроде корреляции

1815
01:04:38,400 --> 01:04:40,480
между

1816
01:04:40,480 --> 01:04:42,480
свойствами и вектором  rs и те

1817
01:04:42,480 --> 01:04:44,240
вещи, которые мы можем интерпретировать, мы можем

1818
01:04:44,240 --> 01:04:47,839
интерпретировать синтаксический анализ зависимостей,

1819
01:04:47,839 --> 01:04:49,680
поэтому есть пара вещей, которые

1820
01:04:49,680 --> 01:04:51,520
мы могли бы найти здесь,

1821
01:04:51,520 --> 01:04:53,760
вы можете захотеть найти семантику, поэтому

1822
01:04:53,760 --> 01:04:55,920
здесь, в предложении, я записываю запись,

1823
01:04:55,920 --> 01:04:59,039
я - агент  это семантическая

1824
01:04:59,039 --> 01:05:00,799
вещь,

1825
01:05:00,799 --> 01:05:02,480
запись о пациенте, это то, что я

1826
01:05:02,480 --> 01:05:05,200
записываю, хорошо, у вас может быть синтаксис, поэтому у

1827
01:05:05,200 --> 01:05:06,640
вас может быть синтаксическое дерево, которое

1828
01:05:06,640 --> 01:05:07,520
вас интересует, это

1829
01:05:07,520 --> 01:05:09,119
дерево синтаксического анализа зависимостей,

1830
01:05:09,119 --> 01:05:10,079
возможно, вас интересует часть

1831
01:05:10,079 --> 01:05:13,200
речи, потому что  у вас есть запись,

1832
01:05:13,200 --> 01:05:16,000
и запись, и первая - это глагол,

1833
01:05:16,000 --> 01:05:17,440
вторая - существительное, они

1834
01:05:17,440 --> 01:05:20,160
идентичны, строки, кодирует ли модель как бы то,

1835
01:05:20,160 --> 01:05:22,240
что одно - одно, а другое

1836
01:05:22,240 --> 01:05:24,559
- другое. Итак, как мы проводим

1837
01:05:24,559 --> 01:05:26,960
такое исследование?  гм, поэтому мы собираемся

1838
01:05:26,960 --> 01:05:29,200
выбрать слой, который мы хотим проанализировать,

1839
01:05:29,200 --> 01:05:31,280
и мы собираемся заморозить его, мы

1840
01:05:31,280 --> 01:05:32,720
не собираемся точно настраивать птицу, все

1841
01:05:32,720 --> 01:05:34,559
параметры заморожены,

1842
01:05:34,559 --> 01:05:36,720
поэтому мы выбираем второй слой, который мы '  мы

1843
01:05:36,720 --> 01:05:38,799
собираемся передать ему несколько предложений, которые мы решим

1844
01:05:38,799 --> 01:05:41,760
на  то, что называется семейством датчиков,

1845
01:05:41,760 --> 01:05:45,440
и вопрос, который я задаю, - могу ли я

1846
01:05:45,440 --> 01:05:47,839
использовать модель из моей семьи, скажем, линейную, для

1847
01:05:47,839 --> 01:05:51,680
декодирования свойства, которое меня действительно интересует,

1848
01:05:51,680 --> 01:05:53,599
из этого слоя

1849
01:05:53,599 --> 01:05:54,559
, что

1850
01:05:54,559 --> 01:05:56,720
указывает на то, что это свойство легко

1851
01:05:56,720 --> 01:05:58,480
доступно для

1852
01:05:58,480 --> 01:06:01,039
линейных моделей  эффективно, так что, может быть,

1853
01:06:01,039 --> 01:06:03,200
я тренирую модель, я тренирую линейный

1854
01:06:03,200 --> 01:06:05,760
классификатор прямо на берте,

1855
01:06:05,760 --> 01:06:07,599
и я получаю действительно высокую

1856
01:06:07,599 --> 01:06:09,680
точность, и это уже интересно,

1857
01:06:09,680 --> 01:06:11,920
потому что вы знаете

1858
01:06:11,920 --> 01:06:13,440
из предыдущей работы и части речевых

1859
01:06:13,440 --> 01:06:14,880
тегов, что если вы запустите линейный

1860
01:06:14,880 --> 01:06:17,280
классификатор  на более простых функциях,

1861
01:06:17,280 --> 01:06:19,280
которые не сгорят, вы, вероятно, не получите такой

1862
01:06:19,280 --> 01:06:20,400
высокой точности, так что

1863
01:06:20,400 --> 01:06:22,400
это интересный вывод, но тогда

1864
01:06:22,400 --> 01:06:24,400
вы также можете взять в качестве основы, поэтому я

1865
01:06:24,400 --> 01:06:26,079
хочу сравнить два слоя сейчас, так что у меня

1866
01:06:26,079 --> 01:06:28,160
есть слой один здесь  Я хочу сравнить его

1867
01:06:28,160 --> 01:06:29,440
со вторым слоем,

1868
01:06:29,440 --> 01:06:32,559
я тренирую на нем зонд, возможно,

1869
01:06:32,559 --> 01:06:35,200
точность не так хороша, и теперь я могу сказать,

1870
01:06:35,200 --> 01:06:39,119
вау, посмотрите на уровень 2, часть речи

1871
01:06:39,119 --> 01:06:40,960
более доступна для линейных

1872
01:06:40,960 --> 01:06:44,240
функций, чем на уровне  1.

1873
01:06:44,240 --> 01:06:46,160
ну и что  сделали это хорошо,

1874
01:06:46,160 --> 01:06:48,000
самовнимание и прямая связь сделали его более

1875
01:06:48,000 --> 01:06:49,839
доступным, это интересно,

1876
01:06:49,839 --> 01:06:51,200
потому что это утверждение о

1877
01:06:51,200 --> 01:06:55,039
том, как обрабатывается информация в модели.

1878
01:06:55,039 --> 01:06:56,640


1879
01:06:56,640 --> 01:06:58,559


1880
01:06:58,559 --> 01:07:01,119


1881
01:07:01,119 --> 01:07:02,480
об этом

1882
01:07:02,480 --> 01:07:05,760
и просто дайте мне всего секунду,

1883
01:07:05,760 --> 01:07:06,960
поэтому, если у вас есть представления модели от

1884
01:07:06,960 --> 01:07:10,000
h1 до ht

1885
01:07:10,000 --> 01:07:12,240
и у вас есть семейство функций f, которое

1886
01:07:12,240 --> 01:07:14,079
является подмножеством линейных моделей или, может быть, у вас

1887
01:07:14,079 --> 01:07:16,400
есть как нейронная сеть с прямой связью,

1888
01:07:16,400 --> 01:07:18,559
какой-то фиксированный набор гиперпараметров

1889
01:07:18,559 --> 01:07:20,000
замораживает  модель

1890
01:07:20,000 --> 01:07:22,000
обучить зонд, чтобы вы получили некоторые

1891
01:07:22,000 --> 01:07:23,839
прогнозы для части речевого тегирования

1892
01:07:23,839 --> 01:07:26,240
или чего-то еще, что это просто зонд,

1893
01:07:26,240 --> 01:07:28,319
применяемый к скрытому состоянию модели,

1894
01:07:28,319 --> 01:07:29,760
зонд был членом семейства зондов,

1895
01:07:29,760 --> 01:07:30,799


1896
01:07:30,799 --> 01:07:32,799
а затем степень, в которой мы можем предсказать,

1897
01:07:32,799 --> 01:07:34,640
почему является мерой  доступность, так

1898
01:07:34,640 --> 01:07:36,319
что это просто написано не так

1899
01:07:36,319 --> 01:07:38,319
наглядно,

1900
01:07:38,319 --> 01:07:39,599
так что я не собираюсь

1901
01:07:39,599 --> 01:07:40,640


1902
01:07:40,640 --> 01:07:43,839
останавливаться на этом слишком долго,

1903
01:07:44,079 --> 01:07:45,200
и

1904
01:07:45,200 --> 01:07:46,720
вы знаете, что это может помочь в поиске  ch для

1905
01:07:46,720 --> 01:07:48,319
причинных механизмов,

1906
01:07:48,319 --> 01:07:49,839
но это просто дает нам приблизительное

1907
01:07:49,839 --> 01:07:51,280
представление о том, как

1908
01:07:51,280 --> 01:07:53,039
обрабатывается модель и какие

1909
01:07:53,039 --> 01:07:55,200
вещи доступны на каком уровне,

1910
01:07:55,200 --> 01:07:57,359
так каковы некоторые результаты здесь, так что одним из

1911
01:07:57,359 --> 01:07:59,280
результатов является то, что

1912
01:07:59,280 --> 01:08:02,079
bert, если вы запустите линейные зонды на нем,

1913
01:08:02,079 --> 01:08:03,760
действительно  действительно хорошо в вещах,

1914
01:08:03,760 --> 01:08:06,240
требующих синтаксиса и части речи, называемой

1915
01:08:06,240 --> 01:08:08,240
распознаванием сущностей, на самом деле в некоторых

1916
01:08:08,240 --> 01:08:10,480
случаях примерно так же хорошо, как просто

1917
01:08:10,480 --> 01:08:12,400
делать самое лучшее, что вы могли бы

1918
01:08:12,400 --> 01:08:13,680
обойтись

1919
01:08:13,680 --> 01:08:16,000
без bert, поэтому он просто делает

1920
01:08:16,000 --> 01:08:17,920
легко доступными удивительно сильные

1921
01:08:17,920 --> 01:08:20,000
функции для этих свойств, и

1922
01:08:20,000 --> 01:08:21,839
это  интересный вид

1923
01:08:21,839 --> 01:08:25,839
эмерджентного качества бурта, вы можете сказать, что

1924
01:08:25,839 --> 01:08:27,839
это похоже на то, что слои

1925
01:08:27,839 --> 01:08:29,279
берта

1926
01:08:29,279 --> 01:08:31,439
обладают этим свойством, поэтому, если вы посмотрите

1927
01:08:31,439 --> 01:08:33,920
на столбцы этого

1928
01:08:33,920 --> 01:08:36,880
графика, здесь каждый столбец представляет собой задачу,

1929
01:08:36,880 --> 01:08:39,520
у вас есть входные слова на  вид

1930
01:08:39,520 --> 01:08:42,000
нулевого слоя альберт здесь слой 24 является

1931
01:08:42,000 --> 01:08:43,920
последним слоем бора при большой

1932
01:08:43,920 --> 01:08:45,439
более низкой производительности - желтый более высокая

1933
01:08:45,439 --> 01:08:48,640
производительность - синий и io

1934
01:08:48,640 --> 01:08:50,640
разрешение не идеальное, но

1935
01:08:50,640 --> 01:08:52,960
совместное  Поистине, лучшее место для считывания

1936
01:08:52,960 --> 01:08:54,799
этих свойств - это где-то немного

1937
01:08:54,799 --> 01:08:56,399
дальше середины

1938
01:08:56,399 --> 01:08:58,479
модели, а это очень последовательное

1939
01:08:58,479 --> 01:09:00,238
правило, которое увлекательно,

1940
01:09:00,238 --> 01:09:01,040


1941
01:09:01,040 --> 01:09:04,000
а потом кажется, что если вы

1942
01:09:04,000 --> 01:09:06,560
посмотрите на эту функцию все более

1943
01:09:06,560 --> 01:09:08,399
абстрактной или  становится все труднее

1944
01:09:08,399 --> 01:09:10,399
вычислять лингвистические свойства по этой

1945
01:09:10,399 --> 01:09:12,640
оси и увеличивать глубину сети

1946
01:09:12,640 --> 01:09:14,158
по этой оси,

1947
01:09:14,158 --> 01:09:16,640
поэтому чем глубже вы заходите в сеть

1948
01:09:16,640 --> 01:09:18,560
, тем

1949
01:09:18,560 --> 01:09:21,520
легче получить доступ к все более и более

1950
01:09:21,520 --> 01:09:23,600
абстрактным лингвистическим свойствам,

1951
01:09:23,600 --> 01:09:26,319
предполагая, что эта доступность

1952
01:09:26,319 --> 01:09:28,238
создается с течением времени

1953
01:09:28,238 --> 01:09:30,158
слоями обработки bert, так что он создает все

1954
01:09:30,158 --> 01:09:32,719
больше и больше абстрактных функций,

1955
01:09:32,719 --> 01:09:34,640
которые, я думаю, снова в некотором роде действительно

1956
01:09:34,640 --> 01:09:36,640
интересный результат

1957
01:09:36,640 --> 01:09:39,279
, и теперь я думаю,

1958
01:09:39,279 --> 01:09:41,439
да, одна вещь, которая, как мне кажется, приходит в

1959
01:09:41,439 --> 01:09:44,000
голову, которая действительно возвращает нас прямо

1960
01:09:44,000 --> 01:09:45,359
в первый день,

1961
01:09:45,359 --> 01:09:48,080
это  эм, мы строили интуицию вокруг слова к

1962
01:09:48,080 --> 01:09:49,920
спине, мы спрашивали, что означает каждое

1963
01:09:49,920 --> 01:09:51,520
измерение слова в век, и

1964
01:09:51,520 --> 01:09:53,359
ответ был, ну, на самом деле, не ре

1965
01:09:53,359 --> 01:09:55,520
что угодно, но мы могли бы

1966
01:09:55,520 --> 01:09:57,199
строить интуитивные представления об этом и думать

1967
01:09:57,199 --> 01:09:59,679
о его свойствах через своего рода

1968
01:09:59,679 --> 01:10:01,199
эти связи между простыми

1969
01:10:01,199 --> 01:10:04,159
математическими свойствами слова для вектора

1970
01:10:04,159 --> 01:10:06,080
и лингвистическими свойствами, которые мы могли бы

1971
01:10:06,080 --> 01:10:07,840
вроде бы понять,

1972
01:10:07,840 --> 01:10:10,400
поэтому у нас было это приближение, но

1973
01:10:10,400 --> 01:10:12,239
не 100 истинное, а приближение  который

1974
01:10:12,239 --> 01:10:15,360
говорит, что косинусное

1975
01:10:15,360 --> 01:10:17,040
сходство эффективно

1976
01:10:17,040 --> 01:10:20,880
коррелирует с семантическим сходством,

1977
01:10:22,239 --> 01:10:23,440
подумайте, даже если все, что мы собираемся

1978
01:10:23,440 --> 01:10:25,360
сделать в конце дня, это все равно точно настроить

1979
01:10:25,360 --> 01:10:28,159
эти вложения слов, так же

1980
01:10:28,159 --> 01:10:29,760
у нас было такое представление о

1981
01:10:29,760 --> 01:10:31,600
аналогиях, кодируемых линейными

1982
01:10:31,600 --> 01:10:33,920
смещениями  так что некоторые

1983
01:10:33,920 --> 01:10:35,920
отношения линейны в пространстве,

1984
01:10:35,920 --> 01:10:38,239
и они не обязательно должны быть

1985
01:10:38,239 --> 01:10:40,159
увлекательными. Это возникающее свойство,

1986
01:10:40,159 --> 01:10:41,840
которое мы теперь можем изучить с тех пор, как

1987
01:10:41,840 --> 01:10:44,159
мы выяснили, почему так обстоит дело

1988
01:10:44,159 --> 01:10:46,880
в словах к вектору и в целом, даже

1989
01:10:46,880 --> 01:10:47,760
если вы можете  не интерпретируют

1990
01:10:47,760 --> 01:10:50,800
отдельные измерения слова, чтобы поддержать

1991
01:10:50,800 --> 01:10:53,199
такого рода возникающие интерпретируемые

1992
01:10:53,199 --> 01:10:54,880
связи между

1993
01:10:54,880 --> 01:10:57,199
приблизительными лингвистическими идеями и  Такая

1994
01:10:57,199 --> 01:10:59,280
простая математика над этими объектами

1995
01:10:59,280 --> 01:11:02,159
увлекательна, и одна часть работы,

1996
01:11:02,159 --> 01:11:04,880
которая расширяет эту идею,

1997
01:11:04,880 --> 01:11:06,640
возвращается к деревьям разбора зависимостей, так что они

1998
01:11:06,640 --> 01:11:09,440
описывают синтаксис предложений и

1999
01:11:09,440 --> 01:11:12,239
в статье, которую я сделал с помощью

2000
01:11:12,239 --> 01:11:13,300
chris um

2001
01:11:13,300 --> 01:11:14,400
[Музыка]

2002
01:11:14,400 --> 01:11:16,560
мы показали, что на самом деле bert и

2003
01:11:16,560 --> 01:11:18,960
подобные ему модели делают возникающую структуру дерева синтаксического анализа зависимостей

2004
01:11:18,960 --> 01:11:22,560
более

2005
01:11:22,560 --> 01:11:25,040
доступной, чем можно представить

2006
01:11:25,040 --> 01:11:26,480
в его векторном пространстве,

2007
01:11:26,480 --> 01:11:28,400
поэтому, если у вас есть дерево прямо здесь,

2008
01:11:28,400 --> 01:11:29,920
повар, который арендовал магазин, был  без

2009
01:11:29,920 --> 01:11:32,320
еды

2010
01:11:32,560 --> 01:11:35,040
то, что вы можете сделать, это подумать

2011
01:11:35,040 --> 01:11:36,800
о дереве с точки зрения

2012
01:11:36,800 --> 01:11:39,600
расстояний между словами, чтобы у вас было

2013
01:11:39,600 --> 01:11:42,640
количество ребер в дереве между

2014
01:11:42,640 --> 01:11:44,159
двумя словами, это расстояние их пути, так

2015
01:11:44,159 --> 01:11:45,440
что у вас есть что-то вроде этого расстояния

2016
01:11:45,440 --> 01:11:48,320
между  chef and was - одно, и мы

2017
01:11:48,320 --> 01:11:49,920
собираемся использовать эту интерпретацию

2018
01:11:49,920 --> 01:11:52,560
дерева как расстояния, чтобы установить связь

2019
01:11:52,560 --> 01:11:55,040
с пространством вложения Берта, и мы

2020
01:11:55,040 --> 01:11:57,360
смогли показать, что при одном

2021
01:11:57,360 --> 01:11:59,520
линейном

2022
01:11:59,520 --> 01:12:01,600
преобразовании квадрат евклидова расстояния будет

2023
01:12:01,600 --> 01:12:04,719
Между векторами Берта для одного и того же предложения на

2024
01:12:04,719 --> 01:12:07,600
самом деле хорошо коррелирует, если вы выберете

2025
01:12:07,600 --> 01:12:09,760
матрицу b прямо

2026
01:12:09,760 --> 01:12:13,040
с расстояниями в дереве, поэтому здесь,

2027
01:12:13,040 --> 01:12:14,560
в этом евклидовом пространстве, которое мы

2028
01:12:14,560 --> 01:12:16,320


2029
01:12:16,320 --> 01:12:18,000
преобразовали приблизительное расстояние между шеф-поваром

2030
01:12:18,000 --> 01:12:20,880
и было, также есть

2031
01:12:20,880 --> 01:12:22,880
разница между was и

2032
01:12:22,880 --> 01:12:25,760
store - четыре в дереве,

2033
01:12:25,760 --> 01:12:28,159
и в моем простом виде преобразования

2034
01:12:28,159 --> 01:12:31,360
пространства bert расстояние между store

2035
01:12:31,360 --> 01:12:33,360
и was также составляет примерно четыре, и

2036
01:12:33,360 --> 01:12:35,280
это верно для широкого диапазона

2037
01:12:35,280 --> 01:12:37,840
предложений, и для меня это как

2038
01:12:37,840 --> 01:12:39,040
захватывающий

2039
01:12:39,040 --> 01:12:41,679
пример снова возникающей приблизительной

2040
01:12:41,679 --> 01:12:43,920
структуры  в этих очень нелинейных

2041
01:12:43,920 --> 01:12:46,000
моделях, которые не обязательно должны

2042
01:12:46,000 --> 01:12:48,719
кодировать вещи, так что просто

2043
01:12:48,719 --> 01:12:51,120
хорошо, хорошо,

2044
01:12:51,120 --> 01:12:52,400


2045
01:12:52,400 --> 01:12:54,480
отлично, так что

2046
01:12:54,480 --> 01:12:56,640
пробные исследования и корреляционные исследования

2047
01:12:56,640 --> 01:12:58,719
, я думаю, интересны и указывают нам

2048
01:12:58,719 --> 01:13:00,320
направления для построения интуитивных представлений о

2049
01:13:00,320 --> 01:13:01,600
моделях,

2050
01:13:01,600 --> 01:13:03,360
но они не аргументы, которые

2051
01:13:03,360 --> 01:13:04,800
модель фактически использует то, что вы

2052
01:13:04,800 --> 01:13:07,040
обнаружите, для принятия решения, а

2053
01:13:07,040 --> 01:13:09,840
не причинно-следственные связи,

2054
01:13:09,840 --> 01:13:11,280
это для исследования и изучения

2055
01:13:11,280 --> 01:13:12,640
корреляции  Поэтому

2056
01:13:12,640 --> 01:13:14,719
в некоторых работах, которые я проделал

2057
01:13:14,719 --> 01:13:16,640
примерно в то же время, мы фактически показали,

2058
01:13:16,640 --> 01:13:19,679
что определенные условия на датчиках

2059
01:13:19,679 --> 01:13:22,080
позволяют достичь высокой точности в задаче,

2060
01:13:22,080 --> 01:13:23,679
которая эффективно просто подбирает случайные

2061
01:13:23,679 --> 01:13:24,800
метки,

2062
01:13:24,800 --> 01:13:27,120
и поэтому существует сложность

2063
01:13:27,120 --> 01:13:28,640


2064
01:13:28,640 --> 01:13:30,560
интерпретации того, что модель может  или

2065
01:13:30,560 --> 01:13:32,400
не мог делать с этой вещью,

2066
01:13:32,400 --> 01:13:34,880
которая каким-то образом легко доступна.

2067
01:13:34,880 --> 01:13:36,640
Интересно, что это свойство легко

2068
01:13:36,640 --> 01:13:38,400
доступно, но модель может ничего не

2069
01:13:38,400 --> 01:13:40,239
делать с ним, например,

2070
01:13:40,239 --> 01:13:42,400
потому что это полностью случайное,

2071
01:13:42,400 --> 01:13:44,560
аналогично другая статья показала, что вы

2072
01:13:44,560 --> 01:13:46,719
можете достичь высокой точности с помощью зонда.

2073
01:13:46,719 --> 01:13:49,040
даже если модель обучена понимать,

2074
01:13:49,040 --> 01:13:50,400
что то, что вы исследуете,

2075
01:13:50,400 --> 01:13:51,520
бесполезно,

2076
01:13:51,520 --> 01:13:54,400
и есть причинно-следственные исследования, которые

2077
01:13:54,400 --> 01:13:56,159
пытаются расширить эту работу, это намного

2078
01:13:56,159 --> 01:13:58,000
сложнее, но прочтите эту статью, и

2079
01:13:58,000 --> 01:14:01,280
это увлекательная линия будущей

2080
01:14:01,280 --> 01:14:04,320
работы.  Мое последнее, что вы знаете, две минуты, я

2081
01:14:04,320 --> 01:14:06,400
хочу поговорить или применить настройки модели

2082
01:14:06,400 --> 01:14:08,800
и абляции в качестве анализа,

2083
01:14:08,800 --> 01:14:11,040
так что у нас был этот процесс улучшения,

2084
01:14:11,040 --> 01:14:12,400
где  У нас была сеть, которая должна была

2085
01:14:12,400 --> 01:14:15,440
работать нормально, и мы посмотрим, сможем ли

2086
01:14:15,440 --> 01:14:17,040
мы настроить ее простыми способами, чтобы улучшить

2087
01:14:17,040 --> 01:14:18,719
ее, а затем вы могли увидеть,

2088
01:14:18,719 --> 01:14:20,400
можно ли удалить что-нибудь, и все

2089
01:14:20,400 --> 01:14:22,080
будет хорошо, и это вроде анализа,

2090
01:14:22,080 --> 01:14:24,159
как я  есть ли моя сеть, хочу ли я, чтобы она

2091
01:14:24,159 --> 01:14:25,840
нравилась, будет ли она лучше, если будет

2092
01:14:25,840 --> 01:14:27,040
сложнее, если будет

2093
01:14:27,040 --> 01:14:28,560
лучше, если будет проще, могу ли я избежать наказания

2094
01:14:28,560 --> 01:14:30,080
за то, что это будет проще,

2095
01:14:30,080 --> 01:14:32,800
и поэтому один из примеров некоторых людей, которые сделали

2096
01:14:32,800 --> 01:14:34,719
это, - они взяли это  идея

2097
01:14:34,719 --> 01:14:37,440
многоголового внимания и сказал, что

2098
01:14:37,440 --> 01:14:39,760
так много голов, все головы важны,

2099
01:14:39,760 --> 01:14:41,120
и что они показали, что если вы

2100
01:14:41,120 --> 01:14:43,360
тренируете систему с многоголовым

2101
01:14:43,360 --> 01:14:45,760
вниманием, а затем просто снимаете головы

2102
01:14:45,760 --> 01:14:48,159
во время теста и не используете их вообще, вы

2103
01:14:48,159 --> 01:14:49,840
действительно можете сделать  довольно хорошо справляется с

2104
01:14:49,840 --> 01:14:52,320
исходной задачей, не переучиваясь вообще

2105
01:14:52,320 --> 01:14:54,239
без некоторых из голов,

2106
01:14:54,239 --> 01:14:56,000
показывающих, что они не важны, вы

2107
01:14:56,000 --> 01:14:57,600
можете просто избавиться от них после

2108
01:14:57,600 --> 01:14:59,280
обучения, и вы можете сделать то

2109
01:14:59,280 --> 01:15:01,199
же самое, потому что это наш машинный

2110
01:15:01,199 --> 01:15:03,199
перевод это  на multi-nli вы

2111
01:15:03,199 --> 01:15:05,199
действительно можете обойтись без большого

2112
01:15:05,199 --> 01:15:09,320
процента вашего внимания,

2113
01:15:09,679 --> 01:15:11,920
давай посмотрим,

2114
01:15:11,920 --> 01:15:13,679
да, так что

2115
01:15:13,679 --> 01:15:14,960
еще одна вещь, о которой вы могли бы подумать,

2116
01:15:14,960 --> 01:15:17,199
это подвергнуть сомнению

2117
01:15:17,199 --> 01:15:19,199
основы моделей, которые мы создаем, поэтому у нас

2118
01:15:19,199 --> 01:15:20,960
есть трансформатор  модели, которые являются своего рода

2119
01:15:20,960 --> 01:15:22,159
самовниманием, направляют

2120
01:15:22,159 --> 01:15:24,400
вперед самовнимание, но, например, почему

2121
01:15:24,400 --> 01:15:26,320
в том порядке с некоторыми вещами,

2122
01:15:26,320 --> 01:15:29,280
испускаемыми здесь, и эта статья задала

2123
01:15:29,280 --> 01:15:31,520
этот вопрос и сказала, что это мое

2124
01:15:31,520 --> 01:15:33,600
трансформерное самовнимание с прямой подачей на себя.

2125
01:15:33,600 --> 01:15:36,000
прямая связь с вниманием и

2126
01:15:36,000 --> 01:15:37,760


2127
01:15:37,760 --> 01:15:39,360


2128
01:15:39,360 --> 01:15:40,800


2129
01:15:40,800 --> 01:15:42,400


2130
01:15:42,400 --> 01:15:45,199


2131
01:15:45,199 --> 01:15:47,040
т.д.  Таким образом, достигается меньшая

2132
01:15:47,040 --> 01:15:48,960
сложность в тесте, и это

2133
01:15:48,960 --> 01:15:51,600
способ анализа того, что важно

2134
01:15:51,600 --> 01:15:53,280
в архитектурах, которые я создаю, и

2135
01:15:53,280 --> 01:15:54,800
как их можно изменить, чтобы они

2136
01:15:54,800 --> 01:15:56,080
работали лучше,

2137
01:15:56,080 --> 01:15:58,560
поэтому нейронные модели очень эффективны.  комплексные, и

2138
01:15:58,560 --> 01:16:00,000
их трудно охарактеризовать и

2139
01:16:00,000 --> 01:16:02,239
невозможно охарактеризовать с помощью одного

2140
01:16:02,239 --> 01:16:04,400
вида статистики, я думаю, для точности вашего тестового

2141
01:16:04,400 --> 01:16:07,280
набора, особенно в предметной области,

2142
01:16:07,280 --> 01:16:08,880
и мы хотим найти интуитивно понятные

2143
01:16:08,880 --> 01:16:11,280
описания поведения модели,

2144
01:16:11,280 --> 01:16:13,040
но мы должны рассматривать несколько уровней

2145
01:16:13,040 --> 01:16:14,640
абстракции и ни один из  они

2146
01:16:14,640 --> 01:16:16,560
будут завершены,

2147
01:16:16,560 --> 01:16:18,159
когда кто-то скажет вам, что их нейронная

2148
01:16:18,159 --> 01:16:21,120
сеть поддается интерпретации, я призываю

2149
01:16:21,120 --> 01:16:23,679
вас критически относиться к тому, что

2150
01:16:23,679 --> 01:16:26,000
это не обязательно ложно, но как

2151
01:16:26,000 --> 01:16:27,679
уровни интерпретируемости и то, что вы

2152
01:16:27,679 --> 01:16:29,440
можете интерпретировать, - это вопросы,

2153
01:16:29,440 --> 01:16:31,199
которые вы должны задавать, потому что это

2154
01:16:31,199 --> 01:16:33,120
будет в некотором роде непрозрачным, почти

2155
01:16:33,120 --> 01:16:34,400
наверняка,

2156
01:16:34,400 --> 01:16:36,719
а потом вы знаете, что

2157
01:16:36,719 --> 01:16:39,440
привнесите такую линзу в свою модель,

2158
01:16:39,440 --> 01:16:40,640
когда вы пытаетесь думать о том, как

2159
01:16:40,640 --> 01:16:42,000
построить лучшие модели, даже если вы

2160
01:16:42,000 --> 01:16:43,600
не собираетесь проводить анализ как  своего

2161
01:16:43,600 --> 01:16:46,400
рода одна из ваших основных движущих целей,

2162
01:16:46,400 --> 01:16:49,120
и благодаря этому вы знаете, удачи в

2163
01:16:49,120 --> 01:16:50,800
ваших финальных проектах, я понимаю, что мы

2164
01:16:50,800 --> 01:16:52,960
вовремя эм преподавательский состав я  Я действительно

2165
01:16:52,960 --> 01:16:55,920
благодарен за ваши усилия в

2166
01:16:55,920 --> 01:16:59,040
этом трудном квартале, и да, надеюсь,

2167
01:16:59,040 --> 01:16:59,840
так

2168
01:16:59,840 --> 01:17:01,760
что да, я думаю, в четверг осталась лекция,

2169
01:17:01,760 --> 01:17:03,280
но да,

2170
01:17:03,280 --> 01:17:07,640
это моя последняя, так что спасибо всем

