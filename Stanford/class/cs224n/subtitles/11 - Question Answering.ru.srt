1
00:00:05,600 --> 00:00:08,880
хорошо, привет всем, добро пожаловать обратно,

2
00:00:08,880 --> 00:00:11,280
мы прошли половину шестой недели

3
00:00:11,280 --> 00:00:15,280
cs 224 n

4
00:00:15,280 --> 00:00:18,160
um, так что позвольте мне сначала сделать

5
00:00:18,160 --> 00:00:20,960
пару быстрых объявлений,

6
00:00:20,960 --> 00:00:22,800
так что сегодня день,

7
00:00:22,800 --> 00:00:25,199
когда вы должны сделать середину

8
00:00:25,199 --> 00:00:28,320
квартальный опрос, проведенный сотнями людей,

9
00:00:28,320 --> 00:00:30,480
но если у вас нет, это ваш

10
00:00:30,480 --> 00:00:32,960
последний шанс получить половину балла за

11
00:00:32,960 --> 00:00:34,000
это

12
00:00:34,000 --> 00:00:37,040
сегодня также день, когда

13
00:00:37,040 --> 00:00:39,200
должны быть представлены окончательные проектные предложения,

14
00:00:39,200 --> 00:00:41,200
мы действительно рекомендуем вам попробовать передать

15
00:00:41,200 --> 00:00:44,239
их  вовремя или почти вовремя, что на

16
00:00:44,239 --> 00:00:46,559
самом деле просто для того, чтобы помочь вам, чтобы мы могли

17
00:00:46,559 --> 00:00:48,719
быстрее дать вам обратную связь по окончательным

18
00:00:48,719 --> 00:00:51,360
предложениям по проектам, а в

19
00:00:51,360 --> 00:00:53,280
фоновом режиме есть еще задание

20
00:00:53,280 --> 00:00:55,760
пять, вы увидите сообщение, которое

21
00:00:55,760 --> 00:00:58,000
мы даем вам на один дополнительный день для этого

22
00:00:58,000 --> 00:01:00,879
но мы, безусловно, призываем вас

23
00:01:00,879 --> 00:01:02,960
усердно работать над пятым заданием на данном

24
00:01:02,960 --> 00:01:04,720
этапе, надеюсь, это отличная захватывающая

25
00:01:04,720 --> 00:01:06,720
возможность узнать все

26
00:01:06,720 --> 00:01:10,320
последние новости о трансформаторах,

27
00:01:10,320 --> 00:01:13,600
и сегодня я рад, что наш

28
00:01:13,600 --> 00:01:16,240
первый приглашенный спикер позвольте мне jus  Я не

29
00:01:16,240 --> 00:01:19,840
упомянул, что в пределах

30
00:01:20,960 --> 00:01:23,840
половины балла за участие

31
00:01:23,840 --> 00:01:27,600
вы, ребята, пишете параграф с реакцией,

32
00:01:27,600 --> 00:01:29,920
говоря о чем-то, о чем

33
00:01:29,920 --> 00:01:31,280
говорит спикер, и их

34
00:01:31,280 --> 00:01:34,640
инструкции для этого мм на эд,

35
00:01:34,640 --> 00:01:37,520
но без дальнейших церемоний

36
00:01:37,520 --> 00:01:40,960
позвольте мне представить данте чен ум так  Данте

37
00:01:40,960 --> 00:01:42,880
- один из ведущих исследователей,

38
00:01:42,880 --> 00:01:44,880
отвечающих на вопросы, и она

39
00:01:44,880 --> 00:01:47,439
особенно хорошо известна в недавней

40
00:01:47,439 --> 00:01:48,399
работе

41
00:01:48,399 --> 00:01:50,560
за то, что была одним из соавторов статьи

42
00:01:50,560 --> 00:01:54,720
Роберты, статьи Спанберта, и по

43
00:01:54,720 --> 00:01:57,119
использованию методов поиска плотных проходов

44
00:01:57,119 --> 00:01:58,880
для ответов на вопросы в открытой предметной области,

45
00:01:58,880 --> 00:02:01,920
а также в качестве профессора.  в

46
00:02:01,920 --> 00:02:05,280
университете принстонского университета эм, но, как еще один

47
00:02:05,280 --> 00:02:09,440
комментарий, она когда-то

48
00:02:09,440 --> 00:02:12,560
была главой cs224n

49
00:02:12,560 --> 00:02:15,040
эм, так что она довольно хорошо знакома с

50
00:02:15,040 --> 00:02:18,160
контекстом этого класса, так что я действительно

51
00:02:18,160 --> 00:02:20,000
рад, что она здесь, чтобы дать

52
00:02:20,000 --> 00:02:21,599
эта лекция по ответам на вопросы

53
00:02:24,000 --> 00:02:26,640
спасибо спасибо Крису за введение ммм

54
00:02:26,640 --> 00:02:28,319
для меня это очень хорошо, это отличная

55
00:02:28,319 --> 00:02:30,519
возможность для меня вернуться к

56
00:02:30,519 --> 00:02:33,680
cs2201 сегодня и g  На этой лекции также

57
00:02:35,040 --> 00:02:36,800
фактически стоит вопрос, отвечая на вопросы, касающиеся областей, в

58
00:02:36,800 --> 00:02:38,160
которых довольно много работали в

59
00:02:38,160 --> 00:02:40,480
последние несколько лет, поэтому сегодня я очень

60
00:02:40,480 --> 00:02:42,000
рад познакомить вас с некоторыми

61
00:02:42,000 --> 00:02:44,400
основами в этой области, а также с

62
00:02:44,400 --> 00:02:48,239
некоторыми передовыми и сохранить наши темы.

63
00:02:48,239 --> 00:02:50,959
Итак, вот мой план на эту лекцию,

64
00:02:50,959 --> 00:02:53,360
поэтому сначала я кратко расскажу,

65
00:02:53,360 --> 00:02:55,040
что такое ответы

66
00:02:55,040 --> 00:02:56,879
на вопросы и какие проблемы

67
00:02:56,879 --> 00:02:58,720
люди начинают сегодня,

68
00:02:58,720 --> 00:03:01,200
поэтому я собираюсь потратить большую часть этой

69
00:03:01,200 --> 00:03:03,200
лекции, сосредоточившись на одном типе

70
00:03:03,200 --> 00:03:04,480
проблемы с ответами на вопросы, называемые пониманием прочитанного,

71
00:03:04,480 --> 00:03:06,720
так что это в основном

72
00:03:06,720 --> 00:03:09,200
проблемы того, как мы создаем системы для

73
00:03:09,200 --> 00:03:12,000
ответов на вопросы по одному пассивному

74
00:03:12,000 --> 00:03:12,959
тексту,

75
00:03:12,959 --> 00:03:14,800
поэтому я знаю, что многие из вас собираются

76
00:03:14,800 --> 00:03:16,879
выполнить проект по умолчанию на

77
00:03:16,879 --> 00:03:18,560
наборе данных ответов на вопросы Стэнфорда, поэтому

78
00:03:18,560 --> 00:03:20,319
понимание этой части будет  быть очень

79
00:03:20,319 --> 00:03:23,040
важным для вашего финального проекта,

80
00:03:23,040 --> 00:03:25,280
поэтому в конце этой лекции

81
00:03:25,280 --> 00:03:27,200
я надеюсь потратить

82
00:03:27,200 --> 00:03:29,680
около 20 минут, чтобы поговорить о более практичном

83
00:03:29,680 --> 00:03:31,840
и, на мой взгляд, или более волнующем  Эта

84
00:03:31,840 --> 00:03:33,599
проблема называется ответом на открытый вопрос домена,

85
00:03:33,599 --> 00:03:35,519
поэтому мы постараемся ответить на

86
00:03:35,519 --> 00:03:37,840
вопросы по очень большой

87
00:03:37,840 --> 00:03:39,599
коллекции документов,

88
00:03:39,599 --> 00:03:41,599
и я, чтобы мои друзья попытались быстро

89
00:03:41,599 --> 00:03:43,680
пройти некоторые из этих государственных методов в

90
00:03:43,680 --> 00:03:47,000
этой области,

91
00:03:47,120 --> 00:03:49,519
хорошо, так что давайте просто начнем,

92
00:03:49,519 --> 00:03:52,959
так что сначала  является ответом на вопрос,

93
00:03:52,959 --> 00:03:54,959
поэтому цель ответа на вопрос состоит в том, чтобы

94
00:03:54,959 --> 00:03:57,360
создать системы, которые могут автоматически

95
00:03:57,360 --> 00:03:59,760
отвечать на вопросы, заданные людьми в вопросе на

96
00:03:59,760 --> 00:04:01,920
естественном языке,

97
00:04:01,920 --> 00:04:04,319
отвечая на все, скажем,

98
00:04:04,319 --> 00:04:07,760
вкратце qa - одна из самых ранних задач mlk,

99
00:04:07,760 --> 00:04:09,840
а ранние системы могут даже восходить

100
00:04:09,840 --> 00:04:11,680
к  1960-е годы,

101
00:04:11,680 --> 00:04:14,560
так что вот один из примеров ранних, таких как

102
00:04:14,560 --> 00:04:17,519
одна из ранних систем um qa системы uh qa

103
00:04:17,519 --> 00:04:21,120
еще в 1964 году. Как вы можете

104
00:04:21,120 --> 00:04:22,960
видеть, эта система пытается ответить

105
00:04:22,960 --> 00:04:25,919
на вопрос, например, что вы хотите, а

106
00:04:25,919 --> 00:04:28,160
затем, наконец, вернуться к  ответ -

107
00:04:28,160 --> 00:04:29,280
это график,

108
00:04:29,280 --> 00:04:31,040
чтобы сделать это, чтобы эта система в

109
00:04:31,040 --> 00:04:32,720
основном пыталась найти какое-то

110
00:04:32,720 --> 00:04:35,199
соответствие текста между вопросом и

111
00:04:35,199 --> 00:04:37,680
некоторыми текстовыми сегментами и с помощью

112
00:04:37,680 --> 00:04:39,759
какой-то зависимости  Я

113
00:04:39,759 --> 00:04:41,199
предполагаю, что вы уже изучили

114
00:04:41,199 --> 00:04:44,960
синтаксический анализ защиты в этом классе,

115
00:04:45,280 --> 00:04:46,960
и существует много различных типов

116
00:04:46,960 --> 00:04:49,199
проблем с ответами на вопросы, и мы

117
00:04:49,199 --> 00:04:51,520
также можем классифицировать все эти

118
00:04:51,520 --> 00:04:53,199
проблемы с ответами на вопросы на основе

119
00:04:53,199 --> 00:04:56,080
либо источника информации, либо

120
00:04:56,080 --> 00:04:58,880
заголовков вопросов, либо  типа ответов,

121
00:04:58,880 --> 00:05:01,199
поэтому для источника информации мы можем

122
00:05:01,199 --> 00:05:03,520
построить систему, которая может поставить в качестве

123
00:05:03,520 --> 00:05:05,440
условия

124
00:05:05,440 --> 00:05:08,080
короткий пассивный тест или очень большую

125
00:05:08,080 --> 00:05:10,240
коллекцию документов, или даже как

126
00:05:10,240 --> 00:05:11,919
структурированная база данных или структурированная

127
00:05:11,919 --> 00:05:13,039
база знаний,

128
00:05:13,039 --> 00:05:16,479
или даже таблицы или изображения,

129
00:05:16,479 --> 00:05:18,720
так что для  тип вопроса, который мы также можем быть

130
00:05:18,720 --> 00:05:20,800
помощниками, которые могут ответить, например, на заводские

131
00:05:20,800 --> 00:05:23,120
вопросы или не заводские вопросы, или на вопросы

132
00:05:23,120 --> 00:05:24,960
открытой предметной области, или закрытые вопросы предметной области

133
00:05:24,960 --> 00:05:27,039
или простые вопросы, по сравнению с

134
00:05:27,039 --> 00:05:29,360
более сложными или композиционными

135
00:05:29,360 --> 00:05:30,400
вопросами,

136
00:05:30,400 --> 00:05:33,120
а для типа ответа он также может быть

137
00:05:33,120 --> 00:05:35,600
похож на короткий сегмент  или текст, или

138
00:05:35,600 --> 00:05:38,400
абзац, или документ, или список, или даже

139
00:05:38,400 --> 00:05:40,400
вопросы «да» или «нет»,

140
00:05:40,400 --> 00:05:41,919
так что просто имейте в виду, что существует много

141
00:05:41,919 --> 00:05:43,440
разных  типы проблем с ответами на

142
00:05:43,440 --> 00:05:45,680
вопросы, и все эти проблемы могут

143
00:05:45,680 --> 00:05:47,680
потребовать очень разных методов или

144
00:05:47,680 --> 00:05:49,680
разных данных или даже разных

145
00:05:49,680 --> 00:05:51,600
показателей оценки, чтобы

146
00:05:51,600 --> 00:05:55,120
разделить все эти разные проблемы,

147
00:05:55,840 --> 00:05:58,160
и консультант по вопросам включил

148
00:05:58,160 --> 00:06:00,319
множество полезных приложений реального мира,

149
00:06:01,600 --> 00:06:03,600
например, сегодня, если вы просто поставите

150
00:06:03,600 --> 00:06:06,479
вопрос в поисковой системе, такой как google,

151
00:06:06,479 --> 00:06:08,080
поэтому, например, вы можете задать свой

152
00:06:08,080 --> 00:06:10,960
вопрос, например, где находится самое глубокое озеро

153
00:06:10,960 --> 00:06:12,160
в мире,

154
00:06:12,160 --> 00:06:13,919
чтобы вы могли видеть, что текущая система в

155
00:06:13,919 --> 00:06:16,720
основном нашла что-то вроде короткого

156
00:06:16,720 --> 00:06:18,479
фрагмента текста,

157
00:06:18,479 --> 00:06:19,680
включая как

158
00:06:19,680 --> 00:06:21,280
озеро

159
00:06:21,280 --> 00:06:24,479
um Карла Барко в  siberia называет

160
00:06:24,479 --> 00:06:26,639
различие быть одновременно самым глубоким

161
00:06:26,639 --> 00:06:28,960
озером в мире и самым большим

162
00:06:28,960 --> 00:06:31,759
озером с пресной водой бла-бла, и тогда он может

163
00:06:31,759 --> 00:06:34,080
фактически точно определить правильный ответ,

164
00:06:34,080 --> 00:06:36,000
который на самом деле является кратким предпринимателем,

165
00:06:36,000 --> 00:06:39,600
которым должна быть сибирь,

166
00:06:39,680 --> 00:06:41,600
и такие системы также могут

167
00:06:41,600 --> 00:06:44,000
справиться  например, более сложные вопросы,

168
00:06:44,000 --> 00:06:46,319
например, как вопросы, я думаю, это,

169
00:06:46,319 --> 00:06:47,919
вероятно, вопрос, который

170
00:06:47,919 --> 00:06:50,639
сейчас волнует всех  Итак, вопрос в

171
00:06:50,639 --> 00:06:54,160
том, как я могу защитить себя от кобе 19. На

172
00:06:54,160 --> 00:06:56,400
самом деле нет простого и короткого

173
00:06:56,400 --> 00:06:58,000
ответа на этот вопрос,

174
00:06:58,000 --> 00:06:59,759
поэтому вы можете видеть, что система на самом деле

175
00:06:59,759 --> 00:07:01,840
возвращается очень долго,

176
00:07:01,840 --> 00:07:03,599
включая лучший способ предотвратить

177
00:07:03,599 --> 00:07:05,759
болезнь - это  избегайте воздействия

178
00:07:05,759 --> 00:07:08,319
этого вируса и чтобы помочь предотвратить

179
00:07:08,319 --> 00:07:10,319
дух kobe 19, вы можете сделать

180
00:07:10,319 --> 00:07:12,800
следующее, так что на самом деле

181
00:07:12,800 --> 00:07:15,680
этот абзац на самом деле представляет собой резюме

182
00:07:15,680 --> 00:07:17,080
этого

183
00:07:17,080 --> 00:07:19,840
cdcsco, если вы просто щелкните эту ссылку и

184
00:07:19,840 --> 00:07:22,319
прочитаете статью, так что это

185
00:07:22,319 --> 00:07:23,840
тоже похоже на  один тип проблем с ответами на

186
00:07:23,840 --> 00:07:25,680
вопросы,

187
00:07:25,680 --> 00:07:27,840
и теперь это обзор вариантов использования

188
00:07:27,840 --> 00:07:30,319
для текущих цифровых систем,

189
00:07:30,319 --> 00:07:32,720
таких как alexa или google home,

190
00:07:32,720 --> 00:07:35,280
поэтому, согласно результатам этого опроса, в

191
00:07:35,280 --> 00:07:38,560
январе 2020 года, то есть год назад, поэтому

192
00:07:38,560 --> 00:07:40,720
вы можете видеть, что люди на

193
00:07:40,720 --> 00:07:43,599
самом деле действительно  люблю задавать вопросы, эм, это

194
00:07:43,599 --> 00:07:46,000
на этом цифровом помощнике, так что вы можете видеть, что

195
00:07:46,000 --> 00:07:47,520
этот мудак-вопрос на самом деле

196
00:07:47,520 --> 00:07:50,479
второй по популярности случай, который занимает место только

197
00:07:50,479 --> 00:07:52,319
после прослушивания музыки

198
00:07:52,319 --> 00:07:54,240
и перед изменчивой погодой.  Вместо таймера времени,

199
00:07:54,240 --> 00:07:56,240
поэтому вопросы были действительно

200
00:07:56,240 --> 00:08:00,319
полезны в этих виртуальных помощниках,

201
00:08:00,560 --> 00:08:02,720
еще один очень известный пример

202
00:08:02,720 --> 00:08:04,879
системы ответов на вопросы - это

203
00:08:04,879 --> 00:08:08,960
ibm из системы вопроса 3, поэтому в 1920

204
00:08:08,960 --> 00:08:12,400
или 2011 году эта идея заключалась в том, что

205
00:08:12,400 --> 00:08:14,720
система qa, как было показано, превзошла два

206
00:08:14,720 --> 00:08:18,000
национальных  японские чемпионы в ответах на

207
00:08:18,000 --> 00:08:19,840
смертельные вопросы,

208
00:08:19,840 --> 00:08:21,680
так что это вроде как

209
00:08:21,680 --> 00:08:23,919
историческое событие,

210
00:08:23,919 --> 00:08:27,120
по крайней мере, в истории LP,

211
00:08:27,120 --> 00:08:29,360
так что если мы посмотрим на эпоху, в которой работает

212
00:08:29,360 --> 00:08:32,000
такая система, чтобы вы могли

213
00:08:32,000 --> 00:08:33,360
увидеть, что это на самом деле очень

214
00:08:33,360 --> 00:08:35,760
сложная и  высокомодульная

215
00:08:35,760 --> 00:08:36,799
система,

216
00:08:36,799 --> 00:08:38,958
поэтому, если система построена как на

217
00:08:38,958 --> 00:08:41,120
неструктурированном тексте, так и на

218
00:08:41,120 --> 00:08:42,958
структурированных данных,

219
00:08:42,958 --> 00:08:45,839
поэтому, посмотрев на систему, если вы пойдете

220
00:08:45,839 --> 00:08:47,600
слева направо, вы увидите, что

221
00:08:47,600 --> 00:08:50,240
эта система состоит из четырех этапов,

222
00:08:50,240 --> 00:08:52,560
включая вопрос,

223
00:08:52,560 --> 00:08:54,640
обрабатывающий кандидата  генерация ответов и

224
00:08:54,640 --> 00:08:56,640
оценка ответов кандидата и

225
00:08:56,640 --> 00:08:58,800
рейтинг слияния уверенности, а затем, если

226
00:08:58,800 --> 00:09:00,399
вы посмотрите на каждый этап, вы увидите, что

227
00:09:00,399 --> 00:09:02,560
существует много разных n  lp методы,

228
00:09:02,560 --> 00:09:04,240
которые были фактически включены в эту

229
00:09:04,240 --> 00:09:06,800
сложную систему запросов, включая

230
00:09:08,480 --> 00:09:10,880
корреляцию извлечения отношения синтаксического анализа классификации вопросов,

231
00:09:10,880 --> 00:09:12,880
так что на самом деле есть действительно много

232
00:09:12,880 --> 00:09:14,880
модулей lpcs, которые были

233
00:09:14,880 --> 00:09:16,000
включены,

234
00:09:16,000 --> 00:09:17,920
и теперь этой системе уже более 10

235
00:09:17,920 --> 00:09:20,640
лет или фактически ровно 10 лет.

236
00:09:20,640 --> 00:09:22,640
и это на самом деле представляет

237
00:09:22,640 --> 00:09:27,200
космическое искусство, как 10 лет назад в то время,

238
00:09:28,000 --> 00:09:30,080
поэтому мы знаем, что этот класс посвящен глубокому

239
00:09:30,080 --> 00:09:31,200
обучению,

240
00:09:31,200 --> 00:09:33,440
поэтому сегодня он по-другому полностью

241
00:09:33,440 --> 00:09:35,920
изменил ландшафт

242
00:09:35,920 --> 00:09:37,760
систем ответов на вопросы,

243
00:09:37,760 --> 00:09:39,760
поэтому нет никаких сомнений в том, что мы можем сказать, что

244
00:09:39,760 --> 00:09:41,920
почти все  государства - это системы персонализации,

245
00:09:41,920 --> 00:09:44,880
которые сегодня построены

246
00:09:44,880 --> 00:09:46,800
на основе непрерывного обучения дипломных

247
00:09:46,800 --> 00:09:48,640
сетей и подходов и языковых

248
00:09:48,640 --> 00:09:51,279
моделей, таких как Bird, поэтому сегодня в этой

249
00:09:51,279 --> 00:09:52,880
лекции мы также собираемся полностью изучить многие

250
00:09:52,880 --> 00:09:54,560
из этих моделей глубокого обучения.

251
00:09:54,560 --> 00:09:56,160
ответ на вопрос,

252
00:09:56,160 --> 00:09:58,640
и это утверждение, вероятно, также верно

253
00:09:58,640 --> 00:10:00,720
почти для всех проблем НЛП, которые мы

254
00:10:00,720 --> 00:10:03,120
можем видеть сегодня, но мы можем  Я также утверждаю, что

255
00:10:03,120 --> 00:10:04,640
ответы на вопросы, вероятно, являются одной из

256
00:10:04,640 --> 00:10:07,120
тех областей, в которых мы наблюдали наиболее

257
00:10:07,120 --> 00:10:09,600
заметный прогресс за

258
00:10:09,600 --> 00:10:11,519
последние пару лет, обусловленный

259
00:10:11,519 --> 00:10:14,160
развертыванием,

260
00:10:16,959 --> 00:10:20,160
поэтому в этой лекции я буду в основном

261
00:10:20,160 --> 00:10:22,640
сосредоточен на таких областях, как э-э ...  текст,

262
00:10:22,640 --> 00:10:25,279
основанный на текстовых проблемах с ответами на сбой,

263
00:10:25,279 --> 00:10:26,720
поэтому в основном мы пытаемся

264
00:10:26,720 --> 00:10:28,399
отвечать на вопросы на основе

265
00:10:28,399 --> 00:10:30,959
неструктурированного текста, поэтому, прежде чем я начну,

266
00:10:30,959 --> 00:10:33,680
я перехожу к этой части, я также

267
00:10:33,680 --> 00:10:35,440
хочу быстро указать, что есть много

268
00:10:35,440 --> 00:10:38,560
других действительно серьезных проблем, и

269
00:10:38,560 --> 00:10:40,720
каждая из них  они могут быть действительно похожи на большое

270
00:10:40,720 --> 00:10:43,440
звездное подполе в nlp, и на самом деле у

271
00:10:43,440 --> 00:10:45,760
них очень разные задачи, а также

272
00:10:45,760 --> 00:10:47,120
дизайн моделей,

273
00:10:47,120 --> 00:10:49,279
поэтому один более крупный класс этой

274
00:10:49,279 --> 00:10:51,200
проблемы с аварийным ответом - это поток вопросов, основанный на знаниях,

275
00:10:51,200 --> 00:10:52,880
поэтому в основном мы хотим создавать

276
00:10:52,880 --> 00:10:54,880
вопросы также в системах, чтобы  отвечать на

277
00:10:54,880 --> 00:10:57,600
вопросы, которые могут отвечать

278
00:10:57,600 --> 00:10:59,519
также на вопросы по очень большой

279
00:10:59,519 --> 00:11:00,880
базе данных,

280
00:11:00,880 --> 00:11:03,200
поэтому для решения этой проблемы некоторые подходы

281
00:11:03,200 --> 00:11:05,200
должны принять этот вопрос

282
00:11:05,200 --> 00:11:07,279
и преобразовать этот вопрос в s  Некоторые

283
00:11:07,279 --> 00:11:09,440
виды более крупных форм и такого рода логические

284
00:11:09,440 --> 00:11:12,079
формы могут быть выполнены для этой

285
00:11:12,079 --> 00:11:16,160
базы данных, чтобы дать вам окончательный ответ,

286
00:11:16,800 --> 00:11:19,040
а затем другой класс, более крупный

287
00:11:19,040 --> 00:11:20,560
класс проблемы представления, называется

288
00:11:20,560 --> 00:11:22,160
визуальным ответом на вопрос, поэтому в

289
00:11:22,160 --> 00:11:23,600
основном вам нужно отвечать на вопросы,

290
00:11:23,600 --> 00:11:25,360
основанные на  изображения,

291
00:11:25,360 --> 00:11:27,279
поэтому эта проблема требует как

292
00:11:27,279 --> 00:11:29,360
понимания вопросов, так и

293
00:11:29,360 --> 00:11:31,680
изображений, и на самом деле существует очень

294
00:11:31,680 --> 00:11:33,839
активное поле между компьютерным зрением

295
00:11:33,839 --> 00:11:35,839
и нашим ключом, поэтому, если вас

296
00:11:35,839 --> 00:11:37,839
интересуют проблемы этого типа, я рекомендую

297
00:11:37,839 --> 00:11:39,760
вам проверить эти проблемы, но я  Я

298
00:11:39,760 --> 00:11:41,680
не собираюсь разбираться в этих проблемах

299
00:11:41,680 --> 00:11:43,839
сегодня,

300
00:11:45,519 --> 00:11:47,760
ладно, так что дальше я начну с

301
00:11:47,760 --> 00:11:50,399
части 2 понимание прочитанного,

302
00:11:50,399 --> 00:11:51,920
я просто хочу быстро проверить, есть ли какие-

303
00:11:51,920 --> 00:11:54,000
нибудь быстрые вопросы, на которые я могу

304
00:11:54,000 --> 00:11:56,639
ответить, прежде чем я начну, эм,

305
00:11:56,639 --> 00:11:58,800
начну, поймаю вас да нет я  Думаю, мы могли бы

306
00:11:58,800 --> 00:12:00,639
сделать это сейчас,

307
00:12:00,639 --> 00:12:02,959
хорошо, так что давайте поговорим о

308
00:12:02,959 --> 00:12:05,279
понимании прочитанного,

309
00:12:05,279 --> 00:12:06,959
тогда память о чтении - это основная

310
00:12:06,959 --> 00:12:09,519
проблема, которую мы хотим

311
00:12:09,519 --> 00:12:11,760
сравнить пассивный текст  и отвечать на вопросы

312
00:12:11,760 --> 00:12:13,279
о содержании,

313
00:12:13,279 --> 00:12:14,800
так что входные данные этой проблемы в

314
00:12:14,800 --> 00:12:17,040
основном представляют собой пассивный текст вопроса,

315
00:12:17,040 --> 00:12:18,720
и цель состоит в том, чтобы вернуть ответ, который

316
00:12:18,720 --> 00:12:21,600
действительно может ответить на этот вопрос,

317
00:12:21,600 --> 00:12:23,600
поэтому вот один пример,

318
00:12:23,600 --> 00:12:26,320
поэтому давайте расскажем, вот пассивный текст,

319
00:12:26,320 --> 00:12:28,560
и мы хотим  ээ, ответьте на вопрос,

320
00:12:28,560 --> 00:12:30,720
вопрос в том, какой язык будет изучать ваш тест,

321
00:12:30,720 --> 00:12:32,800
пока вы

322
00:12:58,480 --> 00:13:02,560
наберете ОК  что люди говорят на немецком,

323
00:13:02,560 --> 00:13:04,000
да, германия,

324
00:13:04,000 --> 00:13:05,600
поэтому ответ должен быть на немецком, так что в

325
00:13:05,600 --> 00:13:07,360
основном, чтобы ответить на этот вопрос, вам

326
00:13:07,360 --> 00:13:10,240
нужно найти это предложение, как в 1861 году, когда

327
00:13:10,240 --> 00:13:12,480
Тесла учился в этой школе, где он

328
00:13:12,480 --> 00:13:14,560
начал немецкую арифметику и религию,

329
00:13:14,560 --> 00:13:16,880
и это только немецкий язык,

330
00:13:16,880 --> 00:13:18,320
поэтому  Ответ на этот вопрос должен быть на

331
00:13:18,320 --> 00:13:20,160
немецком,

332
00:13:20,160 --> 00:13:22,160
хорошо, вот еще один пример, еще

333
00:13:22,160 --> 00:13:25,120
один пассивный текст, и вопрос в том,

334
00:13:25,120 --> 00:13:28,240
какое языковое меньшинство больше хинди

335
00:13:28,240 --> 00:13:29,519
или

336
00:13:29,519 --> 00:13:31,519
мала,

337
00:13:31,519 --> 00:13:35,079
я думаю, да,

338
00:13:36,800 --> 00:13:40,120
пять секунд

339
00:13:49,680 --> 00:13:51,519
о  Кей, поэтому ответом на этот вопрос

340
00:13:51,519 --> 00:13:53,760
должен быть хинди, так что это,

341
00:13:53,760 --> 00:13:55,519
вероятно, не очень сложный вопрос для

342
00:13:55,519 --> 00:13:56,959
людей, на самом деле это довольно сложный

343
00:13:56,959 --> 00:13:59,120
вопрос для машин, потому что, чтобы

344
00:13:59,120 --> 00:14:01,279
правильно ответить на этот вопрос, чтобы машины в

345
00:14:01,279 --> 00:14:02,800
основном понимали, что для

346
00:14:02,800 --> 00:14:05,199
хинди вроде трех целых три десятых процента

347
00:14:05,199 --> 00:14:07,600
населения говорит на хинди, и

348
00:14:07,600 --> 00:14:09,680
только одна целая двадцать семь процентов

349
00:14:09,680 --> 00:14:12,480
говорит на этом языке, мала йеллен, а

350
00:14:12,480 --> 00:14:15,120
затем также сравните эти два числа,

351
00:14:15,120 --> 00:14:17,360
и последний случай - три процента, три

352
00:14:17,360 --> 00:14:19,279
целых три десятых процента - это большее число,

353
00:14:19,279 --> 00:14:21,120
поэтому ответ должен быть на хинди.

354
00:14:21,120 --> 00:14:23,440
вопрос

355
00:14:23,600 --> 00:14:25,600
хорошо, так что дальше я собираюсь поговорить

356
00:14:25,600 --> 00:14:27,760
немного, так почему мы заботимся об этой проблеме,

357
00:14:27,760 --> 00:14:29,199
так почему мы заботимся о проблеме понимания прочитанного,

358
00:14:29,199 --> 00:14:31,760
так что помимо того, что она

359
00:14:31,760 --> 00:14:32,560
фактически

360
00:14:32,560 --> 00:14:35,120
управляет многими полезными практическими приложениями реального мира,

361
00:14:36,399 --> 00:14:39,120
как я уже показал  несколько примеров

362
00:14:39,120 --> 00:14:41,040
в начале, я думаю, есть еще

363
00:14:41,040 --> 00:14:44,000
две другие ключевые причины,

364
00:14:44,000 --> 00:14:46,399
поэтому первая причина, помимо

365
00:14:46,399 --> 00:14:48,880
адаптации, первая причина -

366
00:14:48,880 --> 00:14:50,800
это чтение comp  осознание также

367
00:14:50,800 --> 00:14:53,279
рассматривается как очень важная испытательная площадка для

368
00:14:53,279 --> 00:14:55,680
оценки того, насколько хорошо компьютерные системы

369
00:14:55,680 --> 00:14:58,480
понимают человеческий язык, так что это

370
00:14:58,480 --> 00:15:00,880
действительно похоже на то, как мы,

371
00:15:00,880 --> 00:15:02,480
люди, на самом деле тестируем

372
00:15:02,480 --> 00:15:05,279
тест на понимание прочитанного, чтобы оценить, насколько

373
00:15:05,279 --> 00:15:06,720
хорошо мы на самом деле понимаем

374
00:15:06,720 --> 00:15:08,800
язык, так что это  это также способ, которым мы на

375
00:15:08,800 --> 00:15:10,959
самом деле задаем вопросы для проверки

376
00:15:10,959 --> 00:15:13,360
машин, которые будут понимать языковое

377
00:15:13,360 --> 00:15:16,320
понимание способностей, так что на

378
00:15:16,320 --> 00:15:18,720
самом деле это было официально заявлено

379
00:15:18,720 --> 00:15:22,079
еще в 1977 году Бенни Леонардом в своей

380
00:15:22,079 --> 00:15:25,440
диссертации, поэтому она не сказала, что она

381
00:15:25,440 --> 00:15:26,720
говорит, что

382
00:15:26,720 --> 00:15:28,959
эти  могут быть разработаны вопросы, чтобы исследовать

383
00:15:28,959 --> 00:15:31,360
любой аспект понимания текста, поэтому

384
00:15:31,360 --> 00:15:33,040
способность отвечать на вопросы является наиболее

385
00:15:33,040 --> 00:15:34,959
сильной демонстрацией

386
00:15:34,959 --> 00:15:36,800
понимания, поэтому понимание прочитанного

387
00:15:36,800 --> 00:15:38,240
может быть очень важной

388
00:15:38,240 --> 00:15:40,639
испытательной площадкой, потому что мы не можем разделить дизайн на

389
00:15:40,639 --> 00:15:43,120
очень сложные сложные вопросы, чтобы проверить

390
00:15:43,120 --> 00:15:45,199
это,

391
00:15:45,199 --> 00:15:47,519
а также  я думаю, есть еще одна

392
00:15:47,519 --> 00:15:49,680
интересная и важная причина того, что

393
00:15:49,680 --> 00:15:52,000
понимание прочитанного важно  Так что

394
00:15:52,000 --> 00:15:54,320
за последние несколько лет многие

395
00:15:54,320 --> 00:15:56,480
исследователи действительно обнаружили, что это нормально, так что

396
00:15:56,480 --> 00:15:58,800
для многих других задач НЛП мы можем

397
00:15:58,800 --> 00:16:00,560
также свести их к

398
00:16:00,560 --> 00:16:02,720
проблеме понимания прочитанного, поэтому я

399
00:16:02,720 --> 00:16:04,639
приведу вам два примера,

400
00:16:04,639 --> 00:16:06,880
так что один пример - это действительно извлечение информации,

401
00:16:06,880 --> 00:16:10,560
поэтому  в основном, если мы хотим, чтобы это было

402
00:16:10,560 --> 00:16:12,720
так дано в отношении человека, такого как субъект

403
00:16:12,720 --> 00:16:15,839
Барака Обамы, учитывая образованное отношение,

404
00:16:16,560 --> 00:16:18,720
поэтому мы хотим заполнить то, что заполнить

405
00:16:18,720 --> 00:16:20,560
этот вопросительный знак, и выяснить, хорошо,

406
00:16:20,560 --> 00:16:23,519
где Барак Обама отстаивал это,

407
00:16:23,519 --> 00:16:25,440
так что один из способов решить эту проблему  проблема в

408
00:16:25,440 --> 00:16:27,120
основном пытается

409
00:16:27,120 --> 00:16:29,839
преобразовать это отношение в вопрос,

410
00:16:29,839 --> 00:16:32,480
откуда Барак Обама закончил и

411
00:16:32,480 --> 00:16:35,680
взял соответствующий фрагмент текста, а затем,

412
00:16:35,680 --> 00:16:37,279
применив проблему понимания прочитанного, в

413
00:16:37,279 --> 00:16:39,680
основном мы можем

414
00:16:39,680 --> 00:16:41,600
узнать отрывок, правильный ответ

415
00:16:41,600 --> 00:16:43,680
должен быть в Колумбийском университете, который

416
00:16:43,680 --> 00:16:45,360
также является результатом этой системы извлечения информации.

417
00:16:48,320 --> 00:16:50,560
Другой пример, который на самом деле называется

418
00:16:50,560 --> 00:16:52,240
маркировкой цементита, я не уверен, узнал ли я об

419
00:16:52,240 --> 00:16:53,839
этом в прошлом.  вероятно,

420
00:16:53,839 --> 00:16:56,399
нет, но это задача испанской

421
00:16:56,399 --> 00:16:59,839
маркировки - попытаться взять одно

422
00:16:59,839 --> 00:17:02,160
предложение и попытаться определить

423
00:17:02,160 --> 00:17:04,400
правила для разных глаголов, по крайней мере, для

424
00:17:04,400 --> 00:17:06,319
слов в этом случае в одном

425
00:17:06,319 --> 00:17:08,640
предложении, поэтому в основном пытается дать

426
00:17:08,640 --> 00:17:10,880
им одно предложение о данном глаголе

427
00:17:10,880 --> 00:17:12,959
Закончите попытки выяснить, кто,

428
00:17:12,959 --> 00:17:15,359
что вы и когда и где

429
00:17:15,359 --> 00:17:19,119
сделал,

430
00:17:19,119 --> 00:17:22,400
пытаясь понять все эти правила

431
00:17:22,400 --> 00:17:24,959
в отношении глаголов, поэтому один из способов

432
00:17:24,959 --> 00:17:26,880
решить эту проблему - также

433
00:17:26,880 --> 00:17:28,799
преобразовать  все эти разные роли

434
00:17:28,799 --> 00:17:30,160
в вопросы,

435
00:17:30,160 --> 00:17:32,960
например, кто что-то закончил, что

436
00:17:32,960 --> 00:17:35,440
кто-то закончил и что кто-то

437
00:17:35,440 --> 00:17:37,520
закончил что-то еще, поэтому, преобразуя

438
00:17:37,520 --> 00:17:39,600
все эти вроде

439
00:17:39,600 --> 00:17:42,240
семантических отношений ошибок, мы также можем

440
00:17:42,240 --> 00:17:43,840
применить просто применить

441
00:17:43,840 --> 00:17:45,679
проблему понимания кольца и дать вам

442
00:17:45,679 --> 00:17:47,760
правильный ответ, так что это на самом деле

443
00:17:47,760 --> 00:17:49,840
очень интересная перспектива того, что

444
00:17:49,840 --> 00:17:51,520
понимание прочитанного может быть

445
00:17:51,520 --> 00:17:53,760
универсально полезным для многих других

446
00:17:53,760 --> 00:17:56,080
задач,

447
00:17:56,400 --> 00:17:57,520
поэтому теперь

448
00:17:57,520 --> 00:17:59,600
я собираюсь ввести  сделать это, как

449
00:17:59,600 --> 00:18:01,600
набор данных строки вопроса Стэнфорда, вызвать

450
00:18:01,600 --> 00:18:03,520
бога, поэтому, если вы собираетесь выполнять

451
00:18:03,520 --> 00:18:05,840
окончательные проекты по умолчанию, вам нужно будет

452
00:18:05,840 --> 00:18:07,919
использовать этот набор данных,

453
00:18:07,919 --> 00:18:10,000
поэтому цилиндрические вопросы и наборы данных на

454
00:18:10,000 --> 00:18:11,600
самом деле являются

455
00:18:11,600 --> 00:18:14,240
набором данных для контролируемого понимания чтения, поэтому он состоит

456
00:18:14,240 --> 00:18:16,240
из 100 тыс.

457
00:18:16,240 --> 00:18:18,160
аннотированных отрывков и  ответ на

458
00:18:18,160 --> 00:18:20,799
вопрос также утроился, так что вот один

459
00:18:20,799 --> 00:18:24,480
пример из этого набора данных,

460
00:18:24,480 --> 00:18:26,720
и я просто хочу

461
00:18:26,720 --> 00:18:28,480
сказать, что еще одна важная вещь, которую нужно

462
00:18:28,480 --> 00:18:31,120
иметь в виду, это то, что этот набор

463
00:18:31,120 --> 00:18:34,720
данных состоит из 100k аннотированных примеров

464
00:18:34,720 --> 00:18:36,640
и такого рода крупномасштабных контролируемых

465
00:18:36,640 --> 00:18:38,720
набор данных также является очень

466
00:18:38,720 --> 00:18:40,480
ключевым ингредиентом для обучения

467
00:18:40,480 --> 00:18:42,240
эффективных нейронных моделей для понимания прочитанного,

468
00:18:42,240 --> 00:18:45,280
поэтому после того, как набор

469
00:18:45,280 --> 00:18:47,120
данных был также собран, многие другие, такие как более поздние наборы данных, были

470
00:18:47,120 --> 00:18:49,600
также собраны, в основном, этот

471
00:18:49,600 --> 00:18:52,720
размер составляет около 100 тысяч, поэтому 100 тысяч на

472
00:18:52,720 --> 00:18:54,960
самом деле очень важны для передачи

473
00:18:54,960 --> 00:18:58,400
нейронных сетей.  модели, поэтому для этих наборов данных

474
00:18:58,400 --> 00:19:02,400
отрывки похожи на один отрывок,

475
00:19:02,400 --> 00:19:04,240
на один абзац, выбранный из

476
00:19:04,240 --> 00:19:06,400
английской Википедии, который вы  По сути, состоит

477
00:19:06,400 --> 00:19:08,960
из 100-150 слов, а

478
00:19:08,960 --> 00:19:11,120
вопросы основаны на источниках энергии, в основном это

479
00:19:11,120 --> 00:19:13,200
электронный вид поддержки,

480
00:19:13,200 --> 00:19:15,120
и очень важным

481
00:19:15,120 --> 00:19:17,520
свойством этого набора данных является

482
00:19:17,520 --> 00:19:20,799
то, что каждый ответ представляет собой короткий текстовый сегмент,

483
00:19:20,799 --> 00:19:23,360
или мы могли бы потратить его в отрывке, чтобы

484
00:19:23,360 --> 00:19:25,679
вы  Из этого примера видно, что

485
00:19:25,679 --> 00:19:27,840
вот три разных вопроса, и каждый

486
00:19:27,840 --> 00:19:30,640
из этих ответов um может быть фактически найден

487
00:19:30,640 --> 00:19:33,520
как короткий текст сегмента в отрывке,

488
00:19:33,520 --> 00:19:35,600
так что это на самом деле довольно

489
00:19:35,600 --> 00:19:37,120
интересное свойство, я знаю, что это также

490
00:19:37,120 --> 00:19:39,360
важное важное

491
00:19:39,360 --> 00:19:41,919
свойство этого набора данных, но также  просто для

492
00:19:41,919 --> 00:19:44,880
ээээвиса, что это также ограничение,

493
00:19:44,880 --> 00:19:46,960
потому что не на все вопросы можно

494
00:19:46,960 --> 00:19:49,679
ответить, используйте таким образом, поэтому только те

495
00:19:49,679 --> 00:19:51,600
вопросы, на которые вы можете найти

496
00:19:51,600 --> 00:19:53,919
ответ как заклинание в отрывке,

497
00:19:53,919 --> 00:19:55,840
фактически могут быть включены в этот набор данных в

498
00:19:55,840 --> 00:19:58,320
основном,

499
00:19:58,400 --> 00:20:01,039
но  сегодня, так что эти данные,

500
00:20:01,039 --> 00:20:02,880
да, я забыл сказать, что этот набор данных

501
00:20:02,880 --> 00:20:05,919
был собран в 2016 году несколькими

502
00:20:05,919 --> 00:20:08,159
известными исследователями из Стэнфорда, поэтому он

503
00:20:08,159 --> 00:20:10,400
называется Стэнфордский вопрос. Три набора данных.

504
00:20:10,400 --> 00:20:12,559
д. Спустя четыре или пять

505
00:20:12,559 --> 00:20:14,960
лет школа по-прежнему остается самым

506
00:20:14,960 --> 00:20:17,280
популярным набором данных для понимания прочитанного, так

507
00:20:17,280 --> 00:20:19,039
что на самом деле вы знаете, что он очень чистый в

508
00:20:19,039 --> 00:20:21,360
высококачественном дневном наборе, но это также не

509
00:20:21,360 --> 00:20:23,760
такой очень сложный набор данных, поэтому сегодня в

510
00:20:23,760 --> 00:20:25,679
основном набор данных о состоянии баллов

511
00:20:25,679 --> 00:20:28,159
был почти  продано, и уже существуют сохранения,

512
00:20:28,159 --> 00:20:30,080
оценивающие производительность человека,

513
00:20:34,159 --> 00:20:35,919
и я также хочу быстро упомянуть об

514
00:20:35,919 --> 00:20:38,000
оценке этого

515
00:20:38,000 --> 00:20:40,559
набора данных для кредитного консультирования в Стэнфорде,

516
00:20:40,559 --> 00:20:42,159
так что в основном есть две метрики оценки,

517
00:20:42,159 --> 00:20:44,480
чтобы оценить, насколько хорошо система

518
00:20:44,480 --> 00:20:46,960
может работать с этими данными, установить две метрики

519
00:20:46,960 --> 00:20:50,080
эээ, давайте посмотрим, соответствует ли совпадение и оценка a1, поэтому,

520
00:20:50,080 --> 00:20:51,679
когда вы подписываете совпадение, в основном это просто

521
00:20:51,679 --> 00:20:54,080
бинарный индикатор ноль один эм, основанный на

522
00:20:54,080 --> 00:20:56,000
мерах, может ли ответ действительно

523
00:20:56,000 --> 00:20:58,240
быть точно сопоставлен с золотым ответом,

524
00:20:58,240 --> 00:20:59,679
а оценка восьмой строки в основном

525
00:20:59,679 --> 00:21:02,720
измеряет некоторую частичную оценку

526
00:21:02,720 --> 00:21:05,039
достаточно, чтобы провести оценку, так что в основном

527
00:21:05,039 --> 00:21:07,200
для набора для разработки и

528
00:21:07,200 --> 00:21:08,880
тестирования будет собрано примерно три золотых ответа,

529
00:21:08,880 --> 00:21:11,360
потому что гм

530
00:21:11,360 --> 00:21:12,960
для этого  me, там может быть не

531
00:21:12,960 --> 00:21:14,960
только один уникальный ответ, поэтому может быть

532
00:21:14,960 --> 00:21:16,880
несколько возможных ответов,

533
00:21:16,880 --> 00:21:18,960
и конечная матрица в основном

534
00:21:18,960 --> 00:21:21,360
принимает довольно хороший ответ и сравнивает или

535
00:21:21,360 --> 00:21:23,280
сравнивает прогнозируемый ответ на каждый

536
00:21:23,280 --> 00:21:25,760
ответ кода с некоторыми подобными

537
00:21:25,760 --> 00:21:28,159
статьями, а также включенными перестановками

538
00:21:28,159 --> 00:21:31,039
и, очевидно, вы можете вычислить

539
00:21:31,039 --> 00:21:33,919
точную оценку совпадения, а также точную оценку,

540
00:21:33,919 --> 00:21:36,000
сравнивая, возвращаясь, сравнивая

541
00:21:36,000 --> 00:21:38,080
прогнозируемый ответ с золотым ответом, а

542
00:21:38,080 --> 00:21:40,640
затем, наконец, переходите на следующий курс, и гм,

543
00:21:40,640 --> 00:21:41,760
потому что

544
00:21:41,760 --> 00:21:44,400
в демонстрационном наборе или тестовом наборе есть много разных примеров, и теперь,

545
00:21:44,400 --> 00:21:46,159
наконец, мы  просто возьмите среднее значение

546
00:21:46,159 --> 00:21:48,320
всех примеров для точного совпадения плаката

547
00:21:48,320 --> 00:21:50,320
и эталонной оценки,

548
00:21:50,320 --> 00:21:52,960
чтобы при использовании этого метода

549
00:21:52,960 --> 00:21:56,559
оценки оценочная производительность человека была

550
00:21:56,559 --> 00:21:58,880
оценена исследователями в то время, а

551
00:21:58,880 --> 00:22:00,960
оценка исследователями в то

552
00:22:00,960 --> 00:22:04,799
время была точной оценкой совпадения 82,3  процентов,

553
00:22:04,799 --> 00:22:08,559
а оценка f1 составляет 91,2,

554
00:22:08,559 --> 00:22:10,840
так что вот лишь краткий

555
00:22:10,840 --> 00:22:13,600
пример, так что здесь возникает вопрос, что

556
00:22:13,600 --> 00:22:16,720
делал Tesla в декабре 1878 года

557
00:22:16,720 --> 00:22:19,360
и т.  вот три возможных ответа, поэтому,

558
00:22:19,360 --> 00:22:21,919
если я увижу, что первые два ответа -

559
00:22:21,919 --> 00:22:24,799
это одна и та же левая трава, а третий ответ

560
00:22:24,799 --> 00:22:28,159
- левое дыхание, и, как я думаю,

561
00:22:28,159 --> 00:22:30,960
этот тип страха действительно

562
00:22:30,960 --> 00:22:33,360
связан с его семьей, а затем вы

563
00:22:33,360 --> 00:22:36,240
чувствуете себя перед  предсказание потрачено,

564
00:22:36,240 --> 00:22:38,640
а это задержка дыхания и подачи,

565
00:22:38,640 --> 00:22:40,320
чтобы вы могли видеть, что

566
00:22:40,320 --> 00:22:42,720
нет точного совпадения между

567
00:22:42,720 --> 00:22:45,440
предсказанным ответом и любым из ответов,

568
00:22:45,440 --> 00:22:47,919
поэтому точное совпадение будет нулем, а

569
00:22:47,919 --> 00:22:50,400
оценка a5 будет принимать  max я

570
00:22:50,400 --> 00:22:51,760
не собираюсь говорить о том, как они

571
00:22:51,760 --> 00:22:53,280
вычисляются,

572
00:22:53,280 --> 00:22:55,200
поэтому я предлагаю вам проверить исходную

573
00:22:55,200 --> 00:22:57,679
статью, поэтому, вычислив этот курс и

574
00:22:57,679 --> 00:22:59,919
взяв максимальное и окончательное,

575
00:22:59,919 --> 00:23:02,799
оценка f1 будет 0,667,

576
00:23:02,799 --> 00:23:05,520
что является оценкой f1 для этого креатива

577
00:23:05,520 --> 00:23:08,880
ответ на этот набор данных,

578
00:23:08,880 --> 00:23:11,280
так что дайте один вопрос, на который вы могли бы ответить,

579
00:23:11,280 --> 00:23:14,559
таков: если вы можете выполнять другие задачи, такие как

580
00:23:14,559 --> 00:23:16,799
распознавание именованных объектов или

581
00:23:16,799 --> 00:23:19,600
извлечение отношений, наклеивая что-то на

582
00:23:19,600 --> 00:23:23,520
птицу и настраивая для этого, или выполняйте

583
00:23:23,520 --> 00:23:26,080
это, как ответ на вопрос делает одно или  в

584
00:23:26,080 --> 00:23:30,320
другой метод работает лучше, и

585
00:23:30,559 --> 00:23:34,640
насколько это интересный вопрос,

586
00:23:35,120 --> 00:23:37,200
так что я действительно не видел, что хорошо, так

587
00:23:37,200 --> 00:23:39,120
как были некоторые утверждения, что хорошо,

588
00:23:39,120 --> 00:23:41,200
все задачи могут быть преобразованы в

589
00:23:41,200 --> 00:23:43,200
вопросы и задачи, но я не уверен,

590
00:23:43,200 --> 00:23:44,799
что есть  действительно похоже на очень честное

591
00:23:44,799 --> 00:23:46,640
сравнение, скажем, молодой и

592
00:23:46,640 --> 00:23:48,400
антипризнанный, и действительно

593
00:23:48,400 --> 00:23:50,159
преобразовав это в задачи, отвечающие на вопросы,

594
00:23:50,159 --> 00:23:52,559
чтобы мне не приходилось на это отвечать,

595
00:23:52,559 --> 00:23:54,880
так что вид государственного искусства и ваша система

596
00:23:54,880 --> 00:23:57,279
все еще пытаются просто изменить или

597
00:23:57,279 --> 00:23:59,600
Последовательность tagger uh маркировка поверх

598
00:23:59,600 --> 00:24:01,840
птицы, так что да, у меня действительно нет

599
00:24:01,840 --> 00:24:05,720
предустановки что-то вроде этого,

600
00:24:07,200 --> 00:24:09,919
если я продолжу,

601
00:24:10,159 --> 00:24:12,400
хорошо,

602
00:24:13,919 --> 00:24:15,840
хорошо, теперь я собираюсь поговорить о том, как

603
00:24:15,840 --> 00:24:17,200
построить

604
00:24:17,200 --> 00:24:19,039
нейронные модели для понимания прочитанного,

605
00:24:19,039 --> 00:24:21,360
в частности, как мы можем  построить модель

606
00:24:21,360 --> 00:24:23,039
для решения этих стандартных вопросов в

607
00:24:23,039 --> 00:24:25,360
наборах данных, называемых набором данных, я также хочу

608
00:24:25,360 --> 00:24:27,600
просто быстро упомянуть, что гм, потому

609
00:24:27,600 --> 00:24:28,960
что есть много разных документов, которые он

610
00:24:28,960 --> 00:24:31,039
фактически использует, например,

611
00:24:31,039 --> 00:24:33,039
разные понятия для обозначения одного и того

612
00:24:33,039 --> 00:24:35,200
же, поэтому, начиная с u  м, поэтому я

613
00:24:35,200 --> 00:24:37,840
собираюсь использовать абзацы отрывка в контексте,

614
00:24:37,840 --> 00:24:40,000
а также подвергать сомнению запрос в основном

615
00:24:40,000 --> 00:24:41,840
взаимозаменяемо, поэтому они в основном

616
00:24:41,840 --> 00:24:43,520
относятся к приговору, потому что в

617
00:24:43,520 --> 00:24:45,200
разных документах также используются разные

618
00:24:45,200 --> 00:24:46,960
понятия, поэтому я просто хочу быстро

619
00:24:46,960 --> 00:24:48,799
упомянуть, что

620
00:24:48,799 --> 00:24:50,720
хорошо, так как мы можем построить  модель для

621
00:24:50,720 --> 00:24:52,159
решения этой проблемы,

622
00:24:52,159 --> 00:24:54,480
поэтому давайте сначала сформулируем эту проблему

623
00:24:54,480 --> 00:24:57,039
так, что вход этой проблемы - э-э,

624
00:24:57,039 --> 00:24:59,600
давайте возьмем контекст или абзац,

625
00:24:59,600 --> 00:25:02,799
так что c, который состоит из n токенов c от

626
00:25:02,799 --> 00:25:04,159
одного до cn,

627
00:25:04,159 --> 00:25:07,200
а также мы возьмем вопрос q и

628
00:25:07,200 --> 00:25:09,520
вопрос uh  состоит из m токенов q от единицы

629
00:25:09,520 --> 00:25:10,720
до qm,

630
00:25:10,720 --> 00:25:13,039
поэтому um может быть примерно от 100

631
00:25:13,039 --> 00:25:16,559
до um между 100 и 200 для пятна,

632
00:25:16,559 --> 00:25:18,480
а m будет намного короче, будет

633
00:25:18,480 --> 00:25:20,559
примерно 10 или 15.

634
00:25:20,559 --> 00:25:22,640
а затем, поскольку ответ содержит эти

635
00:25:22,640 --> 00:25:24,480
ограничения в качестве ответа  должен быть вашим

636
00:25:24,480 --> 00:25:27,279
вторым текстом в отрывке, поэтому вывод

637
00:25:27,279 --> 00:25:28,720
может быть просто

638
00:25:28,720 --> 00:25:30,480
записан таким образом, поэтому мы собираемся

639
00:25:30,480 --> 00:25:32,480
предсказать начало и конец,

640
00:25:32,480 --> 00:25:34,799
поэтому начало и затем конец будут расположены

641
00:25:36,000 --> 00:25:38,080
в диапазоне между ними,

642
00:25:38,080 --> 00:25:40,080
чтобы он  это в основном всего две контрольные точки,

643
00:25:40,080 --> 00:25:43,840
извините, два конца точки ответа

644
00:25:46,000 --> 00:25:46,960
и эм,

645
00:25:46,960 --> 00:25:49,799
так что Скотт был собран еще в конце

646
00:25:49,799 --> 00:25:54,320
2016 года. так что после 2016 года было

647
00:25:54,320 --> 00:25:57,520
похоже на посещение двух семейств

648
00:25:57,520 --> 00:25:59,760
нейронных моделей моделей, чтобы решить эту проблему, чтобы решить эту проблему

649
00:25:59,760 --> 00:26:02,559
например, набор данных по основному баллу, так

650
00:26:02,559 --> 00:26:05,200
что первая семья в основном похожа на э-э,

651
00:26:05,200 --> 00:26:07,279
есть много моделей, которые выходят в течение

652
00:26:07,279 --> 00:26:10,720
этого периода между 2016 и 2018 годами.

653
00:26:10,720 --> 00:26:13,120
Итак, это мои семейные модели, которые показывают, что я всегда

654
00:26:13,120 --> 00:26:15,440
могу основывать модели с вниманием,

655
00:26:15,440 --> 00:26:17,760
так что они похожи на список

656
00:26:17,760 --> 00:26:20,640
представленных моделей, появившихся

657
00:26:20,640 --> 00:26:22,480
в этот период, включая некоторую

658
00:26:22,480 --> 00:26:24,880
работу, которую я проделал, когда был аспирантом

659
00:26:24,880 --> 00:26:26,240
в Стэнфорде,

660
00:26:26,240 --> 00:26:28,240
и теперь вторая

661
00:26:28,240 --> 00:26:30,400
модель второго класса, которую я поместил здесь,

662
00:26:30,400 --> 00:26:32,320
действительно есть, которая разделена здесь

663
00:26:32,320 --> 00:26:34,559
до версии после рождения, поэтому

664
00:26:34,559 --> 00:26:37,120
после рождения  вышло так, что почти

665
00:26:37,120 --> 00:26:38,880
эти другие модели понимания прочитанного

666
00:26:38,880 --> 00:26:40,640
были построены на том, как найти две

667
00:26:40,640 --> 00:26:43,039
модели птиц, а не только для размера модели

668
00:26:43,039 --> 00:26:45,120
для моделей жизни при рождении, так что

669
00:26:45,120 --> 00:26:46,880
модели языка прогнозирования и для  такого рода

670
00:26:46,880 --> 00:26:49,919
проблемы с пониманием прочитанного,

671
00:26:49,919 --> 00:26:52,960
так что здесь как два

672
00:26:52,960 --> 00:26:55,760
звука, звук - это иллюстрации этих

673
00:26:55,760 --> 00:26:58,159
двух семейств моделей, так что

674
00:26:58,159 --> 00:27:00,480
слева похожи на результаты моделей на основе iostm,

675
00:27:00,480 --> 00:27:03,679
а справа - на

676
00:27:03,679 --> 00:27:06,720
модели Бертона,

677
00:27:06,720 --> 00:27:08,320
а затем нам нужно  доработайте эту модель

678
00:27:08,320 --> 00:27:09,520
для вопроса для

679
00:27:09,520 --> 00:27:11,919
задачи на понимание прочитанного, чтобы я знал, что

680
00:27:12,640 --> 00:27:15,039
поэтому мой план сегодня - сначала

681
00:27:15,039 --> 00:27:17,520
попытаться поговорить об этих моделях на базе iOS 10,

682
00:27:17,520 --> 00:27:19,440
поэтому я собираюсь потратить

683
00:27:19,440 --> 00:27:21,679
немного больше времени на  эта часть, потому что я

684
00:27:21,679 --> 00:27:23,520
знаю, что для окончательного проекта по умолчанию

685
00:27:23,520 --> 00:27:25,440
вам нужно реализовать эту модель

686
00:27:25,440 --> 00:27:27,600
с самого начала, поэтому я буду

687
00:27:27,600 --> 00:27:29,360
работать над тем, как построить эту модель,

688
00:27:29,360 --> 00:27:31,520
как шаг за шагом, и, надеюсь, вы

689
00:27:31,520 --> 00:27:32,880
сможете хорошо понять, как

690
00:27:32,880 --> 00:27:35,039
эта модель работает, а затем я просто

691
00:27:35,039 --> 00:27:36,880
собираюсь кратко рассказать о том, как

692
00:27:36,880 --> 00:27:38,880
ее построить, используйте модели птиц

693
00:27:38,880 --> 00:27:41,679
для понимания кольца,

694
00:27:41,679 --> 00:27:43,520
хорошо, поэтому, прежде чем я начну говорить об

695
00:27:43,520 --> 00:27:45,760
этих моделях lstm, я знаю, что вы

696
00:27:45,760 --> 00:27:47,600
уже изучили эту последовательность  l

697
00:27:47,600 --> 00:27:49,440
модели последовательностей без напряжения для машинного

698
00:27:49,440 --> 00:27:50,799
перевода,

699
00:27:50,799 --> 00:27:53,760
поэтому я был таким, поэтому я хочу провести некоторые

700
00:27:53,760 --> 00:27:55,279
связи между проблемой машинного

701
00:27:55,279 --> 00:27:56,720
перевода и проблемой понимания прочитанного,

702
00:27:56,720 --> 00:27:58,399
потому что они

703
00:27:58,399 --> 00:28:01,679
действительно имеют много общего,

704
00:28:01,679 --> 00:28:03,120
так что сначала

705
00:28:03,120 --> 00:28:05,200
э-э, так что в модели машинного перевода

706
00:28:05,200 --> 00:28:07,360
или подобном использовании последовательности  В модели

707
00:28:07,360 --> 00:28:10,080
последовательности есть предложение источника и пакета,

708
00:28:10,080 --> 00:28:12,640
поэтому в основном мы используем две последовательности,

709
00:28:12,640 --> 00:28:14,480
но в нашем случае в этом

710
00:28:14,480 --> 00:28:16,799
случае понимания прочитанного у нас также есть две

711
00:28:16,799 --> 00:28:19,279
последовательности: одна - это отрывок, а другая

712
00:28:19,279 --> 00:28:21,200
- вопрос, но длина может быть

713
00:28:21,200 --> 00:28:22,799
немного несбалансированной, потому что отрывок

714
00:28:22,799 --> 00:28:24,559
будет намного длиннее, чем вопрос,

715
00:28:24,559 --> 00:28:26,240
но, по сути, также есть две

716
00:28:26,240 --> 00:28:28,799
последовательности,

717
00:28:29,440 --> 00:28:30,640
и

718
00:28:30,640 --> 00:28:32,159
поэтому в понимании прочитанного нам

719
00:28:32,159 --> 00:28:35,039
нужно смоделировать, например, какие слова в

720
00:28:35,039 --> 00:28:37,200
отрывке наиболее актуальны для вопроса, а

721
00:28:37,200 --> 00:28:38,480
затем, если они не имеют отношения к

722
00:28:38,480 --> 00:28:41,039
вопросу, так что все  также имеет отношение к тому,

723
00:28:41,039 --> 00:28:43,679
какой набор вопросительных слов, так что

724
00:28:43,679 --> 00:28:45,520
это в

725
00:28:45,520 --> 00:28:48,000
основном очень важная вещь,

726
00:28:48,000 --> 00:28:49,520
важная тонкая  g, который нам действительно нужно

727
00:28:49,520 --> 00:28:50,480
моделировать,

728
00:28:50,480 --> 00:28:52,720
и это на самом деле очень похоже на

729
00:28:52,720 --> 00:28:54,559
модель машинного перевода, которая нам нужна

730
00:28:54,559 --> 00:28:55,600
для моделирования того,

731
00:28:55,600 --> 00:28:57,919
какие слова в исходном предложении на

732
00:28:57,919 --> 00:28:59,919
самом деле наиболее релевантны для

733
00:28:59,919 --> 00:29:02,320
текущего пакетного слова, чтобы вы могли представить,

734
00:29:02,320 --> 00:29:03,840
что внимание будет также действительно

735
00:29:03,840 --> 00:29:06,080
ключевым ингредиентом здесь является то, что,

736
00:29:06,080 --> 00:29:08,480
как и в какой-то новой модели последовательности 26, нам

737
00:29:08,480 --> 00:29:09,840
нужно моделировать внимание между

738
00:29:09,840 --> 00:29:12,480
исходным предложением и целевым предложением,

739
00:29:12,480 --> 00:29:14,320
нам также необходимо моделировать внимание

740
00:29:14,320 --> 00:29:16,640
между отрывком и вопросом, так что

741
00:29:16,640 --> 00:29:18,720
это на самом деле очень похоже,

742
00:29:18,720 --> 00:29:20,320
так что что-то на самом деле  не очень

743
00:29:20,320 --> 00:29:21,520
похоже

744
00:29:21,520 --> 00:29:24,320
на модель сигма 6, которую нам нужно построить,

745
00:29:24,320 --> 00:29:26,240
как автоматический регрессивный

746
00:29:26,240 --> 00:29:28,559
декодер декодера для генерации целевого предложения

747
00:29:28,559 --> 00:29:30,640
слово за словом, но в этой

748
00:29:30,640 --> 00:29:32,960
проблеме понимания чтения нам не

749
00:29:32,960 --> 00:29:35,279
нужно действительно ничего генерировать, поэтому мы просто

750
00:29:35,279 --> 00:29:37,200
берем тест  и возьмите вопрос так, чтобы,

751
00:29:37,200 --> 00:29:39,520
по крайней мере, для

752
00:29:39,520 --> 00:29:41,600
набора данных школы нам просто нужно изменить два

753
00:29:41,600 --> 00:29:44,080
файла классов, чтобы предсказать начальную и конечную

754
00:29:44,080 --> 00:29:45,840
позиции ответа,

755
00:29:45,840 --> 00:29:47,840
чтобы  что эта часть на самом деле упрощена,

756
00:29:47,840 --> 00:29:49,200
поэтому, когда вам не нужно менять

757
00:29:49,200 --> 00:29:53,600
декодер для генерации целевого предложения,

758
00:29:53,600 --> 00:29:56,640
хорошо, так что теперь я собираюсь поговорить об одном

759
00:29:56,640 --> 00:29:59,840
um этой модели, окрашенной по def, так что это

760
00:29:59,840 --> 00:30:02,240
означает двунаправленный поток внимания

761
00:30:02,240 --> 00:30:04,480
для машины  понимание, поэтому он был

762
00:30:04,480 --> 00:30:06,880
предложен средним тюленем и другими людьми

763
00:30:06,880 --> 00:30:10,159
в 2017 году, поэтому он остается до того, как лед,

764
00:30:10,159 --> 00:30:12,559
прежде чем птица выйдет, он остается одной

765
00:30:12,559 --> 00:30:13,840
из самых популярных

766
00:30:13,840 --> 00:30:16,480
моделей понимания прочитанного и достиг очень

767
00:30:16,480 --> 00:30:18,240
хороших результатов в то время, по крайней мере,

768
00:30:18,240 --> 00:30:19,919
на небольшом наборе данных,

769
00:30:19,919 --> 00:30:22,320
поэтому  Вы можете видеть, что эта модель

770
00:30:22,320 --> 00:30:24,640
кажется довольно сложной, но

771
00:30:24,640 --> 00:30:27,039
если вы посмотрите, посмотрите на эту модель

772
00:30:27,039 --> 00:30:29,360
снизу вверх, она на самом деле

773
00:30:29,360 --> 00:30:32,799
может быть разложена на множество разных

774
00:30:32,799 --> 00:30:34,240
слоев,

775
00:30:34,240 --> 00:30:36,720
поэтому в следующем я просто буду рассекать или

776
00:30:36,720 --> 00:30:38,720
рассекать  эту модель слой за слоем и

777
00:30:38,720 --> 00:30:40,320
поговорим о том, что на самом деле делают эти слои,

778
00:30:40,320 --> 00:30:42,159
и как мы действительно можем

779
00:30:42,159 --> 00:30:43,840
построить эту модель от нижнего

780
00:30:43,840 --> 00:30:45,520
слоя к верхнему, а затем, наконец,

781
00:30:45,520 --> 00:30:47,440
перейти как модель, которую вы знаете, введите

782
00:30:51,440 --> 00:30:53,840
ну ладно, так что первая диаграмма на самом

783
00:30:53,840 --> 00:30:56,080
деле является тремя нижними слоями,

784
00:30:56,080 --> 00:30:58,320
называемыми слоем встраивания символов,

785
00:30:58,320 --> 00:30:59,760
слоем встраивания слов и слоем встраивания фразы,

786
00:30:59,760 --> 00:31:01,679
так что я просто сложил их

787
00:31:01,679 --> 00:31:03,600
вместе, потому что это функция кодирования,

788
00:31:04,880 --> 00:31:07,039
так что идея здесь в том, что ладно, давайте

789
00:31:07,039 --> 00:31:08,799
возьмем контекст  запроса или рассматриваемого отрывка,

790
00:31:08,799 --> 00:31:10,880
нам нужно кодировать их

791
00:31:10,880 --> 00:31:13,200
отдельно,

792
00:31:13,200 --> 00:31:14,640
чтобы сделать это,

793
00:31:14,640 --> 00:31:17,279
чтобы эта модель в основном предлагала

794
00:31:17,279 --> 00:31:20,159
использовать конкатенацию встраивания слова, а

795
00:31:20,159 --> 00:31:22,240
также встраивание символа

796
00:31:22,240 --> 00:31:24,559
для каждого слова в контексте и

797
00:31:24,559 --> 00:31:26,960
запросе, поэтому для встраивания слова

798
00:31:26,960 --> 00:31:28,799
просто, поэтому, если вы

799
00:31:28,799 --> 00:31:30,480
выучили встраивание слов, чтобы вы могли просто

800
00:31:30,480 --> 00:31:32,880
найти слово для этого слова, например,

801
00:31:32,880 --> 00:31:35,600
Сиэтл, просто используйте глобальное вложение

802
00:31:35,600 --> 00:31:37,840
как репутацию для этого слова

803
00:31:37,840 --> 00:31:39,919
и для части встраивания символов,

804
00:31:39,919 --> 00:31:41,600
поэтому вам в основном нужно

805
00:31:41,600 --> 00:31:44,399
представить каждый символ  в этом мире, таком

806
00:31:44,399 --> 00:31:47,039
как Сиэтл, и обхода

807
00:31:47,039 --> 00:31:49,440
сверточной нейронной сети с некоторыми

808
00:31:49,440 --> 00:31:51,360
операциями максимального объединения, а затем,

809
00:31:51,360 --> 00:31:53,279
наконец, вы можете просто g  и одна репутация

810
00:31:53,279 --> 00:31:55,360
вверху, а затем вы просто объединяете

811
00:31:55,360 --> 00:31:57,519
его собственное вложение слов и

812
00:31:57,519 --> 00:31:58,880
вычисляющее тело,

813
00:31:58,880 --> 00:32:00,640
чтобы эти виды встраивания были

814
00:32:00,640 --> 00:32:02,240
эффективно показаны для улучшения

815
00:32:02,240 --> 00:32:04,320
репликации для невидимых или реальных

816
00:32:04,320 --> 00:32:05,919
слов,

817
00:32:05,919 --> 00:32:08,320
так что математически математически вы можете

818
00:32:08,320 --> 00:32:09,200
видеть, что

819
00:32:09,200 --> 00:32:11,600
для каждого слова  в контексте запроса

820
00:32:11,600 --> 00:32:13,679
вы можете просто представить это

821
00:32:13,679 --> 00:32:16,320
вращение как блоки встраивания

822
00:32:16,320 --> 00:32:18,159
и встраивания символов, а затем мы

823
00:32:18,159 --> 00:32:20,240
просто объединяем их и передаем,

824
00:32:20,240 --> 00:32:22,320
как и все сети шоссе, поэтому я не

825
00:32:22,320 --> 00:32:24,799
пишу функцию здесь, так что  вы можете

826
00:32:24,799 --> 00:32:26,840
просто взглянуть на оранжевый на

827
00:32:26,840 --> 00:32:29,679
бумаге и вторую часть, а для других

828
00:32:29,679 --> 00:32:32,559
мы называем это проблемой очень визуальным словом,

829
00:32:32,559 --> 00:32:35,279
поэтому в следующий раз мы собираемся передать это

830
00:32:35,279 --> 00:32:37,919
как вложение слова в два отдельных

831
00:32:37,919 --> 00:32:41,279
двунаправленных lstms, чтобы по отдельности

832
00:32:41,279 --> 00:32:43,519
создавать эти контекстуализированные вложения

833
00:32:43,519 --> 00:32:45,760
как для контекста, так и для запроса,

834
00:32:45,760 --> 00:32:47,279
поэтому

835
00:32:47,279 --> 00:32:49,279
давайте посмотрим на это уравнение, чтобы

836
00:32:49,279 --> 00:32:52,000
взять репутацию этого слова, и мы

837
00:32:52,000 --> 00:32:53,840
просто, в основном, это как одна

838
00:32:53,840 --> 00:32:56,880
модель lstm.  в одном направлении, и

839
00:32:56,880 --> 00:32:59,120
все это всегда можно смоделировать с другого

840
00:32:59,120 --> 00:33:02,080
направления, поэтому нам просто нужно

841
00:33:02,080 --> 00:33:04,559
согласовать два поворота заголовка в двух

842
00:33:04,559 --> 00:33:06,799
направлениях, и, наконец, мы можем получить

843
00:33:06,799 --> 00:33:09,760
контекстное вращение для этого для

844
00:33:09,760 --> 00:33:12,000
каждого отдельного слова в контексте, и теперь

845
00:33:12,000 --> 00:33:14,080
мы можем сделать  То же самое для

846
00:33:14,080 --> 00:33:16,720
вопроса репутации um,

847
00:33:16,720 --> 00:33:18,320
я также хочу быстро упомянуть, потому что я

848
00:33:18,320 --> 00:33:20,159
упомянул модель последовательной последовательности,

849
00:33:20,159 --> 00:33:21,760
последовательность просто сигма, хотя мы

850
00:33:21,760 --> 00:33:23,840
не можем снова сделать эти двунаправленные

851
00:33:23,840 --> 00:33:26,320
основы для двух последовательностей, например,

852
00:33:26,320 --> 00:33:28,080
потому что декодер полностью

853
00:33:28,080 --> 00:33:30,799
авторегрессивный  модель, поэтому

854
00:33:30,799 --> 00:33:33,320
декодер обычно просто реализуется как

855
00:33:33,320 --> 00:33:36,000
однонаправленный стержень, но поскольку здесь мы

856
00:33:36,000 --> 00:33:38,399
действительно не заботимся о генерации,

857
00:33:38,399 --> 00:33:40,320
поэтому мы можем просто использовать два двунаправленных

858
00:33:40,320 --> 00:33:42,880
сканирования для представления вращений, это на

859
00:33:42,880 --> 00:33:45,360
самом деле очень важно,

860
00:33:45,360 --> 00:33:47,120
это двунаправленное  длина на

861
00:33:47,120 --> 00:33:49,039
самом деле очень важна для захвата

862
00:33:49,039 --> 00:33:50,559
контактов как с левой, так и с правой

863
00:33:50,559 --> 00:33:53,559
стороны,

864
00:33:54,320 --> 00:33:56,720
хорошо, поэтому следующий компонент - это следующий

865
00:33:56,720 --> 00:33:58,559
слой, который он называется  d слой потока внимания,

866
00:33:58,559 --> 00:34:01,039
поэтому я просто обращаю на это внимание,

867
00:34:01,039 --> 00:34:03,200
так что идея изменения идея

868
00:34:03,200 --> 00:34:04,960
внимания пытается

869
00:34:04,960 --> 00:34:07,120
уловить взаимодействия между контактами

870
00:34:07,120 --> 00:34:09,440
и запросом, и ничего в

871
00:34:09,440 --> 00:34:12,000
этой статье они предлагают два

872
00:34:12,000 --> 00:34:14,000
типа внимания,

873
00:34:14,000 --> 00:34:15,839
поэтому первый тип  напряжения мы называем

874
00:34:15,839 --> 00:34:18,000
контекстом, требующим внимания,

875
00:34:18,000 --> 00:34:19,679
поэтому идея состоит в том, чтобы

876
00:34:19,679 --> 00:34:22,960
для каждого контекстного слова

877
00:34:23,040 --> 00:34:26,239
мы могли найти некоторые наиболее релевантные слова

878
00:34:26,239 --> 00:34:27,440
в вопросе

879
00:34:27,440 --> 00:34:29,199
из вопроса для запроса для

880
00:34:29,199 --> 00:34:32,320
слов запроса, поэтому вот один пример, так что

881
00:34:32,320 --> 00:34:35,040
здесь контекстный контекст Барака Обамы

882
00:34:35,040 --> 00:34:37,119
- это  президент США,

883
00:34:37,119 --> 00:34:39,918
поэтому для каждого контекстного слова нам нужно

884
00:34:39,918 --> 00:34:42,399
найти соответствие, но определить, какие слова

885
00:34:42,399 --> 00:34:44,079
в вопросе могут быть фактически согласованы

886
00:34:44,079 --> 00:34:46,239
с этим контекстным словом, чтобы мы могли видеть,

887
00:34:46,239 --> 00:34:48,639
что оба слова Барака Обамы могут быть согласованы с тем,

888
00:34:48,639 --> 00:34:50,800
с кем и президент связан

889
00:34:50,800 --> 00:34:53,359
релиз и альянс сша соединенные

890
00:34:53,359 --> 00:34:55,679
штаты так заняты каждым контентом будут

891
00:34:55,679 --> 00:34:59,359
пытаться найти наиболее релевантные слова запроса

892
00:34:59,920 --> 00:35:02,560
другой второй тип напряжения называется

893
00:35:02,560 --> 00:35:05,040
запрос к контексту или тензио  n, так что это совсем

894
00:35:05,040 --> 00:35:08,079
другое направление, поэтому здесь идея состоит в том, чтобы

895
00:35:08,079 --> 00:35:11,040
выбрать некоторые контекстные слова, которые наиболее

896
00:35:11,040 --> 00:35:12,160
релевантны

897
00:35:12,160 --> 00:35:14,560
одному из предыдущих слов, потому что

898
00:35:14,560 --> 00:35:16,480
контекст может быть очень длинным,

899
00:35:16,480 --> 00:35:18,720
поэтому большая часть контекста может быть просто

900
00:35:18,720 --> 00:35:22,240
неуместна для этого вопроса, поэтому мы

901
00:35:22,240 --> 00:35:25,119
просто пробежавшись по нескольким примерам,

902
00:35:25,119 --> 00:35:26,800
вы увидите, что первое, что нам нужно

903
00:35:26,800 --> 00:35:29,520
сделать, это попытаться определить, какие

904
00:35:29,520 --> 00:35:31,760
части предложений в этом контексте действительно могут иметь

905
00:35:31,760 --> 00:35:33,680
отношение к этому вопросу, поэтому

906
00:35:33,680 --> 00:35:35,680
этот тип запроса к контексту или

907
00:35:35,680 --> 00:35:38,320
вниманию пытается

908
00:35:38,320 --> 00:35:41,119
запишите,

909
00:35:41,119 --> 00:35:43,280
какие контекстные слова на самом деле могут быть наиболее

910
00:35:43,280 --> 00:35:44,400
релевантными

911
00:35:44,400 --> 00:35:47,040
для запроса к одному из слов запроса,

912
00:35:47,040 --> 00:35:49,359
поэтому для этого примера вопрос заключается в том,

913
00:35:49,359 --> 00:35:52,160
какой город ухаживает зимой, поэтому вы,

914
00:35:52,160 --> 00:35:53,599
потому что вопрос задается о

915
00:35:53,599 --> 00:35:55,839
цветении, чтобы вы могли найти

916
00:35:55,839 --> 00:35:58,560
цифры приоритета  хорошо, синий означает, что его речи

917
00:35:58,560 --> 00:36:00,640
на самом деле очень актуальны для этого

918
00:36:00,640 --> 00:36:02,960
вопроса,

919
00:36:02,960 --> 00:36:04,880
и теперь мы также находим это зимой,

920
00:36:04,880 --> 00:36:06,640
потому что зимой он также упоминает

921
00:36:06,640 --> 00:36:07,599
вопрос,

922
00:36:07,599 --> 00:36:10,320
поэтому этот конкретный контекст um также должен был

923
00:36:10,320 --> 00:36:13,200
быть r  подходит к этому вопросу, так что эти

924
00:36:14,160 --> 00:36:16,240
контекстные слова, вероятно, должны быть

925
00:36:16,240 --> 00:36:18,960
захвачены, и в этом внимании,

926
00:36:18,960 --> 00:36:20,560
хорошо, это на самом деле имеет отношение к этому

927
00:36:20,560 --> 00:36:22,400
вопросу,

928
00:36:22,400 --> 00:36:23,760
хорошо, на самом деле это

929
00:36:23,760 --> 00:36:26,320
просто интуиция этих двух типов

930
00:36:26,320 --> 00:36:27,440
напряжения,

931
00:36:27,440 --> 00:36:29,359
и это также то, почему это  Модель

932
00:36:29,359 --> 00:36:31,280
называется двунаправленным потоком внимания,

933
00:36:31,280 --> 00:36:33,280
потому что существует контраст, требующий

934
00:36:33,280 --> 00:36:35,599
внимания, и есть также библиотека для

935
00:36:35,599 --> 00:36:38,640
контекстного внимания,

936
00:36:38,960 --> 00:36:40,800
поэтому позвольте мне просто рассказать о том, как

937
00:36:40,800 --> 00:36:42,400
на самом деле

938
00:36:43,200 --> 00:36:45,440
сделать это, например, кривая для контекстного внимания,

939
00:36:45,440 --> 00:36:47,119
контекстное периодическое напряжение в  эта

940
00:36:47,119 --> 00:36:48,000
модель,

941
00:36:48,000 --> 00:36:50,480
поэтому способ, которым они это делают, состоит в том,

942
00:36:50,480 --> 00:36:53,280
чтобы сначала вычислить форму сходства

943
00:36:53,280 --> 00:36:55,920
для каждой пары контекстуализированного

944
00:36:55,920 --> 00:36:57,760
вектора ci

945
00:36:57,760 --> 00:37:00,000
и для каждой пары вопросов с

946
00:37:00,000 --> 00:37:02,240
qj, так что это фактически результат

947
00:37:02,240 --> 00:37:04,079
уровня кодирования, поэтому это

948
00:37:04,079 --> 00:37:06,560
уже результат  Уровни

949
00:37:06,560 --> 00:37:08,000
lstm и мастер - это просто

950
00:37:08,000 --> 00:37:10,400
компьютерное сходство, формируемое

951
00:37:10,400 --> 00:37:12,960
путем взятия ci

952
00:37:12,960 --> 00:37:14,160
qj,

953
00:37:14,160 --> 00:37:16,960
а также поэлементного

954
00:37:16,960 --> 00:37:18,880
умножения c и qj,

955
00:37:18,880 --> 00:37:21,119
чтобы они b  как правило, просто объедините эти

956
00:37:21,119 --> 00:37:24,240
три вектора, чтобы на выходе получился

957
00:37:24,240 --> 00:37:27,119
шестой h-мерный вектор, и они просто

958
00:37:27,119 --> 00:37:29,440
умножают это, чтобы вычислить скалярное

959
00:37:29,440 --> 00:37:31,920
произведение другого, как обучаемый

960
00:37:31,920 --> 00:37:34,320
вектор, а затем, наконец, просто отбросьте

961
00:37:34,320 --> 00:37:36,640
этот базовый, может дать вам одно скалярное

962
00:37:36,640 --> 00:37:40,320
число sij, которое  измеряет, насколько

963
00:37:40,320 --> 00:37:43,280
сходство между этим контекстом, где ci,

964
00:37:43,280 --> 00:37:46,320
а также этот вопрос были qj, поэтому, если у

965
00:37:46,320 --> 00:37:48,720
меня есть, если я узнал некоторое внимание

966
00:37:48,720 --> 00:37:50,960
раньше, так что на самом деле это всего лишь один

967
00:37:50,960 --> 00:37:53,680
вариант этой модели, поэтому может быть

968
00:37:53,680 --> 00:37:56,079
много разных способов определить это

969
00:37:56,079 --> 00:37:58,560
сходство  и оценки схожести, так что

970
00:37:58,560 --> 00:38:00,480
это, по сути, только один вариант

971
00:38:00,480 --> 00:38:02,400
дизайна этой модели,

972
00:38:02,400 --> 00:38:05,040
хорошо, поэтому после определения этих полей для

973
00:38:05,040 --> 00:38:07,599
sij,

974
00:38:08,160 --> 00:38:10,160
чтобы контекст снова привлекал внимание,

975
00:38:10,160 --> 00:38:11,920
например, какие вопросительные слова наиболее

976
00:38:11,920 --> 00:38:13,680
актуальны для ci,

977
00:38:13,680 --> 00:38:16,160
поэтому способ сделать это в основном

978
00:38:16,160 --> 00:38:18,560
просто  этой матрице сходства

979
00:38:18,560 --> 00:38:20,000
для sij

980
00:38:20,000 --> 00:38:21,520
для каждой строки мы должны в основном

981
00:38:21,520 --> 00:38:24,400
соответствовать как одно контекстное слово для

982
00:38:24,400 --> 00:38:25,520
каждой строки

983
00:38:25,520 --> 00:38:26,960
um,

984
00:38:26,960 --> 00:38:29,200
поэтому они собираются вычислить мягкое

985
00:38:29,200 --> 00:38:32,079
max для каждой строки, и это может дать

986
00:38:32,079 --> 00:38:34,640
нам силу нормализации um alpha ij,

987
00:38:34,640 --> 00:38:36,880
которая является нашим распределением вероятностей

988
00:38:36,880 --> 00:38:40,320
по всем вопросительным словам fij,

989
00:38:40,320 --> 00:38:42,160
так что это действительно похоже на все

990
00:38:42,160 --> 00:38:44,640
механизмы внимания, которые вы,

991
00:38:44,640 --> 00:38:46,320
вероятно, видели в этом классе, поэтому в

992
00:38:46,320 --> 00:38:49,200
основном для каждого  В контексте мы

993
00:38:49,200 --> 00:38:51,119
берем мягкий максимум um

994
00:38:51,119 --> 00:38:52,560
um

995
00:38:52,560 --> 00:38:54,880
по всем вопросительным словам и получаем

996
00:38:54,880 --> 00:38:57,760
распределение вероятностей um, а затем,

997
00:38:57,760 --> 00:39:00,160
наконец, просто возьмем линейную комбинацию

998
00:39:01,280 --> 00:39:02,800
взвешенной комбинации этих

999
00:39:02,800 --> 00:39:05,520
напряжений для rij, а также вопросительного

1000
00:39:05,520 --> 00:39:07,760
вектора qj, а затем, наконец, вы  может

1001
00:39:07,760 --> 00:39:10,960
получить вектор ai, который на самом деле является 2-

1002
00:39:10,960 --> 00:39:13,760
мерным вектором, поэтому этот контекст запроса

1003
00:39:13,760 --> 00:39:15,520
показывает достаточно удержание, в основном просто попробуйте

1004
00:39:15,520 --> 00:39:17,520
захватить, какие слова вопросов

1005
00:39:17,520 --> 00:39:20,720
наиболее актуальны для каждого контекстного слова,

1006
00:39:20,720 --> 00:39:24,079
поэтому следующие пять частей - это абзац,

1007
00:39:24,079 --> 00:39:26,160
извините, название здесь, извините, это  на

1008
00:39:26,160 --> 00:39:27,760
самом деле является запросом к контексту или

1009
00:39:27,760 --> 00:39:30,240
вниманию, что означает, что какие

1010
00:39:30,240 --> 00:39:32,720
контекстные слова имеют отношение к некоторым

1011
00:39:32,720 --> 00:39:35,040
вопросительным словам, поэтому мы не так много

1012
00:39:35,040 --> 00:39:36,800
c  контекстные слова не будут иметь отношения к

1013
00:39:36,800 --> 00:39:39,599
этому вопросу, поэтому идея сделать это, чтобы

1014
00:39:39,599 --> 00:39:43,040
сделать это, состоит в том, чтобы сделать это для каждой строки этого sij this

1015
00:39:43,040 --> 00:39:45,359
busy просто берет математические оценки

1016
00:39:45,359 --> 00:39:48,560
по всем вопросительным словам um и после

1017
00:39:48,560 --> 00:39:51,040
получения этой обратной оценки для вычисления

1018
00:39:51,040 --> 00:39:54,400
softmax по всем  контекстные слова здесь,

1019
00:39:54,400 --> 00:39:56,880
так что здесь я на самом деле многочислен по всем

1020
00:39:56,880 --> 00:39:59,920
контекстным словам, и это может

1021
00:39:59,920 --> 00:40:02,240
привлечь внимание, еще одна оценка внимания бета i,

1022
00:40:02,240 --> 00:40:04,160
которая фиксирует, насколько важен этот

1023
00:40:04,160 --> 00:40:06,640
контекст, имеет отношение к этому

1024
00:40:06,640 --> 00:40:08,160
вопросу,

1025
00:40:08,160 --> 00:40:10,800
поэтому после вычисления этой бета i

1026
00:40:10,800 --> 00:40:13,040
мы снова можем любить вычисление  это похоже на

1027
00:40:13,040 --> 00:40:14,800
взвешенную комбинацию

1028
00:40:14,800 --> 00:40:17,680
путем вычисления um

1029
00:40:17,680 --> 00:40:20,319
где-то посредством суммирования бета i, а

1030
00:40:20,319 --> 00:40:23,440
также вектора контекста контекста ci, а

1031
00:40:23,440 --> 00:40:25,440
затем, наконец, мы можем получить наш вектор bi,

1032
00:40:25,440 --> 00:40:27,599
который также является еще одним 2-мерным

1033
00:40:27,599 --> 00:40:29,119
вектором,

1034
00:40:29,119 --> 00:40:30,960
и окончательный результат этой функции внимания на

1035
00:40:30,960 --> 00:40:32,480
самом деле  очень сложным

1036
00:40:32,480 --> 00:40:35,280
здесь также является выбор дизайна этой

1037
00:40:35,280 --> 00:40:36,640
модели,

1038
00:40:36,640 --> 00:40:39,440
поэтому он принимает контекстную меру ci,

1039
00:40:39,440 --> 00:40:42,000
а поскольку он берет ai из этой части

1040
00:40:42,000 --> 00:40:44,560
контекста для запроса удержания

1041
00:40:44,560 --> 00:40:46,079
и t  шляпа берет элемент из

1042
00:40:46,079 --> 00:40:48,800
умножения между c и ai, а

1043
00:40:48,800 --> 00:40:51,200
также cnbi и, наконец, принимает

1044
00:40:51,200 --> 00:40:53,200
конкатенацию, и он может дать вам

1045
00:40:53,200 --> 00:40:57,760
вектор продукции или h,

1046
00:40:57,760 --> 00:40:59,839
хорошо, возможно, я хочу немного остановиться

1047
00:40:59,839 --> 00:41:01,119
и проверить, есть ли какие-либо вопросы,

1048
00:41:01,119 --> 00:41:02,240
потому что это, вероятно,  немного

1049
00:41:02,240 --> 00:41:04,960
сложный

1050
00:41:05,440 --> 00:41:06,800
один вопрос

1051
00:41:06,800 --> 00:41:09,599
: почему запрос к контексту и контексту

1052
00:41:09,599 --> 00:41:13,520
внимания запроса не симметричен,

1053
00:41:14,480 --> 00:41:16,880
ммм,

1054
00:41:16,880 --> 00:41:19,520
это хороший вопрос, да, так вот, по

1055
00:41:19,520 --> 00:41:21,040
сути, цель, которую вы пытаетесь достичь,

1056
00:41:21,040 --> 00:41:22,880
потому что, если цель является конечной целью,

1057
00:41:22,880 --> 00:41:25,760
пытается найти промежуток  в отрывке,

1058
00:41:25,760 --> 00:41:28,079
чтобы удерживать точку этой

1059
00:41:28,079 --> 00:41:30,079
функции внимания, которую вы знаете, пытаясь

1060
00:41:30,079 --> 00:41:32,880
произвести вращение для каждого отдельного

1061
00:41:32,880 --> 00:41:35,839
слова контекста в этом контексте,

1062
00:41:35,839 --> 00:41:37,280
так что, гм,

1063
00:41:37,280 --> 00:41:39,280
поэтому мы не пытаемся генерировать

1064
00:41:39,280 --> 00:41:40,800
уведомления о вопросах здесь, он

1065
00:41:40,800 --> 00:41:42,960
попытается сгенерировать  контекстные

1066
00:41:42,960 --> 00:41:45,520
ориентации, так что разница

1067
00:41:45,520 --> 00:41:47,839
между этими двумя, например, сначала давайте

1068
00:41:47,839 --> 00:41:49,440
попробуем посмотреть, какие вопросы, слова имеют

1069
00:41:49,440 --> 00:41:51,520
отношение к этому контекстному слову, другая

1070
00:41:51,520 --> 00:41:53,040
часть пытается найти  Выясните, какое

1071
00:41:53,040 --> 00:41:54,880
контекстное слово может быть актуальным, а какой

1072
00:41:54,880 --> 00:41:58,240
контекст не может быть неуместным.

1073
00:41:58,240 --> 00:41:59,680
Надеюсь, это звучит так, что ответы на

1074
00:41:59,680 --> 00:42:00,640
вопрос

1075
00:42:00,640 --> 00:42:02,800
здесь - это более простой вопрос по той

1076
00:42:02,800 --> 00:42:04,960
же теме, который может помочь,

1077
00:42:04,960 --> 00:42:07,760
есть ли причина, по которой вы используете оба запроса

1078
00:42:07,760 --> 00:42:09,680
для контекста и  контекст для запроса

1079
00:42:09,680 --> 00:42:12,160
внимания, иногда полезно

1080
00:42:12,160 --> 00:42:16,400
или нормально использовать только один,

1081
00:42:16,400 --> 00:42:18,560
это хороший вопрос,

1082
00:42:18,560 --> 00:42:21,359
причина в том, что да, поэтому я собираюсь показать

1083
00:42:21,359 --> 00:42:23,040
некоторые обязательства частично из этой статьи,

1084
00:42:23,040 --> 00:42:25,119
поэтому они в основном просто обнаруживают, что

1085
00:42:25,119 --> 00:42:27,839
оба направления могут действительно помочь

1086
00:42:27,839 --> 00:42:30,319
рисование контекста контекстной кривой,

1087
00:42:30,319 --> 00:42:32,880
поэтому будут некоторые исследования отношений, поэтому

1088
00:42:32,880 --> 00:42:35,599
использование одного набора полезно, но не так

1089
00:42:35,599 --> 00:42:39,440
хорошо, как использование обоих направлений.

1090
00:42:49,760 --> 00:42:51,520
bi

1091
00:42:51,520 --> 00:42:54,319
это правильно, или там есть опечатка,

1092
00:42:54,319 --> 00:42:56,079
о, это не опечатка,

1093
00:42:56,079 --> 00:42:58,640
так что снова извините, так что вывод да, я

1094
00:42:58,640 --> 00:43:00,960
знаю, что это будет сбивать с толку, так что также

1095
00:43:00,960 --> 00:43:03,200
вывод этой модели этот

1096
00:43:03,200 --> 00:43:06,240
модуль com должен получить репутацию для каждого

1097
00:43:06,240 --> 00:43:08,880
cont  ext word в конце, так что

1098
00:43:08,880 --> 00:43:12,319
оба вывода для ai и bi i на самом деле

1099
00:43:12,319 --> 00:43:15,280
um перечислить из, например, um, на самом деле вы

1100
00:43:15,280 --> 00:43:16,560
знаете,

1101
00:43:16,560 --> 00:43:19,760
если это по всем контекстным словам,

1102
00:43:19,760 --> 00:43:22,800
так что bi будут навыки, просто попробуйте

1103
00:43:22,800 --> 00:43:25,440
объединить все вопросы

1104
00:43:25,440 --> 00:43:28,000
по всем  контекстные слова, но бета

1105
00:43:28,000 --> 00:43:30,800
i измеряет важность этого

1106
00:43:30,800 --> 00:43:32,079
типа тестовых слов

1107
00:43:32,079 --> 00:43:34,640
по сравнению со всеми контекстными словами,

1108
00:43:34,640 --> 00:43:36,720
поэтому и ai, и bi на самом деле

1109
00:43:36,720 --> 00:43:39,359
относятся к контекстным словам, да, поэтому вы

1110
00:43:39,359 --> 00:43:41,119
можете видеть, что здесь в основном выполняется

1111
00:43:41,119 --> 00:43:42,400
какой-то

1112
00:43:42,400 --> 00:43:44,640
элемент  мудрое умножение, так что

1113
00:43:44,640 --> 00:43:46,960
вывод gi будет фактически упорядочен

1114
00:43:46,960 --> 00:43:49,839
от единицы до um, что является

1115
00:43:49,839 --> 00:43:51,839
количеством контекстных слов,

1116
00:43:51,839 --> 00:43:54,079
есть много вопросов по этому

1117
00:43:54,079 --> 00:43:56,240
um, каково обоснование

1118
00:43:56,240 --> 00:43:58,160
выражения для gi,

1119
00:43:58,160 --> 00:44:00,240
как можно придумать  такое

1120
00:44:00,240 --> 00:44:02,720
выражение

1121
00:44:02,720 --> 00:44:04,960
хорошо, я не знаю, я думаю, вы также

1122
00:44:04,960 --> 00:44:07,119
попробуете много вещей,

1123
00:44:07,119 --> 00:44:09,119
хорошо, поэтому ключевым моментом здесь является попытка

1124
00:44:09,119 --> 00:44:11,359
понять, хорошо, поэтому правила

1125
00:44:11,359 --> 00:44:13,280
конкурса требуют равенства внимания или

1126
00:44:13,280 --> 00:44:15,599
ротации контекста, поэтому я держу пари, что  Для этого

1127
00:44:15,599 --> 00:44:17,359
может быть много разных формаций,

1128
00:44:17,359 --> 00:44:20,000
я также думаю, что авторы пробовали

1129
00:44:20,000 --> 00:44:21,200
много разных,

1130
00:44:21,200 --> 00:44:24,079
но только то, что они вроде могут

1131
00:44:24,079 --> 00:44:28,079
придумать, и я думаю, что если через неделю, ммм,

1132
00:44:28,079 --> 00:44:29,359
могут быть другие способы

1133
00:44:29,359 --> 00:44:31,359
включить оба внимания, но это

1134
00:44:31,359 --> 00:44:35,560
не нужно писать таким образом,

1135
00:44:37,440 --> 00:44:40,000
я имею в виду, что еще один вопрос будет

1136
00:44:40,000 --> 00:44:42,960
в запросе, внимание к контексту,

1137
00:44:42,960 --> 00:44:45,280
почему вы делаете максимум

1138
00:44:45,280 --> 00:44:48,240
внутри мягкого максимума,

1139
00:44:48,240 --> 00:44:50,319
да, да, да, извините, я должен был

1140
00:44:50,319 --> 00:44:52,400
объяснить это более четко, поэтому здесь

1141
00:44:52,400 --> 00:44:54,800
снова запрос к контексту или  внимание, чтобы

1142
00:44:54,800 --> 00:44:56,400
попытаться хорошо измерить,

1143
00:44:56,400 --> 00:44:58,240
является ли важность

1144
00:44:58,240 --> 00:45:01,119
этих контекстных слов по отношению к

1145
00:45:01,119 --> 00:45:05,520
некоторым вопросительным словам um some answer, поэтому, если это

1146
00:45:05,520 --> 00:45:07,520
так, взяв максимум

1147
00:45:07,520 --> 00:45:10,319
для каждой строки в этой матрице ace, поэтому он в

1148
00:45:10,319 --> 00:45:12,160
основном пытается понять, хорошо, какое

1149
00:45:12,160 --> 00:45:14,560
вопросительное слово um  на самом деле наиболее

1150
00:45:14,560 --> 00:45:17,680
актуально для этого контекстного слова, если это

1151
00:45:17,680 --> 00:45:19,920
число все еще очень низкое, что означает,

1152
00:45:19,920 --> 00:45:21,760
что нет никаких вопросительных слов, которые

1153
00:45:21,760 --> 00:45:24,240
можно было бы выровнять с этим контекстным словом,

1154
00:45:24,240 --> 00:45:26,960
так что это будет просто, если я возьму после

1155
00:45:26,960 --> 00:45:28,720
takin  g математика, если это число все еще

1156
00:45:28,720 --> 00:45:30,079
очень низкое, это означает, что этот вопрос

1157
00:45:30,079 --> 00:45:32,880
контекстного голосования не очень актуален, поэтому в

1158
00:45:32,880 --> 00:45:34,480
основном именно поэтому мы берем

1159
00:45:34,480 --> 00:45:37,280
мягкий максимум, наша цена максимума поверх

1160
00:45:37,280 --> 00:45:39,520
максимума

1161
00:45:41,839 --> 00:45:43,760
ах, я знаю, вы хотите еще больше, вы

1162
00:45:43,760 --> 00:45:46,240
хочу продолжить,

1163
00:45:46,240 --> 00:45:48,400
я, наверное, должен ну, у меня не так

1164
00:45:48,400 --> 00:45:50,000
много слайдов, но я счастлив на

1165
00:45:50,000 --> 00:45:52,640
вопросы после обеда, да, может,

1166
00:45:52,640 --> 00:45:54,400
тебе стоит продолжить

1167
00:46:01,200 --> 00:46:03,839
нормальный стимул, так что это два из

1168
00:46:03,839 --> 00:46:05,839
пяти, наконец, есть два слоя меньшего размера

1169
00:46:05,839 --> 00:46:07,520
и выходные слои,

1170
00:46:07,520 --> 00:46:09,680
поэтому для современного слоя снова, потому что

1171
00:46:09,680 --> 00:46:12,880
после слоя внимания они принимают некоторое

1172
00:46:12,880 --> 00:46:14,960
вращение нагревателя,

1173
00:46:14,960 --> 00:46:16,720
так что основное gi,

1174
00:46:16,720 --> 00:46:19,520
которое улавливает напряжение между вашими

1175
00:46:19,520 --> 00:46:21,680
контактами и  запрос, а затем в

1176
00:46:21,680 --> 00:46:24,240
основном просто передает gi на другие

1177
00:46:24,240 --> 00:46:26,720
два уровня двунаправленных основ,

1178
00:46:26,720 --> 00:46:29,200
и многие причины, по которым они это делают, заключается в

1179
00:46:29,200 --> 00:46:30,560
том, что уровень внимания в основном

1180
00:46:30,560 --> 00:46:32,079
моделирует взаимодействия между

1181
00:46:32,079 --> 00:46:33,920
запросом и контекстом,

1182
00:46:33,920 --> 00:46:35,680
и теперь, передав его другому  Два

1183
00:46:35,680 --> 00:46:37,760
уровня двунаправленного lstms

1184
00:46:37,760 --> 00:46:40,000
современные слои - это базовое моделирование, они

1185
00:46:40,000 --> 00:46:42,880
также могут сначала смоделировать взаимодействия,

1186
00:46:42,880 --> 00:46:45,200
используя контекстные слова,

1187
00:46:45,200 --> 00:46:48,160
так что это формулировка здесь um, так

1188
00:46:48,160 --> 00:46:50,319
что это два уровня двунаправленного stm,

1189
00:46:50,319 --> 00:46:52,800
принимая вход gis, а выход

1190
00:46:52,800 --> 00:46:55,599
будет  быть на mi, который является еще одним

1191
00:46:56,880 --> 00:46:59,440
двухмерным вектором для каждого контекстного слова

1192
00:46:59,440 --> 00:47:02,880
в отрывке,

1193
00:47:03,200 --> 00:47:06,000
хорошо, так что финал также связывает до сих пор

1194
00:47:06,000 --> 00:47:07,920
других игроков, это всего лишь два друга класса, которые

1195
00:47:08,880 --> 00:47:11,040
просто пытаются предсказать начальную и конечную

1196
00:47:11,040 --> 00:47:12,240
позиции,

1197
00:47:12,240 --> 00:47:14,720
так что, выполнив  это значит, что первый контакт -

1198
00:47:14,720 --> 00:47:17,599
это gi и mi, так что на самом деле

1199
00:47:17,599 --> 00:47:20,559
это будет 10-часовой размерный вектор, и путем

1200
00:47:20,559 --> 00:47:22,800
вычисления скалярного произведения другого

1201
00:47:22,800 --> 00:47:25,520
вектора, называемого w start, и этого результирующего

1202
00:47:25,520 --> 00:47:27,680
вектора, они могут получить в основном

1203
00:47:27,680 --> 00:47:28,559
оценку

1204
00:47:28,559 --> 00:47:29,599
для каждой

1205
00:47:29,599 --> 00:47:32,240
позиции в контексте  а затем вы можете

1206
00:47:32,240 --> 00:47:34,800
просто применить мягкий максимум,

1207
00:47:34,800 --> 00:47:36,240
и тогда это даст вам

1208
00:47:36,240 --> 00:47:38,559
вероятность того, что хорошо, какова вероятность того, что

1209
00:47:38,559 --> 00:47:41,520
этот раздел i будет на

1210
00:47:41,520 --> 00:47:43,040
самом деле uh

1211
00:47:43,040 --> 00:47:44,240
на основе

1212
00:47:45,440 --> 00:47:47,280
um начальной позиции конечного a  nswer

1213
00:47:47,280 --> 00:47:48,559
string,

1214
00:47:48,559 --> 00:47:50,960
и у них также есть что-то um еще один

1215
00:47:50,960 --> 00:47:53,520
классификатор для прогнозирования конечной

1216
00:47:53,520 --> 00:47:55,200
позиции ответа, но они также сделали

1217
00:47:55,200 --> 00:47:57,040
что-то немного более сложное,

1218
00:47:57,040 --> 00:47:59,280
поэтому они фактически передают mi другому

1219
00:47:59,280 --> 00:48:01,599
двунаправленному lstm здесь, поэтому они называют его

1220
00:48:01,599 --> 00:48:06,480
mi, и они совместимы и  m prime,

1221
00:48:06,480 --> 00:48:08,480
извините, это заголовок, так что это будет

1222
00:48:08,480 --> 00:48:09,599
wn

1223
00:48:09,599 --> 00:48:11,520
um, поэтому они вычисляют скалярное произведение

1224
00:48:11,520 --> 00:48:15,200
между wn и этим вектором, и это может

1225
00:48:15,200 --> 00:48:18,400
дать воспроизведение нашей собственной вероятности uh

1226
00:48:18,400 --> 00:48:20,640
вероятности по всем позициям, которая

1227
00:48:20,640 --> 00:48:23,040
предсказывает, ммм,

1228
00:48:23,040 --> 00:48:25,119
насколько вероятно, что эта позиция будет  конечная

1229
00:48:25,119 --> 00:48:27,839
позиция ответа, чтобы сделать это,

1230
00:48:27,839 --> 00:48:29,839
передав mi другому по их

1231
00:48:29,839 --> 00:48:32,319
характеру и причине, по которой

1232
00:48:32,319 --> 00:48:33,920
они пытаются уловить какую-то

1233
00:48:33,920 --> 00:48:36,000
зависимость между выбором

1234
00:48:36,000 --> 00:48:37,920
начала и конца, чтобы вы могли представить это

1235
00:48:37,920 --> 00:48:40,800
начало и не должны  Это не слишком

1236
00:48:40,800 --> 00:48:43,119
раздельно, так что это не должно быть

1237
00:48:43,119 --> 00:48:45,280
независимым предсказанием, но если они

1238
00:48:45,280 --> 00:48:48,079
заявят, что, если вы столкнетесь с какой-то

1239
00:48:48,079 --> 00:48:51,440
зависимостью между mi и um, просто

1240
00:48:51,440 --> 00:48:53,280
продолжайте начинать, и pn это может  на самом деле работает

1241
00:48:53,280 --> 00:48:56,079
лучше,

1242
00:48:56,079 --> 00:48:57,839
хорошо, я закончил с

1243
00:48:57,839 --> 00:48:59,359
этой частью

1244
00:48:59,359 --> 00:49:01,520
описания модели обхода,

1245
00:49:01,520 --> 00:49:05,200
любые быстрые вопросы, на которые я могу ответить,

1246
00:49:05,440 --> 00:49:07,920
я думаю, вы действительно можете продолжать

1247
00:49:07,920 --> 00:49:09,839
хорошо,

1248
00:49:09,839 --> 00:49:11,920
хорошо, извините, я забыл упомянуть об этом, хорошо,

1249
00:49:11,920 --> 00:49:13,680
окончательная потеря тренировки

1250
00:49:13,680 --> 00:49:15,680
будет просто с учетом этих двух

1251
00:49:15,680 --> 00:49:18,240
вероятностей  распределений, и это в

1252
00:49:18,240 --> 00:49:19,920
основном просто следующая отрицательная логарифмическая

1253
00:49:19,920 --> 00:49:22,880
вероятность того, что золото в качестве ответа на золото,

1254
00:49:22,880 --> 00:49:24,800
просто

1255
00:49:24,800 --> 00:49:27,359
начальная позиция ответа на золото

1256
00:49:27,359 --> 00:49:30,800
и позиция ответа, и

1257
00:49:30,800 --> 00:49:33,599
только мы, в основном, принимаем

1258
00:49:33,599 --> 00:49:35,920
произведение этих двух вероятностей, но

1259
00:49:35,920 --> 00:49:39,119
вы применяете  они применяют много, так что

1260
00:49:39,119 --> 00:49:42,400
это сумма двух отрицательных членов журнала

1261
00:49:42,400 --> 00:49:44,400
будет окончательной потерей цепочки, и

1262
00:49:44,400 --> 00:49:46,160
вся модель в целом может просто

1263
00:49:46,160 --> 00:49:48,079
изменять нашу запись в любом случае со

1264
00:49:48,079 --> 00:49:49,920
слоя кодирования на уровень внимания, на

1265
00:49:49,920 --> 00:49:52,559
современный уровень и на выходной уровень, поэтому  это

1266
00:49:52,559 --> 00:49:55,760
будет просто um завершает все,

1267
00:49:55,760 --> 00:49:58,720
что вся модель этой модели

1268
00:49:58,720 --> 00:50:00,240
хорошо,

1269
00:50:00,240 --> 00:50:02,800
так что эта модель фактически um достигнута,

1270
00:50:02,800 --> 00:50:04,960
как uh на наборе данных она достигнет

1271
00:50:04,960 --> 00:50:08,319
показателя 77,3 f1, так что  Я упоминал

1272
00:50:08,319 --> 00:50:11,119
ранее, так что 2000 операций начали,

1273
00:50:11,119 --> 00:50:12,559
они обнаружили, что

1274
00:50:12,559 --> 00:50:14,800
внимание пульсара в двух

1275
00:50:14,800 --> 00:50:16,800
направлениях действительно важно, если вы обычно

1276
00:50:16,800 --> 00:50:18,400
двигаетесь в одном направлении, производительность на

1277
00:50:18,400 --> 00:50:20,559
самом деле немного упадет, если мы

1278
00:50:20,559 --> 00:50:22,640
удалим контакты до параллельного напряжения,

1279
00:50:22,640 --> 00:50:24,640
производительность упадет до шестидесяти семи

1280
00:50:24,640 --> 00:50:26,960
балл семь восемь, волна один балл, и если

1281
00:50:26,960 --> 00:50:28,720
вы удалите эту часть, она упадет

1282
00:50:28,720 --> 00:50:31,359
до четырех целых восемь баллов, а затем

1283
00:50:31,359 --> 00:50:33,280
также могут помочь вложения персонажей,

1284
00:50:33,280 --> 00:50:34,960
поэтому, если вы удалите персонажа в

1285
00:50:34,960 --> 00:50:38,480
балансе, вы получите как 1,9

1286
00:50:38,480 --> 00:50:40,880
балла

1287
00:50:40,880 --> 00:50:42,720
и справа от этого рисунка у вас есть

1288
00:50:42,720 --> 00:50:44,880
этот слайд, вы можете увидеть очень большую

1289
00:50:44,880 --> 00:50:47,599
таблицу, так что в основном это все модели,

1290
00:50:47,599 --> 00:50:50,480
которые рассчитываются в то время между 2016

1291
00:50:50,480 --> 00:50:54,079
и 2018 годами, так что вы можете видеть это по

1292
00:50:54,079 --> 00:50:55,960
определению здесь, так что вы достигнете

1293
00:50:55,960 --> 00:50:58,960
балл 77,3 f1 и базовый, все

1294
00:50:58,960 --> 00:51:00,559
модели на самом деле очень

1295
00:51:00,559 --> 00:51:03,520
похожи, поэтому цифры варьируются от,

1296
00:51:03,520 --> 00:51:04,559
например,

1297
00:51:04,559 --> 00:51:07,040
наибольшего числа здесь 79,8

1298
00:51:07,040 --> 00:51:09,599
до, например, после того, как Elmo был

1299
00:51:09,599 --> 00:51:11,040
представлен,  числа были на

1300
00:51:11,040 --> 00:51:13,200
самом деле немного улучшены, поэтому

1301
00:51:13,200 --> 00:51:14,960
до локтя в основном все числа на

1302
00:51:14,960 --> 00:51:17,040
самом деле вроде как похожи, так что каждая

1303
00:51:17,040 --> 00:51:19,359
модель фактически улучшает нашу предпосылку

1304
00:51:19,359 --> 00:51:23,680
предыдущей модели примерно на 1,02 балла,

1305
00:51:23,680 --> 00:51:24,880
и теперь вот визуализация нашего внимания,

1306
00:51:24,880 --> 00:51:28,319
эм, чтобы показать, как

1307
00:51:28,319 --> 00:51:30,559
это, как личности для напряжения, на

1308
00:51:30,559 --> 00:51:32,240
самом деле может уловить сходство

1309
00:51:32,240 --> 00:51:33,920
между вопросительными словами и контекстными

1310
00:51:33,920 --> 00:51:36,319
словами, поэтому здесь пример вопроса, где

1311
00:51:36,319 --> 00:51:38,800
суперкубок 50 занимает

1312
00:51:38,800 --> 00:51:41,680
место, так что проблема здесь является фактическим

1313
00:51:41,680 --> 00:51:44,160
вопросительным словом, а каждый столбец представляет собой

1314
00:51:44,160 --> 00:51:46,800
матрицу, в основном, указывает на внимание

1315
00:51:46,800 --> 00:51:49,359
оцените семантическую оценку,

1316
00:51:49,359 --> 00:51:51,440
полученную с помощью этой модели, чтобы вы могли это

1317
00:51:51,440 --> 00:51:52,559
видеть,

1318
00:51:52,559 --> 00:51:54,400
и справа в основном пытается

1319
00:51:56,640 --> 00:51:59,599
распечатать или

1320
00:51:59,599 --> 00:52:02,240
отобразить контекстные слова, которые имеют наивысшие

1321
00:52:02,240 --> 00:52:03,599
оценки,

1322
00:52:03,599 --> 00:52:05,680
чтобы вы могли видеть, что

1323
00:52:05,680 --> 00:52:08,559
был очень хорошо выровнен с э-э, на

1324
00:52:08,559 --> 00:52:11,839
стадионе лева, а также суперкубок 50

1325
00:52:11,839 --> 00:52:13,680
в основном очень хорошо выровнен с

1326
00:52:13,680 --> 00:52:16,400
супербауком 50. так что это в основном реа  Лли говорит,

1327
00:52:16,400 --> 00:52:18,319
что такого рода оценки внимания могут на

1328
00:52:18,319 --> 00:52:20,000
самом деле довольно хорошо отражать эти оценки заслуг,

1329
00:52:22,720 --> 00:52:24,640
хорошо, так что

1330
00:52:24,640 --> 00:52:27,520
теперь я собираюсь поговорить о том, как

1331
00:52:27,520 --> 00:52:29,599
использовать модель бремени для решения этой

1332
00:52:29,599 --> 00:52:30,480
проблемы,

1333
00:52:30,480 --> 00:52:32,400
поэтому я знаю, что вы выучили

1334
00:52:32,400 --> 00:52:34,319
первую из последней лекции  поэтому я не

1335
00:52:34,319 --> 00:52:37,040
собираюсь повторять это так быстро, так что

1336
00:52:37,040 --> 00:52:39,119
bert, по сути, представляет собой глубокий преобразователь направления,

1337
00:52:39,119 --> 00:52:41,119
включающий предварительно обученный на

1338
00:52:41,119 --> 00:52:43,440
большом объеме текста и в

1339
00:52:43,440 --> 00:52:45,680
канале две обучающие цели, включая

1340
00:52:45,680 --> 00:52:47,680
мужское моделирование и предсказание следующего предложения,

1341
00:52:47,680 --> 00:52:49,920
и эта модель имеет  много

1342
00:52:49,920 --> 00:52:51,040
параметров,

1343
00:52:51,920 --> 00:52:54,480
так что основа птицы имеет примерно 110 миллионов

1344
00:52:54,480 --> 00:52:57,040
параметров, а очень большая модель имеет 330

1345
00:52:57,040 --> 00:52:58,839
миллионов

1346
00:52:58,839 --> 00:53:01,520
родителей, так что хорошо, так как же мы можем

1347
00:53:01,520 --> 00:53:03,280
использовать птицу для определения содержания

1348
00:53:03,280 --> 00:53:05,440
углерода, так что на самом деле это очень

1349
00:53:05,440 --> 00:53:07,680
просто и очень прямолинейно.

1350
00:53:07,680 --> 00:53:10,960
принять вопрос как сегмент a,

1351
00:53:10,960 --> 00:53:14,000
чтобы вы также были в трениях, были

1352
00:53:14,000 --> 00:53:15,760
двумя сегментами для следующей

1353
00:53:15,760 --> 00:53:18,079
задачи прогнозирования предложения, поэтому, когда вы применяете

1354
00:53:18,079 --> 00:53:20,240
глагол к пониманию прочитанного t  Задайте

1355
00:53:20,240 --> 00:53:22,000
вам, в основном, просто возьмите вопрос

1356
00:53:22,000 --> 00:53:24,559
как второй a и возьмите проход как

1357
00:53:24,559 --> 00:53:25,599
сегмент b,

1358
00:53:25,599 --> 00:53:27,440
и, наконец, цель состоит в том, чтобы попытаться

1359
00:53:27,440 --> 00:53:31,440
предсказать истинную конечную точку в сегменте b,

1360
00:53:31,440 --> 00:53:33,680
поэтому вот еще один конкретный пример, поэтому

1361
00:53:33,680 --> 00:53:35,599
вопрос в том, сколько параметров у

1362
00:53:35,599 --> 00:53:38,559
Bird large, так что  вы можете видеть это, поэтому

1363
00:53:38,559 --> 00:53:41,280
они в основном просто принимают вопрос

1364
00:53:41,280 --> 00:53:44,559
здесь, а затем принимают пассив здесь,

1365
00:53:44,559 --> 00:53:46,640
вставляя серьезный токен и

1366
00:53:46,640 --> 00:53:49,280
токен acp и просто

1367
00:53:49,280 --> 00:53:51,760
задавая вопрос о токенах перехода, а также

1368
00:53:51,760 --> 00:53:53,200
для вопросов, которые вам просто нужно передать

1369
00:53:53,200 --> 00:53:55,359
от a до вложения сегментов и

1370
00:53:55,359 --> 00:53:56,960
для отрывка, который вам просто нужно вырезать,

1371
00:53:58,079 --> 00:54:00,480
вставьте второй b вложения,

1372
00:54:00,480 --> 00:54:02,000
и теперь, наконец, потери при обучении

1373
00:54:02,000 --> 00:54:04,559
также такие же, так что вы в основном просто

1374
00:54:04,559 --> 00:54:06,800
пытаетесь максимизировать вероятность

1375
00:54:06,800 --> 00:54:09,280
суммы  естественная логарифмическая

1376
00:54:09,280 --> 00:54:11,680
вероятность начала и положения,

1377
00:54:11,680 --> 00:54:13,680
но вот способ, которым компьютер

1378
00:54:13,680 --> 00:54:16,079
запускается, и

1379
00:54:16,079 --> 00:54:17,760
вероятность um немного отличаются, так

1380
00:54:17,760 --> 00:54:19,920
что это очень просто,

1381
00:54:19,920 --> 00:54:22,800
поэтому вы просто передаете это входное обозначение um

1382
00:54:22,800 --> 00:54:26,400
в рождение, и птица может дать вам

1383
00:54:26,400 --> 00:54:28,640
скрытый вектор hi, который может фактически

1384
00:54:28,640 --> 00:54:31,280
представлять скрытый вектор,

1385
00:54:31,280 --> 00:54:33,520
соответствующий контекстному слову

1386
00:54:33,520 --> 00:54:35,280
контекстного слова ci,

1387
00:54:35,280 --> 00:54:37,200
поэтому вы можете просто

1388
00:54:37,200 --> 00:54:39,440
ввести еще два вектора w star и

1389
00:54:39,440 --> 00:54:42,559
wn, вычислив скалярное произведение, а затем

1390
00:54:42,559 --> 00:54:44,720
применить softmax  тогда вы можете просто дать

1391
00:54:44,720 --> 00:54:47,280
вам очень похожее на то, что у нас было раньше,

1392
00:54:47,280 --> 00:54:49,760
но вот высокий результат

1393
00:54:49,760 --> 00:54:51,440
от вертикального кодировщика, а затем мы

1394
00:54:51,440 --> 00:54:53,839
обучаемся этому инструменту, который мы запускаем, и

1395
00:54:53,839 --> 00:54:57,359
w и um для этих двух

1396
00:54:57,359 --> 00:55:00,960
распределений вероятностей p start vpn

1397
00:55:02,799 --> 00:55:05,200
okay  так что для этой модели

1398
00:55:05,200 --> 00:55:07,440
все вертикальные переходы, которые на

1399
00:55:07,440 --> 00:55:10,000
самом деле очень большие, если вы используете в

1400
00:55:10,000 --> 00:55:13,119
основном 110 миллионов параметров, а

1401
00:55:13,119 --> 00:55:15,200
также недавно введенные параметры h

1402
00:55:15,200 --> 00:55:16,799
star и h и

1403
00:55:16,799 --> 00:55:18,799
uh, если вы возьмете основу для рождения,

1404
00:55:18,799 --> 00:55:20,440
поэтому скрытая сторона будет

1405
00:55:20,440 --> 00:55:24,240
768  так что это всего лишь 1500 новых

1406
00:55:24,240 --> 00:55:27,119
параметров, поэтому мы просто вместе оптимизировали

1407
00:55:27,119 --> 00:55:30,559
вместе для этой обучающей цели,

1408
00:55:30,559 --> 00:55:32,480
и она действительно очень хорошо работает с

1409
00:55:32,480 --> 00:55:34,400
этой моделью, так что

1410
00:55:34,400 --> 00:55:36,880
если вы просто возьмете эту модбрейт mo  del,

1411
00:55:36,880 --> 00:55:38,640
и просто оптимизируя все параметры

1412
00:55:38,640 --> 00:55:40,720
вместе, вы можете дать вам очень высокую

1413
00:55:40,720 --> 00:55:43,200
производительность. Я покажу вам через минуту, что

1414
00:55:43,200 --> 00:55:45,119
я знаю, что даже сильные, даже если вы используете

1415
00:55:45,119 --> 00:55:47,200
более сильное творение на своем,

1416
00:55:47,200 --> 00:55:48,880
больше, чем

1417
00:55:48,880 --> 00:55:50,960
стандартные, ммм, более сильные модели, чем

1418
00:55:50,960 --> 00:55:53,119
модели птиц.  они могут даже привести к лучшей

1419
00:55:53,119 --> 00:55:55,599
производительности и по объему, и оценка,

1420
00:55:55,599 --> 00:55:57,440
которая также стала стандартным набором данных

1421
00:55:57,440 --> 00:55:58,960
для тестирования таких моделей игрового времени,

1422
00:55:59,920 --> 00:56:02,559
позвольте мне показать вам некоторые цифры, так что здесь

1423
00:56:02,559 --> 00:56:05,119
снова человеческая производительность в 91 году, а к

1424
00:56:05,119 --> 00:56:07,280
этому и 77,3,

1425
00:56:07,280 --> 00:56:09,520
и если мы просто э-э  сделайте эту работающую

1426
00:56:09,520 --> 00:56:10,480
модель,

1427
00:56:10,480 --> 00:56:13,520
чтобы птичья база могла дать вам 88,5, очень

1428
00:56:13,520 --> 00:56:16,319
большая может дать вам 19,9, чтобы вы могли видеть,

1429
00:56:16,319 --> 00:56:18,559
что это огромный прыжок от

1430
00:56:18,559 --> 00:56:21,200
крутой модели к моделям зданий

1431
00:56:21,200 --> 00:56:23,119
и, наконец, если вы увидите даже

1432
00:56:23,119 --> 00:56:25,200
последнюю гм

1433
00:56:25,200 --> 00:56:27,359
гм предварительную  -переведенные модели включают

1434
00:56:27,359 --> 00:56:30,400
робота exxon или albert, поэтому эти

1435
00:56:30,400 --> 00:56:32,079
модели либо похожи на большие, либо на эти

1436
00:56:32,079 --> 00:56:34,240
умеренные каналы, с большими крышками, либо на

1437
00:56:34,240 --> 00:56:36,559
размер модели больше, поэтому в основном эти

1438
00:56:36,559 --> 00:56:38,079
модели могут

1439
00:56:38,079 --> 00:56:40,480
дать вам другое  ей как три

1440
00:56:40,480 --> 00:56:42,960
четыре балла ii найти оценку по сравнению

1441
00:56:42,960 --> 00:56:45,359
с очень большой моделью, так что это уже

1442
00:56:45,359 --> 00:56:46,480
намного

1443
00:56:46,480 --> 00:56:48,960
выше, чем оценка f1, так что

1444
00:56:48,960 --> 00:56:52,480
это просто работает очень хорошо

1445
00:56:53,359 --> 00:56:56,839
любые быстрые вопросы,

1446
00:56:59,680 --> 00:57:02,799
я думаю, это может быть хорошо

1447
00:57:02,960 --> 00:57:04,799
хорошо так

1448
00:57:04,799 --> 00:57:07,520
хорошо так что да, я думаю, у меня есть  был

1449
00:57:07,520 --> 00:57:09,839
немного быстрым для этих моделей птиц, но затем,

1450
00:57:09,839 --> 00:57:12,160
что так, я хочу также сделать небольшое

1451
00:57:12,160 --> 00:57:13,760
сравнение между моделями биоразнообразия

1452
00:57:13,760 --> 00:57:16,319
и моделями птиц,

1453
00:57:16,319 --> 00:57:18,559
поэтому в горящей модели гораздо больше

1454
00:57:18,559 --> 00:57:20,960
плантаторов, так что это похоже на

1455
00:57:20,960 --> 00:57:24,960
110 миллионов или 330 миллионов  ветвей, но

1456
00:57:24,960 --> 00:57:26,720
у него всего около 2,5 миллионов

1457
00:57:26,720 --> 00:57:28,079
параметров,

1458
00:57:28,079 --> 00:57:29,760
и by death построен на основе

1459
00:57:29,760 --> 00:57:32,000
нескольких двунаправленных команд ios, и в

1460
00:57:32,000 --> 00:57:33,440
то время как Bird построен на их

1461
00:57:33,440 --> 00:57:35,920
трансформаторах, поэтому трансформатор означает, что

1462
00:57:35,920 --> 00:57:38,160
нет никакого повторения

1463
00:57:38,160 --> 00:57:40,000
структурной архитектуры, поэтому

1464
00:57:40,000 --> 00:57:42,720
Трансформеры намного легче парализовать,

1465
00:57:42,720 --> 00:57:45,119
и очень важное различие между

1466
00:57:45,119 --> 00:57:47,680
моделями птиц и моделями спины заключается в том, что

1467
00:57:47,680 --> 00:57:50,000
модель птицы является предварительным трендом, но по этой модели

1468
00:57:50,000 --> 00:57:51,920
строится только поверх перчаток

1469
00:57:51,920 --> 00:57:54,319
векторов  что является предварительным трендом, и все

1470
00:57:54,319 --> 00:57:55,599
остальные

1471
00:57:55,599 --> 00:57:57,839
параметры, которые новые люди узнают из этого

1472
00:57:57,839 --> 00:57:59,280
набора данных или другого

1473
00:57:59,280 --> 00:58:01,440
набора данных надзора,

1474
00:58:01,440 --> 00:58:03,760
очень ясно, что

1475
00:58:03,760 --> 00:58:06,720
предварительное обучение меняет правила игры,

1476
00:58:06,720 --> 00:58:09,440
что понимание базового может просто

1477
00:58:09,440 --> 00:58:11,440
изменить все и  также дает вам

1478
00:58:11,440 --> 00:58:13,280
очень-очень большой прирост

1479
00:58:13,280 --> 00:58:15,839
производительности,

1480
00:58:15,920 --> 00:58:17,680
но также я хочу поднять еще один

1481
00:58:17,680 --> 00:58:20,000
вопрос, поэтому, если мы не думаем об этом

1482
00:58:20,000 --> 00:58:22,960
как о предварительной тренировке, ну точно так же, как у

1483
00:58:22,960 --> 00:58:25,119
этой модели матери и рождения действительно

1484
00:58:25,119 --> 00:58:27,359
фундаментально разные,

1485
00:58:27,359 --> 00:58:29,599
я не понимаю  «Не думаю, что из-за славы - на

1486
00:58:29,599 --> 00:58:31,599
самом деле мой аргумент, поэтому давайте попробуем увидеть,

1487
00:58:31,599 --> 00:58:33,920
как эти две модели на самом деле связаны,

1488
00:58:33,920 --> 00:58:37,280
особенно с точки зрения дизайна модели,

1489
00:58:37,280 --> 00:58:39,119
поэтому с помощью этой модели, по сути, они

1490
00:58:39,119 --> 00:58:41,520
пытаются смоделировать взаимодействия

1491
00:58:41,520 --> 00:58:44,000
между вопросом и отрывком правильно, так что оба

1492
00:58:44,000 --> 00:58:45,680
вопрос, чтобы передать его в отрывке

1493
00:58:45,680 --> 00:58:46,880
вопроса,

1494
00:58:46,880 --> 00:58:48,559
и первая модель, по сути, они

1495
00:58:48,559 --> 00:58:51,119
пытаются

1496
00:58:51,119 --> 00:58:53,280
использовать самоудержание

1497
00:58:53,280 --> 00:58:55,359
поверх конкатенации

1498
00:58:55,359 --> 00:58:57,200
отрывка вопроса, так что это

1499
00:58:57,200 --> 00:58:59,280
преобразователь mo  del, поэтому вам следует взять

1500
00:58:59,280 --> 00:59:00,640
вопрос в отрывке, чтобы это были

1501
00:59:00,640 --> 00:59:02,400
вопросы в отрывке, а затем вы

1502
00:59:02,400 --> 00:59:04,319
примените много разных уровней

1503
00:59:04,319 --> 00:59:06,960
самовнимания, по сути, чтобы это

1504
00:59:06,960 --> 00:59:09,440
самовнимание могло захватить внимание

1505
00:59:10,640 --> 00:59:13,119
между контекстными словами внимание

1506
00:59:13,119 --> 00:59:15,119
между отрывками  был на вопросительных

1507
00:59:15,119 --> 00:59:16,880
словах, и внимание от

1508
00:59:16,880 --> 00:59:18,880
вопроса к пассивной стороне, а

1509
00:59:18,880 --> 00:59:21,280
также внимание между um от

1510
00:59:21,280 --> 00:59:22,960
вопроса было к другим другим вопросительным

1511
00:59:22,960 --> 00:59:24,240
словам,

1512
00:59:24,240 --> 00:59:26,480
поэтому по сравнению с вами, определенно

1513
00:59:26,480 --> 00:59:28,720
пытаясь смоделировать эту часть, но модель бремени по

1514
00:59:28,720 --> 00:59:31,040
существу может  уловить

1515
00:59:31,040 --> 00:59:33,839
напряжение между всеми этими четырьмя частями

1516
00:59:33,839 --> 00:59:36,400
и, на самом деле, после этого, таким образом, как

1517
00:59:36,400 --> 00:59:38,720
раз перед тем, как

1518
00:59:38,720 --> 00:59:41,040
птица успеет выйти, так что он

1519
00:59:41,040 --> 00:59:43,599
также будет демонстрировать, что если вы просто добавите

1520
00:59:43,599 --> 00:59:45,839
слой самопотенциала для пассивного

1521
00:59:45,839 --> 00:59:47,920
сайт, поэтому в основном вы пытаетесь

1522
00:59:47,920 --> 00:59:50,400
явно смоделировать это внимание

1523
00:59:50,400 --> 00:59:52,559
между пассивными словами и пассивными словами

1524
00:59:52,559 --> 00:59:54,319
до глубины, эта учетная запись также улучшает

1525
00:59:54,319 --> 00:59:56,640
производительность  Итак, вы можете видеть, что эти

1526
00:59:56,640 --> 00:59:58,240
две модели, по сути, просто

1527
00:59:58,240 --> 01:00:00,720
пытаются смоделировать напряжение между

1528
01:00:00,720 --> 01:00:02,720
пассивным впечатлением, а также

1529
01:00:02,720 --> 01:00:04,400
вниманием между паролями и

1530
01:00:04,400 --> 01:00:06,240
паролями, и это на самом деле то,

1531
01:00:06,240 --> 01:00:09,599
что именно первая модель делает

1532
01:00:10,400 --> 01:00:11,440
хорошо,

1533
01:00:12,880 --> 01:00:16,319
так что, если больше нет вопросов  гм, так что

1534
01:00:16,319 --> 01:00:18,319
в этот момент я говорил о

1535
01:00:18,319 --> 01:00:20,160
моделях, которые могут очень хорошо справляться с

1536
01:00:20,160 --> 01:00:22,160
таким набором данных для понимания прочитанного, и

1537
01:00:22,160 --> 01:00:23,359
всегда говорить о

1538
01:00:23,359 --> 01:00:25,040
предварительном обучении, может действительно изменить

1539
01:00:25,040 --> 01:00:27,200
производительность, может снова измениться

1540
01:00:27,200 --> 01:00:28,559
понимание прочитанного,

1541
01:00:28,559 --> 01:00:30,160
я думаю,

1542
01:00:30,160 --> 01:00:31,440
вы не

1543
01:00:31,440 --> 01:00:34,480
добавляете сначала один вопрос  люди задаются вопросом,

1544
01:00:34,480 --> 01:00:36,559
можете ли вы преуспеть

1545
01:00:36,559 --> 01:00:38,400
с трансформатором, который не был

1546
01:00:38,400 --> 01:00:40,559
предварительно обучен правильно, если вы попытаетесь построить

1547
01:00:40,559 --> 01:00:42,240
систему ответов на вопросы, используя

1548
01:00:42,240 --> 01:00:44,720
трансформатор, а не rsdns, но

1549
01:00:44,720 --> 01:00:47,359
предварительное обучение не дает этой работы,

1550
01:00:47,359 --> 01:00:50,079
это хороший вопрос да, это работает, но

1551
01:00:50,079 --> 01:00:51,680
вы, вероятно, действительно не можете построить

1552
01:00:51,680 --> 01:00:54,160
модель размером с 110 миллионов

1553
01:00:54,160 --> 01:00:58,000
премий или 200 мм330 миллионов

1554
01:00:58,000 --> 01:01:00,559
моделей параметров, так что на самом деле существует

1555
01:01:00,559 --> 01:01:03,440
модель между um

1556
01:01:03,440 --> 01:01:04,480
s

1557
01:01:04,480 --> 01:01:06,559
o между семейством this like

1558
01:01:06,559 --> 01:01:08,640
моделей ios tn и моделями записи,

1559
01:01:08,640 --> 01:01:11,760
называемыми qa net от Google, поэтому qr net

1560
01:01:11,760 --> 01:01:12,640
фактически построен поверх

1561
01:01:12,640 --> 01:01:15,040
трансформаторов с другим предварительным обучением, так

1562
01:01:15,040 --> 01:01:16,960
что модель действительно может работать лучше,

1563
01:01:16,960 --> 01:01:19,119
чем модели задиры и другие  модели,

1564
01:01:19,119 --> 01:01:20,240
но они на самом деле

1565
01:01:20,240 --> 01:01:22,880
немного отстают от моделей с батареями,

1566
01:01:23,760 --> 01:01:27,680
поэтому просто проверьте их на карте qa,

1567
01:01:29,440 --> 01:01:32,000
хорошо, я просто продолжу,

1568
01:01:32,000 --> 01:01:34,720
так что хорошо, поэтому бесплатное обучение было

1569
01:01:34,720 --> 01:01:37,520
так важно, поэтому теперь я быстро расскажу

1570
01:01:37,520 --> 01:01:39,359
о хорошо,

1571
01:01:39,359 --> 01:01:41,280
вопрос здесь: можем ли мы на самом деле

1572
01:01:41,280 --> 01:01:42,640
даже  разработать лучшие предтренировочные

1573
01:01:42,640 --> 01:01:44,400
задачи для понимания прочитанного или

1574
01:01:44,400 --> 01:01:45,760
ответа на вопросы,

1575
01:01:45,760 --> 01:01:47,680
и ответ на самом деле да, так что

1576
01:01:47,680 --> 01:01:49,680
это действительно работа, которую я проделал с Менделем Джошем

1577
01:01:49,680 --> 01:01:51,760
и другими людьми, как год назад, названный

1578
01:01:51,760 --> 01:01:53,520
spambered,

1579
01:01:53,520 --> 01:01:56,720
так что подумайте об этом, так что для команды

1580
01:01:56,720 --> 01:01:59,039
и других много  экстрактивных данных о понимании прочитанного

1581
01:01:59,039 --> 01:02:00,960
ставит цель

1582
01:02:00,960 --> 01:02:02,960
попытаться предсказать спам-ответ

1583
01:02:02,960 --> 01:02:06,480
из отрывка, а, как вопрос, так что

1584
01:02:06,480 --> 01:02:09,119
как ответ на этот вопрос, так что

1585
01:02:09,119 --> 01:02:11,599
есть  В отношении двух ключевых идей, предлагаемых в

1586
01:02:11,599 --> 01:02:12,640
спамбере,

1587
01:02:12,640 --> 01:02:15,520
первая идея состоит в том, что вместо использования

1588
01:02:15,520 --> 01:02:18,319
только маскировки отдельных слов

1589
01:02:18,319 --> 01:02:20,319
мы предлагаем освоить

1590
01:02:20,319 --> 01:02:23,280
непрерывные обширные слова в

1591
01:02:23,280 --> 01:02:25,520
отрывке, потому что окончательный ответ был

1592
01:02:25,520 --> 01:02:27,839
бы просто сегментом текста в отрывке.

1593
01:02:27,839 --> 01:02:30,640
поэтому мы пытаемся так замаскировать все

1594
01:02:30,640 --> 01:02:32,880
эти возможные ответы из этого

1595
01:02:32,880 --> 01:02:35,440
отрывка в качестве обучающей цели,

1596
01:02:35,440 --> 01:02:37,200
и вторая идея, предложенная с помощью

1597
01:02:37,200 --> 01:02:39,280
спамберга, заключается в том, что

1598
01:02:39,280 --> 01:02:41,119
потому что в конце обзора, потому что мы

1599
01:02:41,119 --> 01:02:43,039
хотим предсказать неподтвержденные запросы,

1600
01:02:43,039 --> 01:02:44,000
поэтому

1601
01:02:44,000 --> 01:02:45,200
мы фактически пытаемся  чтобы

1602
01:02:45,200 --> 01:02:47,039
предсказать две конечные точки

1603
01:02:47,039 --> 01:02:49,920
в качестве ответа, поэтому идея здесь в том, что

1604
01:02:49,920 --> 01:02:52,880
мы можем попытаться сжать две конечные точки

1605
01:02:52,880 --> 01:02:54,240
ничего не подозревающих,

1606
01:02:56,960 --> 01:02:58,799
извините, можем ли мы попытаться сжать всю

1607
01:02:58,799 --> 01:03:01,119
информацию в этом диапазоне в две

1608
01:03:01,119 --> 01:03:04,000
конечные точки, поэтому идея заключается в том, что

1609
01:03:04,000 --> 01:03:06,160
здесь  давайте подумаем об этом, если мы

1610
01:03:06,160 --> 01:03:08,799
замаскируем нападающих здесь, и можем ли мы попытаться

1611
01:03:08,799 --> 01:03:11,760
использовать две конечные точки здесь, на этой

1612
01:03:11,760 --> 01:03:15,200
фигуре, например, x4 и x line, чтобы предсказать

1613
01:03:15,200 --> 01:03:17,280
все слова в середине, так что существенно

1614
01:03:17,280 --> 01:03:19,520
мы пытаемся предварительно взять две конечные

1615
01:03:19,520 --> 01:03:21,760
точки, а также позицию, какую-то

1616
01:03:21,760 --> 01:03:23,920
кодировку позиции, и затем, наконец, мы

1617
01:03:23,920 --> 01:03:25,520
собираемся попытаться предсказать все

1618
01:03:25,520 --> 01:03:27,599
слова в этом диапазоне, поэтому вот почему это

1619
01:03:27,599 --> 01:03:30,160
называется спамовой птицей, поэтому я призываю

1620
01:03:30,160 --> 01:03:32,559
вас  чтобы проверить нашу статью,

1621
01:03:32,559 --> 01:03:34,799
и это действительно действительно очень помогает,

1622
01:03:34,799 --> 01:03:36,319
по крайней мере, для вопроса еще раз,

1623
01:03:36,319 --> 01:03:38,000
так что,

1624
01:03:38,000 --> 01:03:39,760
как вы можете видеть из этого рисунка, это

1625
01:03:39,760 --> 01:03:43,039
называется 1.1, а это 2.0, и

1626
01:03:43,039 --> 01:03:44,799
это много других наборов данных, отвечающих на вопросы,

1627
01:03:46,160 --> 01:03:47,760
которые вы можете  см,

1628
01:03:47,760 --> 01:03:49,359
так что

1629
01:03:49,359 --> 01:03:51,359
синие полосы здесь, которые мы называем google, а не на

1630
01:03:51,359 --> 01:03:54,319
самом деле, исходные контрольные

1631
01:03:54,319 --> 01:03:56,640
точки выпущены Google для исследователей,

1632
01:03:56,640 --> 01:03:58,720
и наше рождение на самом деле просто

1633
01:03:58,720 --> 01:04:00,559
повторная реализация

1634
01:04:00,559 --> 01:04:02,480
первой модели, но мы пытаемся

1635
01:04:02,480 --> 01:04:04,640
использовать те же данные  но мы

1636
01:04:04,640 --> 01:04:06,559
пытались обучить эту модель

1637
01:04:06,559 --> 01:04:08,799
немного дольше, поэтому она на самом деле

1638
01:04:08,799 --> 01:04:10,319
достигла большей производительности, чем

1639
01:04:10,319 --> 01:04:11,680
исходная группа,

1640
01:04:11,680 --> 01:04:13,760
поэтому вы можете видеть, что желтый прямоугольник

1641
01:04:13,760 --> 01:04:16,400
здесь на самом деле является стандартным, поэтому спамер может  На

1642
01:04:16,400 --> 01:04:18,880
самом деле, м-м, ненадолго превосходит синюю

1643
01:04:18,880 --> 01:04:21,280
версию за бортом

1644
01:04:21,280 --> 01:04:23,359
по всем наборам данных, что действительно

1645
01:04:23,359 --> 01:04:25,760
говорит нам, что хорошо, даже если мы этого не сделаем,

1646
01:04:25,760 --> 01:04:27,680
мы не собираемся увеличивать размер модели,

1647
01:04:27,680 --> 01:04:29,760
мы не собираемся увеличивать данные,

1648
01:04:29,760 --> 01:04:31,760
разрабатывая более точные цели прогнозирования.

1649
01:04:31,760 --> 01:04:34,480
также нужно пройти долгий путь и сделать

1650
01:04:34,480 --> 01:04:36,319
гораздо лучшую работу, по крайней мере, в наборах данных для

1651
01:04:36,319 --> 01:04:37,359
ответов на вопросы и понимания прочитанного,

1652
01:04:40,880 --> 01:04:43,039
хорошо, у

1653
01:04:43,039 --> 01:04:45,440
меня осталось несколько слайдов

1654
01:04:45,440 --> 01:04:47,119
в этой части,

1655
01:04:47,119 --> 01:04:50,240
так что пока я должен продемонстрировать это,

1656
01:04:50,240 --> 01:04:52,400
используя  с помощью этой модели и с помощью

1657
01:04:52,400 --> 01:04:54,400
моделей нагрузки мы можем получить очень хорошую

1658
01:04:54,400 --> 01:04:56,240
производительность по набору данных оценки;

1659
01:04:56,240 --> 01:04:58,720
число сопротивления уже существует,

1660
01:04:58,720 --> 01:05:01,039
даже если человеческая производительность в области видимости

1661
01:05:01,039 --> 01:05:02,400
означает, что понимание прочитанного

1662
01:05:02,400 --> 01:05:04,160
уже решено;

1663
01:05:04,160 --> 01:05:06,720
ответ, конечно, не

1664
01:05:06,720 --> 01:05:09,760
так, пусть  я просто так, за последние

1665
01:05:09,760 --> 01:05:11,440
пару лет появилось много

1666
01:05:11,440 --> 01:05:14,400
свидетельств того, что текущая система по-

1667
01:05:14,400 --> 01:05:16,799
прежнему плохо работает на юбилейных

1668
01:05:16,799 --> 01:05:19,200
примерах или примерах из вне

1669
01:05:19,200 --> 01:05:21,599
домена  дистрибутивов,

1670
01:05:21,599 --> 01:05:24,400
вот очень классический пример,

1671
01:05:24,400 --> 01:05:27,280
предложенный президентом канала robin

1672
01:05:27,280 --> 01:05:30,799
в 2017 году. Идея состоит в том, что они

1673
01:05:30,799 --> 01:05:34,400
берут отрывок и отвечают на вопрос,

1674
01:05:34,400 --> 01:05:36,720
и они пытаются просто вставить как

1675
01:05:36,720 --> 01:05:39,039
случайное предложение в конец

1676
01:05:39,039 --> 01:05:41,039
абзац, как вы можете видеть, это

1677
01:05:41,039 --> 01:05:43,680
предложение похоже на

1678
01:05:43,680 --> 01:05:46,400
ерунду в этом контексте, составленном здесь, но

1679
01:05:46,400 --> 01:05:48,720
это предложение на самом деле похоже на большое,

1680
01:05:48,720 --> 01:05:51,200
э-э, некоторые оставшиеся совпадения между

1681
01:05:51,200 --> 01:05:52,880
вопросами на самом деле очень похожи на

1682
01:05:52,880 --> 01:05:54,559
этот вопрос, но на самом деле числа слов

1683
01:05:54,559 --> 01:05:56,640
имеют  были заменены

1684
01:05:56,640 --> 01:05:58,640
антенны были заменены, и затем они обнаружили,

1685
01:05:58,640 --> 01:06:01,119
что такого рода неблагоприятные примеры могут на

1686
01:06:01,119 --> 01:06:02,960
самом деле очень легко обмануть текущие

1687
01:06:02,960 --> 01:06:05,280
системы, а затем последний профессионал и

1688
01:06:05,280 --> 01:06:07,839
помощник по микшированию предсказать ответ на

1689
01:06:07,839 --> 01:06:09,920
черновик,

1690
01:06:09,920 --> 01:06:12,720
поэтому вот таблица показывает, что

1691
01:06:12,720 --> 01:06:14,400
добавив множество примеров противников,

1692
01:06:14,400 --> 01:06:16,960
они обнаружили, что производительность на

1693
01:06:16,960 --> 01:06:18,880
самом деле сильно зависит от этой

1694
01:06:18,880 --> 01:06:22,160
модели, поэтому она упала с 75,5 до примерно

1695
01:06:22,160 --> 01:06:24,960
30 процентов, так что для  даже при таком виде

1696
01:06:24,960 --> 01:06:27,119
атаки производительность упадет до

1697
01:06:27,119 --> 01:06:30,559
очень низкого уровня, например, до 4,8,

1698
01:06:30,960 --> 01:06:32,960
поэтому вот еще одна статья, которая на самом деле

1699
01:06:32,960 --> 01:06:35,680
только что вышла в 2020 году, поэтому у меня есть

1700
01:06:35,680 --> 01:06:37,200
много доказательств, показывающих аналогичные

1701
01:06:37,200 --> 01:06:39,599
вещи, поэтому сегодня мы можем построить очень

1702
01:06:39,599 --> 01:06:41,359
хорошее чтение  набор данных для понимания

1703
01:06:41,359 --> 01:06:43,680
отдельных данных в отдельных наборах данных,

1704
01:06:43,680 --> 01:06:46,319
но в этом сезоне физика канала одного набора

1705
01:06:46,319 --> 01:06:48,160
данных уже может обобщить на другие

1706
01:06:48,160 --> 01:06:50,640
наборы данных, поэтому диагональ

1707
01:06:50,640 --> 01:06:52,319
в этой

1708
01:06:52,319 --> 01:06:54,160
таблице в основном представляет собой канал одного мода для

1709
01:06:54,160 --> 01:06:56,319
моделирования одного набора данных и оценки на тех

1710
01:06:56,319 --> 01:06:58,480
же данных  набор и для всех других

1711
01:06:58,480 --> 01:07:01,440
чисел в этой таблице, но это показывает, что

1712
01:07:01,440 --> 01:07:03,599
если вы попытаетесь запустить какую-то систему на одном

1713
01:07:03,599 --> 01:07:05,039
наборе данных, а затем вы оцените ее на

1714
01:07:05,039 --> 01:07:07,119
другом наборе данных, производительность

1715
01:07:07,119 --> 01:07:09,119
упадет довольно сильно, так что в основном это

1716
01:07:09,119 --> 01:07:10,799
действительно похоже на обобщение из одного набора данных.

1717
01:07:10,799 --> 01:07:13,119
набор данных в другой набор данных,

1718
01:07:13,119 --> 01:07:14,720
так что, наконец, это действительно очень

1719
01:07:14,720 --> 01:07:16,400
интересный

1720
01:07:16,400 --> 01:07:18,960
результат, так что эта небольшая эта статья на

1721
01:07:18,960 --> 01:07:21,839
самом деле лучшая статья из acl 2020

1722
01:07:21,839 --> 01:07:24,640
называется контрольной бумагой, поэтому идея

1723
01:07:24,640 --> 01:07:27,520
что эти авторы в основном пытаются

1724
01:07:27,520 --> 01:07:29,599
предложить какие-то

1725
01:07:29,599 --> 01:07:32,880
тестовые примеры, чтобы проверить, действительно ли эти модели

1726
01:07:32,880 --> 01:07:34,799
действительно могут

1727
01:07:34,799 --> 01:07:36,640
отвечать на некоторые простые вопросы, а скорее с

1728
01:07:36,640 --> 01:07:39,280
некоторыми конкретными или конкретными явлениями, которые

1729
01:07:39,280 --> 01:07:42,880
они находят, просто придумав несколько

1730
01:07:42,880 --> 01:07:45,520
действительно простых вопросов, например, здесь

1731
01:07:45,520 --> 01:07:48,559
Джереми  более оптимистичен, чем Тейлор,

1732
01:07:48,559 --> 01:07:50,799
и который более пессимистичен,

1733
01:07:50,799 --> 01:07:52,640
и они обнаружили, что

1734
01:07:52,640 --> 01:07:55,440
канал большой модели рождения остановился, и он все еще может

1735
01:07:55,440 --> 01:07:58,400
заполнить этот тип тестовых случаев на 100

1736
01:07:58,400 --> 01:08:01,119
процентов,

1737
01:08:01,680 --> 01:08:03,920
и теперь вот еще одна таблица, чтобы вы могли

1738
01:08:03,920 --> 01:08:06,559
видеть, что здесь  еще один умный пример,

1739
01:08:06,559 --> 01:08:09,760
как Виктория и Алекс - друзья, давай,

1740
01:08:09,760 --> 01:08:13,039
это наш агент, который является моим агентом,

1741
01:08:13,039 --> 01:08:15,599
и, чтобы правильно ответить на этот вопрос,

1742
01:08:15,599 --> 01:08:17,679
он должен понимать, что

1743
01:08:17,679 --> 01:08:20,000
изображение на самом деле относится к женщине,

1744
01:08:20,000 --> 01:08:22,319
а алиса относится к человеку мужского пола,

1745
01:08:22,319 --> 01:08:25,040
так что это  модели такого рода

1746
01:08:25,040 --> 01:08:27,359
вопросов также делают какие-то модели

1747
01:08:27,359 --> 01:08:28,880
очень большими множественными каналами для

1748
01:08:28,880 --> 01:08:33,040
полного фильма такого рода тестовых

1749
01:08:35,279 --> 01:08:36,799
примеров хорошо,

1750
01:08:36,799 --> 01:08:38,560
так что у меня есть 10 м  inutes left

1751
01:08:38,560 --> 01:08:40,640
chris - это любой вопрос, на самом деле ответ на

1752
01:08:40,640 --> 01:08:42,000
этот момент,

1753
01:08:42,000 --> 01:08:44,719
я думаю, вы можете продолжать

1754
01:08:44,719 --> 01:08:46,880
хорошо, поэтому за последние 10 минут я собираюсь

1755
01:08:46,880 --> 01:08:48,560
дать вам очень-очень краткое

1756
01:08:48,560 --> 01:08:50,560
введение о том, что открылось в ответ на мой

1757
01:08:50,560 --> 01:08:52,479
вопрос, и чем мы

1758
01:08:52,479 --> 01:08:53,839
были  пытаясь сделать в последние пару

1759
01:08:53,839 --> 01:08:56,080
лет,

1760
01:08:56,080 --> 01:08:57,439
поэтому, хотя главный вопрос, отвечающий

1761
01:08:57,439 --> 01:08:59,920
на проблему, который гм, так это отличается

1762
01:08:59,920 --> 01:09:01,439
от понимания прочитанного, мы

1763
01:09:01,439 --> 01:09:04,158
не предполагаем данный отрывок, поэтому здесь

1764
01:09:04,158 --> 01:09:06,399
с предположением, что у нас есть

1765
01:09:06,399 --> 01:09:08,640
доступ только к большой коллекции

1766
01:09:08,640 --> 01:09:10,960
документов  Итак, один пример - это просто

1767
01:09:10,960 --> 01:09:12,960
вся английская Википедия, в которой

1768
01:09:12,960 --> 01:09:15,279
есть около пяти миллионов статей, поэтому мы действительно не

1769
01:09:15,279 --> 01:09:17,439
знаем, где находится ответ,

1770
01:09:17,439 --> 01:09:19,679
и цель - вернуть ответ на

1771
01:09:19,679 --> 01:09:21,759
любые открытые вопросы домена, поэтому эта

1772
01:09:21,759 --> 01:09:23,439
проблема, чтобы не было  один

1773
01:09:23,439 --> 01:09:25,120
отрывок, поэтому мы должны отвечать на вопросы

1774
01:09:25,120 --> 01:09:27,520
по очень большой коллекции документов

1775
01:09:27,520 --> 01:09:29,679
или даже по всем веб-документам,

1776
01:09:29,679 --> 01:09:31,198
так что это на самом деле гораздо более

1777
01:09:31,198 --> 01:09:33,439
сложная и более практическая

1778
01:09:33,439 --> 01:09:35,359
проблема,

1779
01:09:35,359 --> 01:09:36,080
так что

1780
01:09:36,080 --> 01:09:38,238
если вы  хорошо, подумайте о

1781
01:09:38,238 --> 01:09:40,158
примере Google, который я показал в начале,

1782
01:09:40,158 --> 01:09:42,319
так что это будут методы, которые будут

1783
01:09:42,319 --> 01:09:44,158
очень полезны в практических

1784
01:09:44,158 --> 01:09:46,798
приложениях,

1785
01:09:47,520 --> 01:09:49,839
поэтому термин здесь открытый домен просто

1786
01:09:49,839 --> 01:09:51,920
контрастирует с закрытыми доменами, которые имеют дело с

1787
01:09:51,920 --> 01:09:54,320
вопросами при определенных различиях

1788
01:09:54,320 --> 01:09:58,400
в конкретных  Да,

1789
01:09:58,719 --> 01:09:59,840
хорошо, так

1790
01:09:59,840 --> 01:10:03,040
как вы можете решить этот тип проблемы,

1791
01:10:03,040 --> 01:10:04,480
потому что для проблемы понимания прочитанного

1792
01:10:04,480 --> 01:10:06,080
нам просто нужно отвечать на вопросы,

1793
01:10:06,080 --> 01:10:08,159
основанные на одном отрывке, так что это

1794
01:10:08,159 --> 01:10:10,800
статья, которую я написал в 2017 году четыре года назад,

1795
01:10:10,800 --> 01:10:12,719
поэтому она называется бумагой, которую она называет

1796
01:10:12,719 --> 01:10:15,280
чтением википедии  pdf, чтобы ответить на все

1797
01:10:15,280 --> 01:10:17,840
вопросы, и система под названием doctor qa, поэтому

1798
01:10:18,640 --> 01:10:20,400
фаворит в основном предложил идею о том,

1799
01:10:20,400 --> 01:10:22,719
что мы действительно можем решить эту проблему,

1800
01:10:22,719 --> 01:10:25,040
используя как поиск, так и

1801
01:10:25,040 --> 01:10:26,800
фреймворк для чтения,

1802
01:10:26,800 --> 01:10:29,600
поэтому идея состоит в том, что давайте ответим на вопрос

1803
01:10:29,600 --> 01:10:31,840
хорошо, поэтому здесь наша цель - попробовать  чтобы

1804
01:10:31,840 --> 01:10:34,159
ответить на вопросы, используя очень

1805
01:10:34,159 --> 01:10:35,760
большую коллекцию документов, такую

1806
01:10:35,760 --> 01:10:38,000
как Википедия, поэтому идея состоит в том, что

1807
01:10:38,000 --> 01:10:39,920
есть поиск, а также чтение  r,

1808
01:10:39,920 --> 01:10:42,320
поэтому поиск учитывает

1809
01:10:42,320 --> 01:10:43,199
вопрос,

1810
01:10:43,199 --> 01:10:45,360
и я пытаюсь выяснить, что меньшее

1811
01:10:45,360 --> 01:10:46,880
количество наших документов должно иметь

1812
01:10:46,880 --> 01:10:48,560
отношение к этому вопросу,

1813
01:10:48,560 --> 01:10:50,560
и эта модель чтения в основном

1814
01:10:50,560 --> 01:10:52,560
пытается прочитать все документы, которые

1815
01:10:54,000 --> 01:10:56,320
возвращаются только при поиске, и если я попытаюсь  найти

1816
01:10:56,320 --> 01:10:58,800
правильный ответ

1817
01:10:58,800 --> 01:11:00,080
um, так что

1818
01:11:00,080 --> 01:11:02,159
формально здесь определено, что вход

1819
01:11:02,159 --> 01:11:04,960
- это большая коллекция документов d,

1820
01:11:04,960 --> 01:11:07,360
а вопрос q, а выходом может быть

1821
01:11:07,360 --> 01:11:09,840
наша строка ответа a,

1822
01:11:09,840 --> 01:11:11,760
поэтому мы можем просто разложить эту проблему

1823
01:11:11,760 --> 01:11:13,199
на, как я только что упомянул в

1824
01:11:13,199 --> 01:11:15,440
поиске, и  компонент читателя, поэтому

1825
01:11:15,440 --> 01:11:17,520
ритуал в основном пытается взять

1826
01:11:17,520 --> 01:11:20,239
большой документ коллекции d и q и

1827
01:11:20,239 --> 01:11:21,600
попытаться

1828
01:11:21,600 --> 01:11:24,320
вернуть набор документов или набор отрывков, поэтому

1829
01:11:24,320 --> 01:11:26,560
здесь это число k может быть очень

1830
01:11:26,560 --> 01:11:28,640
маленьким um

1831
01:11:28,640 --> 01:11:30,640
может быть очень маленьким um,

1832
01:11:30,640 --> 01:11:32,320
например, вроде um

1833
01:11:32,320 --> 01:11:34,800
well  точно так же, как 100, поэтому он в основном

1834
01:11:34,800 --> 01:11:37,440
пытается вытащить найденное, например, 100

1835
01:11:37,440 --> 01:11:40,320
отрывков или документов, например,

1836
01:11:40,320 --> 01:11:42,320
скажем, пять миллионов документов,

1837
01:11:42,320 --> 01:11:44,239
и, наконец, читатель в основном

1838
01:11:44,239 --> 01:11:46,239
берет вопрос  n, берет этот

1839
01:11:46,239 --> 01:11:48,560
набор отрывков и, наконец, обнаруживает, что

1840
01:11:48,560 --> 01:11:50,480
наконец-то вернул ответ, так что вторая

1841
01:11:50,480 --> 01:11:51,600
проблема на самом деле

1842
01:11:51,600 --> 01:11:55,280
связана с моделью понимания прочитанного, которую мы только что изучили,

1843
01:11:55,280 --> 01:11:57,679
так что

1844
01:11:59,679 --> 01:12:02,159
бережливое ...  поиск - это

1845
01:12:02,159 --> 01:12:04,640
просто стандартная информационная

1846
01:12:04,640 --> 01:12:07,600
модель триггера - это разреженная информация uh pfidf

1847
01:12:07,600 --> 01:12:09,600
через разреженную модель, а реальная

1848
01:12:09,600 --> 01:12:10,960
модель - это, по сути, просто

1849
01:12:10,960 --> 01:12:13,199
модель понимания дополнения нейронного чтения, о которой я

1850
01:12:13,199 --> 01:12:15,440
только что говорил, так что это очень тенденция по

1851
01:12:15,440 --> 01:12:17,280
Скотту и некоторым другим вопросам три

1852
01:12:17,280 --> 01:12:18,400
набора данных

1853
01:12:18,400 --> 01:12:20,960
мм  так что на самом деле идея очень

1854
01:12:20,960 --> 01:12:22,480
проста, но вы пытаетесь связать

1855
01:12:22,480 --> 01:12:24,880
две вещи: как связать

1856
01:12:24,880 --> 01:12:27,360
этот поиск, а также читатель, чтобы ответить на

1857
01:12:27,360 --> 01:12:28,640
этот вопрос открытого домена,

1858
01:12:32,159 --> 01:12:34,719
так что я просто собираюсь быстро перейти  по

1859
01:12:34,719 --> 01:12:37,600
некоторым действительно захватывающим идеям,

1860
01:12:37,600 --> 01:12:40,320
которые возникли в

1861
01:12:40,320 --> 01:12:42,880
последние два года, в основном, так что первая

1862
01:12:42,880 --> 01:12:45,840
идея состоит в том, что эта часть поиска также может

1863
01:12:45,840 --> 01:12:48,159
быть тенденцией, поэтому мы можем  на самом деле даже не

1864
01:12:48,159 --> 01:12:49,679
делайте этого, присоединяйтесь к обучению

1865
01:12:49,679 --> 01:12:51,760
ретривера на читателе, так что на самом

1866
01:12:53,120 --> 01:12:54,960
деле эта идея была впервые

1867
01:12:54,960 --> 01:12:56,960
предложена в статье кантонской лиги в

1868
01:12:56,960 --> 01:12:59,760
2019 году, называемой легендарным поиском для

1869
01:12:59,760 --> 01:13:02,480
еженедельных контролируемых открытых вопросов,

1870
01:13:02,480 --> 01:13:06,080
поэтому эта часть в основном  первая э-э-

1871
01:13:06,080 --> 01:13:08,239
модель для понимания прочитанного и

1872
01:13:08,239 --> 01:13:10,320
отдельно системы - это, в основном, модель поиска,

1873
01:13:10,320 --> 01:13:12,719
поэтому, чтобы получить этот ритуал среди

1874
01:13:12,719 --> 01:13:15,120
работы, они также пытаются использовать рождение

1875
01:13:15,120 --> 01:13:16,960
для кодирования отрывка, а также вы

1876
01:13:16,960 --> 01:13:18,640
назвали вопрос, и они пытаются

1877
01:13:18,640 --> 01:13:20,080
использовать скалярное произведение между вопросами

1878
01:13:20,080 --> 01:13:21,920
нотация и пассивное представление для

1879
01:13:21,920 --> 01:13:23,600
моделирования того,

1880
01:13:23,600 --> 01:13:26,400
как релевантность и сходство

1881
01:13:26,400 --> 01:13:28,560
между вопросом и отрывком, но на

1882
01:13:28,560 --> 01:13:30,880
самом деле это очень сложная проблема,

1883
01:13:30,880 --> 01:13:33,199
потому что скалярная масштабируемость этой

1884
01:13:33,199 --> 01:13:35,120
проблемы, потому что

1885
01:13:35,120 --> 01:13:37,440
в Википедии около 20 миллионов отрывков, поэтому

1886
01:13:37,440 --> 01:13:39,120
на самом деле очень сложно смоделировать это

1887
01:13:39,120 --> 01:13:41,199
часть, но поэтому я рекомендую вам ознакомиться с

1888
01:13:41,199 --> 01:13:43,760
этой статьей,

1889
01:13:44,960 --> 01:13:47,440
а теперь и со второй таблицей, я хочу

1890
01:13:47,440 --> 01:13:49,600
быстро упомянуть об этом.  Это также работа, которую я

1891
01:13:49,600 --> 01:13:52,880
проделал в прошлом году, это называется лучшим

1892
01:13:52,880 --> 01:13:55,360
инструментом пассивного просмотра, так что идея на

1893
01:13:55,360 --> 01:13:57,600
самом деле очень похожа на

1894
01:13:58,320 --> 01:14:00,719
предыдущую статью, но идея состоит в том, что на

1895
01:14:00,719 --> 01:14:03,040
самом деле это гораздо более упрощенная модель и

1896
01:14:03,040 --> 01:14:05,040
очень простой, очень простой и понятный

1897
01:14:05,040 --> 01:14:06,880
подход.  также можно

1898
01:14:06,880 --> 01:14:08,719
просто трендировать часть извлечения,

1899
01:14:08,719 --> 01:14:10,960
используя две модели птиц, используя только

1900
01:14:10,960 --> 01:14:12,560
пары вопрос-ответ,

1901
01:14:12,560 --> 01:14:14,960
и этот мотоцикл работает очень хорошо,

1902
01:14:14,960 --> 01:14:17,280
а затем в значительной степени все для

1903
01:14:17,280 --> 01:14:20,080
традиционных моделей извлечения, если вы

1904
01:14:20,080 --> 01:14:22,719
видите эту цифру, поэтому синяя кривая здесь

1905
01:14:22,719 --> 01:14:25,360
является традиционной

1906
01:14:25,360 --> 01:14:28,400
Их подход похож на подход bm25, и, поскольку другая

1907
01:14:28,400 --> 01:14:30,159
кривая, оранжевая кривая в основном

1908
01:14:30,159 --> 01:14:31,840
тренирует этот вид поиска, используя

1909
01:14:31,840 --> 01:14:34,159
только одну тысячу пар вопросов и ответов,

1910
01:14:34,159 --> 01:14:36,000
поэтому, глядя на все эти

1911
01:14:36,000 --> 01:14:37,440
разные кривые, в основном используя

1912
01:14:37,440 --> 01:14:39,520
разное количество обучающих примеров, так

1913
01:14:39,520 --> 01:14:41,760
что это действительно мило  в основном вкратце

1914
01:14:41,760 --> 01:14:46,320
из традиционных моделей

1915
01:14:48,800 --> 01:14:51,280
ик, ладно, опять же, у меня нет

1916
01:14:51,280 --> 01:14:53,120
времени говорить о деталях  все

1917
01:14:53,120 --> 01:14:54,800
эти подходы,

1918
01:14:54,800 --> 01:14:57,120
поэтому я просто рекомендую вам проверить

1919
01:14:57,120 --> 01:14:59,520
этот документ, документы, и я думаю, что этот

1920
01:14:59,520 --> 01:15:02,800
результат действительно захватывающий, так что вот на

1921
01:15:02,800 --> 01:15:05,360
самом деле действительно хорошая демонстрация, поэтому вы знаете,

1922
01:15:05,360 --> 01:15:07,199
что демонстрация на самом деле

1923
01:15:07,199 --> 01:15:09,199
размещена на этом веб-сайте, прежде чем

1924
01:15:09,199 --> 01:15:11,199
проверять так

1925
01:15:11,199 --> 01:15:13,280
снова  Итак, база данных здесь - это вся

1926
01:15:13,280 --> 01:15:15,280
Википедия, вы можете увидеть, что если вы зададите

1927
01:15:15,280 --> 01:15:17,360
вопрос, кто говорит Гарри Поттеру, что

1928
01:15:17,360 --> 01:15:19,600
он волшебник и выше в серии о

1929
01:15:19,600 --> 01:15:21,920
Гарри Поттере, и система

1930
01:15:21,920 --> 01:15:23,840
действительно обнаружила, что правильная статья

1931
01:15:23,840 --> 01:15:26,320
должна быть серией фильмов о Гарри Поттере и

1932
01:15:26,320 --> 01:15:28,400
затем, наконец, дайте вам текущий ответ,

1933
01:15:28,400 --> 01:15:30,719
который вы видели

1934
01:15:30,719 --> 01:15:33,360
в примере с Google здесь, поэтому у него есть

1935
01:15:33,360 --> 01:15:35,600
ответ, это может быть рубрика калгари,

1936
01:15:35,600 --> 01:15:38,239
которая на самом деле является человеком, который говорит

1937
01:15:38,239 --> 01:15:40,159
Гарри Поттеру, что он волшебник, так что

1938
01:15:40,159 --> 01:15:41,920
это точно идеальный ответ  на этот

1939
01:15:41,920 --> 01:15:44,239
вопрос,

1940
01:15:45,360 --> 01:15:48,000
хорошо, я собираюсь избежать этого слайда,

1941
01:15:48,000 --> 01:15:51,280
а затем, наконец, очень быстро,

1942
01:15:51,280 --> 01:15:53,199
так что это кое-что, что недавно появилось, э-э, э-

1943
01:15:53,199 --> 01:15:55,679
э, некоторые

1944
01:15:55,679 --> 01:15:58,480
исследователи продемонстрировали, что  возможно,

1945
01:15:58,480 --> 01:16:00,960
вам даже не нужно это поисковое исследование,

1946
01:16:00,960 --> 01:16:03,199
поэтому вы можете, если вы просто используете очень большую

1947
01:16:03,199 --> 01:16:05,520
языковую модель, вы также можете просто

1948
01:16:05,520 --> 01:16:08,080
ответить на вопрос в открытом домене, так что

1949
01:16:08,080 --> 01:16:10,000
способ, которым они это сделали, таков, что я надеюсь, что

1950
01:16:10,000 --> 01:16:11,600
вы изучили модель t5  в этом

1951
01:16:11,600 --> 01:16:13,199
классе уже, поэтому они просто берут

1952
01:16:13,199 --> 01:16:15,600
модель проповеднического языка g5, и они

1953
01:16:15,600 --> 01:16:17,760
пытаются найти через эту модель,

1954
01:16:17,760 --> 01:16:20,159
принимая вопрос и принимая

1955
01:16:20,159 --> 01:16:22,880
вопрос ввода в качестве ответа

1956
01:16:22,880 --> 01:16:25,679
без какого-либо явного поиска, и они

1957
01:16:25,679 --> 01:16:27,679
просто точно настраивают это на  набор данных, и

1958
01:16:27,679 --> 01:16:30,000
они обнаружили, что эта модель может неплохо работать

1959
01:16:30,000 --> 01:16:31,840
во время тестирования, просто принимая

1960
01:16:31,840 --> 01:16:34,000
вопрос, а затем напрямую генерируя

1961
01:16:34,000 --> 01:16:36,560
ответы, не прибегая к каким-либо

1962
01:16:36,560 --> 01:16:38,480
подобным документам или подобной системе поиска,

1963
01:16:38,480 --> 01:16:40,560
так что это на самом деле очень удивительно,

1964
01:16:40,560 --> 01:16:42,960
поэтому такая модель также

1965
01:16:42,960 --> 01:16:46,640
называется арбалетные системы.

1966
01:16:47,679 --> 01:16:51,199
Хорошо, ну очень, в прошлой жизни,

1967
01:16:51,199 --> 01:16:53,920
так что только одно направление, и лично я

1968
01:16:53,920 --> 01:16:55,520
очень взволнован,

1969
01:16:55,520 --> 01:16:56,239
так что

1970
01:16:56,239 --> 01:16:58,159
это на самом деле новое направление, которое в

1971
01:16:58,159 --> 01:16:59,840
основном показывает, что, возможно, для

1972
01:16:59,840 --> 01:17:01,600
о  Возможно,

1973
01:17:01,600 --> 01:17:03,679
эта реальная модель больше не нужна

1974
01:17:03,679 --> 01:17:04,719
,

1975
01:17:05,920 --> 01:17:08,080
поэтому эта идея была впервые предложена

1976
01:17:08,080 --> 01:17:11,040
музеем в 2019 году, и мы недавно написали

1977
01:17:11,040 --> 01:17:13,520
статью под названием танцевальные фразы, чтобы

1978
01:17:13,520 --> 01:17:15,360
попытаться продемонстрировать, что,

1979
01:17:15,360 --> 01:17:17,199
возможно, вам это даже не нужно, как

1980
01:17:17,199 --> 01:17:20,320
читателю  модель, поэтому вместо этого мы можем просто

1981
01:17:20,320 --> 01:17:23,440
закодировать все фразы в Википедии,

1982
01:17:23,440 --> 01:17:25,760
используя какие-то танцевальные векторы, поэтому

1983
01:17:25,760 --> 01:17:27,760
вам просто нужно просто выполнить

1984
01:17:27,760 --> 01:17:29,520
такой поиск ближайшего соседа в

1985
01:17:29,520 --> 01:17:32,320
пространстве ответов, вы просто кодируете все,

1986
01:17:32,320 --> 01:17:34,640
кодируете все фразы в кодировке Википедии  и

1987
01:17:34,640 --> 01:17:37,360
используя векторы и задав вопрос,

1988
01:17:37,360 --> 01:17:38,960
вы можете просто закодировать этот вопрос с

1989
01:17:38,960 --> 01:17:40,800
помощью вектора, а затем мы можем просто выполнить

1990
01:17:40,800 --> 01:17:43,120
вектор поиск ближайшего соседа,

1991
01:17:43,120 --> 01:17:45,440
а затем вы можете напрямую дать вам

1992
01:17:45,440 --> 01:17:47,840
ответ, так что это новый абзац

1993
01:17:47,840 --> 01:17:49,600
такого рода вопроса  отвечающая

1994
01:17:49,600 --> 01:17:51,360
модель, поэтому они вам не нужны, вам просто

1995
01:17:51,360 --> 01:17:53,360
нужен поиск, вам не нужен читатель,

1996
01:17:53,360 --> 01:17:56,000
поэтому большим преимуществом для этого является

1997
01:17:56,000 --> 01:17:57,440
то, что

1998
01:17:57,440 --> 01:17:58,960
для идеальной модели считывателя, по сути,

1999
01:17:58,960 --> 01:18:00,719
вы должны  запустить лучшую модель во

2000
01:18:00,719 --> 01:18:02,000
время вывода, это на самом деле очень

2001
01:18:02,000 --> 01:18:03,280
дорого,

2002
01:18:03,280 --> 01:18:05,760
но вы можете просто избавиться от этой модели,

2003
01:18:05,760 --> 01:18:07,440
вы можете просто выполнить поиск сходства,

2004
01:18:07,440 --> 01:18:09,280
вы можете просто провести ближайшее новое исследование

2005
01:18:09,280 --> 01:18:11,199
без запуска модели птицы, так что

2006
01:18:11,199 --> 01:18:13,600
это может быть очень быстро и  может даже работать

2007
01:18:13,600 --> 01:18:17,120
на процессоре, не ведя

2008
01:18:17,120 --> 01:18:19,120
как очень дорогая глубокая нейронная

2009
01:18:19,120 --> 01:18:22,239
сеть, и вы все еще можете работать очень хорошо,

2010
01:18:22,239 --> 01:18:24,960
работать очень хорошо,

2011
01:18:24,960 --> 01:18:27,840
хорошо, наконец, я надеюсь, что это сработает, поэтому я

2012
01:18:27,840 --> 01:18:30,239
действительно подготовил демо для этого

2013
01:18:30,239 --> 01:18:32,560
переноса, поэтому я хочу показать вам, как

2014
01:18:32,560 --> 01:18:36,120
это действительно работает,

2015
01:18:43,040 --> 01:18:45,120
поэтому вы можете видеть, что после того, как вы наберете этот

2016
01:18:45,120 --> 01:18:48,000
вопрос, кто выиграл нобелевскую премию

2017
01:18:48,000 --> 01:18:50,880
мира в 2014 году, поэтому каждый

2018
01:18:50,880 --> 01:18:53,120
раз просто введите небольшой кусок входного

2019
01:18:53,120 --> 01:18:54,960
вопроса, а затем система может

2020
01:18:54,960 --> 01:18:57,199
просто найти соответствующий

2021
01:18:57,199 --> 01:18:59,280
ответ  в соответствующих отрывках текста, а

2022
01:18:59,280 --> 01:19:01,199
затем, наконец, в ответе, это действительно

2023
01:19:01,199 --> 01:19:03,120
обнаруживается, это на самом деле очень быстро, потому

2024
01:19:03,120 --> 01:19:04,880
что это немного реального времени, которого мы

2025
01:19:04,880 --> 01:19:07,199
не помним на модели рождения, так

2026
01:19:07,199 --> 01:19:10,640
что это просто утешение  rance вот,

2027
01:19:10,640 --> 01:19:13,360
хорошо, я действительно закончил, это лекция,

2028
01:19:13,360 --> 01:19:14,480
так что

2029
01:19:14,480 --> 01:19:16,239
теперь 5 15, да,

2030
01:19:16,239 --> 01:19:18,560
спасибо, что присоединились ко мне сегодня,

2031
01:19:18,560 --> 01:19:20,239
большое спасибо, данте, за этот

2032
01:19:20,239 --> 01:19:22,640
потрясающий обзор

2033
01:19:22,640 --> 01:19:24,320
ответов на вопросы, я думаю, учитывая эту

2034
01:19:24,320 --> 01:19:26,239
демонстрацию в конце, люди хотят знать,

2035
01:19:26,239 --> 01:19:27,840
хотите ли вы  скоро снова запустит свою собственную

2036
01:19:27,840 --> 01:19:29,760
поисковую систему,

2037
01:19:29,760 --> 01:19:31,679
но

2038
01:19:31,679 --> 01:19:34,800
в любом случае дон Чи может остаться

2039
01:19:34,800 --> 01:19:36,480
ненадолго, чтобы ответить на вопросы,

2040
01:19:36,480 --> 01:19:40,159
но не навсегда, но сегодня, потому что

2041
01:19:40,159 --> 01:19:41,760
ты знаешь, что у нее нет стэнфордского

2042
01:19:41,760 --> 01:19:44,800
логина  вопросы внутри

2043
01:19:44,800 --> 01:19:48,560
масштабирования, поэтому, если вы хотите задать вопрос,

2044
01:19:48,560 --> 01:19:51,040
если вы используете кнопку поднять руку,

2045
01:19:51,040 --> 01:19:53,520
мы можем продвигать вас, чтобы вы появлялись

2046
01:19:53,520 --> 01:19:56,320
в обычном окне масштабирования и могли просто задавать

2047
01:19:56,320 --> 01:19:58,400
вопросы и

2048
01:19:58,400 --> 01:20:01,920
видеть друг друга, и если вы остаетесь

2049
01:20:01,920 --> 01:20:02,960
и не делаете  Не

2050
01:20:02,960 --> 01:20:04,640
оставляйте зум больше, чем на несколько

2051
01:20:04,640 --> 01:20:06,480
минут, может быть, мы просто продвинем

2052
01:20:06,480 --> 01:20:09,199
всех, кто все еще там, в

2053
01:20:09,199 --> 01:20:12,400
людей с обычным зумом, чтобы

2054
01:20:12,400 --> 01:20:14,800
немного обсудить, но гм, мы

2055
01:20:14,800 --> 01:20:17,040
будем рады любому, кто захочет задать

2056
01:20:17,040 --> 01:20:18,400
вопрос,

2057
01:20:18,400 --> 01:20:22,480
задав  это сами на данный момент

2058
01:20:25,440 --> 01:20:26,400
хорошо у

2059
01:20:26,400 --> 01:20:29,920
меня есть  один волонтер у

2060
01:20:31,199 --> 01:20:34,639
меня есть больше добровольцев,

2061
01:20:35,360 --> 01:20:37,280
если я увижу какие-то вопросы о, я должен

2062
01:20:37,280 --> 01:20:40,159
посмотреть чат или о нет, я имею в виду,

2063
01:20:40,159 --> 01:20:42,080
что теперь есть четыре человека, которых

2064
01:20:42,080 --> 01:20:44,000
повысили

2065
01:20:44,000 --> 01:20:45,520
эм, четыре человека

2066
01:20:45,520 --> 01:20:48,880
были первыми, так что, может быть, он мог бы начать

2067
01:20:48,880 --> 01:20:51,920
задавая вопрос, а затем другим

2068
01:20:51,920 --> 01:20:54,480
людям, которых мы

2069
01:20:54,480 --> 01:20:56,400
продвинули, хорошо,

2070
01:20:56,400 --> 01:20:58,159
так что большое спасибо за

2071
01:20:58,159 --> 01:21:00,480
сегодняшнюю лекцию, мой вопрос в основном такой, если

2072
01:21:00,480 --> 01:21:03,520
вы используете модель, например, например,

2073
01:21:03,520 --> 01:21:05,520
насколько

2074
01:21:05,520 --> 01:21:08,320
малы ваши обучающие

2075
01:21:08,320 --> 01:21:10,239
данные  установите для вас, чтобы вы получили

2076
01:21:10,239 --> 01:21:13,280
достаточно разумные результаты,

2077
01:21:13,360 --> 01:21:15,760
поэтому вопрос в том, как мы можем попробовать

2078
01:21:15,760 --> 01:21:17,760
понимание и модель, используя только

2079
01:21:17,760 --> 01:21:21,280
небольшое количество возвращаемых примеров,

2080
01:21:21,840 --> 01:21:23,280
да, я думаю, что это действительно хороший

2081
01:21:23,280 --> 01:21:25,760
вопрос,

2082
01:21:25,760 --> 01:21:26,880
особенно

2083
01:21:26,880 --> 01:21:29,360
как то, что вы, вероятно, слышали модель

2084
01:21:29,360 --> 01:21:31,280
потока gpt  что вы показали, что если

2085
01:21:31,280 --> 01:21:33,920
вы используете только несколько, очень мало примеров,

2086
01:21:33,920 --> 01:21:35,600
вы также можете довольно хорошо ответить на вопрос в открытой предметной области,

2087
01:21:37,120 --> 01:21:39,679
так что я, но такая модель огромна, например,

2088
01:21:41,199 --> 01:21:44,000
какое число, например,

2089
01:21:44,000 --> 01:21:46,000
сколько параметров я забыл в  грамм 

2090
01:21:46,000 --> 01:21:48,159
модель потока pu да, это очень большая,

2091
01:21:48,159 --> 01:21:50,880
очень симпатичная модель, но ладно, так что в основном

2092
01:21:50,880 --> 01:21:52,239
мой ответ заключается в том, что

2093
01:21:52,239 --> 01:21:54,639
если мы можем использовать очень большую и очень

2094
01:21:54,639 --> 01:21:56,880
мощную языковую модель прогнозирования,

2095
01:21:56,880 --> 01:21:58,960
есть способ, которым мы, эм, есть

2096
01:21:58,960 --> 01:22:00,639
вероятность, что мы действительно можем сделать

2097
01:22:00,639 --> 01:22:03,440
строка вопроса с um хорошо, только с

2098
01:22:03,440 --> 01:22:05,040
небольшим количеством примеров,

2099
01:22:05,040 --> 01:22:06,960
и теперь также есть некоторые другие

2100
01:22:06,960 --> 01:22:08,960
многообещающие направления, включая, например,

2101
01:22:08,960 --> 01:22:11,040
три вопроса без учителя,

2102
01:22:11,040 --> 01:22:13,440
поэтому, используя какой-то подход, такой как

2103
01:22:14,320 --> 01:22:16,880
из машины, неконтролируемый машинный

2104
01:22:16,880 --> 01:22:19,040
перевод, эта идея, которая может

2105
01:22:19,040 --> 01:22:21,520
быть заимствована  И

2106
01:22:21,520 --> 01:22:24,639
да, идеи сравнения из этого эм

2107
01:22:24,639 --> 01:22:26,639
могут также довольно хорошо работать, разумно,

2108
01:22:26,639 --> 01:22:28,880
достаточно хорошо, в неконтролируемых

2109
01:22:28,880 --> 01:22:30,480
вопросах,

2110
01:22:32,719 --> 01:22:34,400
да, также, я видел много

2111
01:22:34,400 --> 01:22:37,199
работ, например, очень занятых, показывающих, что

2112
01:22:37,199 --> 01:22:39,520
синтетический qrdss также

2113
01:22:39,520 --> 01:22:41,600
может очень помочь в повышении

2114
01:22:41,600 --> 01:22:43,920
производительность, если у вас недостаточно

2115
01:22:43,920 --> 01:22:46,080
контролируемых наборов данных, у меня также есть хорошие

2116
01:22:46,080 --> 01:22:48,239
примеры, да,

2117
01:22:48,239 --> 01:22:50,960
поэтому мой вопрос в том, что я думаю,

2118
01:22:50,960 --> 01:22:52,639
это интересно, что они  e на самом деле не так

2119
01:22:53,760 --> 01:22:56,880
сильно влияет на эффект переноса между

2120
01:22:56,880 --> 01:22:57,920
наборами данных, которые

2121
01:22:57,920 --> 01:23:00,400
вроде бы якобы похожи, поэтому мой

2122
01:23:00,400 --> 01:23:02,000
вопрос похож на то,

2123
01:23:02,000 --> 01:23:05,040
было ли проведено какое-либо исследование о

2124
01:23:05,040 --> 01:23:08,159
том, насколько близко я предполагаю, как форматирование

2125
01:23:08,159 --> 01:23:09,280
и

2126
01:23:09,280 --> 01:23:11,679
э-э семантическое содержание этих

2127
01:23:11,679 --> 01:23:15,040
наборов данных, отвечающих на вопросы, на самом деле

2128
01:23:15,040 --> 01:23:17,920
придерживается данных, которые, как и Burt, предварительно обучены

2129
01:23:17,920 --> 01:23:18,800
на

2130
01:23:18,800 --> 01:23:21,280
um, и если так, был

2131
01:23:21,280 --> 01:23:23,280
ли обнаружен какой-либо эффект между

2132
01:23:23,280 --> 01:23:27,199
этими сходствами или различиями,

2133
01:23:27,679 --> 01:23:29,840
я спрашиваю, была

2134
01:23:29,840 --> 01:23:31,679
ли такая песня,

2135
01:23:31,679 --> 01:23:33,760
хорошо, может быть, я могу просто попытаться

2136
01:23:33,760 --> 01:23:36,159
проясните немного, почему текущие

2137
01:23:36,159 --> 01:23:38,400
модели уже могут хорошо обобщаться от

2138
01:23:38,400 --> 01:23:40,159
одного набора данных к другому, в те дни, когда мы

2139
01:23:40,159 --> 01:23:43,040
ммм да, поэтому

2140
01:23:43,040 --> 01:23:45,199
я действительно считаю, что большинство

2141
01:23:45,199 --> 01:23:47,040
существующих наборов данных для ответов на вопросы или

2142
01:23:47,040 --> 01:23:49,120
данных для понимания прочитанного были

2143
01:23:49,120 --> 01:23:52,880
собраны с помощью механического перка, так что это

2144
01:23:52,880 --> 01:23:55,360
очень сложно, очень сложно избежать

2145
01:23:55,360 --> 01:23:57,360
какого-либо артефакта или вроде простых

2146
01:23:57,360 --> 01:24:00,159
подсказок или супервизуального кода, который проще,

2147
01:24:00,159 --> 01:24:02,400
скажем, не поверхностный, а какой-то

2148
01:24:02,400 --> 01:24:04,320
простой  подсказывает, что машины должны

2149
01:24:04,320 --> 01:24:05,360
подбирать,

2150
01:24:05,360 --> 01:24:06,480
поэтому

2151
01:24:06,480 --> 01:24:08,800
давайте возьмем примеры этих папок,

2152
01:24:08,800 --> 01:24:10,400
чтобы вы могли увидеть, что на самом деле, если вы посмотрите

2153
01:24:10,400 --> 01:24:12,400
на набор данных более внимательно,

2154
01:24:12,400 --> 01:24:14,480
было много примеров как вопрос,

2155
01:24:14,480 --> 01:24:16,400
имеющий большое

2156
01:24:16,400 --> 01:24:18,080
перекрытие с точки зрения слов  между

2157
01:24:18,080 --> 01:24:20,400
вопросом отрывок, поэтому модель на

2158
01:24:20,400 --> 01:24:22,639
самом деле очень хороша в подборе таких

2159
01:24:22,639 --> 01:24:26,400
подсказок, чтобы получить очень высокую

2160
01:24:26,400 --> 01:24:28,639
производительность на этом наборе данных,

2161
01:24:28,639 --> 01:24:31,199
а другой набор данных называется um

2162
01:24:31,199 --> 01:24:33,120
drop, поэтому в основном речь идет о

2163
01:24:33,120 --> 01:24:34,880
сравнении двух чисел, что-то

2164
01:24:34,880 --> 01:24:37,440
вроде этого, поэтому  это причина того, что

2165
01:24:37,440 --> 01:24:39,199
одна специализированная модель, которая была

2166
01:24:39,199 --> 01:24:41,600
очень хорошо проверена на наборе данных один на один,

2167
01:24:41,600 --> 01:24:43,600
очень легко подобрать

2168
01:24:43,600 --> 01:24:45,679
такой курс, и очень

2169
01:24:45,679 --> 01:24:47,440
трудно обобщить такие вещи на

2170
01:24:47,440 --> 01:24:49,040
другой дефицит.

2171
01:24:50,960 --> 01:24:54,960
набор данных о естественных вопросах не позволяет избежать этого возражения.

2172
01:24:54,960 --> 01:24:56,480
Да, естественные

2173
01:24:56,480 --> 01:24:58,800
вопросы будут намного лучше, но

2174
01:24:58,800 --> 01:25:00,400
есть и другие проблемы.

2175
01:25:04,239 --> 01:25:06,880
вопрос, тренд, тест перекрывает

2176
01:25:06,880 --> 01:25:09,040
бумагу, так что это означает, что демонстрация, которую я

2177
01:25:09,040 --> 01:25:10,880
использовал, чтобы прерывать такие естественные вопросы,

2178
01:25:10,880 --> 01:25:13,760
была набором данных, который Google опубликовал

2179
01:25:13,760 --> 01:25:16,159
около полутора лет назад, может быть, где

2180
01:25:16,159 --> 01:25:19,120
они на самом деле брали реальные вопросы

2181
01:25:19,120 --> 01:25:22,719
из журналов поиска Google, а затем

2182
01:25:22,719 --> 01:25:24,880
находили  ответы, пытающиеся найти

2183
01:25:24,880 --> 01:25:28,000
для них ответы в веб-документах, извините, продолжайте

2184
01:25:28,000 --> 01:25:30,480
голландский,

2185
01:25:30,639 --> 01:25:32,239
о, я просто не думаю, что да, я думаю, что это

2186
01:25:32,239 --> 01:25:34,159
определенно естественные вопросы, намного

2187
01:25:34,159 --> 01:25:35,679
лучше, чем я сказал, потому что

2188
01:25:35,679 --> 01:25:38,080
вопросы естественные, как будто вы собраны э-э, мне

2189
01:25:38,080 --> 01:25:39,600
действительно нравятся настоящие вопросы  которые

2190
01:25:39,600 --> 01:25:42,800
задают, как и пользователи, так что это как бы

2191
01:25:42,800 --> 01:25:45,520
позволяет избежать такого рода поверхностных артефактов

2192
01:25:45,520 --> 01:25:47,360
между вопросом и отрывком, но

2193
01:25:47,360 --> 01:25:49,840
есть и другие проблемы, которые

2194
01:25:49,840 --> 01:25:52,719
люди любят задавать некоторые общие вопросы,

2195
01:25:52,719 --> 01:25:55,920
поэтому, если вы просто сделаете случайную

2196
01:25:55,920 --> 01:25:58,239
серию вопросов в тренде  тест по дайвингу,

2197
01:25:58,239 --> 01:26:00,239
и есть недавнее бумажное видео, показывающее,

2198
01:26:00,239 --> 01:26:02,480
что на самом деле существует модель занятости,

2199
01:26:02,480 --> 01:26:06,320
которая неизбежна, что существует

2200
01:26:06,320 --> 01:26:08,000
большее совпадение между обучающим

2201
01:26:08,000 --> 01:26:10,560
персоналом, поэтому, если y  вы найдете этот вопрос, если

2202
01:26:10,560 --> 01:26:12,560
один вопрос, который вы

2203
01:26:12,560 --> 01:26:15,679
пытаетесь проверить на рабочем столе, или тестовый набор,

2204
01:26:15,679 --> 01:26:17,199
который домохозяйство уже появляется в

2205
01:26:17,199 --> 01:26:19,040
изменении, что на самом деле не является

2206
01:26:19,040 --> 01:26:20,800
обобщением, верно,

2207
01:26:20,800 --> 01:26:23,040
да, но это больше похоже на

2208
01:26:23,040 --> 01:26:24,560
настройку открытого домена, а не  в

2209
01:26:24,560 --> 01:26:26,800
разделе понимания прочитанного да

2210
01:26:26,800 --> 01:26:28,239
да хм

2211
01:26:28,239 --> 01:26:31,120
вы хотите задать вопрос

2212
01:26:31,120 --> 01:26:34,320
да, значит, вы упомянули, что в последней

2213
01:26:34,320 --> 01:26:36,239
части презентации

2214
01:26:36,239 --> 01:26:38,560
модель читателя может не понадобиться, и

2215
01:26:38,560 --> 01:26:40,639
вы представили танцевальные фразы, которые

2216
01:26:40,639 --> 01:26:45,600
также могут хорошо работать на процессоре

2217
01:26:45,679 --> 01:26:48,320
Итак, знаем ли мы, насколько хорошо он работает

2218
01:26:48,320 --> 01:26:51,280
с наборами данных, отвечающих на вопросы,

2219
01:26:51,280 --> 01:26:53,440
и по сравнению с другими по сравнению с другими

2220
01:26:53,440 --> 01:26:55,520
моделями, включая птиц и источники

2221
01:26:55,520 --> 01:26:57,600
на графическом процессоре, конечно,

2222
01:26:57,600 --> 01:26:59,440
да, я просто рекомендую вам проверить

2223
01:26:59,440 --> 01:27:01,280
этот документ, так что эта модель в

2224
01:27:01,280 --> 01:27:02,159
основном

2225
01:27:02,159 --> 01:27:04,639
работает на  наравне с подобной

2226
01:27:04,639 --> 01:27:06,480
моделью поиска танцевального рисунка, э-э,

2227
01:27:06,480 --> 01:27:08,800
так что она, э-э, либо

2228
01:27:08,800 --> 01:27:10,800
выполняет часть из них, это все

2229
01:27:10,800 --> 01:27:13,440
модели ритуального считывателя, но на самом деле это

2230
01:27:13,440 --> 01:27:15,600
прямо сейчас, хотя, поэтому я пропускаю  d один слайд,

2231
01:27:15,600 --> 01:27:17,920
так что прямо сейчас сохраненное искусство на

2232
01:27:17,920 --> 01:27:20,000
самом деле доминирует в этой модели,

2233
01:27:20,000 --> 01:27:21,920
гм, плотной пассивной поисковой позитивной

2234
01:27:21,920 --> 01:27:23,440
модели,

2235
01:27:23,440 --> 01:27:26,560
так что такого рода, поэтому с использованием модели t5

2236
01:27:26,560 --> 01:27:28,960
плюс извлечение, это на самом деле

2237
01:27:28,960 --> 01:27:30,800
выполняется очень хорошо, поэтому я просто скажу

2238
01:27:30,800 --> 01:27:34,080
так что это может сработать, это похоже на

2239
01:27:34,080 --> 01:27:36,159
этот блок, но по сравнению с этим типом

2240
01:27:36,159 --> 01:27:37,840
генерирующей модели нам все еще нравятся несколько

2241
01:27:37,840 --> 01:27:40,080
пунктов,

2242
01:27:40,080 --> 01:27:41,920
да ладно, а

2243
01:27:41,920 --> 01:27:44,320
что

2244
01:27:44,320 --> 01:27:46,960
за интуиция за танцевальными фразами,

2245
01:27:46,960 --> 01:27:49,120
кроме того, что ответы, вероятно,

2246
01:27:49,120 --> 01:27:52,000
эм  в непосредственной близости и что, если

2247
01:27:52,000 --> 01:27:53,280
данные говорят, что

2248
01:27:53,280 --> 01:27:56,000
есть ответы, а у квеста есть ответы на

2249
01:27:56,000 --> 01:27:58,880
конкретный вопрос, например, очень

2250
01:27:58,880 --> 01:28:03,520
далеко от фактической информации,

2251
01:28:04,320 --> 01:28:06,719
например, увидеть, что ответы на вопрос могут

2252
01:28:06,719 --> 01:28:09,440
не быть могут не находиться в непосредственной близости

2253
01:28:09,440 --> 01:28:10,960
от um

2254
01:28:10,960 --> 01:28:14,639
к словам в  вопрос,

2255
01:28:14,639 --> 01:28:17,760
так что позвольте мне просто прояснить это,

2256
01:28:17,760 --> 01:28:19,679
хорошо, цель этого проекта - попытаться

2257
01:28:20,400 --> 01:28:22,719
проиндексировать все фразы в

2258
01:28:22,719 --> 01:28:24,800
Википедии,

2259
01:28:24,800 --> 01:28:25,760
поэтому

2260
01:28:25,760 --> 01:28:27,600
я знаю, что такие

2261
01:28:27,600 --> 01:28:29,520
ротации построены с использованием обучающего набора

2262
01:28:29,520 --> 01:28:31,440
наборов данных, отвечающих на вопросы,

2263
01:28:31,440 --> 01:28:34,000
поэтому предположение по-прежнему заключается в

2264
01:28:34,000 --> 01:28:36,000
распределении примеров в

2265
01:28:36,000 --> 01:28:37,600
различных тестах, которые наверняка будут похожи

2266
01:28:37,600 --> 01:28:40,560
на обучающий набор,

2267
01:28:40,880 --> 01:28:42,320
отвечает ли это на ваш вопрос, так что в

2268
01:28:42,320 --> 01:28:43,760
основном мы все еще пытаемся рассмотреть

2269
01:28:43,760 --> 01:28:45,840
все фразы в википедии  и этот

2270
01:28:45,840 --> 01:28:47,920
тест теперь мы просто берем вопросы и

2271
01:28:47,920 --> 01:28:50,639
пытаемся завершить скалярный продукт в порядке,

2272
01:28:50,639 --> 01:28:53,440
поэтому, если мы используем, скажем, другой

2273
01:28:53,440 --> 01:28:55,840
набор данных, который не представляет

2274
01:28:55,840 --> 01:28:57,920
информацию, используя структуру, представленную

2275
01:28:57,920 --> 01:29:01,360
в Википедии, тогда эта модель может не

2276
01:29:01,360 --> 01:29:04,320
работать так же хорошо, как

2277
01:29:05,120 --> 01:29:08,080
то, что делает  Вы имеете в виду под структурой, тогда,

2278
01:29:08,080 --> 01:29:10,400
скажем так, если мы будем

2279
01:29:10,400 --> 01:29:13,360
больше склоняться к более

2280
01:29:13,360 --> 01:29:16,000
четким структурам, таким как отрывки, которые мы видим

2281
01:29:16,000 --> 01:29:19,280
в стандартизированных тестах, где ответы

2282
01:29:19,280 --> 01:29:20,639
на вопрос

2283
01:29:20,639 --> 01:29:22,840
могут быть не такими, как,

2284
01:29:22,840 --> 01:29:26,080
может быть, не в непосредственной близости от того места,

2285
01:29:27,120 --> 01:29:30,000
где была информация  впервые введено о

2286
01:29:30,000 --> 01:29:32,800
нет, поэтому ответы не нужно

2287
01:29:32,800 --> 01:29:34,560
видеть на этапе обучения, поэтому

2288
01:29:34,560 --> 01:29:36,320
бизнес будет использовать

2289
01:29:36,320 --> 01:29:38,480
кодировщик канала обучающего набора для

2290
01:29:38,480 --> 01:29:41,440
фраз  и, используя, а затем мы применяем

2291
01:29:41,440 --> 01:29:43,679
этот кодировщик ко всем свободным,

2292
01:29:43,679 --> 01:29:46,400
всем местам, ко многим, вроде шестиметровых

2293
01:29:46,400 --> 01:29:49,440
фраз в этом видео, так что модель

2294
01:29:49,440 --> 01:29:51,920
определенно может обобщить из

2295
01:29:51,920 --> 01:29:54,159
обучающего набора um на все фразы для

2296
01:29:54,159 --> 01:29:56,080
использования мультимедиа, поэтому  он не должен

2297
01:29:56,080 --> 01:29:58,000
видеть то,

2298
01:29:58,000 --> 01:30:00,960
о чем вы спрашиваете,

2299
01:30:04,480 --> 01:30:07,440
я вижу, хорошо,

2300
01:30:08,800 --> 01:30:10,639
это на самом деле очень, так что на самом деле

2301
01:30:10,639 --> 01:30:12,239
это похоже на поиск или

2302
01:30:12,239 --> 01:30:14,560
лучший пассивный поиск, так что вам все еще нравится

2303
01:30:14,560 --> 01:30:16,000
эм

2304
01:30:16,000 --> 01:30:17,360
да, я пытался направить пассивное

2305
01:30:17,360 --> 01:30:20,400
вращение  здесь, на первой станции, но

2306
01:30:20,400 --> 01:30:22,639
так что ротация - это только тенденция с

2307
01:30:22,639 --> 01:30:25,199
использованием обучающего набора наборов данных, отвечающих на вопросы,

2308
01:30:26,800 --> 01:30:29,040
но гм, взяв кодировщик, а затем мы

2309
01:30:29,040 --> 01:30:31,920
собираемся кодировать все ротации

2310
01:30:31,920 --> 01:30:34,480
всех отрывков фраз в Википедии,

2311
01:30:34,480 --> 01:30:37,120
а затем мы  Можно ожидать, что это

2312
01:30:37,120 --> 01:30:39,199
вращение может действительно хорошо обобщить

2313
01:30:39,199 --> 01:30:41,199
невидимые вопросы,

2314
01:30:41,199 --> 01:30:42,880
да,

2315
01:30:42,880 --> 01:30:46,239
так что, так что вопрос в том, а

2316
01:30:46,239 --> 01:30:47,920
что, если ближайший сосед, чтобы она

2317
01:30:47,920 --> 01:30:51,120
не вернула ответ,

2318
01:30:52,800 --> 01:30:54,320
так почему вы думаете, что ближайший сосед

2319
01:30:54,320 --> 01:30:55,920
я имею в виду, что вы всегда можете найти что-то

2320
01:30:55,920 --> 01:30:57,520
правильное, просто вопрос в том,

2321
01:30:57,520 --> 01:31:00,239
звонит ли он ему или нет,

2322
01:31:00,239 --> 01:31:02,080
да, поэтому возникает вопрос, что, по

2323
01:31:02,080 --> 01:31:03,679
вашему мнению, данные говорят о том, что

2324
01:31:03,679 --> 01:31:07,120
ответ недостаточно близок, тогда

2325
01:31:07,120 --> 01:31:08,800
эм

2326
01:31:08,800 --> 01:31:10,400
да, это хороший вопрос, я не  не знаю,

2327
01:31:10,400 --> 01:31:12,320
если вы действительно придумаете что-то,

2328
01:31:12,320 --> 01:31:15,040
что действительно очень далеко от

2329
01:31:15,040 --> 01:31:16,880
всех вопросов, которые мы

2330
01:31:16,880 --> 01:31:18,320
видели в учебном центре, что могло

2331
01:31:18,320 --> 01:31:21,280
быть возможным, я не знаю, в

2332
01:31:21,280 --> 01:31:23,760
основном, это зависит от

2333
01:31:23,760 --> 01:31:27,360
того, как тексты отформатированы

2334
01:31:27,360 --> 01:31:29,440
тогда поиск ближайшего соседа может

2335
01:31:29,440 --> 01:31:33,600
не работать так же хорошо, как другие модели,

2336
01:31:33,600 --> 01:31:35,440
поэтому снова вопрос в

2337
01:31:35,440 --> 01:31:37,280
том, что приглашение к вопросу также возвращается с

2338
01:31:37,280 --> 01:31:39,280
кодом вопроса,

2339
01:31:40,639 --> 01:31:42,400
поэтому вопрос в том, может ли этот

2340
01:31:42,400 --> 01:31:44,400
кодировщик вопросов дать вам что-то разумное

2341
01:31:44,400 --> 01:31:46,960
в этом пространстве или нет

2342
01:31:46,960 --> 01:31:49,040
но я не знаю, да, поэтому мы

2343
01:31:49,040 --> 01:31:51,040
много тестировали как случайные, даже

2344
01:31:51,040 --> 01:31:53,520
импортированные предложения, или

2345
01:31:53,520 --> 01:31:55,199
даже вопрос не должен быть реальным

2346
01:31:55,199 --> 01:31:56,880
вопросом, это может быть предложение, это

2347
01:31:56,880 --> 01:31:58,880
не похоже на нашу проблему, поэтому  далеко

2348
01:31:58,880 --> 01:31:59,920
да,

2349
01:31:59,920 --> 01:32:02,000
может быть, нам стоит

2350
01:32:02,000 --> 01:32:03,920
попробовать еще пару человек, и тебе разрешат

2351
01:32:03,920 --> 01:32:05,840
включить камеру или задать вопрос, если

2352
01:32:05,840 --> 01:32:11,400
хочешь, так что наш следующий

2353
01:32:13,040 --> 01:32:15,120
человек хорошо привет эм спасибо за то, что нашли

2354
01:32:15,120 --> 01:32:17,520
время научить нас ммм  мой вопрос

2355
01:32:17,520 --> 01:32:19,679
довольно быстрый, поэтому вы упомянули работу, которая

2356
01:32:19,679 --> 01:32:21,760
подняла ряд относительно простых

2357
01:32:21,760 --> 01:32:24,639
вопросов, которые показывают, насколько хрупкими или

2358
01:32:24,639 --> 01:32:27,120
плохими могут быть текущие модели.

2359
01:32:27,120 --> 01:32:30,800
Мне любопытно, правда

2360
01:32:33,040 --> 01:32:34,880
ли это.

2361
01:32:34,880 --> 01:32:36,320
сообществу, чтобы

2362
01:32:36,320 --> 01:32:39,199
улучшить то, как оценивать модели,

2363
01:32:39,199 --> 01:32:41,360
потому что они на самом деле довольно

2364
01:32:41,360 --> 01:32:44,239
плохо справляются с некоторыми из них.

2365
01:32:53,760 --> 01:32:55,760
пытаюсь проверить, например, отрицание или временные

2366
01:32:55,760 --> 01:32:57,840
предпочтения в отношениях, поэтому

2367
01:32:57,840 --> 01:32:58,800
вопросы не связаны

2368
01:32:58,800 --> 01:33:00,239
с рассуждениями о

2369
01:33:00,239 --> 01:33:02,320
емкости, это не так просто, просто

2370
01:33:02,320 --> 01:33:03,840
формулировка очень проста

2371
01:33:03,840 --> 01:33:05,040
ммм,

2372
01:33:05,040 --> 01:33:07,280
я действительно думаю, что хорошо, так что эта статья

2373
01:33:07,280 --> 01:33:08,639
определенно r  привлек много внимания

2374
01:33:08,639 --> 01:33:10,320
в лучшей статье прошлого года в ACL, самой

2375
01:33:10,320 --> 01:33:12,560
большой стране на конференции,

2376
01:33:12,560 --> 01:33:15,120
так что я думаю, что многие люди

2377
01:33:15,120 --> 01:33:16,719
пытаются решить эту проблему,

2378
01:33:16,719 --> 01:33:19,120
я не могу вам сказать, хорошо ли у нас

2379
01:33:19,120 --> 01:33:21,199
действительно есть решение для этого да о

2380
01:33:21,199 --> 01:33:23,679
нет  да,

2381
01:33:23,679 --> 01:33:25,120
круто, да, спасибо, спасибо, что

2382
01:33:25,120 --> 01:33:26,639
подняли этот вопрос, это действительно

2383
01:33:26,639 --> 01:33:28,159
интересно,

2384
01:33:28,159 --> 01:33:31,040
хорошо, дальше,

2385
01:33:31,600 --> 01:33:34,320
привет, спасибо, что нашли время, так что мой

2386
01:33:34,320 --> 01:33:37,040
вопрос не имеет отношения к делу, но я

2387
01:33:37,040 --> 01:33:39,040
хотел бы создать надежную систему

2388
01:33:39,040 --> 01:33:40,480
ответов на вопросы,

2389
01:33:40,480 --> 01:33:43,440
в какой степени можно обучаться в контексте

2390
01:33:43,440 --> 01:33:45,840
помочь моделям быть более надежными по

2391
01:33:45,840 --> 01:33:49,360
отношению к разным доменам

2392
01:33:53,840 --> 01:33:57,840
о, так что вроде бы в основном вы предоставляете

2393
01:33:57,840 --> 01:34:01,040
шаблон, сгенерированный Bird, а затем

2394
01:34:01,040 --> 01:34:03,679
вместо того, чтобы напрямую предсказывать

2395
01:34:03,679 --> 01:34:07,199
разделы текстовых классификаций, вы просто

2396
01:34:07,199 --> 01:34:12,800
используете какое-то слово для представления этого предложения,

2397
01:34:15,679 --> 01:34:17,840
хорошо,

2398
01:34:17,840 --> 01:34:19,360
поэтому я предполагаю, что вы  на самом деле

2399
01:34:19,360 --> 01:34:21,840
имел в виду

2400
01:34:23,679 --> 01:34:26,400
такие вещи, как индустрия контекстного обучения,

2401
01:34:26,480 --> 01:34:28,159
хорошо, на самом деле, я недавно делал

2402
01:34:28,159 --> 01:34:31,280
что-то, связанное с динамикой,

2403
01:34:31,280 --> 01:34:32,960
но я не уверен, как мы могли  на самом деле

2404
01:34:32,960 --> 01:34:35,280
использовать это в контексте обучения в любой

2405
01:34:35,280 --> 01:34:39,520
сцене для школьного типа, вы знаете проблемы,

2406
01:34:40,480 --> 01:34:43,119
да, поэтому я не знаю, может ли это быть

2407
01:34:43,119 --> 01:34:45,679
надежностью или нет, я даже думал, что вы

2408
01:34:45,679 --> 01:34:47,679
использовали эту технику для вопросов,

2409
01:34:47,679 --> 01:34:48,719
три года

2410
01:34:48,719 --> 01:34:50,960
я вижу, я вижу, спасибо, и я  Раньше также

2411
01:34:50,960 --> 01:34:53,760
упоминалось, что мы можем обучать ретривера

2412
01:34:53,760 --> 01:34:56,480
без ридера, так что есть ли статья

2413
01:34:56,480 --> 01:34:57,920
о

2414
01:34:57,920 --> 01:35:00,800
текущих попытках сделать это,

2415
01:35:00,800 --> 01:35:03,280
да, так любимые уже выключены, так что просто

2416
01:35:03,280 --> 01:35:06,639
ну да ладно

2417
01:35:10,000 --> 01:35:12,639
ладно в следующий раз

2418
01:35:15,520 --> 01:35:17,920
для лекции у меня будет

2419
01:35:17,920 --> 01:35:21,440
более широкий вопрос

2420
01:35:21,440 --> 01:35:23,679
о будущем НЛП

2421
01:35:23,679 --> 01:35:24,800
ммм

2422
01:35:24,800 --> 01:35:26,960
Вы думаете, что для

2423
01:35:26,960 --> 01:35:29,199
решения НЛП в том смысле, что

2424
01:35:29,199 --> 01:35:32,000
вы можете выполнять наравне с людьми

2425
01:35:32,000 --> 01:35:35,679
все задачи НЛП, достаточно

2426
01:35:35,679 --> 01:35:38,159
взаимодействовать только с текстом  данные, что бы вы ни

2427
01:35:38,159 --> 01:35:41,040
думали, в конечном итоге потребуют

2428
01:35:41,040 --> 01:35:42,880
определенного опыта и здравого смысла, которые

2429
01:35:42,880 --> 01:35:46,080
вы получаете только от видения и своего

2430
01:35:46,080 --> 01:35:47,600
рода ощущения мира и от

2431
01:35:47,600 --> 01:35:51,679
таких взаимодействий, которые есть у нас, людей,

2432
01:35:52,320 --> 01:35:54,239
да, я имею в виду, что здравый смысл был  очень

2433
01:35:54,239 --> 01:35:55,760
сложно, даже в контексте

2434
01:35:55,760 --> 01:35:58,239
ограничения здравого смысла, это очень

2435
01:35:58,239 --> 01:36:00,880
да, сейчас очень, очень важные темы, которые

2436
01:36:00,880 --> 01:36:02,800
все еще остаются, я думаю, что это все еще

2437
01:36:02,800 --> 01:36:04,480
остается в результате,

2438
01:36:04,480 --> 01:36:05,840
ну,

2439
01:36:05,840 --> 01:36:08,560
в этой части честно, именно да,

2440
01:36:08,560 --> 01:36:11,119
я также хочу упомянуть, что

2441
01:36:11,119 --> 01:36:12,719
хорошо, так что для  многие

2442
01:36:12,719 --> 01:36:14,880
базы данных понимания прочитанного или вопросы,

2443
01:36:14,880 --> 01:36:16,639
которые вы видите, что мы чисты с

2444
01:36:16,639 --> 01:36:18,560
людьми, начинают достигать

2445
01:36:18,560 --> 01:36:21,040
человеческих качеств, но это, но мы также

2446
01:36:21,040 --> 01:36:23,199
видим, насколько хороши эти системы,

2447
01:36:23,199 --> 01:36:25,440
потому что да, я имею в виду, что они не могут

2448
01:36:25,440 --> 01:36:28,000
регенерировать или решать простые  проблемы, так что

2449
01:36:28,000 --> 01:36:30,320
все эти вещи должны быть решены

2450
01:36:30,320 --> 01:36:32,270
мм

2451
01:36:32,270 --> 01:36:35,469
[Музыка]

2452
01:36:38,480 --> 01:36:41,610
[Музыка]

2453
01:36:47,600 --> 01:36:50,960
пытается привлечь человека к кругу

2454
01:36:50,960 --> 01:36:53,119
рамок для оценки таких

2455
01:36:53,119 --> 01:36:55,920
систем, просто попробуйте сломать текущую

2456
01:36:55,920 --> 01:36:57,440
систему, вернитесь с некоторыми более сложными

2457
01:36:57,440 --> 01:36:58,480
вопросами,

2458
01:36:58,480 --> 01:36:59,840
так

2459
01:36:59,840 --> 01:37:01,600
что да  это означает, что, возможно,

2460
01:37:01,600 --> 01:37:03,920
статические предприятия недостаточно хороши

2461
01:37:03,920 --> 01:37:06,000
для измерения прогресса, поэтому нам

2462
01:37:06,000 --> 01:37:07,360
действительно нужна какая-то динамическая

2463
01:37:07,360 --> 01:37:08,800
оценка, а

2464
01:37:08,800 --> 01:37:10,400
также представить все больше этого рода  d

2465
01:37:10,400 --> 01:37:12,239
отрицательных примеров или

2466
01:37:12,239 --> 01:37:14,239
э-э да более сложные вопросы или что-то в

2467
01:37:14,239 --> 01:37:15,679
этом

2468
01:37:15,679 --> 01:37:17,199
роде, вы все еще собираетесь задать еще пару

2469
01:37:17,199 --> 01:37:19,679
вопросов,

2470
01:37:19,760 --> 01:37:21,520
ну, конечно, я не хочу быть уверенным, что сейчас

2471
01:37:21,520 --> 01:37:24,880
девять или девять 10 вечера.

2472
01:37:26,960 --> 01:37:31,239
это связь

2473
01:37:34,159 --> 01:37:35,119
в

2474
01:37:35,119 --> 01:37:37,760
нерфах 2020, был этот эффективный открытый

2475
01:37:37,760 --> 01:37:40,800
вопрос, ответивший на вызов,

2476
01:37:40,800 --> 01:37:41,920
и,

2477
01:37:41,920 --> 01:37:44,480
судя по производительности, казалось,

2478
01:37:44,480 --> 01:37:47,040
что было довольно существенное

2479
01:37:47,040 --> 01:37:49,760
уменьшение по сравнению с человеческой точностью,

2480
01:37:49,760 --> 01:37:52,800
вероятно, в

2481
01:37:52,800 --> 01:37:55,920
первую очередь, квантование и гм

2482
01:37:55,920 --> 01:37:58,159
также некоторый дрейф, который произошел,

2483
01:37:58,159 --> 01:37:59,760
когда они были  квантование

2484
01:37:59,760 --> 01:38:01,280
гм, так что

2485
01:38:01,280 --> 01:38:04,000
я недавно наткнулся на эту статью

2486
01:38:04,000 --> 01:38:07,040
под названием э-э обучаемые квантователи, э-э, которая, по

2487
01:38:07,040 --> 01:38:08,159
сути,

2488
01:38:08,159 --> 01:38:09,199
изучает,

2489
01:38:09,199 --> 01:38:11,440
э-э, учится, как базовые представления

2490
01:38:11,440 --> 01:38:14,560
для квантователей, например, вместе с

2491
01:38:14,560 --> 01:38:17,280
весами сети, гм,

2492
01:38:17,280 --> 01:38:18,320
и

2493
01:38:18,320 --> 01:38:21,199
хотя это было бы очень

2494
01:38:21,199 --> 01:38:23,199
эффективно, если бы вы просто хотели сказать

2495
01:38:23,199 --> 01:38:25,040
поезда из  царапина, мне просто было очень

2496
01:38:25,040 --> 01:38:28,000
любопытно, как ты думаешь,

2497
01:38:28,000 --> 01:38:29,420
есть такие способы

2498
01:38:29,420 --> 01:38:32,479
[Музыка]

2499
01:38:36,500 --> 01:38:42,739
[Музыка]

2500
01:38:43,280 --> 01:38:46,639
ммм да, я не думаю ii '  Я действительно

2501
01:38:46,639 --> 01:38:49,760
эксперт, чтобы ответить на этот вопрос,

2502
01:38:49,760 --> 01:38:51,520
да, я не уверен, действительно ли у меня есть

2503
01:38:51,520 --> 01:38:52,719
ответ, но я также хочу быстро

2504
01:38:52,719 --> 01:38:54,960
упомянуть, что да, квантование было

2505
01:38:54,960 --> 01:38:56,800
очень и очень полезным методом для

2506
01:38:56,800 --> 01:38:58,719
уменьшения размера модели, поэтому мы также

2507
01:38:58,719 --> 01:39:02,000
изучали взаимодействие  в проекте танцевальных

2508
01:39:02,000 --> 01:39:04,719
фраз в последнее время из-за того, что

2509
01:39:04,719 --> 01:39:06,320
хранилище все

2510
01:39:06,320 --> 01:39:08,639
еще было очень, все еще очень велико,

2511
01:39:08,639 --> 01:39:10,480
поэтому мы пытаемся сократить эту

2512
01:39:10,480 --> 01:39:11,520
историю,

2513
01:39:12,719 --> 01:39:15,119
да, я не уверен, есть ли

2514
01:39:15,119 --> 01:39:16,480
вопрос о связи между

2515
01:39:16,480 --> 01:39:18,880
композицией, а также  тренировка

2516
01:39:18,880 --> 01:39:20,719
ага да я не уверен, что

2517
01:39:20,719 --> 01:39:23,360
я тоже делаю это да извините да спасибо

2518
01:39:24,080 --> 01:39:26,719
спасибо данте был слишком

2519
01:39:26,719 --> 01:39:28,159
скромен, чтобы упомянуть, что она была одним

2520
01:39:28,159 --> 01:39:31,600
из соорганизаторов эффективной

2521
01:39:31,600 --> 01:39:37,560
совместной задачи qa um ну ладно следующий вопрос

2522
01:39:40,080 --> 01:39:41,600
Привет, ребята, вы большое спасибо за то, что были

2523
01:39:41,600 --> 01:39:43,199
здесь сегодня,

2524
01:39:43,199 --> 01:39:46,400
так что мой вопрос немного другой,

2525
01:39:46,400 --> 01:39:48,239
так что один из примеров, который вы дали, который

2526
01:39:48,239 --> 01:39:50,800
привлек мое внимание, был этот пример Алекс Виктория

2527
01:39:50,800 --> 01:39:53,040
контрольный список мм, и я думал, что

2528
01:39:53,040 --> 01:39:55,280
технически Алекс был в этом  неправильный ответ

2529
01:39:55,280 --> 01:39:56,800
правильный, он гендерно нейтральный, и

2530
01:39:56,800 --> 01:39:59,520
в вопросе не было достаточного контекста контекста,

2531
01:39:59,520 --> 01:40:01,679
чтобы определить, к кому он относится,

2532
01:40:01,679 --> 01:40:04,639
поэтому мой вопрос заключается в том, насколько

2533
01:40:04,639 --> 01:40:06,960
мы должны быть обеспокоены потенциальным

2534
01:40:06,960 --> 01:40:09,840
кодированием определенных предубеждений в эти

2535
01:40:09,840 --> 01:40:13,040
ярлыки круга, или о том, как мы их оцениваем

2536
01:40:13,040 --> 01:40:15,280
или  это просто больше беспокоит более

2537
01:40:15,280 --> 01:40:18,400
открытых вопросов,

2538
01:40:19,920 --> 01:40:21,600
да, это определенно очень важно

2539
01:40:21,600 --> 01:40:23,280
снова, так как многие люди

2540
01:40:23,280 --> 01:40:25,440
пытаются понять, хорошо, сколько

2541
01:40:25,440 --> 01:40:27,520
покупателей справляется с моделями и как мы

2542
01:40:27,520 --> 01:40:28,880
можем,

2543
01:40:28,880 --> 01:40:30,400
да,

2544
01:40:30,400 --> 01:40:31,520
да, я '  Я не уверен, что у меня есть хороший

2545
01:40:31,520 --> 01:40:34,320
ответ на этот вопрос,

2546
01:40:34,320 --> 01:40:36,239
например, я просто хочу сказать, например, как

2547
01:40:36,239 --> 01:40:37,920
сделать смещение моделей языка создания,

2548
01:40:37,920 --> 01:40:39,119
все эти вещи

2549
01:40:39,119 --> 01:40:40,400
очень важны,

2550
01:40:40,400 --> 01:40:42,639
и

2551
01:40:42,639 --> 01:40:43,440
ммм,

2552
01:40:43,440 --> 01:40:45,040
да, это всего лишь один, так что вы говорите

2553
01:40:45,040 --> 01:40:46,719
об этом примере правильно, так что это всего лишь

2554
01:40:46,719 --> 01:40:48,840
один тестовый пример

2555
01:40:48,840 --> 01:40:51,280
мм да мм

2556
01:40:51,280 --> 01:40:54,000
да я не знаю да

2557
01:40:54,000 --> 01:40:55,440
правильно да я думаю я просто немного больше

2558
01:40:55,440 --> 01:40:56,639
о том, кто придумывает

2559
01:40:56,639 --> 01:40:58,480
тестовые примеры правильно кто определяет

2560
01:40:58,480 --> 01:41:01,520
другой да есть

2561
01:41:01,520 --> 01:41:02,719
благодарить  Вы,

2562
01:41:02,719 --> 01:41:04,560
я имею в виду, мы будем очень

2563
01:41:04,560 --> 01:41:07,440
скоро обсуждать токсичность в предвзятости, в

2564
01:41:07,440 --> 01:41:09,440
том числе лекцию в четверг,

2565
01:41:09,440 --> 01:41:12,159
а также более позднюю лекцию

2566
01:41:12,159 --> 01:41:15,360
эм не конкретно о qa, хотя, ладно,

2567
01:41:15,360 --> 01:41:19,080
следующий человек

2568
01:41:19,600 --> 01:41:22,320
прав, спасибо за лекцию

2569
01:41:22,320 --> 01:41:24,400
да, мой вопрос  также относится к

2570
01:41:24,400 --> 01:41:27,840
истории класса с открытым доменом, так что, ммм,

2571
01:41:27,840 --> 01:41:31,280
мне просто интересно, насколько, например,

2572
01:41:31,280 --> 01:41:34,719
э-э, учебная сторона области ммм,

2573
01:41:34,719 --> 01:41:38,080
такая как своего рода обобщение,

2574
01:41:38,080 --> 01:41:41,199
ммм или как выравнивание предметной области, умные техники

2575
01:41:41,199 --> 01:41:43,760
могут быть

2576
01:41:43,760 --> 01:41:47,679
скомбинированы с подобным языковым уровнем

2577
01:41:47,679 --> 01:41:49,600
например, вопрос о строке, например, в какой

2578
01:41:49,600 --> 01:41:51,600
степени они будут работать, и,

2579
01:41:51,600 --> 01:41:53,920
например, какой тип

2580
01:41:53,920 --> 01:41:56,239
дизайна для конкретного языка следует использовать, чтобы

2581
01:41:56,239 --> 01:41:57,760
объединить с ними, чтобы

2582
01:41:57,760 --> 01:42:01,760
вроде как, например, если мы хотим получить более высокую

2583
01:42:01,760 --> 01:42:05,119
производительность и тому подобное,

2584
01:42:05,119 --> 01:42:06,400
есть вопрос о том, как

2585
01:42:06,400 --> 01:42:08,000
обобщить между  разные домены или

2586
01:42:08,000 --> 01:42:10,239
давай поговорим о том, как спроектировать

2587
01:42:10,239 --> 01:42:11,920
систему qa с открытым доменом для разных

2588
01:42:11,920 --> 01:42:14,960
языков, я не уверен

2589
01:42:18,960 --> 01:42:20,960
ning конкретных

2590
01:42:20,960 --> 01:42:22,800
проектов, таких как

2591
01:42:23,760 --> 01:42:26,239
выравнивание господства и как

2592
01:42:26,239 --> 01:42:28,239
методы распутывания будущего уровня,

2593
01:42:29,199 --> 01:42:31,840
которые были, которые показали некоторые, как,

2594
01:42:33,280 --> 01:42:36,000
например, интересную производительность в

2595
01:42:36,000 --> 01:42:38,880
других задачах, и я увидел, что, как и

2596
01:42:38,880 --> 01:42:41,119
недавно, некоторые люди также любят использовать

2597
01:42:41,119 --> 01:42:43,920
подобные вещи, например  для ответа на

2598
01:42:43,920 --> 01:42:45,440
вопрос, так что мне просто было

2599
01:42:45,440 --> 01:42:48,480
интересно, в какой степени

2600
01:42:48,480 --> 01:42:51,440
эти методы работают,

2601
01:42:51,440 --> 01:42:54,719
например, с языковыми задачами, не только с

2602
01:42:54,719 --> 01:42:56,880
ограниченными ответами на вопросы, но, в

2603
01:42:56,880 --> 01:43:00,400
основном, с ответами на вопросы,

2604
01:43:00,400 --> 01:43:02,080
извините, о какой работе вы

2605
01:43:02,080 --> 01:43:04,320
говорите  Я все еще не уверен,

2606
01:43:04,320 --> 01:43:05,520
что вы имеете в виду под всеми этими

2607
01:43:05,520 --> 01:43:08,400
разговорами или вопросами,

2608
01:43:08,400 --> 01:43:10,560
так что, в основном,

2609
01:43:10,560 --> 01:43:12,400
я имею в виду, что это как бы немного более

2610
01:43:12,400 --> 01:43:15,760
конкретное, так что есть эта

2611
01:43:15,760 --> 01:43:18,000
статья под названием

2612
01:43:18,000 --> 01:43:20,480
эм эээ,

2613
01:43:20,480 --> 01:43:25,239
я забыл точную  имя ну

2614
01:43:35,119 --> 01:43:36,800
хорошо, у меня все в порядке, я просто хочу

2615
01:43:36,800 --> 01:43:38,480
убедиться, что мы находимся на одной странице, поэтому у меня

2616
01:43:38,480 --> 01:43:40,480
есть вещи, которые работают, вместо того,

2617
01:43:40,480 --> 01:43:42,800
чтобы пытаться узнать что-то вроде распада,

2618
01:43:42,800 --> 01:43:45,199
поэтому  Я могу лучше обобщить на

2619
01:43:45,199 --> 01:43:47,760
разные области или неблагоприятные примеры,

2620
01:43:47,760 --> 01:43:49,119
это то, что вы говорите,

2621
01:43:49,119 --> 01:43:50,719
да, да,

2622
01:43:50,719 --> 01:43:52,719
и вопрос в том, что эта техника

2623
01:43:52,719 --> 01:43:54,960
может быть общей, обычно

2624
01:43:54,960 --> 01:43:57,840
применяемой к личной силе, о да,

2625
01:43:57,840 --> 01:44:00,480
они просто задаются вопросом, как, в какой

2626
01:44:00,480 --> 01:44:02,880
степени  будут ли они работать, потому

2627
01:44:02,880 --> 01:44:05,119
что я думаю, что язык

2628
01:44:05,119 --> 01:44:06,960
имеет много чего-то похожего, например,

2629
01:44:06,960 --> 01:44:09,840
зависимости и других вещей, которые

2630
01:44:09,840 --> 01:44:12,880
не нравятся этим методам, на самом деле

2631
01:44:20,480 --> 01:44:22,960
я позаботился бы о них  нужно

2632
01:44:22,960 --> 01:44:25,840
попробовать, но это интересный момент,

2633
01:44:25,840 --> 01:44:27,920
да, я не знаю, по крайней мере, для работы,

2634
01:44:27,920 --> 01:44:30,080
которую я видел до сих пор, все

2635
01:44:30,080 --> 01:44:33,199
применяются или работают в очень простой

2636
01:44:33,199 --> 01:44:35,679
задаче классификации предложений, может быть,

2637
01:44:35,679 --> 01:44:38,880
анонимно, может быть, семь или правильно,

2638
01:44:38,880 --> 01:44:40,080
так что

2639
01:44:40,080 --> 01:44:41,600
мое понимание  в качестве базового возьмите

2640
01:44:41,600 --> 01:44:44,159
кодировщик уровня, применяемый к простой

2641
01:44:44,159 --> 01:44:46,400
задаче тестовой классификации, и возьмите скрытое

2642
01:44:46,400 --> 01:44:48,400
вращение, сделайте какое-

2643
01:44:48,400 --> 01:44:50,639
то преобразование и убедитесь, что

2644
01:44:50,639 --> 01:44:52,719
да, он может изучить какие-то

2645
01:44:52,719 --> 01:44:54,239
особенности окружающей среды  из скрытой

2646
01:44:54,239 --> 01:44:56,000
репутации что-то в этом

2647
01:44:56,000 --> 01:44:59,280
роде да, круто,

2648
01:44:59,679 --> 01:45:02,000
да, я не уверен, что чувствую, что qa - это

2649
01:45:02,000 --> 01:45:04,880
более структурированная задача, а также обрабатывает

2650
01:45:04,880 --> 01:45:05,760
более длинные

2651
01:45:05,760 --> 01:45:08,320
последовательности

2652
01:45:08,320 --> 01:45:09,199
ммм

2653
01:45:09,199 --> 01:45:11,520
да, поэтому я не знаю, работает ли это,

2654
01:45:11,520 --> 01:45:14,239
если только люди не пробовали это да,

2655
01:45:14,239 --> 01:45:16,800
спасибо  спасибо, хорошо, а потом у нас

2656
01:45:16,800 --> 01:45:18,639
есть, и, может быть, нам следует назвать это

2657
01:45:18,639 --> 01:45:21,119
последним вопросом

2658
01:45:21,119 --> 01:45:23,600
Привет, мне просто интересно,

2659
01:45:23,600 --> 01:45:26,159
каково интуитивное различие между

2660
01:45:26,159 --> 01:45:28,800
решением вопросов с ответами на

2661
01:45:28,800 --> 01:45:31,920
гарантированные модели, такие как t5, и

2662
01:45:31,920 --> 01:45:35,360
кодировщиками, такими как птица,

2663
01:45:35,679 --> 01:45:39,040
хорошо, это  точка, хорошо,

2664
01:45:39,040 --> 01:45:41,440
так что я пропустил этот слайд, так

2665
01:45:41,440 --> 01:45:43,600
почему эта модель работает так хорошо, на

2666
01:45:43,600 --> 01:45:45,440
самом деле причина в том, что на самом деле дело не

2667
01:45:45,440 --> 01:45:47,280
в модели извлечения, а в модели генерации,

2668
01:45:47,280 --> 01:45:50,159
причина в том, что

2669
01:45:50,159 --> 01:45:52,400
они на самом деле гм для модели извлечения,

2670
01:45:53,360 --> 01:45:55,760
поэтому, если извлечение вернется  скажем,

2671
01:45:55,760 --> 01:45:58,560
100 отрывков, поэтому они должны извлечь

2672
01:45:58,560 --> 01:46:00,960
ответ из каждого отрывка, а

2673
01:46:00,960 --> 01:46:02,560
затем, наконец, выяснить, какой из них является

2674
01:46:02,560 --> 01:46:04,960
максимальным, что имеет наивысший балл, но

2675
01:46:04,960 --> 01:46:06,320
для генерирующей модели по существу они  Я

2676
01:46:06,320 --> 01:46:08,960
пытаюсь объединить все 100 проходов

2677
01:46:08,960 --> 01:46:11,920
и их репутацию вместе и сделать

2678
01:46:11,920 --> 01:46:14,400
их генерацию вместе, понимаете ли вы,

2679
01:46:15,440 --> 01:46:17,600
что, по сути, объединение 100 станций

2680
01:46:17,600 --> 01:46:20,320
вместе для совместной генерации, а

2681
01:46:20,320 --> 01:46:22,560
не только извлечение из каждого

2682
01:46:22,560 --> 01:46:24,639
из проходов, так что я думаю, что на самом деле

2683
01:46:24,639 --> 01:46:27,119
это ключ  разница, вот почему эта

2684
01:46:27,119 --> 01:46:29,280
генерирующая модель может очень хорошо работать

2685
01:46:29,280 --> 01:46:31,199
по сравнению с

2686
01:46:31,199 --> 01:46:33,119
извлекающими моделями, поэтому я также хочу

2687
01:46:33,119 --> 01:46:34,719
упомянуть, что хорошо,

2688
01:46:34,719 --> 01:46:37,199
поэтому, если вы посмотрите на эту модель ig, на

2689
01:46:37,199 --> 01:46:38,480
самом деле это

2690
01:46:38,480 --> 01:46:41,440
похоже на сравнение модели dpi и rhg, поэтому

2691
01:46:41,440 --> 01:46:43,280
модель ig всегда выполняет генеративную

2692
01:46:43,280 --> 01:46:45,040
модель, но они не выполняют такого

2693
01:46:45,040 --> 01:46:47,520
рода агрегацию, они просто пытаются

2694
01:46:47,520 --> 01:46:49,520
извлечь один проход и выполнить

2695
01:46:49,520 --> 01:46:52,239
генерацию, поэтому модель rng на самом деле

2696
01:46:52,239 --> 01:46:54,639
не работает так же хорошо, как эта модель,

2697
01:46:54,639 --> 01:46:56,159
кстати, я также хочу упомянуть модель rng.

2698
01:46:56,159 --> 01:46:58,000
на самом деле не лучше, чем dpr,

2699
01:46:58,000 --> 01:47:00,239
потому что эта базовая модель - большая модель,

2700
01:47:00,239 --> 01:47:02,320
поэтому эти цифры немного

2701
01:47:02,320 --> 01:47:04,320
сбивают с толку, поэтому они на самом деле в основном

2702
01:47:04,320 --> 01:47:05,600
действительно совпадают, они  в основном

2703
01:47:05,600 --> 01:47:08,639
выполняется аналогично, но гм, поэтому

2704
01:47:08,639 --> 01:47:10,080
ключевое различие между генерирующей

2705
01:47:10,080 --> 01:47:11,600
моделью и извлекающей моделью заключается в том, что

2706
01:47:11,600 --> 01:47:13,600
для общих моделей вы можете фактически

2707
01:47:13,600 --> 01:47:15,679
использовать больше com на входном проходе

2708
01:47:15,679 --> 01:47:19,040
вместе, и генерация

2709
01:47:19,199 --> 01:47:23,119
делает это так ясно или нет,

2710
01:47:23,119 --> 01:47:24,880
да,

2711
01:47:24,880 --> 01:47:26,800
да, спасибо,

2712
01:47:26,800 --> 01:47:28,400
да  в противном случае вы должны просто проверить

2713
01:47:28,400 --> 01:47:30,480
этот документ здесь, так что этот документ действительно

2714
01:47:30,480 --> 01:47:32,239
начался довольно хорошо, тогда почему эта модель

2715
01:47:32,239 --> 01:47:33,840
может работать лучше, чем предыдущие

2716
01:47:33,840 --> 01:47:37,320
модели генерации моделей

2717
01:47:38,560 --> 01:47:41,699
[Музыка]

2718
01:47:48,239 --> 01:47:49,940
для

2719
01:47:49,940 --> 01:47:56,020
[Музыка]

2720
01:48:02,239 --> 01:48:05,199
о,

2721
01:48:05,199 --> 01:48:06,960
кодировщики, это похоже на то,

2722
01:48:06,960 --> 01:48:08,880
что вы обнаруживаете сходство между

2723
01:48:08,880 --> 01:48:10,320
их

2724
01:48:10,320 --> 01:48:12,719
кодировками и  затем сгенерируйте модели, вам нравится

2725
01:48:12,719 --> 01:48:15,600
запоминать весь вопрос,

2726
01:48:15,600 --> 01:48:17,119
и

2727
01:48:17,119 --> 01:48:18,719
вы пытаетесь

2728
01:48:18,719 --> 01:48:22,400
получить это, в основном, как

2729
01:48:22,400 --> 01:48:25,520
когда вы отвечаете на вопрос

2730
01:48:25,840 --> 01:48:28,080
хорошо, поэтому для этой модели нет никакого

2731
01:48:28,080 --> 01:48:29,280
извлечения,

2732
01:48:29,280 --> 01:48:31,280
поэтому вы не можете найти ответ

2733
01:48:31,280 --> 01:48:32,880
на вопрос правильно,

2734
01:48:32,880 --> 01:48:35,040
поэтому эта модель действительно имеет  полагаться на

2735
01:48:35,040 --> 01:48:37,119
все параметры для запоминания всей

2736
01:48:37,119 --> 01:48:38,400
информации,

2737
01:48:38,400 --> 01:48:40,400
поэтому, просто принимая этот ввод, он должен

2738
01:48:40,400 --> 01:48:42,560
просто полагаться на ветви, чтобы вывести t  его

2739
01:48:42,560 --> 01:48:44,320
ответ,

2740
01:48:44,320 --> 01:48:46,560
так что на самом деле это тоже очень сложно, так что да,

2741
01:48:46,560 --> 01:48:49,520
он определенно сбалансирован между

2742
01:48:49,520 --> 01:48:52,159
памятью и обобщением,

2743
01:48:52,159 --> 01:48:54,400
я вижу, так что

2744
01:48:54,400 --> 01:48:56,560
я просто

2745
01:48:56,560 --> 01:48:58,960
скажу, что мне нравится, это похоже на то, когда вы

2746
01:48:58,960 --> 01:49:01,280
задаете этот вопрос, встраивает его в

2747
01:49:01,280 --> 01:49:03,600
какое-то пространство, а затем

2748
01:49:03,600 --> 01:49:06,239
использует  то, что встраивание генератора

2749
01:49:06,239 --> 01:49:09,080
соответствует тому, что похоже на

2750
01:49:09,080 --> 01:49:13,760
1882, заключается в том, что там происходит то, что

2751
01:49:13,760 --> 01:49:14,639
да,

2752
01:49:14,639 --> 01:49:16,719
модель выглядит очень большой, как

2753
01:49:17,440 --> 01:49:20,239
11 миллиардов параметров, поэтому все эти

2754
01:49:20,239 --> 01:49:22,480
параметры в основном пытаются

2755
01:49:22,480 --> 01:49:24,639
запомнить много информации,

2756
01:49:24,639 --> 01:49:26,480
которая была, потому что  Модель была

2757
01:49:26,480 --> 01:49:27,679
красивой

2758
01:49:27,679 --> 01:49:29,280
от текста, а также была

2759
01:49:29,280 --> 01:49:31,280
доработана, поэтому модель

2760
01:49:31,280 --> 01:49:32,960
пыталась запомнить всю информацию из

2761
01:49:32,960 --> 01:49:35,679
текста да,

2762
01:49:36,080 --> 01:49:38,320
хм, вы хотите называть это кумиром, хотите ли

2763
01:49:38,320 --> 01:49:41,960
вы еще один вопрос в

2764
01:49:42,320 --> 01:49:44,560
любом случае да,

2765
01:49:44,560 --> 01:49:46,800
это  до вас,

2766
01:49:46,800 --> 01:49:48,400
я уверен, я рад ответить еще на один

2767
01:49:48,400 --> 01:49:51,520
вопрос, хорошо, позвольте мне просто ответить, хорошо,

2768
01:49:51,520 --> 01:49:54,080
еще один вопрос,

2769
01:49:54,080 --> 01:49:56,880
хорошо, первый вопрос о том,

2770
01:49:56,880 --> 01:49:58,400
насколько легко эти методы

2771
01:49:58,400 --> 01:49:59,920
распространяются на

2772
01:49:59,920 --> 01:50:01,520
другие языки, которые

2773
01:50:01,520 --> 01:50:03,440
мне нравятся  o говорят, что языки, которые сильно

2774
01:50:03,440 --> 01:50:05,520
отличаются друг от друга, совершенно разные грамматические

2775
01:50:05,520 --> 01:50:07,760
правила, такие как китайский,

2776
01:50:07,760 --> 01:50:09,040
японский или

2777
01:50:09,040 --> 01:50:11,360
арабский, или некоторые другие языки

2778
01:50:11,360 --> 01:50:12,880
вроде другого

2779
01:50:12,880 --> 01:50:15,679
вопроса, может быть, не совсем ваша область

2780
01:50:15,679 --> 01:50:17,440
знаний,

2781
01:50:17,440 --> 01:50:19,360
есть большой интерес к моделированию

2782
01:50:19,360 --> 01:50:21,920
поведения пользователя, скажем, в отличие от

2783
01:50:21,920 --> 01:50:25,199
поведения при поиске, поведение при просмотре как последовательность

2784
01:50:25,199 --> 01:50:28,080
с использованием  скажем, трансформеры самовнимание

2785
01:50:28,080 --> 01:50:30,480
um, а затем вы можете использовать это, чтобы предсказать,

2786
01:50:30,480 --> 01:50:32,719
как пользователь может встроить пользователя в качестве

2787
01:50:32,719 --> 01:50:33,679
вектора

2788
01:50:33,679 --> 01:50:36,320
и может предсказать действия пользователя,

2789
01:50:36,320 --> 01:50:38,400
насколько многообещающим, по вашему мнению, будет

2790
01:50:38,400 --> 01:50:40,239
я знаю, что это может быть не ваша область

2791
01:50:40,239 --> 01:50:42,480
знаний, но есть  Большой интерес

2792
01:50:42,480 --> 01:50:44,239
в расширении этих эээ,

2793
01:50:44,239 --> 01:50:45,920
плюс техники ответов - это просто

2794
01:50:45,920 --> 01:50:48,000
методы кодирования, встраиваемые методы,

2795
01:50:48,000 --> 01:50:48,719
чтобы

2796
01:50:48,719 --> 01:50:50,639
рекомендовать наши системы.

2797
01:50:50,639 --> 01:50:52,400
Я

2798
01:50:52,400 --> 01:50:53,520
просто

2799
01:50:53,520 --> 01:50:56,320
хочу высказать свои мысли,

2800
01:50:56,960 --> 01:50:59,280
хорошо. Первый вопрос:

2801
01:50:59,280 --> 01:51:01,360
можно ли эти методы распространить на

2802
01:51:01,360 --> 01:51:04,239
другие языки? Я думаю, что честно,

2803
01:51:04,239 --> 01:51:06,560
да и  в этом направлении было проведено много активных

2804
01:51:06,560 --> 01:51:08,960
исследований, но

2805
01:51:08,960 --> 01:51:11,119
были также некоторые ограничения t  То, что

2806
01:51:11,119 --> 01:51:13,199
многие модели или системы, которые я описал

2807
01:51:13,199 --> 01:51:15,840
здесь, на самом деле требуют, чтобы многие из них

2808
01:51:15,840 --> 01:51:18,159
требовали очень сильных, таких как предварительно обученная

2809
01:51:18,159 --> 01:51:21,040
языковая модель, а также требовали

2810
01:51:21,040 --> 01:51:24,159
множества обучающих образцов для чистой idss,

2811
01:51:24,159 --> 01:51:26,960
так что на самом деле это было бы,

2812
01:51:26,960 --> 01:51:28,719
я бы сказал,  узкое место для многих

2813
01:51:28,719 --> 01:51:30,800
языков с низким уровнем ресурсов,

2814
01:51:31,760 --> 01:51:33,280
поэтому очень сложно собрать так много

2815
01:51:33,280 --> 01:51:35,119
примеров для других языков,

2816
01:51:35,119 --> 01:51:37,119
если у нас есть на самом деле, я думаю, что

2817
01:51:37,119 --> 01:51:39,840
методы, которые можно проверить, могут быть обобщены, в

2818
01:51:39,840 --> 01:51:42,400
общем, применимы к другим языкам,

2819
01:51:42,400 --> 01:51:44,000
и также было много работы,

2820
01:51:44,000 --> 01:51:45,360
пытающейся  любите вопросы на разных языках

2821
01:51:45,360 --> 01:51:49,400
через подобные вещи

