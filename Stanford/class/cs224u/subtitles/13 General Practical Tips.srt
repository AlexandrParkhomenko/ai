1
00:00:00,000 --> 00:00:04,662


2
00:00:04,662 --> 00:00:06,120
CHRISTOPHER POTTS:
Hello, everyone,

3
00:00:06,120 --> 00:00:08,580
welcome to part 2 in our
series on supervised sentiment

4
00:00:08,580 --> 00:00:09,180
analysis.

5
00:00:09,180 --> 00:00:12,330
The screencast is going to focus
on some general practical tips

6
00:00:12,330 --> 00:00:14,640
for doing work in this
space, especially focused

7
00:00:14,640 --> 00:00:16,850
on setting up a
project and doing kind

8
00:00:16,850 --> 00:00:19,830
of pre-processing of your data.

9
00:00:19,830 --> 00:00:21,770
So first I just wanted
to give you links

10
00:00:21,770 --> 00:00:24,650
to a whole bunch of benchmark
data sets in the space.

11
00:00:24,650 --> 00:00:27,650
We're going to concentrate
on the SST and DynaSent,

12
00:00:27,650 --> 00:00:29,150
but there are a lot
of other choices

13
00:00:29,150 --> 00:00:32,180
you could make both for
developing original systems

14
00:00:32,180 --> 00:00:34,100
and also supplementing
training data

15
00:00:34,100 --> 00:00:36,090
that you've got for a
particular application.

16
00:00:36,090 --> 00:00:38,210
Some of these data sets
are really, really large,

17
00:00:38,210 --> 00:00:40,080
and they cover a
diversity of domains.

18
00:00:40,080 --> 00:00:42,980
So these could be
important assets for you.

19
00:00:42,980 --> 00:00:45,560
In a similar spirit, there
are lots of sentiment lexicons

20
00:00:45,560 --> 00:00:46,310
out there.

21
00:00:46,310 --> 00:00:48,320
They cover different
emotional dimensions

22
00:00:48,320 --> 00:00:50,097
and different aspects
of the problem.

23
00:00:50,097 --> 00:00:51,680
And they too could
be used to help you

24
00:00:51,680 --> 00:00:53,287
with powerful featurization.

25
00:00:53,287 --> 00:00:55,370
They could supplement
features that you've created

26
00:00:55,370 --> 00:00:57,200
or help you group
your vocabulary

27
00:00:57,200 --> 00:00:59,540
into interesting
subcategories that

28
00:00:59,540 --> 00:01:02,070
would be powerful for making
sentiment predictions.

29
00:01:02,070 --> 00:01:04,250
And these range from
simple word lists up

30
00:01:04,250 --> 00:01:08,700
to highly structured
multi-dimensional lexicons.

31
00:01:08,700 --> 00:01:10,310
Now for a first
pre-processing step,

32
00:01:10,310 --> 00:01:12,810
I thought we would just talk a
little bit about tokenization

33
00:01:12,810 --> 00:01:15,780
because I think that this can
be a definitional choice that

34
00:01:15,780 --> 00:01:18,100
really affects
downstream success.

35
00:01:18,100 --> 00:01:19,650
So just as a running
example here,

36
00:01:19,650 --> 00:01:21,780
let's imagine we start
with this raw text, which

37
00:01:21,780 --> 00:01:23,850
is a kind of imagined tweet.

38
00:01:23,850 --> 00:01:25,467
We have an @ mention here.

39
00:01:25,467 --> 00:01:27,300
And then you can see
that some of the markup

40
00:01:27,300 --> 00:01:28,650
has gotten a little bit garbled.

41
00:01:28,650 --> 00:01:31,590
We have an emoticon that
looks sort of obscured

42
00:01:31,590 --> 00:01:33,540
and a link at the end.

43
00:01:33,540 --> 00:01:35,640
I think as a very
preliminary step,

44
00:01:35,640 --> 00:01:37,200
even before we
tokenize it, we might

45
00:01:37,200 --> 00:01:38,700
want to isolate
some of that markup

46
00:01:38,700 --> 00:01:40,775
and replace the HTML entities.

47
00:01:40,775 --> 00:01:42,150
It's a pretty easy
thing that you

48
00:01:42,150 --> 00:01:43,942
can do that could really
make a difference.

49
00:01:43,942 --> 00:01:45,660
Now we've got an apostrophe.

50
00:01:45,660 --> 00:01:47,460
We've got our emoticon intact.

51
00:01:47,460 --> 00:01:50,508
And we still have the link
and other things in here.

52
00:01:50,508 --> 00:01:52,050
So even before you
do that, you might

53
00:01:52,050 --> 00:01:55,350
check to see whether a simple
replacement of the HTML

54
00:01:55,350 --> 00:01:58,290
entities would make a
difference in your data.

55
00:01:58,290 --> 00:02:00,115
Now we begin the
tokenization question.

56
00:02:00,115 --> 00:02:01,740
And I think a good
baseline choice here

57
00:02:01,740 --> 00:02:03,350
would be simply
whitespace tokenizing.

58
00:02:03,350 --> 00:02:05,100
I think we're going
to split on whitespace

59
00:02:05,100 --> 00:02:07,800
and treat all the resulting
strings as tokens.

60
00:02:07,800 --> 00:02:10,580
So that would take our raw
text up here and split it up.

61
00:02:10,580 --> 00:02:13,080
As you can see on these
independent lines,

62
00:02:13,080 --> 00:02:14,483
this looks OK to me.

63
00:02:14,483 --> 00:02:16,650
So we're going to have a
problem with our @ mention,

64
00:02:16,650 --> 00:02:18,270
because it has this
colon on the end.

65
00:02:18,270 --> 00:02:22,500
So we might miss the fact that
this is the actual @ mention.

66
00:02:22,500 --> 00:02:25,900
The unigrams look OK, although
the date has been split apart.

67
00:02:25,900 --> 00:02:27,660
We've preserved our hashtag.

68
00:02:27,660 --> 00:02:30,450
We've got this token that
might appear only once even

69
00:02:30,450 --> 00:02:32,940
though there's a clear
consistent signal there.

70
00:02:32,940 --> 00:02:34,380
We do have our emoticon.

71
00:02:34,380 --> 00:02:37,620
And our link is mostly
intact although this period

72
00:02:37,620 --> 00:02:39,060
could be disruptive
if we actually

73
00:02:39,060 --> 00:02:41,018
want to follow the link,
because it could still

74
00:02:41,018 --> 00:02:44,340
go on onto the end of the URL.

75
00:02:44,340 --> 00:02:47,100
Treebank tokenizing is another
very common scheme in NLP

76
00:02:47,100 --> 00:02:50,700
I would say at this point
largely for historical reasons.

77
00:02:50,700 --> 00:02:53,490
The way treebank tokenizing
works is it takes this raw text

78
00:02:53,490 --> 00:02:55,865
and splits it up into a
whole lot of tokens, right?

79
00:02:55,865 --> 00:02:57,240
In comparison with
whitespace, we

80
00:02:57,240 --> 00:02:59,220
have a lot of
distinct pieces here.

81
00:02:59,220 --> 00:03:01,660
And this really looks kind
of problematic, right?

82
00:03:01,660 --> 00:03:03,840
So we have destroyed
our @ mention,

83
00:03:03,840 --> 00:03:06,270
we don't have that
username anymore.

84
00:03:06,270 --> 00:03:08,910
It does this interesting
thing with words like "can"

85
00:03:08,910 --> 00:03:11,970
that they get split
apart into two tokens.

86
00:03:11,970 --> 00:03:13,140
We've lost our date.

87
00:03:13,140 --> 00:03:15,420
We have lost our hashtag.

88
00:03:15,420 --> 00:03:16,440
This is possibly good.

89
00:03:16,440 --> 00:03:19,530
So YAAAAAAY has been split up
according to its punctuation.

90
00:03:19,530 --> 00:03:22,110
So we have now four
exclamation marks

91
00:03:22,110 --> 00:03:24,480
separated out from
this word here.

92
00:03:24,480 --> 00:03:26,405
But our emoticon
is completely lost

93
00:03:26,405 --> 00:03:28,030
and our link has been
really destroyed.

94
00:03:28,030 --> 00:03:30,090
So this looks problematic
from the point of view

95
00:03:30,090 --> 00:03:33,570
of accurate featurization
and also doing things

96
00:03:33,570 --> 00:03:35,705
with social media.

97
00:03:35,705 --> 00:03:37,080
So that kind of
brings me to what

98
00:03:37,080 --> 00:03:38,538
we might want from
what I've called

99
00:03:38,538 --> 00:03:40,260
the sentiment-aware tokenizer.

100
00:03:40,260 --> 00:03:43,020
We would like to isolate
emoticons clearly because they

101
00:03:43,020 --> 00:03:45,300
can be really sentimentally--

102
00:03:45,300 --> 00:03:47,760
We want to probably respect
Twitter and other domain

103
00:03:47,760 --> 00:03:50,820
specific markup because that's
often the space in which--

104
00:03:50,820 --> 00:03:52,560
our data come from,
the kind of place

105
00:03:52,560 --> 00:03:54,522
we want to make predictions in.

106
00:03:54,522 --> 00:03:55,980
In a similar spirit,
you might take

107
00:03:55,980 --> 00:03:57,510
advantage of underlying markup.

108
00:03:57,510 --> 00:03:59,760
Maybe don't filter off the
HTML, because there could

109
00:03:59,760 --> 00:04:01,680
be an important signal there.

110
00:04:01,680 --> 00:04:05,240
You might be aware that the
website or data producer might

111
00:04:05,240 --> 00:04:06,990
have done some
pre-processing of their own

112
00:04:06,990 --> 00:04:09,350
that might disrupt
things like curses which

113
00:04:09,350 --> 00:04:12,000
could of course carry a
lot of important sentiment

114
00:04:12,000 --> 00:04:13,320
information.

115
00:04:13,320 --> 00:04:15,120
You might want to
preserve capitalization

116
00:04:15,120 --> 00:04:17,591
because of course that
could be used for emphasis.

117
00:04:17,591 --> 00:04:19,049
In a similar spirit,
you might want

118
00:04:19,050 --> 00:04:22,770
to regularize emotive
lengthening like YAAAAAY down

119
00:04:22,770 --> 00:04:24,840
to just three characters
here to capture

120
00:04:24,840 --> 00:04:26,520
that it is an
emotive lengthening

121
00:04:26,520 --> 00:04:29,730
but also regularize all
those distinct tokens.

122
00:04:29,730 --> 00:04:31,120
And then there's a stretch goal.

123
00:04:31,120 --> 00:04:33,120
Although this might be
less important in the era

124
00:04:33,120 --> 00:04:35,160
of contextual models,
you might think

125
00:04:35,160 --> 00:04:37,410
about capturing multiword
expressions that

126
00:04:37,410 --> 00:04:38,370
carry sentiment.

127
00:04:38,370 --> 00:04:40,950
Just think of an example
like "out of this world,"

128
00:04:40,950 --> 00:04:42,340
which is positive.

129
00:04:42,340 --> 00:04:44,400
But none of its component
pieces are positive.

130
00:04:44,400 --> 00:04:45,990
So many models
will miss that that

131
00:04:45,990 --> 00:04:48,030
is conveying clear
sentiment, whereas

132
00:04:48,030 --> 00:04:50,190
with a clever
tokenization scheme,

133
00:04:50,190 --> 00:04:54,300
you might capture that
as one single token.

134
00:04:54,300 --> 00:04:57,330
So here's a simple example
that meets a lot of those goals

135
00:04:57,330 --> 00:04:59,370
here for a
sentiment-aware tokenizer.

136
00:04:59,370 --> 00:05:01,110
We begin from our
usual raw text.

137
00:05:01,110 --> 00:05:04,050
We normalize and
preserve the @ mention.

138
00:05:04,050 --> 00:05:06,750
We keep most of these words
intact and we kind of capture

139
00:05:06,750 --> 00:05:09,180
that June 9 thing was a date.

140
00:05:09,180 --> 00:05:11,400
Preserve the hashtag, of course.

141
00:05:11,400 --> 00:05:14,670
We're treating all these
potentially emotion-laden

142
00:05:14,670 --> 00:05:16,740
punctuation marks as
separate unigrams.

143
00:05:16,740 --> 00:05:18,360
I think that could be good.

144
00:05:18,360 --> 00:05:21,630
Of course capture the emoticon
and capture the link, right?

145
00:05:21,630 --> 00:05:23,850
And if you want something
that meets more or less all

146
00:05:23,850 --> 00:05:26,850
these criteria, except I
think the date normalization,

147
00:05:26,850 --> 00:05:29,970
you could just use the
nltk TweetTokenizer.

148
00:05:29,970 --> 00:05:31,710
It's a good simple
choice that you

149
00:05:31,710 --> 00:05:35,700
could make that I think will be
useful for sentiment analysis.

150
00:05:35,700 --> 00:05:37,885
And to quantify that
a little bit, here's

151
00:05:37,885 --> 00:05:39,510
some experimental
evidence that I think

152
00:05:39,510 --> 00:05:41,302
is going to be relevant
to the kind of work

153
00:05:41,302 --> 00:05:42,730
that you all are doing.

154
00:05:42,730 --> 00:05:44,370
So my data is OpenTable.

155
00:05:44,370 --> 00:05:46,590
That's restaurant
review, short ones.

156
00:05:46,590 --> 00:05:49,500
I've got 6,000 reviews
in my test set.

157
00:05:49,500 --> 00:05:51,420
And what I'm doing
along the x-axis

158
00:05:51,420 --> 00:05:53,460
here is varying the
amount of training data

159
00:05:53,460 --> 00:05:55,290
that these systems can see.

160
00:05:55,290 --> 00:05:58,950
It's simply a Softmax classifier
and my primary manipulation

161
00:05:58,950 --> 00:06:01,950
is I have the sentiment-aware
tokenizer in orange,

162
00:06:01,950 --> 00:06:05,430
treebank in green, and
whitespace in gray.

163
00:06:05,430 --> 00:06:07,230
And the picture is pretty clear.

164
00:06:07,230 --> 00:06:09,750
Right along the x-axis,
we have accuracy.

165
00:06:09,750 --> 00:06:11,650
It's a balanced problem.

166
00:06:11,650 --> 00:06:14,550
And what you can see is that
the sentiment-aware tokenizer

167
00:06:14,550 --> 00:06:17,170
is the clear winner
here, especially where

168
00:06:17,170 --> 00:06:19,200
training data are sparse.

169
00:06:19,200 --> 00:06:21,280
In the limit of adding
lots of training data,

170
00:06:21,280 --> 00:06:24,257
I think we can make up for a lot
of shortcomings of tokenizers

171
00:06:24,257 --> 00:06:26,340
because we see a lot of
redundancy in the training

172
00:06:26,340 --> 00:06:27,420
data.

173
00:06:27,420 --> 00:06:30,090
But where data are sparse,
the sentiment-aware tokenizer

174
00:06:30,090 --> 00:06:31,230
is clearly a good choice.

175
00:06:31,230 --> 00:06:34,230
And another thing I would add
is that because it produces

176
00:06:34,230 --> 00:06:36,690
more intuitive tokens,
the sentiment-aware models

177
00:06:36,690 --> 00:06:40,800
might be more interpretable
in some sense.

178
00:06:40,800 --> 00:06:42,510
And to really connect
with the homework

179
00:06:42,510 --> 00:06:44,400
that you all are
doing in the bakeoff,

180
00:06:44,400 --> 00:06:46,630
this is what happens when
we go across domains.

181
00:06:46,630 --> 00:06:49,530
So here I'm training on
OpenTable restaurant reviews,

182
00:06:49,530 --> 00:06:52,230
but I'm going to test on
movie review sentences here.

183
00:06:52,230 --> 00:06:54,960
Otherwise, this is the
same experimental paradigm.

184
00:06:54,960 --> 00:06:56,490
Because of the
cross domain thing,

185
00:06:56,490 --> 00:06:59,340
the results are a
little bit more chaotic.

186
00:06:59,340 --> 00:07:01,740
But I think, again, the
sentiment-aware tokenizer

187
00:07:01,740 --> 00:07:04,860
is a clear winner with the
largest gains where training

188
00:07:04,860 --> 00:07:06,480
data are a little bit sparse.

189
00:07:06,480 --> 00:07:09,490
And that's the expected picture.

190
00:07:09,490 --> 00:07:11,067
So be thoughtful
about tokenizing.

191
00:07:11,067 --> 00:07:13,150
As a counterpoint to that,
I've called the section

192
00:07:13,150 --> 00:07:14,770
on stemming the
dangers of stemming

193
00:07:14,770 --> 00:07:16,960
because what I want to try
to do is convince you not

194
00:07:16,960 --> 00:07:19,670
to stem your data, the
first word is stemming.

195
00:07:19,670 --> 00:07:22,120
So stemming is a kind of
pre-processing technique

196
00:07:22,120 --> 00:07:25,180
that would collapse
distinct word forms.

197
00:07:25,180 --> 00:07:27,520
There are three common
algorithms for this.

198
00:07:27,520 --> 00:07:29,740
Easy to use, the Porter stemmer.

199
00:07:29,740 --> 00:07:32,170
The Lancaster stemmer,
and the WordNet stemmer.

200
00:07:32,170 --> 00:07:34,390
And my criticisms
are largely leveled

201
00:07:34,390 --> 00:07:36,340
at Porter and Lancaster.

202
00:07:36,340 --> 00:07:38,050
Here is the bottom line.

203
00:07:38,050 --> 00:07:39,880
In doing this kind
of stemming, you

204
00:07:39,880 --> 00:07:42,220
are apt to destroy many
important sentiment

205
00:07:42,220 --> 00:07:44,950
distinctions, making
this a counterproductive

206
00:07:44,950 --> 00:07:46,840
pre-processing step.

207
00:07:46,840 --> 00:07:48,490
On the other hand,
the WordNet stemmer

208
00:07:48,490 --> 00:07:50,510
does not have this problem.

209
00:07:50,510 --> 00:07:53,470
It's much more conservative,
but it also doesn't really

210
00:07:53,470 --> 00:07:55,630
do enough to make it worthwhile.

211
00:07:55,630 --> 00:07:59,140
It's costly to run and has some
requirements that might make it

212
00:07:59,140 --> 00:08:00,430
simply not worth it.

213
00:08:00,430 --> 00:08:02,680
And I would say that the
bottom line here for stemming

214
00:08:02,680 --> 00:08:06,460
is that in an era where we have
very large sentiment data sets,

215
00:08:06,460 --> 00:08:07,840
the function of
stemming would be

216
00:08:07,840 --> 00:08:10,450
to collapse the size
of your vocabulary

217
00:08:10,450 --> 00:08:13,450
and make learning more
easier in small domains,

218
00:08:13,450 --> 00:08:16,730
but we mostly don't confront
that problem anymore.

219
00:08:16,730 --> 00:08:18,910
But just to drive
home this point here,

220
00:08:18,910 --> 00:08:21,970
here are some examples
focused on the Porter stemmer,

221
00:08:21,970 --> 00:08:24,070
of cases where running
the Porter stemmer

222
00:08:24,070 --> 00:08:26,620
actually collapses clear
sentiment distinctions

223
00:08:26,620 --> 00:08:28,540
according to the
Harvard Inquirer, which

224
00:08:28,540 --> 00:08:31,270
is one of those lexicons
I mentioned before.

225
00:08:31,270 --> 00:08:33,020
I got defense and defensive.

226
00:08:33,020 --> 00:08:36,340
They get collapsed down into
this funny, non-word defens.

227
00:08:36,340 --> 00:08:39,250
Extravagance and extravagant,
different sentiment

228
00:08:39,250 --> 00:08:42,700
collapsed down into this
word fragment, and so forth

229
00:08:42,700 --> 00:08:43,830
for these other examples.

230
00:08:43,830 --> 00:08:46,450
I think this is showing that
in pre-processing your data,

231
00:08:46,450 --> 00:08:50,170
you might be removing some
important sentiment signals.

232
00:08:50,170 --> 00:08:52,810
The Lancaster stemmer uses
a very similar strategy

233
00:08:52,810 --> 00:08:55,810
and has arguably even more
problems in this space.

234
00:08:55,810 --> 00:08:59,890
Here we've got the positive
word complement and complicate.

235
00:08:59,890 --> 00:09:01,563
According to the
Harvard Inquirer again,

236
00:09:01,563 --> 00:09:02,980
they could both
get collapsed down

237
00:09:02,980 --> 00:09:06,250
into what is a completely
distinct word, comply.

238
00:09:06,250 --> 00:09:08,450
That should be concerning
for many reasons.

239
00:09:08,450 --> 00:09:12,568
And the other examples
make a very similar point.

240
00:09:12,568 --> 00:09:15,110
The WordNet stemmer I mentioned
before, I think this actually

241
00:09:15,110 --> 00:09:16,620
has something going for it.

242
00:09:16,620 --> 00:09:18,620
There might be cases where
you'd want to use it.

243
00:09:18,620 --> 00:09:19,880
It's high precision.

244
00:09:19,880 --> 00:09:23,210
It requires word,
part of speech pairs.

245
00:09:23,210 --> 00:09:25,340
And the general issue
is just that it removes

246
00:09:25,340 --> 00:09:26,673
some comparative morphology.

247
00:09:26,673 --> 00:09:29,090
That's the only thing you might
worry about for sentiment.

248
00:09:29,090 --> 00:09:31,850
But otherwise it's going to
take like exclaims, explained,

249
00:09:31,850 --> 00:09:33,680
and exclaiming, and
collapse them down.

250
00:09:33,680 --> 00:09:35,480
That could be a
useful compression

251
00:09:35,480 --> 00:09:36,830
of your feature space.

252
00:09:36,830 --> 00:09:40,110
It will leave exclamation
alone, which I think is good.

253
00:09:40,110 --> 00:09:41,810
Similarly for these
things, they all

254
00:09:41,810 --> 00:09:44,120
get preserved across
the two verb forms

255
00:09:44,120 --> 00:09:45,930
but we preserve the
adjective is different.

256
00:09:45,930 --> 00:09:47,490
I think that could be good.

257
00:09:47,490 --> 00:09:50,180
And as I said, the only concern
would be that happy, happier,

258
00:09:50,180 --> 00:09:52,910
and happiest all go down
into their base form

259
00:09:52,910 --> 00:09:54,830
whereas I think
these could encode

260
00:09:54,830 --> 00:09:56,510
different gradations
of sentiment

261
00:09:56,510 --> 00:09:58,710
that you might want to preserve.

262
00:09:58,710 --> 00:10:00,560
That's worth some
thought, but overall I

263
00:10:00,560 --> 00:10:02,840
think you probably want
to avoid doing stemming.

264
00:10:02,840 --> 00:10:04,340
And to bring that
home, let's return

265
00:10:04,340 --> 00:10:06,590
to my experimental
paradigm using

266
00:10:06,590 --> 00:10:10,550
a Softmax classifier, OpenTable
reviews, 6,000 of them

267
00:10:10,550 --> 00:10:13,040
in my test set, and
here along the x-axis,

268
00:10:13,040 --> 00:10:15,740
I'm varying the amount
of training data I have.

269
00:10:15,740 --> 00:10:19,040
And I think what you see is
that the Porter and Lancaster

270
00:10:19,040 --> 00:10:21,350
stemmer in purple and
black respectively

271
00:10:21,350 --> 00:10:24,680
are kind of forever behind,
right, versus just simply

272
00:10:24,680 --> 00:10:26,210
sentiment-aware tokenizing.

273
00:10:26,210 --> 00:10:27,530
It gives you a lead.

274
00:10:27,530 --> 00:10:29,300
The lead is especially
clear as you

275
00:10:29,300 --> 00:10:32,060
get out of this very
sparse domain here

276
00:10:32,060 --> 00:10:34,850
with very few
training instances.

277
00:10:34,850 --> 00:10:37,317
To close, just a few
other pre-processing

278
00:10:37,317 --> 00:10:38,900
techniques that you
might think about.

279
00:10:38,900 --> 00:10:41,150
So you could part-of-speech
tag your data

280
00:10:41,150 --> 00:10:43,730
in the spirit of trying
to capture more sentiment

281
00:10:43,730 --> 00:10:45,810
distinctions that you
might capture otherwise.

282
00:10:45,810 --> 00:10:48,020
So just for example,
arrest, like

283
00:10:48,020 --> 00:10:50,990
arresting as an adjective is
positive, but arrest as a verb

284
00:10:50,990 --> 00:10:52,910
is typically negative.

285
00:10:52,910 --> 00:10:55,340
Fine as an adjective
is positive,

286
00:10:55,340 --> 00:10:58,800
but to incur a fine as a noun
is negative, and so forth.

287
00:10:58,800 --> 00:11:01,040
You can see that some
sentiment distinctions actually

288
00:11:01,040 --> 00:11:03,920
do turn on the part
of speech of the word.

289
00:11:03,920 --> 00:11:08,390
So treating all of your unigram
features as based in word

290
00:11:08,390 --> 00:11:11,720
part-of-speech tag pairs
could be useful for preserving

291
00:11:11,720 --> 00:11:13,010
some of these distinctions.

292
00:11:13,010 --> 00:11:15,680
Again as a pre-processing
step to help your model

293
00:11:15,680 --> 00:11:19,830
be more attuned to these points
of variation in comparison.

294
00:11:19,830 --> 00:11:21,740
But there are limits
even to this, right?

295
00:11:21,740 --> 00:11:23,600
So there is just some
cases on the slides

296
00:11:23,600 --> 00:11:25,850
where even within the
same part of speech,

297
00:11:25,850 --> 00:11:28,880
we have an adjective that
in one sense is positive

298
00:11:28,880 --> 00:11:30,240
and another negative.

299
00:11:30,240 --> 00:11:33,650
For example, the adjective
mean can mean hateful,

300
00:11:33,650 --> 00:11:36,890
but it can also mean excellent
as in they make a mean apple

301
00:11:36,890 --> 00:11:38,750
pie.

302
00:11:38,750 --> 00:11:44,510
Smart as an adjective could be
both painful and also bright

303
00:11:44,510 --> 00:11:46,230
and brilliant, and
so forth like that.

304
00:11:46,230 --> 00:11:49,050
And similarly for serious
and fantastic and sneer,

305
00:11:49,050 --> 00:11:51,740
depending on the context and
the intention of the speaker,

306
00:11:51,740 --> 00:11:54,895
they can kind of cut in
different directions.

307
00:11:54,895 --> 00:11:56,270
So even part-of-speech
tagging is

308
00:11:56,270 --> 00:11:59,150
going to be limiting when it
comes to really recovering

309
00:11:59,150 --> 00:12:01,910
the underlying word
sense, even for something

310
00:12:01,910 --> 00:12:05,940
as low dimensional as a
sentiment distinction.

311
00:12:05,940 --> 00:12:08,550
Finally, this is another
powerful technique

312
00:12:08,550 --> 00:12:09,990
that you might use
and think about

313
00:12:09,990 --> 00:12:13,270
as you select and
evaluate different models.

314
00:12:13,270 --> 00:12:15,210
This is what I've called
simple negation mark.

315
00:12:15,210 --> 00:12:17,310
And the phenomenon
is just that if I

316
00:12:17,310 --> 00:12:21,570
have a verb like enjoy, which
sounds positive in isolation,

317
00:12:21,570 --> 00:12:23,850
of course its contribution
to the overall sentiment

318
00:12:23,850 --> 00:12:25,770
will change depending
on whether it's

319
00:12:25,770 --> 00:12:27,480
in the scope of a negation.

320
00:12:27,480 --> 00:12:29,610
"I didn't enjoy" is negative.

321
00:12:29,610 --> 00:12:32,700
A negation can be
expressed in many ways

322
00:12:32,700 --> 00:12:35,670
as this modifier of
auxiliaries, like not.

323
00:12:35,670 --> 00:12:38,730
But as an adverb like never,
it could be in the subject

324
00:12:38,730 --> 00:12:39,450
like "No one."

325
00:12:39,450 --> 00:12:41,610
And it could even be
really encoded for things

326
00:12:41,610 --> 00:12:45,390
like "I have yet to enjoy it,"
which is a kind of negation.

327
00:12:45,390 --> 00:12:48,330
And then of course the
negation in 5 here is very far.

328
00:12:48,330 --> 00:12:51,270
"I don't think I will enjoy
it," is probably negative,

329
00:12:51,270 --> 00:12:57,260
but the negation is way far away
from the verb that we want to--

330
00:12:57,260 --> 00:13:01,110
with sentiment we want to
modulate with a negation.

331
00:13:01,110 --> 00:13:04,020
So here's a very simple
method that I think was first

332
00:13:04,020 --> 00:13:05,280
explored by Das and Chen.

333
00:13:05,280 --> 00:13:06,760
It's also used in Pang et al.

334
00:13:06,760 --> 00:13:09,390
These are classic early
sentiment analysis papers.

335
00:13:09,390 --> 00:13:13,410
And the idea is simply to append
a _NEG suffix to every word

336
00:13:13,410 --> 00:13:16,530
in the sequence that appears
between the negation and some

337
00:13:16,530 --> 00:13:18,390
clause level mark
of punctuation,

338
00:13:18,390 --> 00:13:22,530
to sort of roughly indicate the
semantic scope of the negation.

339
00:13:22,530 --> 00:13:25,650
This is a simple pre-processing
step, highly heuristic.

340
00:13:25,650 --> 00:13:28,050
It would take a sentence
like "No one enjoys it,"

341
00:13:28,050 --> 00:13:31,530
and literally turn the
unigrams one, enjoys,

342
00:13:31,530 --> 00:13:34,125
and it into variant
forms of them

343
00:13:34,125 --> 00:13:36,390
where one has a NEG
appended to it, and so does

344
00:13:36,390 --> 00:13:37,752
enjoys, and so does it.

345
00:13:37,752 --> 00:13:39,210
And the idea is
that in doing this,

346
00:13:39,210 --> 00:13:41,070
we're giving our
model the opportunity

347
00:13:41,070 --> 00:13:44,610
to discover that enjoys in
this context is actually

348
00:13:44,610 --> 00:13:48,000
a different token in some
sense than enjoys when it's not

349
00:13:48,000 --> 00:13:49,470
in the scope of negation.

350
00:13:49,470 --> 00:13:51,750
And for many of the
linear models with handout

351
00:13:51,750 --> 00:13:55,200
features that we explore, simply
making that initial distinction

352
00:13:55,200 --> 00:13:57,420
might create some
space for your model

353
00:13:57,420 --> 00:13:59,790
to learn the
interaction of negation

354
00:13:59,790 --> 00:14:01,980
with these other features.

355
00:14:01,980 --> 00:14:04,770
And just to quantify it a little
bit by way of rounding this

356
00:14:04,770 --> 00:14:07,110
out, I think this slide shows
the impact that this can

357
00:14:07,110 --> 00:14:09,000
have despite its simplicity.

358
00:14:09,000 --> 00:14:12,720
So similar, we have
OpenTable as our test set.

359
00:14:12,720 --> 00:14:14,400
We're using a
Softmax classifier.

360
00:14:14,400 --> 00:14:17,190
And the x-axis is again varying
the amount of training data

361
00:14:17,190 --> 00:14:19,230
that we have.

362
00:14:19,230 --> 00:14:21,120
The whitespace
tokenizer is in gray.

363
00:14:21,120 --> 00:14:23,880
It's the worst, followed
by Treebank in green.

364
00:14:23,880 --> 00:14:25,920
Then we have that
sentiment-aware tokenizer

365
00:14:25,920 --> 00:14:27,240
in orange.

366
00:14:27,240 --> 00:14:29,520
And then way above
them, consistently

367
00:14:29,520 --> 00:14:32,100
for all parts of the data
here are sentiment-aware

368
00:14:32,100 --> 00:14:34,230
plus that negation marking.

369
00:14:34,230 --> 00:14:36,480
That is obviously
the superior model

370
00:14:36,480 --> 00:14:38,753
for all kinds of amounts
of training data.

371
00:14:38,753 --> 00:14:40,170
And I think what
that's showing is

372
00:14:40,170 --> 00:14:42,810
that the influence of
negation is actually

373
00:14:42,810 --> 00:14:45,730
really real and severe in a
lot of sentiment datasets.

374
00:14:45,730 --> 00:14:48,960
It's just very common to
combine sentiment words,

375
00:14:48,960 --> 00:14:51,270
positive or negative,
with negation

376
00:14:51,270 --> 00:14:52,890
and it has this
predictable effect

377
00:14:52,890 --> 00:14:55,000
of kind of flipping the value.

378
00:14:55,000 --> 00:14:57,810
So in doing this sentiment, and
doing this negation marking,

379
00:14:57,810 --> 00:15:00,300
we're giving our
model a better chance

380
00:15:00,300 --> 00:15:03,030
at discovering exactly
those distinctions.

381
00:15:03,030 --> 00:15:05,700
And here's a similar set
of results for cross-domain

382
00:15:05,700 --> 00:15:09,070
where I'm starting on
OpenTable and testing on IMDB.

383
00:15:09,070 --> 00:15:11,070
Again the results are a
little bit more chaotic,

384
00:15:11,070 --> 00:15:14,490
but I think it's a clear win
for the sentiment-aware plus

385
00:15:14,490 --> 00:15:16,850
negation marking model.

386
00:15:16,850 --> 00:15:21,000


