1
00:00:00,000 --> 00:00:04,038


2
00:00:04,038 --> 00:00:05,580
CHRISTOPHER POTTS:
Welcome, everyone,

3
00:00:05,580 --> 00:00:08,530
to part 2 in our series on
natural language inference.

4
00:00:08,530 --> 00:00:10,500
We're going to focus
on the three data sets

5
00:00:10,500 --> 00:00:13,890
that we'll be concentrating
on this unit, which are SNLI--

6
00:00:13,890 --> 00:00:16,140
the Stanford Natural
Language Inference Corpus--

7
00:00:16,140 --> 00:00:18,300
MultiNLI, and Adversarial NLI.

8
00:00:18,300 --> 00:00:20,160
I think they're
interestingly different,

9
00:00:20,160 --> 00:00:21,900
and they're all
big benchmark tasks

10
00:00:21,900 --> 00:00:23,683
that can support
the training of lots

11
00:00:23,683 --> 00:00:24,850
of diverse kinds of systems.

12
00:00:24,850 --> 00:00:28,130


13
00:00:28,130 --> 00:00:30,580
So let's begin with SNLI,
which is the first to appear

14
00:00:30,580 --> 00:00:31,540
of these three.

15
00:00:31,540 --> 00:00:34,100
The associated paper is
Bowman, et al., 2015.

16
00:00:34,100 --> 00:00:35,860
Sam Bowman was a student
in the NLP group,

17
00:00:35,860 --> 00:00:38,650
and I was his advisor,
along with Chris Manning,

18
00:00:38,650 --> 00:00:41,488
and a bunch of us
contributed to that paper.

19
00:00:41,488 --> 00:00:43,030
An important thing
to know about SNLI

20
00:00:43,030 --> 00:00:46,360
is that the premises are all
image captions from the image

21
00:00:46,360 --> 00:00:48,060
Flickr30K data set.

22
00:00:48,060 --> 00:00:49,840
So that's an important
genre restriction

23
00:00:49,840 --> 00:00:52,215
that you should be aware of
when you think about training

24
00:00:52,215 --> 00:00:54,640
systems on this data.

25
00:00:54,640 --> 00:00:57,100
All the hypotheses were
written by crowdworkers.

26
00:00:57,100 --> 00:00:58,820
I'll show you the
prompt in a little bit.

27
00:00:58,820 --> 00:01:01,042
But the idea is they were
given this premise, which

28
00:01:01,042 --> 00:01:02,500
was an image caption,
and then they

29
00:01:02,500 --> 00:01:04,930
wrote three different
texts corresponding

30
00:01:04,930 --> 00:01:08,050
to the three NLI labels.

31
00:01:08,050 --> 00:01:10,783
Unfortunately, as is common
with crowdsourced data sets,

32
00:01:10,783 --> 00:01:12,700
you should be aware that
some of the sentences

33
00:01:12,700 --> 00:01:14,020
do reflect stereotypes.

34
00:01:14,020 --> 00:01:16,450
I think this traces to the
fact that crowdworkers,

35
00:01:16,450 --> 00:01:19,845
trying to do a lot of work, are
faced with a creative block.

36
00:01:19,845 --> 00:01:21,220
And the way they
overcome that is

37
00:01:21,220 --> 00:01:23,710
by falling back on easy
tricks, and some of those

38
00:01:23,710 --> 00:01:25,012
involve stereotypes.

39
00:01:25,012 --> 00:01:26,470
Completely
understandable, and this

40
00:01:26,470 --> 00:01:28,060
is something that
the field is trying

41
00:01:28,060 --> 00:01:32,020
to come to grips with as we
think about data set creation.

42
00:01:32,020 --> 00:01:33,130
It's a big data set.

43
00:01:33,130 --> 00:01:35,620
It has over 550,000
training examples.

44
00:01:35,620 --> 00:01:37,510
And it has dev and test sets.

45
00:01:37,510 --> 00:01:40,690
Each have 10,000
examples balanced

46
00:01:40,690 --> 00:01:42,143
across the three classes.

47
00:01:42,143 --> 00:01:43,810
Here's a look at the
mean token lengths.

48
00:01:43,810 --> 00:01:46,268
It's just sort of noteworthy
that premises are a little bit

49
00:01:46,268 --> 00:01:47,272
longer than hypotheses.

50
00:01:47,272 --> 00:01:48,730
I guess that comes
down to the fact

51
00:01:48,730 --> 00:01:51,980
that crowdworkers were
writing these sentences.

52
00:01:51,980 --> 00:01:54,925
In terms of clause types,
mostly, we talk about NLI

53
00:01:54,925 --> 00:01:56,060
as a sentence task.

54
00:01:56,060 --> 00:01:59,420
But in fact, only
74% of the examples

55
00:01:59,420 --> 00:02:02,750
are sentences that is S-rooted
in their syntactic parses.

56
00:02:02,750 --> 00:02:04,730
It has a large
vocabulary, but may

57
00:02:04,730 --> 00:02:06,949
be modest relative to
the size of the data set,

58
00:02:06,949 --> 00:02:08,449
and that might come
back to the fact

59
00:02:08,449 --> 00:02:11,870
that the genre is
kind of restricted.

60
00:02:11,870 --> 00:02:13,670
We had about 60,000
examples that

61
00:02:13,670 --> 00:02:17,330
were additionally validated
by four other annotators.

62
00:02:17,330 --> 00:02:19,910
And I'll show you the response
distributions, which suggests

63
00:02:19,910 --> 00:02:22,960
some sources of variation.

64
00:02:22,960 --> 00:02:25,040
They had high
interannotator agreement.

65
00:02:25,040 --> 00:02:28,450
So given that
validation, about 60%

66
00:02:28,450 --> 00:02:30,610
examples had a
unanimous gold label.

67
00:02:30,610 --> 00:02:33,280
And we rate the overall
human level of agreement

68
00:02:33,280 --> 00:02:36,280
at about 91.2% for
the gold labels.

69
00:02:36,280 --> 00:02:38,470
And that's the measure
of human performance

70
00:02:38,470 --> 00:02:40,902
that's commonly used for SNLI.

71
00:02:40,902 --> 00:02:43,050
And the overall
Fleiss kappa measured

72
00:02:43,050 --> 00:02:45,510
interannotator
agreement was 0.7, which

73
00:02:45,510 --> 00:02:47,015
is a high rate of agreement.

74
00:02:47,015 --> 00:02:48,390
And then for the
leaderboard, you

75
00:02:48,390 --> 00:02:49,680
can check out this link here.

76
00:02:49,680 --> 00:02:52,380
Sam has been good about curating
all the systems that enter,

77
00:02:52,380 --> 00:02:54,780
and you can get a sense for
which approaches are best.

78
00:02:54,780 --> 00:02:56,470
It's clear at this
point, for example,

79
00:02:56,470 --> 00:02:58,440
that ensembles of
deep learning methods

80
00:02:58,440 --> 00:03:01,695
are the best for this problem.

81
00:03:01,695 --> 00:03:03,570
I mentioned before, the
crowdsourcing methods

82
00:03:03,570 --> 00:03:05,640
I think it's worth thinking
about precisely what happened

83
00:03:05,640 --> 00:03:06,140
here.

84
00:03:06,140 --> 00:03:08,130
So here's the
crowdsourcing interface.

85
00:03:08,130 --> 00:03:09,960
There's some
instructions up here.

86
00:03:09,960 --> 00:03:11,970
Here's the caption--
that is, the premise

87
00:03:11,970 --> 00:03:13,560
sentence in our
terms-- a little boy

88
00:03:13,560 --> 00:03:15,398
in an apron helps his mother.

89
00:03:15,398 --> 00:03:17,940
And then the crowdworker had to
come up with three sentences.

90
00:03:17,940 --> 00:03:21,030
One definitely correct--
that's an entailment case.

91
00:03:21,030 --> 00:03:22,420
One may be correct--

92
00:03:22,420 --> 00:03:24,240
that is our gloss on neutral.

93
00:03:24,240 --> 00:03:26,237
And one definitely
incorrect, which is our

94
00:03:26,237 --> 00:03:27,195
gloss on contradiction.

95
00:03:27,195 --> 00:03:29,340
So you can see here
that there's an attempt

96
00:03:29,340 --> 00:03:31,200
to use informal
language connecting

97
00:03:31,200 --> 00:03:34,630
with informal reasoning, common
sense reasoning in the prompt

98
00:03:34,630 --> 00:03:35,130
here.

99
00:03:35,130 --> 00:03:37,170
And then those get
translated into our three

100
00:03:37,170 --> 00:03:39,630
labels for the task.

101
00:03:39,630 --> 00:03:41,970
And here are some examples
from the validated set.

102
00:03:41,970 --> 00:03:44,137
And I think they're sort
of interesting, because you

103
00:03:44,137 --> 00:03:45,660
get high rates of
agreement, but you

104
00:03:45,660 --> 00:03:48,060
do find some examples that
have a lot of uncertainty

105
00:03:48,060 --> 00:03:51,020
about them, like
this last one here.

106
00:03:51,020 --> 00:03:53,270
And I think that might be a
hallmark, actually, of NLI

107
00:03:53,270 --> 00:03:53,770
problems.

108
00:03:53,770 --> 00:03:56,120


109
00:03:56,120 --> 00:03:57,650
Now, one really
fundamental thing

110
00:03:57,650 --> 00:03:59,690
that I mentioned in
the overview screencast

111
00:03:59,690 --> 00:04:01,280
as definitely worth
being aware of

112
00:04:01,280 --> 00:04:03,620
relates specifically to
the contradiction relation.

113
00:04:03,620 --> 00:04:05,570
And there's discussion
of this in the paper.

114
00:04:05,570 --> 00:04:07,400
It's a tricky point.

115
00:04:07,400 --> 00:04:10,640
What we say for SNLI, using
these simple examples here,

116
00:04:10,640 --> 00:04:12,980
is that both of them are in
the contradiction relation.

117
00:04:12,980 --> 00:04:16,370
The first one is "a boat
sank in the Pacific Ocean."

118
00:04:16,370 --> 00:04:18,529
It has premise and
hypothesis, "a boat

119
00:04:18,529 --> 00:04:20,060
sank in the Atlantic Ocean."

120
00:04:20,060 --> 00:04:23,090
You might ask, of course,
those could be true together.

121
00:04:23,090 --> 00:04:25,298
They should be neutral,
not contradiction.

122
00:04:25,298 --> 00:04:26,840
The reason we call
them contradiction

123
00:04:26,840 --> 00:04:29,810
is because we make an
assumption of event coreference,

124
00:04:29,810 --> 00:04:32,720
that we're talking about the
same boat in the same event.

125
00:04:32,720 --> 00:04:35,360
And therefore, the locations
contradict each other

126
00:04:35,360 --> 00:04:37,480
in a common sense way.

127
00:04:37,480 --> 00:04:40,330
And the second example is an
even more extreme case of this.

128
00:04:40,330 --> 00:04:42,790
Ruth Bader Ginsburg was
appointed to the Supreme Court

129
00:04:42,790 --> 00:04:44,770
and I had a sandwich
for lunch today.

130
00:04:44,770 --> 00:04:47,440
We say those are in the
contradiction relation.

131
00:04:47,440 --> 00:04:49,570
Of course, they could
be true together.

132
00:04:49,570 --> 00:04:53,500
But they couldn't, in our terms,
be true of the same event.

133
00:04:53,500 --> 00:04:55,300
They're describing
very different events.

134
00:04:55,300 --> 00:04:57,670
And for that reason, they
get the contradiction label.

135
00:04:57,670 --> 00:05:00,590


136
00:05:00,590 --> 00:05:02,840
If a premise and
hypothesis probably

137
00:05:02,840 --> 00:05:06,110
describe a different photo,
then the label is contradiction.

138
00:05:06,110 --> 00:05:08,960
That's kind of anchoring back
into our underlying domain

139
00:05:08,960 --> 00:05:11,850
that you might have in mind.

140
00:05:11,850 --> 00:05:14,190
We can mark progress on
SNLI, because Sam has

141
00:05:14,190 --> 00:05:15,510
been curating that leaderboard.

142
00:05:15,510 --> 00:05:17,820
As I mentioned before, we
estimate human performance

143
00:05:17,820 --> 00:05:19,620
up here at almost 92.

144
00:05:19,620 --> 00:05:22,260
And along this x-axis
here, I've got time.

145
00:05:22,260 --> 00:05:24,900


146
00:05:24,900 --> 00:05:27,510
And you can see that very
quickly, the community

147
00:05:27,510 --> 00:05:30,720
has hill-climbed toward systems
that are superhuman, according

148
00:05:30,720 --> 00:05:31,770
to our estimate.

149
00:05:31,770 --> 00:05:34,560
But down here at 78
is the original paper.

150
00:05:34,560 --> 00:05:37,050
That was from an era when deep
learning systems were really

151
00:05:37,050 --> 00:05:39,930
not clearly the winners in
this kind of competition,

152
00:05:39,930 --> 00:05:42,960
but SNLI helped change that by
introducing a lot of new data.

153
00:05:42,960 --> 00:05:46,890
So a very rapid rise in
system performance, and then

154
00:05:46,890 --> 00:05:50,040
basically monotonic
increase until 2019,

155
00:05:50,040 --> 00:05:51,570
when we saw the
first systems that

156
00:05:51,570 --> 00:05:54,180
were, in these
restrictive terms,

157
00:05:54,180 --> 00:05:58,180
better than humans
at the SNLI task.

158
00:05:58,180 --> 00:06:03,190
Let's move to MultiNLI,
which was a kind of successor

159
00:06:03,190 --> 00:06:04,520
to SNLI.

160
00:06:04,520 --> 00:06:06,730
This was collected by Idina
Williams and colleagues,

161
00:06:06,730 --> 00:06:08,830
including Sam Bowman.

162
00:06:08,830 --> 00:06:10,390
The train premises,
in this case,

163
00:06:10,390 --> 00:06:11,807
are going to be
much more diverse.

164
00:06:11,807 --> 00:06:13,450
They're drawn from five genres--

165
00:06:13,450 --> 00:06:17,330
fiction; government reports,
and letters and things;

166
00:06:17,330 --> 00:06:20,830
the Slate website; the
Switchboard corpus; which

167
00:06:20,830 --> 00:06:23,350
is people interacting
over the phone;

168
00:06:23,350 --> 00:06:26,020
and Berlitz travel guides.

169
00:06:26,020 --> 00:06:29,110
And then interestingly, they
have additional genres just

170
00:06:29,110 --> 00:06:29,943
for dev and test.

171
00:06:29,943 --> 00:06:32,110
And this is what they call
the mismatched condition.

172
00:06:32,110 --> 00:06:36,730
And those are the "9/11 Report,"
face-to-face conversations,

173
00:06:36,730 --> 00:06:39,190
fundraising letters,
and nonfiction

174
00:06:39,190 --> 00:06:41,230
from Oxford University
Press, as well as

175
00:06:41,230 --> 00:06:44,190
articles about linguistics.

176
00:06:44,190 --> 00:06:47,690
So this is noteworthy because
in the mismatched condition

177
00:06:47,690 --> 00:06:50,250
that MultiLNI sets
up, you are forced

178
00:06:50,250 --> 00:06:52,170
to train on those
training examples

179
00:06:52,170 --> 00:06:53,865
and then test on
entirely new genres.

180
00:06:53,865 --> 00:06:56,100
And you can just see how
different, for example,

181
00:06:56,100 --> 00:06:59,760
Berlitz travel guides might
be from the "9/11 Report."

182
00:06:59,760 --> 00:07:01,950
I think this is an
interesting early example

183
00:07:01,950 --> 00:07:03,990
of being adversarial
and enforcing

184
00:07:03,990 --> 00:07:07,590
our systems to grapple with
new domains and new genres.

185
00:07:07,590 --> 00:07:10,980
And I think that's a really
productive step in testing

186
00:07:10,980 --> 00:07:13,740
these systems for robustness.

187
00:07:13,740 --> 00:07:16,590
It's another large data set,
slightly smaller than SNLI.

188
00:07:16,590 --> 00:07:20,130
But actually, the example
lengths tend to be longer.

189
00:07:20,130 --> 00:07:22,392
They did the same
kind of validation,

190
00:07:22,392 --> 00:07:24,600
and that gives us our
estimates of human performance.

191
00:07:24,600 --> 00:07:26,662
And once again, I
would say that we

192
00:07:26,662 --> 00:07:27,870
can have a lot of confidence.

193
00:07:27,870 --> 00:07:30,150
There was a high
rate of agreement.

194
00:07:30,150 --> 00:07:34,770
92.6% is the traditional measure
of human performance here.

195
00:07:34,770 --> 00:07:36,960
For MultiNLI, the test
set is available only

196
00:07:36,960 --> 00:07:41,070
as a Kaggle competition, and you
can check out the project page

197
00:07:41,070 --> 00:07:43,130
here.

198
00:07:43,130 --> 00:07:46,490
I love the fact that
MultiNLI was distributed with

199
00:07:46,490 --> 00:07:48,950
annotations that could
help someone kind of do

200
00:07:48,950 --> 00:07:50,750
out-of-the-box error analysis.

201
00:07:50,750 --> 00:07:52,580
What they did is have
linguists go through

202
00:07:52,580 --> 00:07:55,400
and label specific
examples for whether or not

203
00:07:55,400 --> 00:07:58,460
they manifested specific
linguistic phenomena, like do

204
00:07:58,460 --> 00:08:00,800
the premise and hypothesis
involve variation

205
00:08:00,800 --> 00:08:03,180
in active-passive morphology?

206
00:08:03,180 --> 00:08:05,390
Which might be a clue
that the sentences are

207
00:08:05,390 --> 00:08:08,240
synonymous or in an
entailment relation,

208
00:08:08,240 --> 00:08:10,490
but nonetheless hard for
systems to predict because

209
00:08:10,490 --> 00:08:11,750
of the change in word order.

210
00:08:11,750 --> 00:08:14,330
We also have things like whether
there are belief statements,

211
00:08:14,330 --> 00:08:16,550
conditionals,
whether coreference

212
00:08:16,550 --> 00:08:19,280
is involved in a
nontrivial way, modality,

213
00:08:19,280 --> 00:08:22,280
negation, quantifiers--
things that you might think

214
00:08:22,280 --> 00:08:25,820
would be good probes for the
true systematicity of the model

215
00:08:25,820 --> 00:08:26,480
you've trained.

216
00:08:26,480 --> 00:08:27,980
And you can use
these annotations

217
00:08:27,980 --> 00:08:29,480
to kind of benchmark
yourself there.

218
00:08:29,480 --> 00:08:32,770
I think that's
incredibly productive.

219
00:08:32,770 --> 00:08:34,780
How are we doing on MulitiNLI?

220
00:08:34,780 --> 00:08:37,280
So again, we're going to
have our score over here

221
00:08:37,280 --> 00:08:39,490
and on the x-axis, time.

222
00:08:39,490 --> 00:08:42,890
We have that human
estimate at 92.6%.

223
00:08:42,890 --> 00:08:46,150
And since it's on Kaggle, we
can look at lots more systems.

224
00:08:46,150 --> 00:08:48,190
For SNLI, we just have
the published papers.

225
00:08:48,190 --> 00:08:49,660
But on Kaggle, lots
of people enter

226
00:08:49,660 --> 00:08:51,530
and they try lots
of different things.

227
00:08:51,530 --> 00:08:54,010
As a result, you get much
more variance across this.

228
00:08:54,010 --> 00:08:55,280
It's much less monotonic.

229
00:08:55,280 --> 00:08:58,825
But nonetheless, you can see
that the community is rapidly

230
00:08:58,825 --> 00:09:02,200
hill climbing toward superhuman
performance on this task,

231
00:09:02,200 --> 00:09:02,870
as well.

232
00:09:02,870 --> 00:09:05,350
And again, I would just want
to reiterate, recalling themes

233
00:09:05,350 --> 00:09:07,273
from our introductory
lecture, this

234
00:09:07,273 --> 00:09:09,190
does not necessarily
mean that we have systems

235
00:09:09,190 --> 00:09:11,530
that are superhuman at
the task of common sense

236
00:09:11,530 --> 00:09:15,430
reasoning, which is a very human
and complex thing, but rather,

237
00:09:15,430 --> 00:09:17,620
systems that are just
narrowly outperforming

238
00:09:17,620 --> 00:09:22,120
humans on this one particular
very machine-like metric, which

239
00:09:22,120 --> 00:09:25,240
gives us our estimate of
human performance here.

240
00:09:25,240 --> 00:09:28,610
Still, startling progress.

241
00:09:28,610 --> 00:09:30,610
And then finally,
adversarial NLIs,

242
00:09:30,610 --> 00:09:33,160
kind of a response to that
dynamic that looks like we're

243
00:09:33,160 --> 00:09:34,557
making lots of progress.

244
00:09:34,557 --> 00:09:36,640
But we might worry that
our systems are benefiting

245
00:09:36,640 --> 00:09:39,790
from idiosyncrasies and
artifacts in the data sets,

246
00:09:39,790 --> 00:09:42,700
and that they're not
actually good at the kind

247
00:09:42,700 --> 00:09:45,670
of human reasoning that we're
truly trying to capture.

248
00:09:45,670 --> 00:09:48,680
And that gave rise to the
Adversarial NLI project.

249
00:09:48,680 --> 00:09:50,470
The paper is Nie,
et al., which also

250
00:09:50,470 --> 00:09:53,380
involves some authors from
earlier data sets, SNLI

251
00:09:53,380 --> 00:09:54,670
and MultiNLI.

252
00:09:54,670 --> 00:09:56,080
It's another large data set.

253
00:09:56,080 --> 00:09:57,880
A little bit smaller,
but you'll see why

254
00:09:57,880 --> 00:10:00,190
it's special in some respects.

255
00:10:00,190 --> 00:10:02,460
The premises come from
very diverse sources.

256
00:10:02,460 --> 00:10:04,060
We don't have the
genre overfitting

257
00:10:04,060 --> 00:10:06,040
you might get from SNLI.

258
00:10:06,040 --> 00:10:09,050
And the hypotheses were again,
written by crowdworkers.

259
00:10:09,050 --> 00:10:12,910
But here, crucially, they were
written not in the abstract,

260
00:10:12,910 --> 00:10:15,540
but rather with the goal
of fooling state-of-the-art

261
00:10:15,540 --> 00:10:16,040
models.

262
00:10:16,040 --> 00:10:19,150
That's the adversarial
part of this project.

263
00:10:19,150 --> 00:10:21,550
And this is a direct
response to this feeling

264
00:10:21,550 --> 00:10:25,000
that results in findings
for SNLI and MultiNLI,

265
00:10:25,000 --> 00:10:27,005
while impressive,
might be overstating

266
00:10:27,005 --> 00:10:29,380
the extent to which we've made
progress on the underlying

267
00:10:29,380 --> 00:10:32,720
task of common sense reasoning.

268
00:10:32,720 --> 00:10:34,300
So here's how the
dataset collection

269
00:10:34,300 --> 00:10:35,690
worked in a little more detail.

270
00:10:35,690 --> 00:10:37,480
I think this is a
fascinating dynamic.

271
00:10:37,480 --> 00:10:40,870
The annotator was presented
with a premise sentence and one

272
00:10:40,870 --> 00:10:43,210
condition, which would just
correspond to the label

273
00:10:43,210 --> 00:10:44,920
that they want to create.

274
00:10:44,920 --> 00:10:48,310
They write a hypothesis, and
a state-of-the-art model makes

275
00:10:48,310 --> 00:10:50,920
a prediction about the
premise-hypothesis pair,

276
00:10:50,920 --> 00:10:54,350
basically predicting one of
these three condition labels.

277
00:10:54,350 --> 00:10:56,500
If the model's prediction
matches the condition,

278
00:10:56,500 --> 00:10:59,410
the annotator returns
to step 2 to try again

279
00:10:59,410 --> 00:11:00,910
with a new sentence.

280
00:11:00,910 --> 00:11:03,490
If the model was fooled, though,
the premise hypothesis pair

281
00:11:03,490 --> 00:11:05,200
is independently validated.

282
00:11:05,200 --> 00:11:07,030
So in this way, we're
kind of guaranteed

283
00:11:07,030 --> 00:11:08,440
to get a lot of
examples that are

284
00:11:08,440 --> 00:11:10,840
very hard for
whatever model we have

285
00:11:10,840 --> 00:11:13,415
in the loop in this process.

286
00:11:13,415 --> 00:11:14,540
Here are some more details.

287
00:11:14,540 --> 00:11:16,350
So it has three
rounds, this data set,

288
00:11:16,350 --> 00:11:18,960
for its first release.

289
00:11:18,960 --> 00:11:22,060
Overall, that results
in that large data set.

290
00:11:22,060 --> 00:11:23,850
And you can see that
in subsequent rounds,

291
00:11:23,850 --> 00:11:26,130
the model is going
to be expanded

292
00:11:26,130 --> 00:11:28,300
to include previous
rounds of data,

293
00:11:28,300 --> 00:11:31,720
in addition, possibly,
to other data resources.

294
00:11:31,720 --> 00:11:33,690
And so what we're hoping
is that as we progress

295
00:11:33,690 --> 00:11:35,370
through these rounds,
these examples

296
00:11:35,370 --> 00:11:38,070
are going to get harder and
harder in virtue of the fact

297
00:11:38,070 --> 00:11:40,560
that the model is
trained on more data

298
00:11:40,560 --> 00:11:42,960
and is getting better
as a result of seeing

299
00:11:42,960 --> 00:11:45,720
all these adversarial examples.

300
00:11:45,720 --> 00:11:47,640
In terms of the
splits, the train set

301
00:11:47,640 --> 00:11:49,920
is a mix of cases where the
model's predictions were

302
00:11:49,920 --> 00:11:51,378
correct and where
it was incorrect,

303
00:11:51,378 --> 00:11:53,790
because sometimes in that
loop, the annotator was

304
00:11:53,790 --> 00:11:56,010
unable to fool the model
after some specified

305
00:11:56,010 --> 00:11:57,030
number of attempts.

306
00:11:57,030 --> 00:11:59,322
And we keep those examples,
because they're nonetheless

307
00:11:59,322 --> 00:12:00,580
interesting training data.

308
00:12:00,580 --> 00:12:04,080
However, in the
dev and test sets,

309
00:12:04,080 --> 00:12:06,780
we have only examples
that fooled the models.

310
00:12:06,780 --> 00:12:10,260
So with respect to the
best model for each round,

311
00:12:10,260 --> 00:12:13,530
the test set is as adversarial
as it could possibly get.

312
00:12:13,530 --> 00:12:17,331
The model has gotten every
single example wrong.

313
00:12:17,331 --> 00:12:19,790
And Adversarial NLI is
exciting because it's

314
00:12:19,790 --> 00:12:22,190
given rise to a whole
movement around creating

315
00:12:22,190 --> 00:12:23,450
adversarial datasets.

316
00:12:23,450 --> 00:12:26,930
And that's represented by this
open-source project, Dynabench.

317
00:12:26,930 --> 00:12:29,690
And we just recently
published a paper

318
00:12:29,690 --> 00:12:31,520
that's on the Dynabench
effort, reporting

319
00:12:31,520 --> 00:12:34,640
on a bunch of tasks that are
going to use approximately

320
00:12:34,640 --> 00:12:38,060
adversarial NLI techniques
to develop datasets that are

321
00:12:38,060 --> 00:12:39,680
adversarial in lots of domains.

322
00:12:39,680 --> 00:12:43,520
And you've actually seen one of
these in the Dynasent dataset

323
00:12:43,520 --> 00:12:47,180
from our previous unit
on sentiment analysis.

324
00:12:47,180 --> 00:12:48,680
And here's the
Dynabench interface.

325
00:12:48,680 --> 00:12:50,150
And I guess I'm
just exhorting you,

326
00:12:50,150 --> 00:12:52,220
if you would like to get
involved in this effort,

327
00:12:52,220 --> 00:12:55,700
it's a community-wide thing to
develop better benchmarks that

328
00:12:55,700 --> 00:12:58,460
are going to get us closer to
assessing how much progress

329
00:12:58,460 --> 00:13:00,623
we're actually making.

330
00:13:00,623 --> 00:13:02,540
And then finally, there
are a lot of other NLI

331
00:13:02,540 --> 00:13:04,380
data sets that I didn't mention.

332
00:13:04,380 --> 00:13:06,140
So let me just
run through these.

333
00:13:06,140 --> 00:13:08,480
The GLUE benchmark
has a lot of NLI tasks

334
00:13:08,480 --> 00:13:12,410
in it, as does SuperGLUE,
which is its successor.

335
00:13:12,410 --> 00:13:14,570
I mentioned before, in
the context of ANLI,

336
00:13:14,570 --> 00:13:16,460
this NLI-style FEVER dataset.

337
00:13:16,460 --> 00:13:19,370
FEVER is fact verification,
and I've just translated

338
00:13:19,370 --> 00:13:22,050
the examples into NLI ones.

339
00:13:22,050 --> 00:13:24,950
Here's an NLI
corpus for Chinese,

340
00:13:24,950 --> 00:13:26,420
and here's one for Turkish.

341
00:13:26,420 --> 00:13:29,060
The Chinese examples
are all original,

342
00:13:29,060 --> 00:13:30,920
and the Turkish one
is a translation

343
00:13:30,920 --> 00:13:36,140
with validation of SNLI
and MultiNLI into Turkish.

344
00:13:36,140 --> 00:13:38,870
XNLI is a bunch of
assessment data sets

345
00:13:38,870 --> 00:13:42,980
that is dev-test splits for
more than a dozen languages,

346
00:13:42,980 --> 00:13:44,760
drawing on the
MultiNLI examples.

347
00:13:44,760 --> 00:13:47,000
Those are human-created
translations

348
00:13:47,000 --> 00:13:50,540
that could be used to benchmark
multilingual NLI systems.

349
00:13:50,540 --> 00:13:52,040
And then there are
a few others down

350
00:13:52,040 --> 00:13:55,220
here kind of pointing out
trying to get genre diversity,

351
00:13:55,220 --> 00:13:58,280
and then NLI for
specialized domains.

352
00:13:58,280 --> 00:13:59,810
Here is medicine and science.

353
00:13:59,810 --> 00:14:02,393
And those could be interesting
for seeing how well a model can

354
00:14:02,393 --> 00:14:03,980
grapple with
variation that comes

355
00:14:03,980 --> 00:14:07,020
in very specific and
maybe technical domains.

356
00:14:07,020 --> 00:14:09,260
So there's a wide world
of tasks you can explore,

357
00:14:09,260 --> 00:14:11,780
and I think that makes NLI
a really exciting space

358
00:14:11,780 --> 00:14:14,150
in which to develop original
systems, and projects,

359
00:14:14,150 --> 00:14:16,030
and so forth.

360
00:14:16,030 --> 00:14:20,000


