1
00:00:04,560 --> 00:00:06,160
привет всем, добро пожаловать в шестую часть

2
00:00:06,160 --> 00:00:07,759
нашей серии по контролируемому анализу настроений.

3
00:00:07,759 --> 00:00:09,440
Этот скринкаст будет

4
00:00:09,440 --> 00:00:11,280
охватывать два важных метода в этом

5
00:00:11,280 --> 00:00:13,360
пространстве: поиск по гиперпараметрам и

6
00:00:13,360 --> 00:00:15,679
сравнение классификаторов,

7
00:00:15,679 --> 00:00:17,199
поэтому давайте начнем с

8
00:00:17,199 --> 00:00:19,039
поиска по гиперпараметрам, и сначала я просто предложу

9
00:00:19,039 --> 00:00:20,320
обоснование

10
00:00:20,320 --> 00:00:22,800
, скажем, что  параметры модели

11
00:00:22,800 --> 00:00:24,880
— это те, значения которых изучаются как

12
00:00:24,880 --> 00:00:26,960
часть оптимизации самой модели, поэтому

13
00:00:26,960 --> 00:00:28,880
для классификаторов, которые мы изучали,

14
00:00:28,880 --> 00:00:30,960
параметры на самом деле представляют собой просто

15
00:00:30,960 --> 00:00:32,719
веса, которые вы изучаете для каждой из

16
00:00:32,719 --> 00:00:34,640
отдельных функций,

17
00:00:34,640 --> 00:00:35,760
и это то, что

18
00:00:35,760 --> 00:00:37,680
непосредственно  целевыми для процесса оптимизации,

19
00:00:37,680 --> 00:00:38,879


20
00:00:38,879 --> 00:00:40,640
параметры модели, как правило,

21
00:00:40,640 --> 00:00:42,399
довольно четко определены, потому что они как

22
00:00:42,399 --> 00:00:43,680
бы следуют из

23
00:00:43,680 --> 00:00:45,840
математической структуры исследуемой модели.

24
00:00:45,840 --> 00:00:47,440


25
00:00:47,440 --> 00:00:49,039


26
00:00:49,039 --> 00:00:50,559


27
00:00:50,559 --> 00:00:52,879


28
00:00:52,879 --> 00:00:54,800
за пределами процесса оптимизации,

29
00:00:54,800 --> 00:00:57,280
упомянутого в одном, поэтому примеры

30
00:00:57,280 --> 00:00:59,520
из моделей, которые мы видели  в нашей перчатке и lsa

31
00:00:59,520 --> 00:01:01,680
есть эта настройка размерности,

32
00:01:01,680 --> 00:01:03,440
сама модель не дает вам указаний

33
00:01:03,440 --> 00:01:04,479
о том, что выбрать для

34
00:01:04,479 --> 00:01:05,920
размерности,

35
00:01:05,920 --> 00:01:07,920
и размерность не выбирается

36
00:01:07,920 --> 00:01:09,760
как часть оптимизации самой модели

37
00:01:09,760 --> 00:01:12,159
, вы должны выбрать ее через какой-то

38
00:01:12,159 --> 00:01:14,400
внешний механизм, делающий ее  гиперпараметр

39
00:01:14,400 --> 00:01:15,840


40
00:01:15,840 --> 00:01:17,360
и перчатка на самом деле имеют два других

41
00:01:17,360 --> 00:01:19,600
дополнительных важных гиперпараметра

42
00:01:19,600 --> 00:01:22,080
xmax и альфа, которые снова не

43
00:01:22,080 --> 00:01:23,680
оптимизированы моделью, вам нужно

44
00:01:23,680 --> 00:01:26,400
выбрать их с помощью какого-то внешнего механизма,

45
00:01:26,400 --> 00:01:28,000
а для классификаторов, которые мы

46
00:01:28,000 --> 00:01:29,840
изучали, вы знаете, что у нас есть условия регуляризации,

47
00:01:29,840 --> 00:01:32,079
это  классические гиперпараметры,

48
00:01:32,079 --> 00:01:33,840
если у вас есть глубокий классификатор, то

49
00:01:33,840 --> 00:01:35,920
скрытые размерности в модели

50
00:01:35,920 --> 00:01:37,200
также могут считаться

51
00:01:37,200 --> 00:01:39,600
скоростью обучения гиперпараметров. Вы знаете, что

52
00:01:39,600 --> 00:01:41,360
любая основная функция самого метода оптимизации

53
00:01:41,360 --> 00:01:43,280
может считаться

54
00:01:43,280 --> 00:01:45,759
гиперпараметрами и даже вещами, которые можно

55
00:01:45,759 --> 00:01:48,079
считать своего рода архитектурными  как

56
00:01:48,079 --> 00:01:49,840
функция активации в глубоком

57
00:01:49,840 --> 00:01:52,000
классификаторе, вы можете подумать об этом  как

58
00:01:52,000 --> 00:01:54,240
неотъемлемая часть модели,

59
00:01:54,240 --> 00:01:56,240
которую вы оцениваете, но, поскольку

60
00:01:56,240 --> 00:01:58,399
на данном этапе для нас это простая точка выбора, у вас возникнет

61
00:01:58,399 --> 00:02:00,320
соблазн изучить несколько различных

62
00:02:00,320 --> 00:02:01,759
вариантов для этого конкретного

63
00:02:01,759 --> 00:02:04,079
архитектурного выбора, и таким образом он

64
00:02:04,079 --> 00:02:06,240
может стать  гиперпараметр, и в

65
00:02:06,240 --> 00:02:08,878
этот момент даже методы оптимизации

66
00:02:08,878 --> 00:02:11,120
могут также появиться как гиперпараметр, по

67
00:02:11,120 --> 00:02:14,000
которому вы хотели бы выполнить поиск,

68
00:02:14,000 --> 00:02:15,520
и т. д. и т. д. вам,

69
00:02:15,520 --> 00:02:18,160
вероятно, следует довольно широко взглянуть на

70
00:02:18,160 --> 00:02:19,920
то, что представляют собой гиперпараметры вашей модели

71
00:02:19,920 --> 00:02:23,120
, если вы  может теперь вот

72
00:02:23,120 --> 00:02:25,120
суть аргумента

73
00:02:25,120 --> 00:02:27,200
оптимизация гиперпараметров имеет решающее значение для создания

74
00:02:27,200 --> 00:02:29,760
убедительного аргумента принципиально для

75
00:02:29,760 --> 00:02:31,680
любого вида сравнения, которое мы делаем мы

76
00:02:31,680 --> 00:02:34,160
хотим представить каждую модель в самом лучшем

77
00:02:34,160 --> 00:02:35,120
свете

78
00:02:35,120 --> 00:02:36,640
мы могли бы считать само собой разумеющимся, что для

79
00:02:36,640 --> 00:02:38,800
любой достаточно сложной модели

80
00:02:38,800 --> 00:02:40,400
есть  некоторая настройка его гиперпараметров,

81
00:02:40,400 --> 00:02:42,160
которая является своего рода вырожденной и

82
00:02:42,160 --> 00:02:44,560
заставит модель выглядеть очень плохо,

83
00:02:44,560 --> 00:02:46,160
и поэтому вы, конечно, не захотите проводить

84
00:02:46,160 --> 00:02:48,000
какие-либо сравнения.  Вместо этого действительно

85
00:02:48,000 --> 00:02:50,560
проблематичного набора вариантов

86
00:02:50,560 --> 00:02:52,480
мы хотим, скорее, сказать, что давайте представим все

87
00:02:52,480 --> 00:02:54,720
модели в их лучшем свете, выбрав

88
00:02:54,720 --> 00:02:56,560
для них оптимальные гиперпараметры в

89
00:02:56,560 --> 00:02:58,560
меру наших возможностей, и тогда мы сможем сказать,

90
00:02:58,560 --> 00:03:00,159
что одна модель лучше другой.

91
00:03:00,159 --> 00:03:02,480
если он выйдет победителем в этой очень

92
00:03:02,480 --> 00:03:04,000
строгой

93
00:03:04,000 --> 00:03:05,360
настройке,

94
00:03:05,360 --> 00:03:06,879
и последнее, что я скажу об этом

95
00:03:06,879 --> 00:03:09,440
методологически, это то, что, конечно, вся

96
00:03:09,440 --> 00:03:11,680
настройка гиперпараметров должна выполняться только

97
00:03:11,680 --> 00:03:13,840
для данных обучения и разработки, которые вы

98
00:03:13,840 --> 00:03:16,319
считаете, вы можете считать, что все

99
00:03:16,319 --> 00:03:18,400
честно с точки зрения его использования  однако вы

100
00:03:18,400 --> 00:03:19,920
хотите выбрать оптимальные гиперпараметры,

101
00:03:19,920 --> 00:03:22,319
но как только этот выбор установлен,

102
00:03:22,319 --> 00:03:24,560
он фиксируется, и это параметры,

103
00:03:24,560 --> 00:03:26,239
которые вы используете во время тестирования, и

104
00:03:26,239 --> 00:03:28,080
это фундаментальная оценка, которую вы

105
00:03:28,080 --> 00:03:29,920
будете использовать для любого сравнения моделей,

106
00:03:29,920 --> 00:03:32,319
и ни в коем случае не должны  вы

107
00:03:32,319 --> 00:03:34,400
настраиваете эти гиперпараметры на самих

108
00:03:34,400 --> 00:03:36,400
тестовых данных, что было бы

109
00:03:36,400 --> 00:03:39,599
совершенно незаконным,

110
00:03:39,599 --> 00:03:41,440
я надеюсь, что мы действительно упростили

111
00:03:41,440 --> 00:03:42,959
такой поиск гиперпараметров в

112
00:03:42,959 --> 00:03:44,480
контекст работы, которую вы выполняете для

113
00:03:44,480 --> 00:03:46,480
контролируемого анализа тональности, вот

114
00:03:46,480 --> 00:03:48,239
несколько фрагментов кода, которые показывают, как это

115
00:03:48,239 --> 00:03:49,360
может произойти.

116
00:03:49,360 --> 00:03:51,680


117
00:03:51,680 --> 00:03:53,760


118
00:03:53,760 --> 00:03:55,439


119
00:03:55,439 --> 00:03:57,920
функция steamer

120
00:03:57,920 --> 00:04:00,239
изменение происходит внутри оболочки модели,

121
00:04:00,239 --> 00:04:01,200


122
00:04:01,200 --> 00:04:03,200
тогда как до этого, по сути, все, что мы сделали, это

123
00:04:03,200 --> 00:04:05,120
настроили модель логистической регрессии, а

124
00:04:05,120 --> 00:04:07,120
затем вызвали ее метод подгонки,

125
00:04:07,120 --> 00:04:09,280
здесь мы настроили эту модель, но также

126
00:04:09,280 --> 00:04:11,680
установили сетку гиперпараметров,

127
00:04:11,680 --> 00:04:13,280
это разные точки выбора для

128
00:04:13,280 --> 00:04:15,280
этого  модель логистической регрессии, например, есть

129
00:04:15,280 --> 00:04:17,839
ли у меня термин смещения,

130
00:04:17,839 --> 00:04:19,680
значение параметра регуляризации

131
00:04:19,680 --> 00:04:21,918
и даже алгоритм, используемый

132
00:04:21,918 --> 00:04:25,199
для самой регуляризации l1 или l2,

133
00:04:25,199 --> 00:04:27,199
модель будет исследовать полную сетку

134
00:04:27,199 --> 00:04:29,440
этих параметров, она собирается выполнить пятикратную

135
00:04:29,440 --> 00:04:31,759
перекрестную проверку, поэтому  тестировать по одному каждые пять

136
00:04:31,759 --> 00:04:34,240
раз на разных разбиениях данных,

137
00:04:34,240 --> 00:04:36,720
и в этом очень долгом процессе поиска он

138
00:04:36,720 --> 00:04:39,040
найдет то, что нужно, чтобы быть лучшей

139
00:04:39,040 --> 00:04:40,800
настройкой всех t  эти

140
00:04:40,800 --> 00:04:42,639
гиперпараметры всех комбинаций, которые могут

141
00:04:42,639 --> 00:04:44,320
быть установлены логически,

142
00:04:44,320 --> 00:04:45,440


143
00:04:45,440 --> 00:04:47,120
и это модель, которую мы, наконец,

144
00:04:47,120 --> 00:04:49,040
возвращаем здесь прямо сейчас, так что теперь вы можете увидеть

145
00:04:49,040 --> 00:04:50,800
ценность наличия оболочки вокруг этих

146
00:04:50,800 --> 00:04:52,880
методов подгонки, потому что тогда я мог бы выполнять

147
00:04:52,880 --> 00:04:55,440
всю эту дополнительную работу, не меняя

148
00:04:55,440 --> 00:04:57,759
интерфейс для эксперимента sst во всех

149
00:04:57,759 --> 00:05:00,000
экспериментах выглядит так же, как и в

150
00:05:00,000 --> 00:05:01,919
предыдущем режиме, просто они

151
00:05:01,919 --> 00:05:03,600
займут намного больше времени, потому что вы

152
00:05:03,600 --> 00:05:05,919
проводите десятки и десятки экспериментов

153
00:05:05,919 --> 00:05:08,720
как часть этого исчерпывающего перебора

154
00:05:08,720 --> 00:05:10,400
всех возможных настроек,

155
00:05:10,400 --> 00:05:13,600
хорошо, r2  сравнение классификатора давайте

156
00:05:13,600 --> 00:05:15,520
снова начнем с обоснования предположим, что

157
00:05:15,520 --> 00:05:17,759
вы оценили базовую модель b

158
00:05:17,759 --> 00:05:19,840
и вашу любимую модель m, и

159
00:05:19,840 --> 00:05:22,639
выбранная вами метрика оценки отдает предпочтение m правильно,

160
00:05:22,639 --> 00:05:24,080
и это кажется вам маленькой победой

161
00:05:24,080 --> 00:05:26,320
, но вы все равно должны спросить себя,

162
00:05:26,320 --> 00:05:29,360
действительно ли m лучше правильно  теперь, если

163
00:05:29,360 --> 00:05:31,440
разница между b и m имеет явное

164
00:05:31,440 --> 00:05:33,120
практическое значение, вам может

165
00:05:33,120 --> 00:05:34,639
не понадобиться ничего делать, кроме

166
00:05:34,639 --> 00:05:37,199
правильного представления чисел, если e  каждое

167
00:05:37,199 --> 00:05:38,720
из ваших классификационных решений

168
00:05:38,720 --> 00:05:40,080
соответствует чему-то действительно

169
00:05:40,080 --> 00:05:41,919
важному в мире, и ваш

170
00:05:41,919 --> 00:05:43,680
классификатор делает на тысячи больше хороших

171
00:05:43,680 --> 00:05:45,680
прогнозов, чем другая модель, чего

172
00:05:45,680 --> 00:05:48,240
может быть достаточно для аргумента, но

173
00:05:48,240 --> 00:05:50,160
даже в этой ситуации вы можете спросить

174
00:05:50,160 --> 00:05:51,919
, есть ли различия в том, как эти

175
00:05:51,919 --> 00:05:53,840
две модели b  и мне

176
00:05:53,840 --> 00:05:55,440
повезло, вам просто повезло, когда вы увидели то, что выглядело

177
00:05:55,440 --> 00:05:57,600
как практическая разница, и с небольшими

178
00:05:57,600 --> 00:05:59,199
изменениями в инициализации

179
00:05:59,199 --> 00:06:00,639
чего-то вы бы увидели совсем другие

180
00:06:00,639 --> 00:06:01,600
результаты,

181
00:06:01,600 --> 00:06:03,759
если ответ, возможно, да, тогда вы

182
00:06:03,759 --> 00:06:05,360
все еще можете сделать какое-то

183
00:06:05,360 --> 00:06:08,240
сравнение классификатора

184
00:06:08,240 --> 00:06:10,080
теперь есть эта хорошая статья от

185
00:06:10,080 --> 00:06:12,960
dempshark 2006, в которой рекомендуется использовать

186
00:06:12,960 --> 00:06:15,120
знаковый ранговый тест Уилкоксона для ситуаций, в которых

187
00:06:15,120 --> 00:06:17,919
вы можете позволить себе повторно оценить свои

188
00:06:17,919 --> 00:06:20,479
две модели bm на разных сплитах теста поезда,

189
00:06:20,479 --> 00:06:23,360
и мы поговорим позже в

190
00:06:23,360 --> 00:06:25,039
этом термине о точном обосновании  для

191
00:06:25,039 --> 00:06:27,039
этого, но идея в том, что вы проведете

192
00:06:27,039 --> 00:06:28,880
много экспериментов с немного

193
00:06:28,880 --> 00:06:31,280
разными представлениями о своем отце.  ta и своего рода

194
00:06:31,280 --> 00:06:33,440
среднее значение по ним, чтобы понять, являются

195
00:06:33,440 --> 00:06:35,520
ли эти две модели тем, как две модели

196
00:06:35,520 --> 00:06:38,000
сравниваются друг с другом

197
00:06:38,000 --> 00:06:40,479
в ситуациях, когда вы не можете повторно

198
00:06:40,479 --> 00:06:41,919
оценить

199
00:06:41,919 --> 00:06:45,120
тест bm mars, разумной альтернативой, он

200
00:06:45,120 --> 00:06:46,880
работает с матрицами путаницы,

201
00:06:46,880 --> 00:06:48,960
созданными двумя  модели, проверяющие

202
00:06:48,960 --> 00:06:50,880
нулевую гипотезу о том, что две модели

203
00:06:50,880 --> 00:06:53,120
имеют одинаковую частоту ошибок,

204
00:06:53,120 --> 00:06:54,960
причина, по которой вы можете выбрать тест Макнемара,

205
00:06:54,960 --> 00:06:56,560
заключается, например, в том, что вы проводите

206
00:06:56,560 --> 00:06:58,720
эксперимент по глубокому обучению, в котором все

207
00:06:58,720 --> 00:07:01,039
модели занимают несколько недель для оптимизации, тогда,

208
00:07:01,039 --> 00:07:02,800
конечно, вы можете  Вероятно, вы не можете позволить себе

209
00:07:02,800 --> 00:07:05,199
проводить десятки и десятки экспериментов с

210
00:07:05,199 --> 00:07:07,280
каждой из них, так что вы можете быть вынуждены

211
00:07:07,280 --> 00:07:09,520
использовать mcnee mars на основе одного единственного

212
00:07:09,520 --> 00:07:11,759
прогона двух моделей.

213
00:07:11,759 --> 00:07:13,680


214
00:07:13,680 --> 00:07:15,520


215
00:07:15,520 --> 00:07:17,440
работает, и Макни Марс на

216
00:07:17,440 --> 00:07:19,520
самом деле не собирается бороться с

217
00:07:19,520 --> 00:07:21,199
этим так, как это сделает тест на правильность знака Уилкоксона

218
00:07:21,199 --> 00:07:22,479
,

219
00:07:22,479 --> 00:07:24,319
но это, возможно, лучше, чем ничего

220
00:07:24,319 --> 00:07:26,240
в большинстве ситуаций, так что вы можете  ht по умолчанию используется

221
00:07:26,240 --> 00:07:27,680
mcnee mars,

222
00:07:27,680 --> 00:07:30,800
если wilcoxon слишком дорог,

223
00:07:30,800 --> 00:07:32,240
и позвольте мне просто показать вам, насколько просто это

224
00:07:32,240 --> 00:07:34,160
может быть в контексте нашей кодовой базы,

225
00:07:34,160 --> 00:07:36,720
так что в качестве иллюстрации мы, по

226
00:07:36,720 --> 00:07:38,319
сути, собираемся сравнить

227
00:07:38,319 --> 00:07:41,840
логистическую регрессию и наивный байесовский анализ.  я

228
00:07:41,840 --> 00:07:43,680
призываю вас, когда вы делаете эти

229
00:07:43,680 --> 00:07:46,000
сравнения, иметь только одну точку

230
00:07:46,000 --> 00:07:48,560
вариации, поэтому мы собираемся исправить данные

231
00:07:48,560 --> 00:07:49,919
, мы собираемся исправить функцию

232
00:07:49,919 --> 00:07:52,080
функции и сравнить только архитектуры моделей, которые

233
00:07:52,080 --> 00:07:53,680


234
00:07:53,680 --> 00:07:55,360
вы могли бы отдельно сказать, я собираюсь

235
00:07:55,360 --> 00:07:57,199
иметь единую фиксированную модель, такую как логистическая ре 

236
00:07:57,199 --> 00:07:59,520
рессия, и исследовать несколько разных фу 

237
00:07:59,520 --> 00:08:00,960
кций функций, но 

238
00:08:00,960 --> 00:08:03,120
бы посоветовал не исследовать две ра 

239
00:08:03,120 --> 00:08:04,879
ные функции функций в сочетании с д

240
00:08:04,879 --> 00:08:06,800
умя разными моделями, потому что, когда вы 

241
00:08:06,800 --> 00:08:08,479
аблюдаете различия в конце, вы 

242
00:08:08,479 --> 00:08:10,639
е будете уверены, было ли это вызвано  с

243
00:08:10,639 --> 00:08:12,639
помощью выбора модели или функций признаков

244
00:08:12,639 --> 00:08:14,319
мы хотим как бы изолировать

245
00:08:14,319 --> 00:08:16,479
эти вещи и проводить систематические

246
00:08:16,479 --> 00:08:18,000
сравнения,

247
00:08:18,000 --> 00:08:19,440
поэтому здесь я собираюсь провести систематическое

248
00:08:19,440 --> 00:08:21,759
сравнение логистической регрессии.  и

249
00:08:21,759 --> 00:08:24,240
наивный байес на sst с использованием

250
00:08:24,240 --> 00:08:26,960
теста Уилкоксона, и вот настройка,

251
00:08:26,960 --> 00:08:29,520
функция sst сравнивает модели,

252
00:08:29,520 --> 00:08:31,919
я указываю на свои данные обучения, у

253
00:08:31,919 --> 00:08:33,440
вас может быть две функции функций, но

254
00:08:33,440 --> 00:08:35,120
в этом случае у вас должна быть только одна

255
00:08:35,120 --> 00:08:37,360
модель-оболочка, здесь у меня есть одна  функция

256
00:08:37,360 --> 00:08:39,039
функции, используемая для обеих моделей, и у меня

257
00:08:39,039 --> 00:08:40,320
будут эти две разные оболочки,

258
00:08:40,320 --> 00:08:42,000
соответствующие оценке, которую я

259
00:08:42,000 --> 00:08:45,200
хочу выполнить для этих двух классов моделей.

260
00:08:45,200 --> 00:08:47,680
Я собираюсь использовать wilcoxon, как было рекомендовано.

261
00:08:47,680 --> 00:08:50,000


262
00:08:50,000 --> 00:08:53,120
размер данных 70, и,

263
00:08:53,120 --> 00:08:54,880
как всегда, в этой настройке я буду использовать

264
00:08:54,880 --> 00:08:57,360
макрос f1 в качестве своей оценки,

265
00:08:57,360 --> 00:08:59,200
так что это будет делать внутренне, это запускать

266
00:08:59,200 --> 00:09:00,000
10

267
00:09:00,000 --> 00:09:02,399
10 экспериментов на разных

268
00:09:02,399 --> 00:09:04,480
разделениях тестов поезда для каждой из этих моделей, что

269
00:09:04,480 --> 00:09:06,480
дает нам вектор оценки

270
00:09:06,480 --> 00:09:09,200
эээ, 10 вы знаете 10 чисел для каждой модели,

271
00:09:09,200 --> 00:09:10,880
а затем то, что делает Уилкоксон,

272
00:09:10,880 --> 00:09:12,800
сравнивает или делает оценку

273
00:09:12,800 --> 00:09:14,720
того, являются ли средние значения этих двух

274
00:09:14,720 --> 00:09:17,519
векторов оценок статистически значимо

275
00:09:17,519 --> 00:09:19,440
разными, и здесь похоже, что у нас есть

276
00:09:19,440 --> 00:09:20,959
некоторые доказательства того, что  мы можем отклонить

277
00:09:20,959 --> 00:09:23,200
нулевую гипотезу о том, что эти модели

278
00:09:23,200 --> 00:09:24,320
идентичны,

279
00:09:24,320 --> 00:09:26,080
что, по-видимому, является аргументом, который

280
00:09:26,080 --> 00:09:28,160
мы пытались построить

281
00:09:28,160 --> 00:09:29,920
сейчас, конечно, это очень дорого,

282
00:09:29,920 --> 00:09:31,920
потому что нам пришлось провести 20 экспериментов в

283
00:09:31,920 --> 00:09:33,440
этой ситуации, и, конечно, вы могли бы

284
00:09:33,440 --> 00:09:35,680
провести гораздо больше, если бы вы  также выполняя

285
00:09:35,680 --> 00:09:37,760
настройку гиперпараметров как часть вашего

286
00:09:37,760 --> 00:09:39,760
экспериментального рабочего процесса,

287
00:09:39,760 --> 00:09:41,760
поэтому в ситуациях, когда вы не можете позволить

288
00:09:41,760 --> 00:09:43,360
себе делать что-то, что включает в себя столько

289
00:09:43,360 --> 00:09:45,680
экспериментов, как я сказал, вы можете по умолчанию

290
00:09:45,680 --> 00:09:47,120
создать новый mars

291
00:09:47,120 --> 00:09:50,480
, включенный в utils.mcneimar,

292
00:09:50,480 --> 00:09:53,279
и возвращаемые значения  Эксперимент с ssd

293
00:09:53,279 --> 00:09:54,880
даст вам всю необходимую информацию, в

294
00:09:54,880 --> 00:09:57,120
основном для mcneemars, вам

295
00:09:57,120 --> 00:09:59,440
нужен фактический золотой вектор меток, а

296
00:09:59,440 --> 00:10:01,360
затем два вектора прогнозов для

297
00:10:01,360 --> 00:10:03,040
каждого из ваших экспериментов, так что это

298
00:10:03,040 --> 00:10:04,800
простая альтернатива в ситуации,

299
00:10:04,800 --> 00:10:09,399
когда wilcoxon был слишком дорогим

