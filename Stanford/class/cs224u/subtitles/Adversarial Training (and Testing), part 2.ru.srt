1
00:00:05,200 --> 00:00:06,799
приветствуем всех в третьей части нашей

2
00:00:06,799 --> 00:00:08,960
серии, посвященной методам анализа в НЛП, мы

3
00:00:08,960 --> 00:00:10,719
будем говорить о состязательном

4
00:00:10,719 --> 00:00:12,559
обучении, а также о тестировании систем,

5
00:00:12,559 --> 00:00:14,880
это второй из рассматриваемых нами

6
00:00:14,880 --> 00:00:16,079
методов поведенческой оценки,

7
00:00:16,079 --> 00:00:17,760
мы ранее говорили о

8
00:00:17,760 --> 00:00:19,520
состязательном тестировании,

9
00:00:19,520 --> 00:00:21,199
состязательном  обучение и тестирование,

10
00:00:21,199 --> 00:00:22,480
конечно же, подразумевают, что у нас есть гораздо

11
00:00:22,480 --> 00:00:24,080
больший набор данных, поэтому это

12
00:00:24,080 --> 00:00:25,519
труднее сделать,

13
00:00:25,519 --> 00:00:27,279
но для отдельных задач, где у нас есть

14
00:00:27,279 --> 00:00:29,519
такие наборы данных, это может быть очень увлекательно

15
00:00:29,519 --> 00:00:31,119
и подтолкнуть вас к решению всевозможных

16
00:00:31,119 --> 00:00:33,840
интересных передовых вопросов.

17
00:00:33,840 --> 00:00:35,840
начнем с хабара, это ранний

18
00:00:35,840 --> 00:00:37,680
вход в пространство враждебных

19
00:00:37,680 --> 00:00:40,239
наборов поездов хабар обозначает ситуации

20
00:00:40,239 --> 00:00:43,440
с враждебными поколениями,

21
00:00:43,440 --> 00:00:45,440
на самом деле есть два набора данных хабар

22
00:00:45,440 --> 00:00:47,440
и красочно названный хабар, и

23
00:00:47,440 --> 00:00:49,039
вы увидите, почему их два в секунду,

24
00:00:49,039 --> 00:00:51,360
это принципиально  еще одна

25
00:00:51,360 --> 00:00:53,840
интересная история очень быстрого прогресса

26
00:00:53,840 --> 00:00:56,000
в нашей области,

27
00:00:56,000 --> 00:00:58,160
вот как хабарные примеры работы были даны

28
00:00:58,160 --> 00:01:00,000
в качестве ввода системы

29
00:01:00,000 --> 00:01:02,399
в контекст, например  он бросает дротики в

30
00:01:02,399 --> 00:01:03,359
цель,

31
00:01:03,359 --> 00:01:05,119
и другой ввод системы, который является

32
00:01:05,119 --> 00:01:06,960
началом предложения, здесь это другой

33
00:01:06,960 --> 00:01:08,000
человек,

34
00:01:08,000 --> 00:01:09,840
и задача системы состоит в том, чтобы

35
00:01:09,840 --> 00:01:11,680
выяснить, каким должно быть продолжение,

36
00:01:11,680 --> 00:01:13,360
чтобы фактическое продолжение, которое мы предсказываем,

37
00:01:13,360 --> 00:01:15,439
могло быть брошено дротиком в  доска мишеней,

38
00:01:15,439 --> 00:01:16,560


39
00:01:16,560 --> 00:01:17,759
и это, по сути,

40
00:01:17,759 --> 00:01:19,840
задача классификации, системе даются

41
00:01:19,840 --> 00:01:22,080
некоторые отвлекающие факторы, такие как прибегает

42
00:01:22,080 --> 00:01:23,840
и стреляет стрелой в цель, или

43
00:01:23,840 --> 00:01:25,840
показывается на стороне людей, или бросает дротики

44
00:01:25,840 --> 00:01:27,920
в диск, и перед системой ставится задача

45
00:01:27,920 --> 00:01:30,000
выяснить, какие  из вариантов является

46
00:01:30,000 --> 00:01:32,240
фактическим продолжением предложения с

47
00:01:32,240 --> 00:01:34,159
учетом контекста,

48
00:01:34,159 --> 00:01:36,000
источниками данных для этого являются

49
00:01:36,000 --> 00:01:37,759
сеть действий и задача описания крупномасштабного фильма.

50
00:01:37,759 --> 00:01:39,439
Я думаю, что идея

51
00:01:39,439 --> 00:01:40,880
здесь в том, что мы собираемся использовать все

52
00:01:40,880 --> 00:01:43,280
виды интересных понятий здравого

53
00:01:43,280 --> 00:01:45,280
смысла.  Рассуждая

54
00:01:45,280 --> 00:01:47,200
теперь, вот где появляется состязательная часть

55
00:01:47,200 --> 00:01:48,399
этого, мы собираемся выполнить

56
00:01:48,399 --> 00:01:50,880
состязательную фильтрацию для добычи

57
00:01:50,880 --> 00:01:52,720
для каждого из примеров в нашем корпусе,

58
00:01:52,720 --> 00:01:54,320
а их более сотни.  d тысяч

59
00:01:54,320 --> 00:01:56,560
примеров в хабаре, нам

60
00:01:56,560 --> 00:01:58,560
дадут системный ввод, например, смесь

61
00:01:58,560 --> 00:02:01,280
взбивает масляный сахар,

62
00:02:01,280 --> 00:02:03,360
а затем у нас будет модель генератора,

63
00:02:03,360 --> 00:02:05,680
в случае хабара это был lstm,

64
00:02:05,680 --> 00:02:07,840
производящий некоторые отвлекающие факторы для цели,

65
00:02:07,840 --> 00:02:09,679
поэтому давайте предположим, что  фактическое целевое

66
00:02:09,679 --> 00:02:11,520
продолжение добавляется, у нас будет

67
00:02:11,520 --> 00:02:13,760
полученная модель, сладкая и во многих

68
00:02:13,760 --> 00:02:14,879
продуктах,

69
00:02:14,879 --> 00:02:17,440
а затем у нас есть модель фильтрации, если

70
00:02:17,440 --> 00:02:19,360
она правильно угадывает ее, потому что добавляется,

71
00:02:19,360 --> 00:02:21,280
тогда мы собираемся исключить весь этот

72
00:02:21,280 --> 00:02:23,040
пример, и мы'  создадим несколько новых

73
00:02:23,040 --> 00:02:25,760
отвлекающих факторов, таких как посыпание сверху

74
00:02:25,760 --> 00:02:28,000
или во многих продуктах питания, и в этом случае, если

75
00:02:28,000 --> 00:02:30,239
модель угадывает неправильно, например, предположим, что

76
00:02:30,239 --> 00:02:32,640
она выбирает b в этом случае, мы

77
00:02:32,640 --> 00:02:34,879
сохраним этот пример, потому что по сравнению

78
00:02:34,879 --> 00:02:36,879
с текущими моделями для языка

79
00:02:36,879 --> 00:02:38,239
вещь  мы используем для создания этих

80
00:02:38,239 --> 00:02:39,519
отвлекающих факторов, и то, что мы

81
00:02:39,519 --> 00:02:41,519
привыкли использовать для фильтрации, является

82
00:02:41,519 --> 00:02:43,760
сложным примером, и идея состоит в том, что

83
00:02:43,760 --> 00:02:45,120
мы можем повторять это для множества

84
00:02:45,120 --> 00:02:47,040
итераций, постоянно переобучая

85
00:02:47,040 --> 00:02:48,720
модель фильтрации, чтобы  он становится все лучше

86
00:02:48,720 --> 00:02:50,800
и лучше, и поэтому в итоге

87
00:02:50,800 --> 00:02:52,319


88
00:02:52,319 --> 00:02:54,720


89
00:02:54,720 --> 00:02:57,519
мы получаем набор данных, который

90
00:02:57,519 --> 00:02:59,519


91
00:02:59,519 --> 00:03:00,640


92
00:03:00,640 --> 00:03:02,959
действительно очень сложен с точки зрения текущих

93
00:03:02,959 --> 00:03:05,040
моделей, которые у нас были доступны.  чтобы попытаться ввести различные

94
00:03:05,040 --> 00:03:07,440
понятия, которые могут указывать на то, какое

95
00:03:07,440 --> 00:03:09,599
продолжение является правильным, поэтому они

96
00:03:09,599 --> 00:03:11,200
начинают с использования только многослойного

97
00:03:11,200 --> 00:03:13,360
персептрона для эффективности, а затем

98
00:03:13,360 --> 00:03:15,200
вводят все эти ансамбли, и вы

99
00:03:15,200 --> 00:03:17,760
можете увидеть точность теста, когда мы делаем этот

100
00:03:17,760 --> 00:03:20,000
итеративный  фильтрация очень быстро

101
00:03:20,000 --> 00:03:22,560
снижается, так что к итерации 140 мы

102
00:03:22,560 --> 00:03:24,560


103
00:03:24,560 --> 00:03:25,920
достигаем точности 10, так что в этом смысле это

104
00:03:25,920 --> 00:03:27,680
очень сложный набор данных, потому что, учитывая

105
00:03:27,680 --> 00:03:29,440
модель генератора и модель фильтрации,

106
00:03:29,440 --> 00:03:31,840
которые у нас есть, у нас

107
00:03:31,840 --> 00:03:34,159
есть набор данных, который  очень сложно

108
00:03:34,159 --> 00:03:36,799
с точки зрения задачи классификации,

109
00:03:36,799 --> 00:03:38,159
так что это выглядит действительно захватывающим и

110
00:03:38,159 --> 00:03:39,519
сложным, и я думаю, что авторы

111
00:03:39,519 --> 00:03:41,760
ожидали, что этот набор данных сохранится в течение

112
00:03:41,760 --> 00:03:44,879
очень долгого времени h  Как бы

113
00:03:44,879 --> 00:03:47,360
то ни было, оригинальная статья bert провела

114
00:03:47,360 --> 00:03:49,360
оценку хабара и, по сути, решила

115
00:03:49,360 --> 00:03:51,400
проблемы, которые берт большой получил

116
00:03:51,400 --> 00:03:55,360
86,6 и 86,3 на тестовых наборах

117
00:03:55,360 --> 00:03:57,920
Девона для хабара, соответственно, очень неожиданный

118
00:03:57,920 --> 00:04:00,400
результат, учитывая, что я только что показал вам,

119
00:04:00,400 --> 00:04:03,200
что авторы хабара получили около 10 с их

120
00:04:03,200 --> 00:04:05,840
Текущие модели и даже модели,

121
00:04:05,840 --> 00:04:07,920
тесно связанные с Бертом, такие как эта

122
00:04:07,920 --> 00:04:10,319
модель электронной симуляции здесь, были действительно довольно низкими

123
00:04:10,319 --> 00:04:11,920
по своей производительности, поэтому Берт выглядел

124
00:04:11,920 --> 00:04:13,360
как настоящий прорыв, и вы можете видеть, что

125
00:04:13,360 --> 00:04:15,439
это в некотором смысле сверхчеловеческое по

126
00:04:15,439 --> 00:04:17,918
сравнению с оценками хабара,

127
00:04:17,918 --> 00:04:20,238
так что вау, так  Конечно, мы знаем, какой

128
00:04:20,238 --> 00:04:21,519
ответ следует дать, что мы

129
00:04:21,519 --> 00:04:23,360
говорим, по сути, о

130
00:04:23,360 --> 00:04:26,080
создании состязательного набора данных модели в цикле, который

131
00:04:26,080 --> 00:04:28,400
приводит нас к чертовой добыче, они внесли некоторые

132
00:04:28,400 --> 00:04:30,320
изменения в наборы данных, которые они используют

133
00:04:30,320 --> 00:04:31,840
для чертовой добычи, но я бы сказал, что

134
00:04:31,840 --> 00:04:34,240
фундаментальные  дело в том, что мы делаем

135
00:04:34,240 --> 00:04:36,160
такую же фильтрацию со стороны

136
00:04:36,160 --> 00:04:38,800
генератора, за исключением того, что теперь у нас есть гораздо более

137
00:04:38,800 --> 00:04:41,280
мощные модели фильтрации и генератора

138
00:04:41,280 --> 00:04:42,960
благодаря разработке  вопросы, связанные с

139
00:04:42,960 --> 00:04:45,600
трансформерами, так что для heliswag у нас снова

140
00:04:45,600 --> 00:04:47,120
есть человеческая производительность, которая действительно

141
00:04:47,120 --> 00:04:49,440
хороша, это очень обнадеживает, потому что мы

142
00:04:49,440 --> 00:04:51,520
используем гораздо более мощные модели на

143
00:04:51,520 --> 00:04:52,639
четвертом шаге,

144
00:04:52,639 --> 00:04:55,360
как вы можете ожидать, Берт уже не

145
00:04:55,360 --> 00:04:57,600
может легко решить эту проблему,

146
00:04:57,600 --> 00:04:59,360
вот дальнейшее резюме  результаты

147
00:04:59,360 --> 00:05:01,600
с burt big, прежде чем помните, что это по

148
00:05:01,600 --> 00:05:03,840
существу решает хабар, теперь он упал

149
00:05:03,840 --> 00:05:05,039
примерно на 50,

150
00:05:05,039 --> 00:05:05,919
что

151
00:05:05,919 --> 00:05:07,919
показывает, что он все еще получает тягу, но не имеет

152
00:05:07,919 --> 00:05:09,440
ничего общего с человеческими

153
00:05:09,440 --> 00:05:11,199
сверхчеловеческими способностями, которые мы видели для

154
00:05:11,199 --> 00:05:13,039
хабара,

155
00:05:13,039 --> 00:05:14,400
хорошо, теперь давайте перейдем в немного

156
00:05:14,400 --> 00:05:15,759
другой режим, и это будет  будьте своего

157
00:05:15,759 --> 00:05:17,680
рода человеком в

158
00:05:17,680 --> 00:05:20,240
методе создания состязательного набора данных первой записью

159
00:05:20,240 --> 00:05:22,400
в этом пространстве был состязательный

160
00:05:22,400 --> 00:05:23,840
набор данных nli, я думаю, что это действительно

161
00:05:23,840 --> 00:05:26,400
дальновидный и захватывающий документ,

162
00:05:26,400 --> 00:05:29,600
состязательный nli является прямым ответом

163
00:05:29,600 --> 00:05:31,919
на предыдущие вещи, которые мы видели

164
00:05:31,919 --> 00:05:34,880
с наборами данных snli и multi-nli, где

165
00:05:34,880 --> 00:05:36,560
модели, кажется, хорошо справляются с этими

166
00:05:36,560 --> 00:05:39,199
тестами, но легко уязвимы для

167
00:05:39,199 --> 00:05:41,919
простых противников с  adversarial nli

168
00:05:41,919 --> 00:05:44,639
мы надеемся сделать

169
00:05:44,639 --> 00:05:46,800
системы намного более устойчивыми к этим противникам

170
00:05:46,800 --> 00:05:48,800
и исследовать гораздо более широкий спектр

171
00:05:48,800 --> 00:05:50,880
вещей, которые вы можете увидеть под

172
00:05:50,880 --> 00:05:52,960
заголовком вывода на естественном языке, так что

173
00:05:52,960 --> 00:05:54,400
вот как это работало,

174
00:05:54,400 --> 00:05:56,319
есть человек в петле  аннотатору

175
00:05:56,319 --> 00:05:57,919
и аннотатору предоставляется предложение с

176
00:05:57,919 --> 00:06:00,080
предпосылкой и условие, в котором

177
00:06:00,080 --> 00:06:01,840
они должны находиться, которое является просто

178
00:06:01,840 --> 00:06:03,759
противоречием или нейтральным следствием nli label,

179
00:06:03,759 --> 00:06:05,199


180
00:06:05,199 --> 00:06:07,280
аннотатор пишет гипотезу,

181
00:06:07,280 --> 00:06:09,440
соответствующую предпосылке и условию,

182
00:06:09,440 --> 00:06:11,280
а затем состояние  - появляется современная модель

183
00:06:11,280 --> 00:06:12,800
и делает прогноз относительно

184
00:06:12,800 --> 00:06:15,120
пары предпосылок-гипотез,

185
00:06:15,120 --> 00:06:16,960
если прогноз модели соответствует

186
00:06:16,960 --> 00:06:18,639
условию, то есть если модель была

187
00:06:18,639 --> 00:06:20,560
правильной, то аннотатор должен

188
00:06:20,560 --> 00:06:22,800
вернуться на второй шаг и повторить попытку с

189
00:06:22,800 --> 00:06:25,280
новой гипотезой, и мы могли бы продолжить  в

190
00:06:25,280 --> 00:06:26,319
этом цикле,

191
00:06:26,319 --> 00:06:28,080
если модель была обманута, пара предпосылок-

192
00:06:28,080 --> 00:06:29,680
гипотез независимо

193
00:06:29,680 --> 00:06:31,919
проверяется другими аннотаторами, конечно,

194
00:06:31,919 --> 00:06:34,479
так что мы получаем из этого, что мы надеемся, что

195
00:06:34,479 --> 00:06:36,560
данные  набор, который интуитивно понятен для людей

196
00:06:36,560 --> 00:06:38,639
из-за проверки на пятом шаге, но

197
00:06:38,639 --> 00:06:40,240
при условии, что мы продолжаем

198
00:06:40,240 --> 00:06:42,560
перебирать два, три и четыре, пример

199
00:06:42,560 --> 00:06:44,319
, который действительно сложен для любой

200
00:06:44,319 --> 00:06:45,919
модели, находящейся в цикле,

201
00:06:45,919 --> 00:06:48,000
и ожидается, что по мере того, как мы помещаем все

202
00:06:48,000 --> 00:06:49,520
лучшие и лучшие модели  в цикле

203
00:06:49,520 --> 00:06:50,880
здесь мы собираемся получить еще более

204
00:06:50,880 --> 00:06:55,440
сложные наборы данных в качестве результата.

205
00:06:55,440 --> 00:06:57,360
nli примеры, как правило, впечатляюще

206
00:06:57,360 --> 00:06:59,039
сложны, вы можете видеть, что этот пример

207
00:06:59,039 --> 00:07:01,919
имеет очень длинную предпосылку,

208
00:07:01,919 --> 00:07:03,759
гипотеза относительно короче, и интригующий

209
00:07:03,759 --> 00:07:06,160
аспект состязательной MLI заключается в том, что

210
00:07:06,160 --> 00:07:08,400
аннотаторы также построили причину

211
00:07:08,400 --> 00:07:10,240
или обоснование своего ярлыка

212
00:07:10,240 --> 00:07:12,560
между парой предпосылок и гипотез. На

213
00:07:12,560 --> 00:07:14,160
сегодняшний день, насколько мне известно,

214
00:07:14,160 --> 00:07:15,919
эти тексты использовались относительно мало,

215
00:07:15,919 --> 00:07:17,440
но я думаю, что они могли бы привнести другие

216
00:07:17,440 --> 00:07:19,919
аспекты рассуждений о выводе на естественном языке,

217
00:07:19,919 --> 00:07:21,520
и это могло бы  быть захватывающим

218
00:07:21,520 --> 00:07:24,160
новым направлением

219
00:07:24,160 --> 00:07:27,039
состязательности nli - это сложный набор данных,

220
00:07:27,039 --> 00:07:28,560
действительно, у нас есть похожая

221
00:07:28,560 --> 00:07:30,000
таблица лидеров, которую мы видели на протяжении всей

222
00:07:30,000 --> 00:07:32,319
этой игры.  dversarial режим, когда

223
00:07:32,319 --> 00:07:34,400
в разных раундах li

224
00:07:34,400 --> 00:07:36,720
есть три или в совокупности для набора данных,

225
00:07:36,720 --> 00:07:39,599
даже действительно отличные модели, которые

226
00:07:39,599 --> 00:07:42,560
действительно хорошо работают на snli и multi-nli,

227
00:07:42,560 --> 00:07:45,280
публикуют очень низкие числа для

228
00:07:45,280 --> 00:07:47,280
всех этих вариантов набора данных, и

229
00:07:47,280 --> 00:07:49,360
это показывает вам  что это действительно

230
00:07:49,360 --> 00:07:51,759
сложная проблема, и, насколько я знаю,

231
00:07:51,759 --> 00:07:54,319
не было достигнуто большого прогресса с тех пор, как

232
00:07:54,319 --> 00:07:56,160
этот набор данных был выпущен для увеличения

233
00:07:56,160 --> 00:07:57,520
этих чисел,

234
00:07:57,520 --> 00:08:00,960
так что это представляет собой интересную проблему,

235
00:08:00,960 --> 00:08:02,560
отступая здесь, я просто хотел бы сказать,

236
00:08:02,560 --> 00:08:04,240
что я думаю  в этой статье мы находим

237
00:08:04,240 --> 00:08:06,240
реальное видение будущего развития,

238
00:08:06,240 --> 00:08:07,840
и вы видите это также в

239
00:08:07,840 --> 00:08:11,280
добыче в справочных документах, поскольку эти авторы говорят,

240
00:08:11,280 --> 00:08:13,360
что создание состязательного набора данных — это

241
00:08:13,360 --> 00:08:15,440
путь для прогресса nlp, продвигающегося вперед

242
00:08:15,440 --> 00:08:17,440
к эталонным показателям, которые состязательно

243
00:08:17,440 --> 00:08:19,840
развиваются вместе с развивающимся состоянием.  современные

244
00:08:19,840 --> 00:08:22,160
модели прямо с swag и heliswag мы

245
00:08:22,160 --> 00:08:24,000
видели, что эта swag была решена, но

246
00:08:24,000 --> 00:08:26,479
ответ был ясен: принесите лучшую

247
00:08:26,479 --> 00:08:28,319
модель и используйте ее для создания последующего

248
00:08:28,319 --> 00:08:31,280
набора данных, который  представляет собой реальную проблему, у

249
00:08:31,280 --> 00:08:32,880
вас есть аналогичная картина из

250
00:08:32,880 --> 00:08:35,760
состязательной бумаги nli, этот

251
00:08:35,760 --> 00:08:38,000
процесс итерационных раундов с людьми

252
00:08:38,000 --> 00:08:40,559
в цикле дает движущуюся пост-динамическую

253
00:08:40,559 --> 00:08:41,760
цель для систем понимания естественного языка,

254
00:08:41,760 --> 00:08:43,919
а не

255
00:08:43,919 --> 00:08:45,600
статические тесты, которые в конечном итоге

256
00:08:45,600 --> 00:08:48,080
насыщаются, и мы видели  многократно повторяю, что

257
00:08:48,080 --> 00:08:49,920
наши тесты очень быстро насыщаются в

258
00:08:49,920 --> 00:08:51,760
эти дни, поэтому нам нужен такой

259
00:08:51,760 --> 00:08:53,680
движущийся пост, чтобы убедиться, что мы продолжаем добиваться

260
00:08:53,680 --> 00:08:54,399


261
00:08:54,399 --> 00:08:56,800
значимого прогресса,

262
00:08:56,800 --> 00:08:59,120
который дал начало проекту neodoll, я считаю

263
00:08:59,120 --> 00:09:01,040
, что эта платформа dynabench является платформой с открытым

264
00:09:01,040 --> 00:09:03,120
исходным кодом для модели и человека

265
00:09:03,120 --> 00:09:05,279
в наборе данных цикла  создание

266
00:09:05,279 --> 00:09:07,279
там на момент написания этой статьи есть четыре

267
00:09:07,279 --> 00:09:08,720
доступных набора данных, которые были

268
00:09:08,720 --> 00:09:11,839
созданы на dynabench, набор данных nli,

269
00:09:11,839 --> 00:09:14,640
который является своего рода преемником li,

270
00:09:14,640 --> 00:09:17,120
набор данных для ответов на вопросы, набор данных о

271
00:09:17,120 --> 00:09:20,000
настроениях и набор данных о разжигании ненависти,

272
00:09:20,000 --> 00:09:22,000
поэтому, если вы  вы работаете над задачами этой

273
00:09:22,000 --> 00:09:23,920
формы, или у вас есть модель, которая подходит

274
00:09:23,920 --> 00:09:26,160
для этой формы для одной из этих задач, я

275
00:09:26,160 --> 00:09:28,000
бы посоветовал вам  Изучите некоторые

276
00:09:28,000 --> 00:09:30,399
обучающие системы на этих наборах данных,

277
00:09:30,399 --> 00:09:32,800
чтобы увидеть, добиваетесь ли вы прогресса,

278
00:09:32,800 --> 00:09:34,160
или они являются настоящими

279
00:09:34,160 --> 00:09:35,760
противниками любых инновационных

280
00:09:35,760 --> 00:09:37,839
вещей, которые вы делаете,

281
00:09:37,839 --> 00:09:39,760
наконец, я хочу закрыть действительно

282
00:09:39,760 --> 00:09:41,279
важным вопросом для этой области, которая

283
00:09:41,279 --> 00:09:43,200
остается

284
00:09:43,200 --> 00:09:45,600
может ли состязательное обучение улучшить системы,

285
00:09:45,600 --> 00:09:47,760
есть опасения, что по мере того, как мы

286
00:09:47,760 --> 00:09:50,080
создаем все более сложные наборы данных, мы

287
00:09:50,080 --> 00:09:52,560
толкаем системы в незнакомые

288
00:09:52,560 --> 00:09:54,720
части лингвистического и концептуального пространства,

289
00:09:54,720 --> 00:09:56,959
что может фактически ухудшить их производительность в реальном

290
00:09:56,959 --> 00:09:59,040
мире, мы должны следить

291
00:09:59,040 --> 00:10:01,680
за этим  и доказательства до сих пор, я думаю

292
00:10:01,680 --> 00:10:03,519
, указывают на «да» в качестве ответа на этот

293
00:10:03,519 --> 00:10:05,440
вопрос, но доказательства немного смешаны,

294
00:10:05,440 --> 00:10:07,680
поэтому я упомянул, что в

295
00:10:07,680 --> 00:10:10,079
состязательном документе отряда от gia о

296
00:10:10,079 --> 00:10:12,000
обучении на состязательных примерах делает

297
00:10:12,000 --> 00:10:13,839
их более отдаленными устойчивыми к  к этим

298
00:10:13,839 --> 00:10:16,800
примерам, но не к простым вариантам, поэтому

299
00:10:16,800 --> 00:10:19,920


300
00:10:19,920 --> 00:10:21,120
в этой статье вряд ли есть большой прогресс, они обнаружили, что

301
00:10:21,120 --> 00:10:22,880
состязательное обучение не обеспечивает

302
00:10:22,880 --> 00:10:24,959
дополнительной надежности  эффективность в

303
00:10:24,959 --> 00:10:26,880
экспериментах с использованием тестового набора, несмотря

304
00:10:26,880 --> 00:10:28,399
на то, что модель достигла почти

305
00:10:28,399 --> 00:10:31,040
100 точности, классифицируя враждебные

306
00:10:31,040 --> 00:10:33,200
примеры, включенные в набор поездов, так

307
00:10:33,200 --> 00:10:35,279
что это более тревожная картина,

308
00:10:35,279 --> 00:10:37,279
но это более обнадеживающая тонкая настройка

309
00:10:37,279 --> 00:10:39,279
с несколькими враждебными примерами

310
00:10:39,279 --> 00:10:42,079
в некоторых случаях улучшает системы  особенно там, где

311
00:10:42,079 --> 00:10:44,320
вы вносите прививку, и это

312
00:10:44,320 --> 00:10:46,000
обнадеживает, еще раз

313
00:10:46,000 --> 00:10:48,079
сгенерированные противником перефразы улучшают

314
00:10:48,079 --> 00:10:50,800
надежность модели до синтаксической вариации, это

315
00:10:50,800 --> 00:10:53,040
действительно мечта, что в

316
00:10:53,040 --> 00:10:55,279
результате этого нового вида обучения мы

317
00:10:55,279 --> 00:10:57,760
получаем действительно более надежные системы,

318
00:10:57,760 --> 00:10:59,760
но я думаю, что нам нужно  больше доказательств по

319
00:10:59,760 --> 00:11:01,760
этой картине, что означает больше наборов

320
00:11:01,760 --> 00:11:04,240
данных в этой форме и более интересное

321
00:11:04,240 --> 00:11:06,320
использование доступных ресурсов,

322
00:11:06,320 --> 00:11:07,760
и я просто хотел бы увидеть,

323
00:11:07,760 --> 00:11:09,600
какая картина появится в течение следующих года

324
00:11:09,600 --> 00:11:12,760
или двух

325
00:11:15,120 --> 00:11:17,200
вы

