1
00:00:05,200 --> 00:00:06,720
приветствую всех, это четвертая часть

2
00:00:06,720 --> 00:00:08,720
нашей серии статей о методах анализа в НЛП,

3
00:00:08,720 --> 00:00:10,240
мы собираемся поговорить о зондировании,

4
00:00:10,240 --> 00:00:12,160
это первый из двух

5
00:00:12,160 --> 00:00:13,599
методов структурной оценки, которые мы собираемся

6
00:00:13,599 --> 00:00:14,559
рассмотреть,

7
00:00:14,559 --> 00:00:16,239
пришло время по-настоящему задуматься

8
00:00:16,239 --> 00:00:18,800
о наших моделях.  мы делаем

9
00:00:18,800 --> 00:00:21,039
здесь обзор идеи зондирования.

10
00:00:21,039 --> 00:00:23,279
Суть в том, что

11
00:00:23,279 --> 00:00:24,960
мы собираемся использовать модели

12
00:00:24,960 --> 00:00:27,680
с учителем, это модели зондирования, чтобы определить,

13
00:00:27,680 --> 00:00:29,760
что латентно закодировано в скрытых

14
00:00:29,760 --> 00:00:33,440
представлениях наших целевых моделей,

15
00:00:33,440 --> 00:00:35,440
это часто применяется в контексте

16
00:00:35,440 --> 00:00:38,000
бертологии, которая  было бы похоже на то, что у меня есть

17
00:00:38,000 --> 00:00:39,760
bert в качестве предварительно обученного артефакта, и я

18
00:00:39,760 --> 00:00:41,760
хотел бы понять природу

19
00:00:41,760 --> 00:00:43,680
его скрытых представлений, что они

20
00:00:43,680 --> 00:00:46,000
латентно кодируют, и для этого вы можете

21
00:00:46,000 --> 00:00:49,120
использовать pro-models

22
00:00:49,280 --> 00:00:51,120
probink, поскольку вы увидите, что он может быть

23
00:00:51,120 --> 00:00:52,800
источником действительно ценного и  интересные

24
00:00:52,800 --> 00:00:55,120
идеи, но нам нужно действовать

25
00:00:55,120 --> 00:00:58,800
осторожно по двум основным вопросам, во-первых,

26
00:00:58,800 --> 00:01:01,199
очень мощная модель зонда, поскольку это

27
00:01:01,199 --> 00:01:03,760
контролируемая модель, которая может привести вас к тому, чтобы увидеть это.

28
00:01:03,760 --> 00:01:05,840
ngs, которые на самом деле не находятся в вашей целевой

29
00:01:05,840 --> 00:01:07,680
модели, а просто то,

30
00:01:07,680 --> 00:01:09,520
чему научилась ваша модель зонда,

31
00:01:09,520 --> 00:01:12,240
и поэтому вы можете передиагностировать

32
00:01:12,240 --> 00:01:14,799
скрытую информацию в вашей целевой модели,

33
00:01:14,799 --> 00:01:16,479
когда на самом деле вся она хранится

34
00:01:16,479 --> 00:01:17,920
в зонде, и я собираюсь предложить вам

35
00:01:17,920 --> 00:01:20,320
метод навигации по этому

36
00:01:20,320 --> 00:01:21,600
ботинку,

37
00:01:21,600 --> 00:01:23,439
второй заключается в том, что зонды не могут

38
00:01:23,439 --> 00:01:25,200
сказать нам о том, имеет ли информация,

39
00:01:25,200 --> 00:01:26,720
которую мы

40
00:01:26,720 --> 00:01:28,799
идентифицируем, какую-либо причинно-следственную связь с

41
00:01:28,799 --> 00:01:30,720
поведением целевой модели, у вас будет очень

42
00:01:30,720 --> 00:01:32,720
соблазнительный ответ: «О, я

43
00:01:32,720 --> 00:01:34,720
обнаружил, что этот

44
00:01:34,720 --> 00:01:36,560
уровень представления включает в себя

45
00:01:36,560 --> 00:01:38,880
информации о части речи, и поэтому вы можете

46
00:01:38,880 --> 00:01:40,320
заключить, что информация о части

47
00:01:40,320 --> 00:01:42,159
речи важна для любой

48
00:01:42,159 --> 00:01:44,960
поставленной вами задачи, но на самом деле мы не можем

49
00:01:44,960 --> 00:01:46,799
сделать такой вывод, возможно, что информация о

50
00:01:46,799 --> 00:01:48,640
части речи просто

51
00:01:48,640 --> 00:01:51,040
скрыто закодирована, но на самом деле не имеет

52
00:01:51,040 --> 00:01:52,960
особого отношения к  поведение ввода-вывода вашей модели. В

53
00:01:52,960 --> 00:01:56,320


54
00:01:57,280 --> 00:01:58,719
последнем разделе этого слайд-шоу

55
00:01:58,719 --> 00:02:00,079
я собираюсь кратко рассказать о

56
00:02:00,079 --> 00:02:02,320
неконтролируемых зондах, которые  ch, по-видимому,

57
00:02:02,320 --> 00:02:04,159
здесь решает эту первую проблему, заключающуюся в том, что

58
00:02:04,159 --> 00:02:05,840
зондовая модель на самом деле может быть той вещью,

59
00:02:05,840 --> 00:02:08,000
которая кодирует всю эту информацию,

60
00:02:08,000 --> 00:02:10,080
которую мы, как мы утверждаем, обнаружили,

61
00:02:10,080 --> 00:02:11,760
а затем, когда мы говорим о

62
00:02:11,760 --> 00:02:14,080
методах атрибуции признаков, мы приблизимся к

63
00:02:14,080 --> 00:02:15,599
тому, чтобы решить некоторые из них.  эти

64
00:02:15,599 --> 00:02:18,080
причинно-следственные вопросы,

65
00:02:18,080 --> 00:02:19,920
давайте начнем с основного метода

66
00:02:19,920 --> 00:02:22,000
исследования, и только потому, что это

67
00:02:22,000 --> 00:02:24,239
типичное обрамление этих идей, я

68
00:02:24,239 --> 00:02:25,840
изобразил здесь то, что вы можете представить как

69
00:02:25,840 --> 00:02:27,760
своего рода модель на основе трансформатора,

70
00:02:27,760 --> 00:02:30,319
где у нас есть три слоя со

71
00:02:30,319 --> 00:02:32,080
всеми этими блоками.  это, возможно,

72
00:02:32,080 --> 00:02:33,920
выходные представления от каждого из

73
00:02:33,920 --> 00:02:35,920
блоков преобразователя, и вы можете видеть, что у

74
00:02:35,920 --> 00:02:37,760
меня есть входная последовательность, поступающая

75
00:02:37,760 --> 00:02:40,239
сюда, и идея заключалась бы в том, что мы могли бы

76
00:02:40,239 --> 00:02:42,080
выбрать какое-то скрытое представление в этой

77
00:02:42,080 --> 00:02:44,400
модели, например, это среднее h здесь, и

78
00:02:44,400 --> 00:02:46,239
решить  что мы собираемся

79
00:02:46,239 --> 00:02:48,800
подогнать небольшую линейную модель, предположительно, к этому

80
00:02:48,800 --> 00:02:50,480
скрытому представлению,

81
00:02:50,480 --> 00:02:52,239
и посмотрим, сможем ли мы выяснить

82
00:02:52,239 --> 00:02:54,319
, кодирует ли это представление какую-то

83
00:02:54,319 --> 00:02:56,400
информацию.  о какой-то задаче, которая нас

84
00:02:56,400 --> 00:02:58,480
волнует, например, если вы хотите

85
00:02:58,480 --> 00:03:00,480
выяснить, были ли закодированы настроения или лексические

86
00:03:00,480 --> 00:03:02,640
следствия в этот момент,

87
00:03:02,640 --> 00:03:04,239
вам понадобится набор данных меток для

88
00:03:04,239 --> 00:03:06,080
настроений или следствий,

89
00:03:06,080 --> 00:03:07,760
а затем вы подгоните модель зонда

90
00:03:07,760 --> 00:03:09,519
к этому представлению и  используйте это, чтобы

91
00:03:09,519 --> 00:03:11,680
определить степень, в которой эта

92
00:03:11,680 --> 00:03:14,080
информация закодирована там,

93
00:03:14,080 --> 00:03:15,840
это изображение немного поэтично,

94
00:03:15,840 --> 00:03:17,120
поэтому стоит просто механически пройтись по

95
00:03:17,120 --> 00:03:18,560
тому, что вы на самом деле будете

96
00:03:18,560 --> 00:03:21,040
делать, вы должны использовать эту модель bert и

97
00:03:21,040 --> 00:03:23,040
обрабатывать различные примеры, такие как для

98
00:03:23,040 --> 00:03:25,040
последовательности здесь и  получить выходное

99
00:03:25,040 --> 00:03:26,799
представление, которое должно быть связано

100
00:03:26,799 --> 00:03:28,560
с некоторой меткой задачи,

101
00:03:28,560 --> 00:03:30,319
и вы будете неоднократно делать это для

102
00:03:30,319 --> 00:03:32,000
разных входных данных, вы по существу

103
00:03:32,000 --> 00:03:35,120
используете эту модель bert в качестве механизма для

104
00:03:35,120 --> 00:03:36,799
создания представлений, которые

105
00:03:36,799 --> 00:03:38,640
станут вашей матрицей представления функций

106
00:03:38,640 --> 00:03:42,000
x в паре с вашими метками y и

107
00:03:42,000 --> 00:03:44,080
это  эта модель будет основой

108
00:03:44,080 --> 00:03:46,400
для вашей модели линейного зонда эта небольшая

109
00:03:46,400 --> 00:03:48,959
линейная модель, как я определил ее здесь,

110
00:03:48,959 --> 00:03:50,400
так что вы  Использование птицы в качестве

111
00:03:50,400 --> 00:03:52,640
механизма для создания набора данных, который затем

112
00:03:52,640 --> 00:03:54,720
является входными данными для задачи обучения с учителем.

113
00:03:54,720 --> 00:03:56,319
Другая точка зрения заключается в том,

114
00:03:56,319 --> 00:03:58,720
что в этом случае вы как бы используете замороженные

115
00:03:58,720 --> 00:04:00,400
параметры

116
00:04:00,400 --> 00:04:02,239
и подгоняете модель поверх них, это

117
00:04:02,239 --> 00:04:04,159
просто так.  вместо выбора точки вывода

118
00:04:04,159 --> 00:04:06,879
вы выбираете, возможно,

119
00:04:06,879 --> 00:04:09,519
одно из внутренних представлений,

120
00:04:09,519 --> 00:04:12,000
и это очень общее, и на самом деле

121
00:04:12,000 --> 00:04:13,760
чаще всего, когда вы читаете без зондов

122
00:04:13,760 --> 00:04:14,879
в литературе, они на самом деле представляют собой

123
00:04:14,879 --> 00:04:16,798
проблемы последовательности, такие как тегирование части речи

124
00:04:16,798 --> 00:04:19,600
или распознавание именованных объектов, и,

125
00:04:19,600 --> 00:04:21,519
следовательно,  вы можете использовать целый слой

126
00:04:21,519 --> 00:04:24,000
или даже набор слоев в качестве основы для

127
00:04:24,000 --> 00:04:26,880
вашей модели зонда.

128
00:04:27,040 --> 00:04:29,360
Теперь вы можете услышать в моем описании,

129
00:04:29,360 --> 00:04:30,960
что есть что-то вроде интересного

130
00:04:30,960 --> 00:04:32,560
суждения, которое вы делаете о

131
00:04:32,560 --> 00:04:34,720
том, исследуете ли вы или просто

132
00:04:34,720 --> 00:04:37,120
изучаете  новые модели правильных зондов в том

133
00:04:37,120 --> 00:04:39,120
смысле, что я только что представил их,

134
00:04:39,120 --> 00:04:41,280
являются контролируемыми моделями, чьи входные данные являются

135
00:04:41,280 --> 00:04:43,120
замороженными параметрами моделей, которые

136
00:04:43,120 --> 00:04:45,360
мы зондируем в наших целевых моделях,

137
00:04:45,360 --> 00:04:47,440
это правильно.  трудно отличить от простой

138
00:04:47,440 --> 00:04:49,840
подгонки модели под наблюдением, как обычно, с

139
00:04:49,840 --> 00:04:53,600
каким-то конкретным выбором характеристик,

140
00:04:53,600 --> 00:04:56,000
поскольку в результате этого, по сути,

141
00:04:56,000 --> 00:04:57,919
заранее сделан вывод о том, что по крайней мере

142
00:04:57,919 --> 00:05:00,400
часть информации, которую мы идентифицируем с помощью

143
00:05:00,400 --> 00:05:02,560
нашего зонда, фактически хранится в

144
00:05:02,560 --> 00:05:04,240
параметрах модели зонда и

145
00:05:04,240 --> 00:05:06,000
просто мы предоставили полезные функции ввода,

146
00:05:06,000 --> 00:05:08,400
которые позволяют этому зонду быть

147
00:05:08,400 --> 00:05:10,400
успешным, и в этом смысле

148
00:05:10,400 --> 00:05:12,800
входы латентно кодируют эту

149
00:05:12,800 --> 00:05:14,560
информацию, но с зондом мы

150
00:05:14,560 --> 00:05:16,479
не определили, что он действительно скрыт,

151
00:05:16,479 --> 00:05:18,639
а скорее что он принимает

152
00:05:18,639 --> 00:05:20,880
ступенька к модели, которая может

153
00:05:20,880 --> 00:05:23,120
быть успешной в этом, задумана

154
00:05:23,120 --> 00:05:25,360
как тест обучения с учителем, поэтому это

155
00:05:25,360 --> 00:05:27,440
важные различия, о которых следует помнить,

156
00:05:27,440 --> 00:05:30,400
поскольку в результате этого более мощные зонды,

157
00:05:30,400 --> 00:05:32,400
такие как глубокие нейронные сети,

158
00:05:32,400 --> 00:05:34,639
могут найти больше информации, чем простые

159
00:05:34,639 --> 00:05:36,479
линейные модели, но это  не потому, что

160
00:05:36,479 --> 00:05:38,160
они могут извлечь больше

161
00:05:38,160 --> 00:05:40,400
информации из самих представлений,

162
00:05:40,400 --> 00:05:42,720
а потому, что  как видите, профессиональная

163
00:05:42,720 --> 00:05:45,440
модель теперь имеет гораздо больше возможностей

164
00:05:45,440 --> 00:05:47,440
для хранения информации о задаче,

165
00:05:47,440 --> 00:05:49,360
которую вы исследуете,

166
00:05:49,360 --> 00:05:50,479
поэтому здесь есть куча различных

167
00:05:50,479 --> 00:05:53,360
вызовов суждений, и это

168
00:05:53,360 --> 00:05:55,280
сложно очень продуктивный вход в это пространство

169
00:05:55,280 --> 00:05:56,960
- это действительно прекрасная статья от Hewitt

170
00:05:56,960 --> 00:05:59,280
и 2019 год, когда они ввели

171
00:05:59,280 --> 00:06:01,520
понятие контрольной задачи и

172
00:06:01,520 --> 00:06:03,280
соответствующую метрику избирательности проверки,

173
00:06:03,280 --> 00:06:05,840
поэтому здесь идея контрольной

174
00:06:05,840 --> 00:06:08,800
задачи будет некоторой случайной задачей с той

175
00:06:08,800 --> 00:06:10,960
же структурой ввода-вывода, что и

176
00:06:10,960 --> 00:06:12,800
целевой тест, который мы хотим использовать для нашего

177
00:06:12,800 --> 00:06:14,160
исследования,

178
00:06:14,160 --> 00:06:15,840
например  например, для классификации слов по смыслу у

179
00:06:15,840 --> 00:06:17,520
вас могут быть слова, которым

180
00:06:17,520 --> 00:06:19,919
назначены случайные фиксированные смыслы слов,

181
00:06:19,919 --> 00:06:22,400
независимые от их контекста, или для

182
00:06:22,400 --> 00:06:23,919
маркировки части речи вместо использования

183
00:06:23,919 --> 00:06:25,840
фактической части речевых тегов вы можете

184
00:06:25,840 --> 00:06:29,199
случайным образом назначать слова фиксированным тегам из

185
00:06:29,199 --> 00:06:30,960
того же пространства тегов

186
00:06:30,960 --> 00:06:33,120
или для синтаксического анализа  это становится немного более

187
00:06:33,120 --> 00:06:35,280
нюансированным, но у вас могут быть некоторые

188
00:06:35,280 --> 00:06:37,120
стратегии назначения ребер, которые вы

189
00:06:37,120 --> 00:06:39,280
используете полуслучайно, чтобы связать разные

190
00:06:39,280 --> 00:06:41,759
пары o  f слов в своего рода псевдоанализ,

191
00:06:41,759 --> 00:06:43,840
и это будет служить контрольной

192
00:06:43,840 --> 00:06:46,080
задачей для попытки выявить скрытую фактическую

193
00:06:46,080 --> 00:06:48,080
информацию о разборе,

194
00:06:48,080 --> 00:06:50,319
так что это контрольные задачи, а затем

195
00:06:50,319 --> 00:06:52,479
избирательность — это просто разница

196
00:06:52,479 --> 00:06:54,400
между вашей производительностью зонда в

197
00:06:54,400 --> 00:06:56,880
задаче и вашей идентичной структурой модели зонда

198
00:06:56,880 --> 00:06:57,919


199
00:06:57,919 --> 00:07:00,560
на  эти контрольные задачи,

200
00:07:00,560 --> 00:07:02,800
и Хьюитт и Леон используют это, чтобы

201
00:07:02,800 --> 00:07:04,160
выявить то, что я думаю, является довольно ясной

202
00:07:04,160 --> 00:07:06,400
интуицией, которая заключается в том, что по мере того, как вы получаете более

203
00:07:06,400 --> 00:07:08,720
мощные зонды, они просто становятся менее

204
00:07:08,720 --> 00:07:11,840
избирательными, поэтому вдоль оси x здесь у нас

205
00:07:11,840 --> 00:07:14,720
есть млп скрытых единиц, поэтому у нас есть

206
00:07:14,720 --> 00:07:16,560
сложность модели слева направо, где у нас

207
00:07:16,560 --> 00:07:18,639
есть очень сложные мощные модели

208
00:07:18,639 --> 00:07:20,080
с правой стороны,

209
00:07:20,080 --> 00:07:22,080
и здесь у нас есть точность,

210
00:07:22,080 --> 00:07:24,319
и мы измеряем нашу контрольную задачу

211
00:07:24,319 --> 00:07:25,360
красным цветом,

212
00:07:25,360 --> 00:07:27,520
а нашу фактическую задачу зонда - этим

213
00:07:27,520 --> 00:07:29,919
голубым здесь, и селективность - это

214
00:07:29,919 --> 00:07:32,160
разница между этими  два, так что вы можете

215
00:07:32,160 --> 00:07:34,080
видеть, например, что очень слабые

216
00:07:34,080 --> 00:07:36,319
модели с двумя скрытыми

217
00:07:36,319 --> 00:07:39,440
единицами имеют очень высокую избирательность, тогда как

218
00:07:39,440 --> 00:07:41,520
к тому времени, когда у меня есть это очень  мощный

219
00:07:41,520 --> 00:07:43,599
млп с большим количеством скрытых юнитов

220
00:07:43,599 --> 00:07:45,680
избирательность почти нулевая,

221
00:07:45,680 --> 00:07:47,680
и очень сложно сказать, что вы

222
00:07:47,680 --> 00:07:49,919
раскрыли какую-то скрытую информацию, потому что

223
00:07:49,919 --> 00:07:50,960
даже

224
00:07:50,960 --> 00:07:54,080
задача управления полностью решаема

225
00:07:54,080 --> 00:07:56,879
с моделью, которая имеет такую большую мощность,

226
00:07:56,879 --> 00:07:58,160
так что я думаю, к чему это толкает

227
00:07:58,160 --> 00:08:01,120


228
00:08:01,120 --> 00:08:03,280


229
00:08:03,280 --> 00:08:05,919


230
00:08:05,919 --> 00:08:09,440


231
00:08:09,440 --> 00:08:11,120
Это важный и простой практический

232
00:08:11,120 --> 00:08:12,560
шаг, который даст вам более четкое

233
00:08:12,560 --> 00:08:14,960
представление о том, что вы на самом деле обнаружили.

234
00:08:14,960 --> 00:08:17,280
с вашим зондом

235
00:08:17,280 --> 00:08:18,960
это первая проблема, вторая проблема

236
00:08:18,960 --> 00:08:20,160
- это просто то, что вы должны иметь

237
00:08:20,160 --> 00:08:22,479
в виду как теоретический факт о

238
00:08:22,479 --> 00:08:23,759
зондировании, который заключается в том, что он

239
00:08:23,759 --> 00:08:25,680
фундаментально ограничен в том смысле, что

240
00:08:25,680 --> 00:08:28,160
он не может сказать вам, что информация, которую

241
00:08:28,160 --> 00:08:30,400
вы обнаруживаете, имеет какое-либо причинное влияние на

242
00:08:30,400 --> 00:08:32,719
поведения ввода-вывода модели, чтобы

243
00:08:32,719 --> 00:08:34,080
проиллюстрировать это, я просто покажу

244
00:08:34,080 --> 00:08:36,320
вам простой пример, который как бы доказывает

245
00:08:36,320 --> 00:08:37,120
это,

246
00:08:37,120 --> 00:08:38,719
так что представьте здесь, на  слева у меня

247
00:08:38,719 --> 00:08:40,240
есть простая модель, которая будет принимать

248
00:08:40,240 --> 00:08:41,760
три целых числа

249
00:08:41,760 --> 00:08:43,919
и суммировать их, поэтому вывод здесь

250
00:08:43,919 --> 00:08:45,760
будет суммой трех целых чисел, например, если я

251
00:08:45,760 --> 00:08:48,399
добавлю один два три, он выведет шесть, и

252
00:08:48,399 --> 00:08:50,320
он делает это, представляя каждое из

253
00:08:50,320 --> 00:08:52,880
этих целых чисел  как одномерный

254
00:08:52,880 --> 00:08:55,040
вектор, который просто является этим целым числом, а

255
00:08:55,040 --> 00:08:56,160
затем у нас есть целая куча

256
00:08:56,160 --> 00:08:58,320
преобразователей, таких как параметры модели, плотные

257
00:08:58,320 --> 00:09:00,080
связи здесь, которые приведут нас,

258
00:09:00,080 --> 00:09:02,640
наконец, к выходному слою

259
00:09:02,640 --> 00:09:04,560
справа, так что вы можете легко представить, что вы

260
00:09:04,560 --> 00:09:07,360
исследуете эту позицию l1 здесь, и вы находите

261
00:09:07,360 --> 00:09:10,080
что он вычисляет x плюс y,

262
00:09:10,080 --> 00:09:11,839
что может начать показывать

263
00:09:11,839 --> 00:09:13,200
вам, что в этой модели есть какая-то древовидная

264
00:09:13,200 --> 00:09:14,720
структура, даже несмотря на то, что она

265
00:09:14,720 --> 00:09:17,040
была плотно связана, она изучила

266
00:09:17,040 --> 00:09:18,880
структурированное решение проблемы, и

267
00:09:18,880 --> 00:09:20,480
вы можете исследовать l2 и обнаружить, что она

268
00:09:20,480 --> 00:09:21,760
вычисляет z

269
00:09:21,760 --> 00:09:23,120
и это действительно привело бы вас

270
00:09:23,120 --> 00:09:24,640
к мысли, что у вас есть своего рода

271
00:09:24,640 --> 00:09:26,160
интересная древовидная структура с

272
00:09:26,160 --> 00:09:29,519
составляющими для этой задачи на сложение,

273
00:09:29,519 --> 00:09:32,000
и это, безусловно, наводит на размышления.

274
00:09:32,000 --> 00:09:34,080
вот пример модели, которая показывает,

275
00:09:34,080 --> 00:09:37,519
что ни l1, ни l2 не имеют ничего

276
00:09:37,519 --> 00:09:39,600
общего с прогнозами выходных данных модели,

277
00:09:39,600 --> 00:09:42,160
это полностью то среднее состояние, которое

278
00:09:42,160 --> 00:09:43,760
рассказывает полную историю о

279
00:09:43,760 --> 00:09:45,040
выходных данных.

280
00:09:45,040 --> 00:09:46,160
я оставлю вас для проработки

281
00:09:46,160 --> 00:09:48,320
деталей, если вы выберете

282
00:09:48,320 --> 00:09:50,160
чтобы увидеть, что окончательные

283
00:09:50,160 --> 00:09:51,760
параметры, которые ведут нас от этих

284
00:09:51,760 --> 00:09:53,279
выходных представлений к

285
00:09:53,279 --> 00:09:56,399
прогнозам, обнулили первую

286
00:09:56,399 --> 00:09:58,560
и третью позиции, оставив только

287
00:09:58,560 --> 00:10:00,959
вторую как имеющую какую-либо причинно-следственную

288
00:10:00,959 --> 00:10:02,480
эффективность,

289
00:10:02,480 --> 00:10:04,800
даже если в этой модели, если вы  зонда,

290
00:10:04,800 --> 00:10:07,120
вы действительно обнаружите, что

291
00:10:07,120 --> 00:10:09,120
эти представления идеально кодируют

292
00:10:09,120 --> 00:10:11,200
эти две части информации,

293
00:10:11,200 --> 00:10:13,760
что является драматической и ясной простой

294
00:10:13,760 --> 00:10:15,680
иллюстрацией того, как зонд может

295
00:10:15,680 --> 00:10:18,720
оторваться от фактического каузального

296
00:10:18,720 --> 00:10:20,720
поведения модели, снова что-то, что

297
00:10:20,720 --> 00:10:22,959
стоит иметь в виду,

298
00:10:22,959 --> 00:10:24,800
и, наконец,  чтобы закрыть это, конечно,

299
00:10:24,800 --> 00:10:26,399
для той первой проблемы, связанной с

300
00:10:26,399 --> 00:10:28,079
различием между

301
00:10:28,079 --> 00:10:30,560
пропускной способностью зонда и действительно латентно

302
00:10:30,560 --> 00:10:32,640
латентно закодированной информацией.

303
00:10:32,640 --> 00:10:34,640
Одним из ответов на то, что в настоящее время развивается

304
00:10:34,640 --> 00:10:36,480
в литературе, является разработка

305
00:10:36,480 --> 00:10:38,640
неконтролируемых исследований, это будут

306
00:10:38,640 --> 00:10:42,000
модели, подобные этим, которые стремятся найти

307
00:10:42,000 --> 00:10:44,640
в реальных фактах о модели без

308
00:10:44,640 --> 00:10:46,800
дополнительного наблюдения скрытую

309
00:10:46,800 --> 00:10:48,959
информацию, которую мы надеемся найти, и

310
00:10:48,959 --> 00:10:51,040
это будет исходить просто от  просто выполняя

311
00:10:51,040 --> 00:10:53,360
линейные преобразования параметров

312
00:10:53,360 --> 00:10:54,720
и измеряя расстояние между

313
00:10:54,720 --> 00:10:56,959
параметрами, чтобы получить представление

314
00:10:56,959 --> 00:10:58,959
о том, что на самом деле происходит, без

315
00:10:58,959 --> 00:11:01,040
сложностей, связанных с наличием этой

316
00:11:01,040 --> 00:11:03,920
дополнительной контролируемой модели зонда,

317
00:11:03,920 --> 00:11:05,680
и, наконец, для получения гораздо большей информации

318
00:11:05,680 --> 00:11:07,680
о зондах и о том, что, по нашему мнению, они дают.

319
00:11:07,680 --> 00:11:09,040
мы узнали от них и что они

320
00:11:09,040 --> 00:11:11,040
могут нам сказать. Я рекомендую вам ознакомиться с

321
00:11:11,040 --> 00:11:14,079
этой статьей Роджерса. Это учебник по

322
00:11:14,079 --> 00:11:16,640
бертологии. В ней есть большой и интересный

323
00:11:16,640 --> 00:11:19,040
подраздел, полностью посвященный тому, что

324
00:11:19,040 --> 00:11:21,040
нам рассказали зонды.

325
00:11:21,040 --> 00:11:25,480
обзор пространства

326
00:11:28,240 --> 00:11:30,320
вы

