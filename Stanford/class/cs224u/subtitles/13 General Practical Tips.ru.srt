1
00:00:05,359 --> 00:00:07,040
привет всем, добро пожаловать во вторую часть

2
00:00:07,040 --> 00:00:08,559
нашей серии по анализу настроений под наблюдением.

3
00:00:08,559 --> 00:00:10,160
Этот скринкаст будет

4
00:00:10,160 --> 00:00:12,559
посвящен некоторым общим практическим советам по

5
00:00:12,559 --> 00:00:14,160
работе в этой области, особенно

6
00:00:14,160 --> 00:00:15,519
сосредоточенным на

7
00:00:15,519 --> 00:00:17,279
настройке проекта и

8
00:00:17,279 --> 00:00:19,600
предварительной обработке ваших данных,

9
00:00:19,600 --> 00:00:21,680
поэтому сначала я  просто хотел дать вам ссылки

10
00:00:21,680 --> 00:00:23,680
на целую кучу наборов тестовых данных

11
00:00:23,680 --> 00:00:25,680
в этом пространстве, мы собираемся сосредоточиться

12
00:00:25,680 --> 00:00:28,240
на sst и dynacent, но есть

13
00:00:28,240 --> 00:00:30,560
много других вариантов, которые вы могли бы сделать как

14
00:00:30,560 --> 00:00:32,479
для разработки оригинальных систем, так и для

15
00:00:32,479 --> 00:00:34,320
дополнения данных обучения, которые  у вас

16
00:00:34,320 --> 00:00:36,079
есть для конкретного приложения, некоторые из

17
00:00:36,079 --> 00:00:38,160
этих наборов данных действительно очень велики,

18
00:00:38,160 --> 00:00:40,000
и они охватывают множество областей, поэтому

19
00:00:40,000 --> 00:00:42,879
они могут быть важными активами для вас

20
00:00:42,879 --> 00:00:44,399
в том же духе, существует множество

21
00:00:44,399 --> 00:00:46,800
словарей настроений, они охватывают

22
00:00:46,800 --> 00:00:48,320
различные эмоциональные измерения и

23
00:00:48,320 --> 00:00:50,160
различные аспекты проблемы, и

24
00:00:50,160 --> 00:00:51,760
они также могут быть использованы, чтобы помочь вам с

25
00:00:51,760 --> 00:00:53,680
мощной характеристикой, они могут

26
00:00:53,680 --> 00:00:55,280
дополнить функции, которые вы создали

27
00:00:55,280 --> 00:00:57,360
или помочь вам сгруппировать ваш словарный запас в

28
00:00:57,360 --> 00:00:59,680
интересные подкатегории, которые будут

29
00:00:59,680 --> 00:01:01,039
полезны для прогнозирования настроений,

30
00:01:01,039 --> 00:01:03,120
и они варьируются от простых

31
00:01:03,120 --> 00:01:05,040
бессловесных до

32
00:01:05,040 --> 00:01:08,560
высокоструктурированных многомерных словарей.

33
00:01:08,640 --> 00:01:10,479
Сейчас для нашего первого шага предварительной обработки я

34
00:01:10,479 --> 00:01:11,680
подумал, что мы просто поговорим немного

35
00:01:11,680 --> 00:01:13,360
о токенизации.  потому что я думаю, что

36
00:01:13,360 --> 00:01:15,600
это может быть определяющий выбор, который

37
00:01:15,600 --> 00:01:18,000
действительно влияет на успех последующего потока, поэтому

38
00:01:18,000 --> 00:01:19,759
просто в качестве рабочего примера здесь давайте

39
00:01:19,759 --> 00:01:21,439
представим, что мы начинаем с этого необработанного текста,

40
00:01:21,439 --> 00:01:23,759
который является своего рода воображаемым твитом,

41
00:01:23,759 --> 00:01:25,920
у нас есть упоминание здесь, а затем вы

42
00:01:25,920 --> 00:01:27,280
можете видеть, что некоторые

43
00:01:27,280 --> 00:01:29,200
разметка немного искажена, у нас есть

44
00:01:29,200 --> 00:01:31,680
смайлик, который выглядит как бы скрытым

45
00:01:31,680 --> 00:01:33,439
в ссылке в конце,

46
00:01:33,439 --> 00:01:35,759
я думаю, что это очень предварительный шаг, даже

47
00:01:35,759 --> 00:01:37,360
до того, как мы токенизируем, мы могли бы захотеть

48
00:01:37,360 --> 00:01:39,119
изолировать часть этой разметки и

49
00:01:39,119 --> 00:01:41,600
заменить html-объекты, которые это  довольно простая

50
00:01:41,600 --> 00:01:42,880
вещь, которую вы можете сделать, которая действительно может

51
00:01:42,880 --> 00:01:44,320
иметь значение, теперь у нас есть наш

52
00:01:44,320 --> 00:01:47,439
апостроф, у нас есть наш неповрежденный смайлик,

53
00:01:47,439 --> 00:01:49,040
а затем мы все еще  здесь есть ссылка и

54
00:01:49,040 --> 00:01:50,560
другие вещи,

55
00:01:50,560 --> 00:01:51,920
поэтому даже до того, как вы это сделаете, вы можете

56
00:01:51,920 --> 00:01:53,840
проверить, будет ли простая

57
00:01:53,840 --> 00:01:55,840
замена html-объектов

58
00:01:55,840 --> 00:01:58,240
иметь значение в ваших данных,

59
00:01:58,240 --> 00:02:00,000
теперь мы начинаем вопрос о токенизации,

60
00:02:00,000 --> 00:02:01,600
и я думаю, что хорошим базовым выбором здесь

61
00:02:01,600 --> 00:02:03,360
будет  просто токенизация пробелов,

62
00:02:03,360 --> 00:02:05,119
мы собираемся разбить пробелы и

63
00:02:05,119 --> 00:02:06,799
рассматривать все полученные строки как

64
00:02:06,799 --> 00:02:09,119
токены, чтобы взять наш необработанный

65
00:02:09,119 --> 00:02:10,959
текст здесь и разделить его, как вы можете

66
00:02:10,959 --> 00:02:12,959
видеть на этих независимых строках,

67
00:02:12,959 --> 00:02:14,959
это выглядит нормально для меня, поэтому мы  у

68
00:02:14,959 --> 00:02:16,560
нас будут проблемы с нашим при упоминании,

69
00:02:16,560 --> 00:02:18,319
потому что у него есть двоеточие в конце, поэтому

70
00:02:18,319 --> 00:02:20,480
мы можем пропустить тот факт, что это

71
00:02:20,480 --> 00:02:23,520
фактическое при упоминании, униграммы выглядят нормально,

72
00:02:23,520 --> 00:02:25,680
хотя дата была разделена на части,

73
00:02:25,680 --> 00:02:28,080
мы сохранили наш хэштег, мы  у нас есть

74
00:02:28,080 --> 00:02:30,080
этот токен, который может появиться только один раз,

75
00:02:30,080 --> 00:02:31,840
даже если есть четкий последовательный

76
00:02:31,840 --> 00:02:34,560
сигнал, у нас есть наш смайлик, и

77
00:02:34,560 --> 00:02:37,120
наша ссылка в основном не повреждена, хотя этот

78
00:02:37,120 --> 00:02:38,720
период может быть разрушительным, если мы

79
00:02:38,720 --> 00:02:40,480
действительно хотим перейти по ссылке.  потому что

80
00:02:40,480 --> 00:02:42,239
он все еще находится в конце

81
00:02:42,239 --> 00:02:44,239


82
00:02:44,239 --> 00:02:46,160
токенизации банка дерева URL-адресов, это еще одна очень

83
00:02:46,160 --> 00:02:47,920
распространенная схема в nlp, я бы сказал, что на данный

84
00:02:47,920 --> 00:02:50,640
момент в основном по историческим причинам

85
00:02:50,640 --> 00:02:52,400
токенизация банка дерева работает следующим образом: он

86
00:02:52,400 --> 00:02:54,080
берет этот необработанный текст и разбивает его

87
00:02:54,080 --> 00:02:55,840
на целую кучу  токенов прямо по

88
00:02:55,840 --> 00:02:57,360
сравнению с пробелом у нас

89
00:02:57,360 --> 00:02:59,680
здесь много отдельных частей, и это

90
00:02:59,680 --> 00:03:01,519
действительно выглядит довольно проблематично,

91
00:03:01,519 --> 00:03:03,840
поэтому мы уничтожили наше упоминание, у

92
00:03:03,840 --> 00:03:06,159
нас больше нет этого имени пользователя,

93
00:03:06,159 --> 00:03:07,840
оно делает эту интересную вещь со

94
00:03:07,840 --> 00:03:09,519
словами, как не может  что они

95
00:03:09,519 --> 00:03:11,760
разделены на два знака

96
00:03:11,760 --> 00:03:13,920
мы потеряли нашу дату мы потеряли наш

97
00:03:13,920 --> 00:03:15,040
хэштег

98
00:03:15,040 --> 00:03:17,360
это, возможно, хорошо, так что ура был

99
00:03:17,360 --> 00:03:19,599
разделен в соответствии с его пунктуацией, так

100
00:03:19,599 --> 00:03:22,000
что теперь у нас есть четыре восклицательных знака,

101
00:03:22,000 --> 00:03:24,319
отделенных от этого слова,

102
00:03:24,319 --> 00:03:26,400
но наш смайлик  полностью потеряна, и

103
00:03:26,400 --> 00:03:28,159
наша ссылка была действительно уничтожена, так что

104
00:03:28,159 --> 00:03:29,840
это выглядит проблематично с точки

105
00:03:29,840 --> 00:03:32,799
зрения точной характеристики, а также

106
00:03:32,799 --> 00:03:35,680
работы с социальными сетями,

107
00:03:35,680 --> 00:03:37,120
так что это приносит мне  e к тому, что мы

108
00:03:37,120 --> 00:03:38,400
могли бы хотеть от того, что я назвал

109
00:03:38,400 --> 00:03:40,720
токенизатором настроений, мы хотели бы

110
00:03:40,720 --> 00:03:42,799
четко изолировать смайлики, потому что

111
00:03:42,799 --> 00:03:45,120
они могут быть действительно перегружены чувствами,

112
00:03:45,120 --> 00:03:46,959
мы, вероятно, хотим уважать твиттер и

113
00:03:46,959 --> 00:03:48,799
другую разметку, специфичную для предметной области, потому

114
00:03:48,799 --> 00:03:50,720
что это часто пространство, в котором

115
00:03:50,720 --> 00:03:52,400
наши данные исходят из и того места, в котором

116
00:03:52,400 --> 00:03:54,400
мы хотим делать прогнозы в том

117
00:03:54,400 --> 00:03:55,920
же духе, вы можете воспользоваться

118
00:03:55,920 --> 00:03:57,680
преимуществами базовой разметки, возможно

119
00:03:57,680 --> 00:03:59,519
, не фильтровать html, потому что

120
00:03:59,519 --> 00:04:01,599
там может быть важный сигнал,

121
00:04:01,599 --> 00:04:04,239
вы, возможно, знаете, что  веб-сайт или

122
00:04:04,239 --> 00:04:05,599
производитель данных, возможно, выполнил некоторую

123
00:04:05,599 --> 00:04:07,200
собственную предварительную обработку, которая может

124
00:04:07,200 --> 00:04:09,439
нарушить такие вещи, как проклятия, которые,

125
00:04:09,439 --> 00:04:11,200
конечно, могут нести много важной

126
00:04:11,200 --> 00:04:13,200
важной информации о настроении, которую

127
00:04:13,200 --> 00:04:14,080
вы, возможно, захотите сохранить.

128
00:04:14,080 --> 00:04:15,680


129
00:04:15,680 --> 00:04:17,440


130
00:04:17,440 --> 00:04:19,040
подобный дух, вы, возможно,

131
00:04:19,040 --> 00:04:22,400
захотите упорядочить эмоциональное удлинение, например

132
00:04:22,400 --> 00:04:24,400
, до трех символов здесь, чтобы

133
00:04:24,400 --> 00:04:25,680
понять, что это эмоциональное

134
00:04:25,680 --> 00:04:27,680
удлинение, но все  поэтому упорядочите все

135
00:04:27,680 --> 00:04:29,680
эти отдельные токены,

136
00:04:29,680 --> 00:04:31,440
а затем в качестве дополнительной цели, хотя это

137
00:04:31,440 --> 00:04:33,120
может быть менее важно в эпоху

138
00:04:33,120 --> 00:04:35,280
контекстуальных моделей, вы можете подумать о

139
00:04:35,280 --> 00:04:37,280
захвате многословных выражений, которые

140
00:04:37,280 --> 00:04:39,280
несут чувства, просто подумайте о примере,

141
00:04:39,280 --> 00:04:42,160
например, из этого мира, который является положительным,

142
00:04:42,160 --> 00:04:43,840
но  ни одна из его составных частей не является

143
00:04:43,840 --> 00:04:45,680
положительной, поэтому многие модели пропустят то,

144
00:04:45,680 --> 00:04:47,520
что передает четкое настроение,

145
00:04:47,520 --> 00:04:49,520
тогда как с умной

146
00:04:49,520 --> 00:04:51,600
схемой токенизации вы можете зафиксировать это как

147
00:04:51,600 --> 00:04:54,160
один токен,

148
00:04:54,160 --> 00:04:56,320
так что вот простой пример, который

149
00:04:56,320 --> 00:04:58,000
отвечает многим из этих целей здесь для набора

150
00:04:58,000 --> 00:05:00,400
осведомленный токенизатор мы начинаем с нашего обычного

151
00:05:00,400 --> 00:05:02,639
необработанного текста, мы нормализуем и сохраняем

152
00:05:02,639 --> 00:05:03,919
при упоминании,

153
00:05:03,919 --> 00:05:05,759
мы сохраняем большинство этих слов нетронутыми, и

154
00:05:05,759 --> 00:05:07,600
мы как бы фиксируем, что эта вещь 9 июня

155
00:05:07,600 --> 00:05:09,120
была датой,

156
00:05:09,120 --> 00:05:11,280
сохраняем хэштег, конечно,

157
00:05:11,280 --> 00:05:13,440
мы обрабатываем все эти потенциально

158
00:05:13,440 --> 00:05:15,680
эмоции  -нагруженные знаки препинания в виде

159
00:05:15,680 --> 00:05:17,440
отдельных униграмм, я думаю, это может быть

160
00:05:17,440 --> 00:05:18,240
хорошо,

161
00:05:18,240 --> 00:05:19,759
конечно, захватить смайлик и

162
00:05:19,759 --> 00:05:21,600
захватить ссылку,

163
00:05:21,600 --> 00:05:23,039
и если вы хотите что-то, что м  есть

164
00:05:23,039 --> 00:05:25,039
более или менее все эти критерии, за исключением, я

165
00:05:25,039 --> 00:05:27,039
думаю, нормализации даты, которую вы могли бы

166
00:05:27,039 --> 00:05:30,240
просто использовать токенизатор твитов nltk, это

167
00:05:30,240 --> 00:05:32,880
хороший простой выбор, который вы могли бы сделать

168
00:05:32,880 --> 00:05:34,160
, и я думаю, что он будет полезен для

169
00:05:34,160 --> 00:05:36,639
анализа настроений и для количественной оценки,

170
00:05:36,639 --> 00:05:38,639
что немного вот некоторые экспериментальные

171
00:05:38,639 --> 00:05:39,840
доказательства, которые, я думаю, будут иметь

172
00:05:39,840 --> 00:05:41,440
отношение к той работе, которую вы

173
00:05:41,440 --> 00:05:42,560
все делаете,

174
00:05:42,560 --> 00:05:44,479
поэтому мои данные представляют собой открытую таблицу, в которой есть

175
00:05:44,479 --> 00:05:46,560
обзоры ресторанов, короткие. У

176
00:05:46,560 --> 00:05:49,520
меня есть 6 000 отзывов в моем тестовом наборе,

177
00:05:49,520 --> 00:05:51,520
и что я делаю вдоль x  ось

178
00:05:51,520 --> 00:05:53,360
здесь варьирует количество обучающих данных,

179
00:05:53,360 --> 00:05:55,199
которые эти системы могут видеть,

180
00:05:55,199 --> 00:05:57,520
это просто классификатор softmax, и моя

181
00:05:57,520 --> 00:05:59,600
основная манипуляция заключается в том, что у меня есть

182
00:05:59,600 --> 00:06:01,919
токенизатор настроений в оранжевом

183
00:06:01,919 --> 00:06:05,440
дереве в зеленом и пробелы в сером,

184
00:06:05,440 --> 00:06:07,280
и картина довольно четкая прямо

185
00:06:07,280 --> 00:06:09,840
вдоль x-  ось у нас есть точность, это

186
00:06:09,840 --> 00:06:11,440
сбалансированная проблема,

187
00:06:11,440 --> 00:06:13,199
и вы можете видеть, что

188
00:06:13,199 --> 00:06:15,039
токенизатор с учетом настроений является здесь явным

189
00:06:15,039 --> 00:06:17,520
победителем, особенно там, где обучающие

190
00:06:17,520 --> 00:06:19,840
данные скудны, в пределе

191
00:06:19,840 --> 00:06:21,680
добавления  много обучающих данных, я думаю, мы

192
00:06:21,680 --> 00:06:23,440
можем компенсировать многие недостатки

193
00:06:23,440 --> 00:06:25,039
токенизаторов, потому что мы видим много

194
00:06:25,039 --> 00:06:27,199
избыточности в обучающих данных,

195
00:06:27,199 --> 00:06:29,039
но там, где данных

196
00:06:29,039 --> 00:06:30,800
мало, центральный ручной токенизатор, безусловно, является хорошим

197
00:06:30,800 --> 00:06:32,319
выбором, и еще я хотел бы добавить,

198
00:06:32,319 --> 00:06:34,880
что  поскольку он создает более интуитивно понятные

199
00:06:34,880 --> 00:06:36,800
токены, модели с учетом настроений могут

200
00:06:36,800 --> 00:06:40,720
быть в некотором смысле более интерпретируемыми,

201
00:06:40,720 --> 00:06:42,400
и они действительно связаны с домашней работой,

202
00:06:42,400 --> 00:06:44,240
которую вы все делаете, и выпечка —

203
00:06:44,240 --> 00:06:45,919
это то, что происходит, когда мы переходим через

204
00:06:45,919 --> 00:06:47,840
домены, поэтому здесь я тренируюсь на открытых

205
00:06:47,840 --> 00:06:49,759
обзоры ресторанов за столом, но я

206
00:06:49,759 --> 00:06:52,160
собираюсь протестировать предложения с обзорами фильмов здесь, в

207
00:06:52,160 --> 00:06:54,000
противном случае это та же экспериментальная

208
00:06:54,000 --> 00:06:56,160
парадигма из-за того, что междоменные

209
00:06:56,160 --> 00:06:58,160
вещи результаты немного более

210
00:06:58,160 --> 00:07:00,800
хаотичны, но я снова думаю, что

211
00:07:00,800 --> 00:07:03,120
токенизатор с учетом настроений является явным победителем

212
00:07:03,120 --> 00:07:05,120
с  наибольшая прибыль там, где обучающие

213
00:07:05,120 --> 00:07:06,880
данные немного скудны, и это

214
00:07:06,880 --> 00:07:09,360
ожидаемая картина,

215
00:07:09,360 --> 00:07:11,199
поэтому подумайте о токенизации в качестве

216
00:07:11,199 --> 00:07:12,720
контрапункта к тому, что я назвал этой

217
00:07:12,720 --> 00:07:14,240
секундой.  Об устранении опасностей определения

218
00:07:14,240 --> 00:07:15,680
корней, потому что то, что я хочу попытаться

219
00:07:15,680 --> 00:07:18,560
сделать, — это убедить вас не ограничивать ваши данные,

220
00:07:18,560 --> 00:07:20,240
а сначала выяснить, что является определением корней, поэтому

221
00:07:20,240 --> 00:07:22,000
выделение корней — это своего рода метод предварительной обработки,

222
00:07:22,000 --> 00:07:24,160
который может свернуть свернуть отдельные

223
00:07:24,160 --> 00:07:26,000
словоформы, для этого есть три общих

224
00:07:26,000 --> 00:07:27,520
алгоритма.

225
00:07:27,520 --> 00:07:29,759
легко использовать порт или кипятить

226
00:07:29,759 --> 00:07:31,599
стеммер ланкастера и стеммер wordnet,

227
00:07:31,599 --> 00:07:33,919
и моя критика в основном направлена

228
00:07:33,919 --> 00:07:36,240
ортера и ланкастера, во 

229
00:07:36,240 --> 00:07:38,080
суть в в

230
00:07:38,080 --> 00:07:40,000
полнении такого рода стемминга, вы ск 

231
00:07:40,000 --> 00:07:42,160
онны разрушить многие важные ра 

232
00:07:42,160 --> 00:07:43,840
личия в настроениях, что делает это ко 

233
00:07:43,840 --> 00:07:46,800
трпродуктивным.  шаг обработки,

234
00:07:46,800 --> 00:07:48,400
с другой стороны, слово netstemmer

235
00:07:48,400 --> 00:07:50,319
не имеет этой проблемы,

236
00:07:50,319 --> 00:07:52,879
оно гораздо более консервативно, но на

237
00:07:52,879 --> 00:07:54,560
самом деле оно также не делает достаточно, чтобы окупиться, его запуск

238
00:07:54,560 --> 00:07:57,039
довольно затратен, у него

239
00:07:57,039 --> 00:07:59,039
есть некоторые требования, которые могут сделать его

240
00:07:59,039 --> 00:08:01,120
просто бесполезным и  я бы сказал,

241
00:08:01,120 --> 00:08:02,800
что суть здесь в том,

242
00:08:02,800 --> 00:08:05,280
что в эпоху, когда у нас есть очень большие

243
00:08:05,280 --> 00:08:06,960
данные о настроениях, задается функция

244
00:08:06,960 --> 00:08:08,720
стемминга.  было бы сократить

245
00:08:08,720 --> 00:08:11,120
размер вашего словарного запаса и

246
00:08:11,120 --> 00:08:13,759
облегчить обучение в небольших областях, но мы в

247
00:08:13,759 --> 00:08:15,440
основном больше не сталкиваемся с этой проблемой

248
00:08:15,440 --> 00:08:16,639
,

249
00:08:16,639 --> 00:08:18,800
а просто доводим до конца этот момент,

250
00:08:18,800 --> 00:08:20,639
вот несколько примеров, сосредоточенных на

251
00:08:20,639 --> 00:08:23,039
переносе или стеммере случаев, когда

252
00:08:23,039 --> 00:08:25,039
запуск  port или simmer на самом деле разрушает

253
00:08:25,039 --> 00:08:26,879
четкие различия настроений в соответствии

254
00:08:26,879 --> 00:08:28,720
с harvard inquirer, который является одним из тех словарей, которые

255
00:08:28,720 --> 00:08:31,280
я упомянул до того, как у меня

256
00:08:31,280 --> 00:08:33,200
есть защита и оборона, они

257
00:08:33,200 --> 00:08:35,279
рушатся в эту забавную

258
00:08:35,279 --> 00:08:38,080
экстравагантность защиты без слов, экстравагантное

259
00:08:38,080 --> 00:08:40,080
другое настроение рушится в

260
00:08:40,080 --> 00:08:42,719
это слово  фрагмент и т. д. для

261
00:08:42,719 --> 00:08:44,320
этих других примеров, и я думаю, что это

262
00:08:44,320 --> 00:08:46,320
показывает, что при предварительной обработке ваших данных

263
00:08:46,320 --> 00:08:48,160
вы можете удалить некоторые важные

264
00:08:48,160 --> 00:08:50,000


265
00:08:50,000 --> 00:08:51,760
сигналы тональности, ланкастерский стеммер использует очень

266
00:08:51,760 --> 00:08:53,920
похожую стратегию и, возможно, имеет даже

267
00:08:53,920 --> 00:08:56,000
больше проблем в этой области здесь мы

268
00:08:56,000 --> 00:08:58,640
получил положительное слово, э-э, дополнить и

269
00:08:58,640 --> 00:08:59,839
усложнить,

270
00:08:59,839 --> 00:09:01,519
согласно гарвардскому исследователю,

271
00:09:01,519 --> 00:09:03,200
они оба могут рухнуть  вниз к

272
00:09:03,200 --> 00:09:04,880
тому, что является совершенно другим словом «

273
00:09:04,880 --> 00:09:05,920
соблюдать»,

274
00:09:05,920 --> 00:09:07,440
и это должно вызывать беспокойство по многим

275
00:09:07,440 --> 00:09:09,519
причинам, и другие примеры делают

276
00:09:09,519 --> 00:09:12,560
очень похожий

277
00:09:12,560 --> 00:09:14,320
момент слова netstemmer, о котором я упоминал ранее, я

278
00:09:14,320 --> 00:09:15,839
думаю, что это действительно имеет что-то

279
00:09:15,839 --> 00:09:17,519
для этого, возможно, были бы случаи, когда

280
00:09:17,519 --> 00:09:19,760
вы бы  хотите использовать его, это высокая точность, для

281
00:09:19,760 --> 00:09:23,120
этого требуются пары частей речи,

282
00:09:23,120 --> 00:09:24,880
и общая проблема заключается в том, что он просто

283
00:09:24,880 --> 00:09:26,800
удаляет некоторую сравнительную морфологию

284
00:09:26,800 --> 00:09:28,160
, это единственное, о чем вы можете беспокоиться

285
00:09:28,160 --> 00:09:30,000
о чувствах, но в противном случае это

286
00:09:30,000 --> 00:09:31,760
будет похоже на объяснение

287
00:09:31,760 --> 00:09:33,519
восклицаний, восклицание и схлопывание их  вниз,

288
00:09:33,519 --> 00:09:35,440
это может быть полезным сжатием

289
00:09:35,440 --> 00:09:37,279
вашего функционального пространства, оно оставит

290
00:09:37,279 --> 00:09:39,920
только восклицание, что, я думаю, хорошо,

291
00:09:39,920 --> 00:09:41,600
аналогично для этих вещей, все они как

292
00:09:41,600 --> 00:09:43,600
бы сохраняются в двух формах глагола,

293
00:09:43,600 --> 00:09:45,440
но мы сохраняем прилагательное как

294
00:09:45,440 --> 00:09:47,440
другое, я думаю, что это может быть хорошо и

295
00:09:47,440 --> 00:09:49,200
как я уже сказал, единственной заботой будет то, что

296
00:09:49,200 --> 00:09:51,760
счастливые, более счастливые и самые счастливые все опустятся

297
00:09:51,760 --> 00:09:53,839
в свою базовую форму, в то время как я думаю, что

298
00:09:53,839 --> 00:09:55,760
они могли бы  закодируйте разные

299
00:09:55,760 --> 00:09:57,040
градации настроений, которые вы, возможно, захотите

300
00:09:57,040 --> 00:09:58,640
сохранить

301
00:09:58,640 --> 00:10:00,399
, это стоит задуматься, но в целом я

302
00:10:00,399 --> 00:10:02,399
думаю, что вы, вероятно, захотите избежать

303
00:10:02,399 --> 00:10:03,839
стояния и вернуться к этому домой, давайте

304
00:10:03,839 --> 00:10:06,480
вернемся к моей экспериментальной парадигме,

305
00:10:06,480 --> 00:10:09,600
используя классификатор softmax opentable обзоры

306
00:10:09,600 --> 00:10:11,920
6000 из них в моем наборе тестов  и здесь

307
00:10:11,920 --> 00:10:13,839
по оси X я варьирую

308
00:10:13,839 --> 00:10:15,680
количество имеющихся у меня обучающих данных,

309
00:10:15,680 --> 00:10:18,000
и я думаю, что вы видите, что

310
00:10:18,000 --> 00:10:19,839
стеммер портера и ланкастера, а также фиолетовый

311
00:10:19,839 --> 00:10:21,760
и черный, соответственно,

312
00:10:21,760 --> 00:10:24,640
навсегда отстают от правильного, а не просто

313
00:10:24,640 --> 00:10:26,560
токенизация с учетом настроений, которую он дает

314
00:10:26,560 --> 00:10:27,680
вы лидируете,

315
00:10:27,680 --> 00:10:29,440
это особенно ясно, когда вы

316
00:10:29,440 --> 00:10:32,079
выходите из этой очень разреженной области здесь с

317
00:10:32,079 --> 00:10:34,720
очень небольшим количеством обучающих примеров,

318
00:10:34,720 --> 00:10:37,279
чтобы закрыть всего несколько других

319
00:10:37,279 --> 00:10:38,959
методов предварительной обработки, о которых вы могли бы подумать, чтобы

320
00:10:38,959 --> 00:10:41,120
вы могли разделить речь, связанную с вашими данными

321
00:10:41,120 --> 00:10:43,200
в духе попытки  чтобы уловить больше

322
00:10:43,200 --> 00:10:44,640
различий в настроении, которые вы могли

323
00:10:44,640 --> 00:10:47,120
бы уловить в противном случае, например,

324
00:10:47,120 --> 00:10:49,200
rest или like a resting в качестве

325
00:10:49,200 --> 00:10:50,959
прилагательного положительное, но ar  est как глагол, как

326
00:10:50,959 --> 00:10:52,399
правило, имеет отрицательное значение,

327
00:10:52,399 --> 00:10:55,360
um fine, как прилагательное, имеет положительное значение, но

328
00:10:55,360 --> 00:10:57,920
to beanable a fine, поскольку существительное имеет отрицательное значение,

329
00:10:57,920 --> 00:10:59,519
и т. д.

330
00:10:59,519 --> 00:11:01,920


331
00:11:01,920 --> 00:11:04,480


332
00:11:04,480 --> 00:11:07,279
Функции униграммы,

333
00:11:07,279 --> 00:11:10,079
основанные на парах тегов части слова,

334
00:11:10,079 --> 00:11:11,920
могут быть полезны для повторного сохранения некоторых из

335
00:11:11,920 --> 00:11:13,440
этих различий в качестве

336
00:11:13,440 --> 00:11:15,600
шага предварительной обработки, чтобы помочь вашей модели

337
00:11:15,600 --> 00:11:17,519
быть более настроенной на эти точки

338
00:11:17,519 --> 00:11:19,600
вариации в сравнении,

339
00:11:19,600 --> 00:11:21,360
но если есть ограничения даже на это

340
00:11:21,360 --> 00:11:22,959
право  так что это всего лишь несколько случаев на

341
00:11:22,959 --> 00:11:24,959
этих слайдах, где даже в одной и той же

342
00:11:24,959 --> 00:11:27,360
части речи у нас есть прилагательное, которое

343
00:11:27,360 --> 00:11:29,279
в одном смысле положительное, а в другом

344
00:11:29,279 --> 00:11:32,399
отрицательное, например, прилагательное означает

345
00:11:32,399 --> 00:11:34,480
может означать ненавистный, но также может означать

346
00:11:34,480 --> 00:11:36,480
превосходный, поскольку они делают  средний

347
00:11:36,480 --> 00:11:38,000
яблочный пирог

348
00:11:38,000 --> 00:11:38,800


349
00:11:38,800 --> 00:11:40,240
умный

350
00:11:40,240 --> 00:11:43,279
как прилагательное может быть и болезненным эээ

351
00:11:43,279 --> 00:11:45,360
а также ярким и блестящим и так

352
00:11:45,360 --> 00:11:46,720
далее в том же духе и аналогично для

353
00:11:46,720 --> 00:11:48,880
серьезного и фантастического и насмешливого в

354
00:11:48,880 --> 00:11:50,399
зависимости от контекста и т

355
00:11:50,399 --> 00:11:52,160
Намерение говорящего они могут как

356
00:11:52,160 --> 00:11:54,880
бы разрезать в разных направлениях, так что

357
00:11:54,880 --> 00:11:56,320
даже пометка части речи

358
00:11:56,320 --> 00:11:58,480
будет ограничивать, когда дело доходит до реального

359
00:11:58,480 --> 00:12:00,560
восстановления основного смысла слова,

360
00:12:00,560 --> 00:12:02,959
даже для чего-то столь же низкого измерения,

361
00:12:02,959 --> 00:12:05,920
как различие настроений,

362
00:12:05,920 --> 00:12:08,000
наконец, нет, это другое  мощная

363
00:12:08,000 --> 00:12:09,600
техника, которую вы можете использовать и

364
00:12:09,600 --> 00:12:11,839
обдумывать, выбирая и оценивая

365
00:12:11,839 --> 00:12:13,519
различные модели, это то, что я

366
00:12:13,519 --> 00:12:15,360
называю простым отрицанием, обозначающим

367
00:12:15,360 --> 00:12:17,760
явление, просто если у меня есть глагол

368
00:12:17,760 --> 00:12:20,240
вроде «наслаждаться», который звучит положительно

369
00:12:20,240 --> 00:12:21,519
изолированно,

370
00:12:21,519 --> 00:12:22,880
конечно, его вклад в

371
00:12:22,880 --> 00:12:25,040
общее  настроение будет меняться в зависимости

372
00:12:25,040 --> 00:12:26,480
от того, находится ли оно в рамках

373
00:12:26,480 --> 00:12:29,519
отрицания, мне не понравилось, как отрицательное,

374
00:12:29,519 --> 00:12:31,519
и отрицание может быть выражено многими

375
00:12:31,519 --> 00:12:32,639
способами,

376
00:12:32,639 --> 00:12:35,600
как этот модификатор вспомогательных слов, как нет,

377
00:12:35,600 --> 00:12:37,920
но как наречие, как никогда, это может быть

378
00:12:37,920 --> 00:12:39,760
в теме, как нет  один, и это может

379
00:12:39,760 --> 00:12:41,760
даже быть действительно закодировано для таких вещей, как я

380
00:12:41,760 --> 00:12:44,240
еще не наслаждался этим, что является своего рода

381
00:12:44,240 --> 00:12:45,360
отрицанием,

382
00:12:45,360 --> 00:12:47,120
а затем, конечно, отрицанием через пять

383
00:12:47,120 --> 00:12:49,200
лет.  Далеко я не думаю, что мне

384
00:12:49,200 --> 00:12:51,440
понравится это, вероятно, отрицательное, но

385
00:12:51,440 --> 00:12:54,240
отрицание очень далеко от

386
00:12:54,240 --> 00:12:57,120
глагола, который мы хотим иметь, что мы хотим,

387
00:12:57,120 --> 00:12:58,800
чье настроение мы хотим модулировать с

388
00:12:58,800 --> 00:13:00,959
помощью отрицания,

389
00:13:00,959 --> 00:13:02,480
так что вот очень простой метод, который я

390
00:13:02,480 --> 00:13:04,480
think был впервые использован исследователем

391
00:13:04,480 --> 00:13:06,480
Доусоном Ченом, он также используется в peng

392
00:13:06,480 --> 00:13:08,079
вообще, это классические ранние

393
00:13:08,079 --> 00:13:10,320
документы по анализу настроений, и идея состоит в том,

394
00:13:10,320 --> 00:13:13,360
чтобы просто добавить отрицательный суффикс к каждому слову

395
00:13:13,360 --> 00:13:15,040
в последовательности, которая появляется между

396
00:13:15,040 --> 00:13:17,519
отрицанием и некоторым знаком уровня предложения

397
00:13:17,519 --> 00:13:19,920
знаки препинания, чтобы примерно

398
00:13:19,920 --> 00:13:22,639
указать семантический объем отрицания,

399
00:13:22,639 --> 00:13:24,639
это простой шаг предварительной обработки, очень

400
00:13:24,639 --> 00:13:26,720
эвристический, он возьмет предложение, как будто оно

401
00:13:26,720 --> 00:13:29,680
никому не нравится, и буквально превратит

402
00:13:29,680 --> 00:13:32,399
униграммы один и радость, и это

403
00:13:32,399 --> 00:13:34,639
в их различные формы, где есть

404
00:13:34,639 --> 00:13:36,320
яйцо, добавленное к нему, и оно

405
00:13:36,320 --> 00:13:38,399
наслаждается, и оно тоже, и идея состоит в

406
00:13:38,399 --> 00:13:39,760
том, что, делая это, мы даем нашей

407
00:13:39,760 --> 00:13:42,399
модели возможность обнаружить, что

408
00:13:42,399 --> 00:13:44,720
наслаждается в этом контексте на самом деле

409
00:13:44,720 --> 00:13:46,800
отличается от  в каком-то смысле лучше, чем

410
00:13:46,800 --> 00:13:48,480
нравится, когда это не входит в область

411
00:13:48,480 --> 00:13:50,720
отрицания, и для многих линейных

412
00:13:50,720 --> 00:13:52,320
моделей с раздаточными функциями, которые мы

413
00:13:52,320 --> 00:13:54,560
исследуем, простое проведение этого начального

414
00:13:54,560 --> 00:13:56,480
различия может создать некоторое пространство для

415
00:13:56,480 --> 00:13:59,040
вашей модели, чтобы изучить взаимодействие

416
00:13:59,040 --> 00:14:00,839
отрицания с этими другими

417
00:14:00,839 --> 00:14:03,279
функциями и  просто чтобы немного количественно оценить это

418
00:14:03,279 --> 00:14:04,959
, округляя это, я

419
00:14:04,959 --> 00:14:06,639
думаю, что этот слайд показывает влияние, которое

420
00:14:06,639 --> 00:14:09,600
это может оказать, несмотря на его простоту, настолько

421
00:14:09,600 --> 00:14:12,079
похожее, что у нас есть открытая таблица в качестве нашего тестового

422
00:14:12,079 --> 00:14:14,399
набора, мы используем классификатор softmax, а

423
00:14:14,399 --> 00:14:16,399
ось x  снова варьируя

424
00:14:16,399 --> 00:14:19,120
количество обучающих данных, которые у нас есть,

425
00:14:19,120 --> 00:14:20,880
токенизатор пробелов не серый,

426
00:14:20,880 --> 00:14:22,880
это худший, за которым следует банк деревьев и

427
00:14:22,880 --> 00:14:23,760
зеленый,

428
00:14:23,760 --> 00:14:25,120
затем у нас есть

429
00:14:25,120 --> 00:14:27,199
токенизатор с учетом настроений в оранжевом цвете,

430
00:14:27,199 --> 00:14:29,680
а затем последовательно над ними для

431
00:14:29,680 --> 00:14:31,680
всех частей данных здесь

432
00:14:31,680 --> 00:14:34,079
осведомленность о настроении плюс эта маркировка отрицания,

433
00:14:34,079 --> 00:14:36,720
которая, очевидно, является лучшей моделью для

434
00:14:36,720 --> 00:14:38,639
всех видов объемов обучающих данных,

435
00:14:38,639 --> 00:14:40,320
и я думаю, что это показывает,

436
00:14:40,320 --> 00:14:42,800
что влияние отрицания  n на самом деле

437
00:14:42,800 --> 00:14:44,560
действительно реальное и серьезное во многих

438
00:14:44,560 --> 00:14:46,320
наборах данных тональности, просто очень

439
00:14:46,320 --> 00:14:48,000
часто комбинируют

440
00:14:48,000 --> 00:14:50,240
слова тональности, положительные или отрицательные,

441
00:14:50,240 --> 00:14:51,839
с отрицанием, и это имеет

442
00:14:51,839 --> 00:14:53,600
предсказуемый эффект

443
00:14:53,600 --> 00:14:54,800
переворачивания значения,

444
00:14:54,800 --> 00:14:56,639
поэтому при выполнении этого настроения и выполнении

445
00:14:56,639 --> 00:14:58,240
этой маркировки отрицания мы  даем нашей

446
00:14:58,240 --> 00:15:00,959
модели больше шансов обнаружить

447
00:15:00,959 --> 00:15:02,880
именно эти различия,

448
00:15:02,880 --> 00:15:04,800
и вот аналогичный набор результатов для

449
00:15:04,800 --> 00:15:06,720
кросс-домена, где я начинаю с открытой

450
00:15:06,720 --> 00:15:09,519
таблицы и снова тестирую на imdb,

451
00:15:09,519 --> 00:15:10,959
результаты немного более хаотичны,

452
00:15:10,959 --> 00:15:13,199
но я думаю, что это ясно  победа за

453
00:15:13,199 --> 00:15:14,880
модель осведомленности о настроениях плюс

454
00:15:14,880 --> 00:15:18,199
модель маркировки отрицания

