1
00:00:00,000 --> 00:00:03,950


2
00:00:03,950 --> 00:00:05,700
CHRISTOPHER POTTS:
Welcome back, everyone.

3
00:00:05,700 --> 00:00:08,283
This is part 3 in our series on
supervised sentiment analysis.

4
00:00:08,283 --> 00:00:10,742
This screencast is going to
focus on the Stanford Sentiment

5
00:00:10,742 --> 00:00:11,250
Treebank.

6
00:00:11,250 --> 00:00:13,980
Let me start with a
quick project overview.

7
00:00:13,980 --> 00:00:15,630
The associated paper
is Socher et al.

8
00:00:15,630 --> 00:00:17,200
2013.

9
00:00:17,200 --> 00:00:19,530
I think this paper is a kind
of model of open science.

10
00:00:19,530 --> 00:00:21,060
At this website
here, you can see

11
00:00:21,060 --> 00:00:23,590
the full code, all
the data of course,

12
00:00:23,590 --> 00:00:26,130
as well as an API that will
let you try out new examples

13
00:00:26,130 --> 00:00:28,440
and kind of interact
with the core models

14
00:00:28,440 --> 00:00:30,870
that are motivated in the paper.

15
00:00:30,870 --> 00:00:32,280
It's a sentence-level corpus.

16
00:00:32,280 --> 00:00:34,650
It's got about 11,000
sentences in total.

17
00:00:34,650 --> 00:00:36,450
And all of those
sentences are originally

18
00:00:36,450 --> 00:00:37,650
from Rotten Tomatoes.

19
00:00:37,650 --> 00:00:40,033
So they are sentences
from movie reviews.

20
00:00:40,033 --> 00:00:41,700
The sentences themselves
were originally

21
00:00:41,700 --> 00:00:44,010
released by Pang
and Lee in 2005.

22
00:00:44,010 --> 00:00:45,750
It's a kind of classic data set.

23
00:00:45,750 --> 00:00:48,750
And what the SST did
was expand the data set

24
00:00:48,750 --> 00:00:52,440
by labeling not only the
full sentences but all

25
00:00:52,440 --> 00:00:54,090
of the sub-constituents
according

26
00:00:54,090 --> 00:00:56,640
to a kind of traditional
parse, syntactic parse,

27
00:00:56,640 --> 00:00:57,790
of each of the examples.

28
00:00:57,790 --> 00:00:59,680
And those are all
crowdsourced labels.

29
00:00:59,680 --> 00:01:02,850
So what this means is that we
have vastly more supervision

30
00:01:02,850 --> 00:01:05,777
signals all throughout the
structure of these examples

31
00:01:05,777 --> 00:01:07,860
than we would get from the
original, where we just

32
00:01:07,860 --> 00:01:12,052
had a single sentiment label
for the entire sentence.

33
00:01:12,052 --> 00:01:14,010
The labels themselves
and the underlying corpus

34
00:01:14,010 --> 00:01:17,760
are five-way labels that are
extracted from workers' slider

35
00:01:17,760 --> 00:01:18,480
responses.

36
00:01:18,480 --> 00:01:21,690
So there's kind of an
initial layer of aggregation.

37
00:01:21,690 --> 00:01:22,800
They made a slider choice.

38
00:01:22,800 --> 00:01:25,722
They were all grouped
together into five labels.

39
00:01:25,722 --> 00:01:27,930
And then we are going to
work with a formulation that

40
00:01:27,930 --> 00:01:30,610
is even more collapsed
down to ternary sentiment.

41
00:01:30,610 --> 00:01:33,630
I'll return to that a bit later.

42
00:01:33,630 --> 00:01:35,250
The fully labeled
tree thing is one

43
00:01:35,250 --> 00:01:37,650
of the really exciting
aspects of this corpus

44
00:01:37,650 --> 00:01:40,230
that we will be able to take
advantage of, especially

45
00:01:40,230 --> 00:01:41,010
during training.

46
00:01:41,010 --> 00:01:43,470
So the way that worked
is, there were parses.

47
00:01:43,470 --> 00:01:46,830
This is a simple constituent
parse of a sentence,

48
00:01:46,830 --> 00:01:48,330
NLU is enlightening.

49
00:01:48,330 --> 00:01:49,920
And as I've indicated
here, we have

50
00:01:49,920 --> 00:01:53,340
labels in that
space, 0 through 4,

51
00:01:53,340 --> 00:01:56,400
on all of the lexical items,
NLU, is, and enlightening,

52
00:01:56,400 --> 00:01:59,083
as well as all the
subconstituents in this phrase.

53
00:01:59,083 --> 00:02:00,750
And so you can see
that "is" is neutral.

54
00:02:00,750 --> 00:02:02,790
But since "enlightening"
is positive,

55
00:02:02,790 --> 00:02:05,730
the whole verb phrase, "is
enlightening" is positive.

56
00:02:05,730 --> 00:02:07,860
We can say that NLU is neutral.

57
00:02:07,860 --> 00:02:09,360
But in the context
of this sentence,

58
00:02:09,360 --> 00:02:12,270
the overall contribution
is a highly positive one.

59
00:02:12,270 --> 00:02:16,230
So label 4 on the root.

60
00:02:16,230 --> 00:02:17,970
In the first screencast
for this unit,

61
00:02:17,970 --> 00:02:20,178
I motivated sentiment
analysis with some cases

62
00:02:20,178 --> 00:02:21,720
that I thought were
kind of difficult

63
00:02:21,720 --> 00:02:23,638
from a syntactic point of view.

64
00:02:23,638 --> 00:02:25,680
This is one of them, they
said it would be great.

65
00:02:25,680 --> 00:02:27,240
I love how this
is being handled.

66
00:02:27,240 --> 00:02:29,580
We can see that down
here, "be great"

67
00:02:29,580 --> 00:02:31,290
is kind of clearly positive.

68
00:02:31,290 --> 00:02:34,170
But by the time we have filtered
that through this report,

69
00:02:34,170 --> 00:02:36,720
they said just kind of
displacing the sentiment

70
00:02:36,720 --> 00:02:37,800
onto another agent.

71
00:02:37,800 --> 00:02:40,110
The speaker is not
necessarily endorsing

72
00:02:40,110 --> 00:02:41,392
the claim of greatness.

73
00:02:41,392 --> 00:02:43,725
What we get in the end is
more like a neutral sentiment.

74
00:02:43,725 --> 00:02:45,360
I think that's interesting.

75
00:02:45,360 --> 00:02:47,220
And we can extend that
even further, right?

76
00:02:47,220 --> 00:02:49,740
These are actual predictions
from the model that's motivated

77
00:02:49,740 --> 00:02:51,210
in the underlying paper.

78
00:02:51,210 --> 00:02:53,880
If we take that constituent
that I just showed you

79
00:02:53,880 --> 00:02:55,620
and conjoin it with
"they were wrong,"

80
00:02:55,620 --> 00:02:58,470
which is clearly negative,
strikingly the model

81
00:02:58,470 --> 00:03:01,350
is able to figure out that the
overall sentiment is determined

82
00:03:01,350 --> 00:03:03,580
by this second clause here,
and assigned negatives

83
00:03:03,580 --> 00:03:06,330
to the entire thing, despite the
fact that there are obviously

84
00:03:06,330 --> 00:03:08,295
subconstituents in
here that are positive.

85
00:03:08,295 --> 00:03:10,680
And that exactly the kind
of mixing that I think

86
00:03:10,680 --> 00:03:12,750
is correct for
how language works

87
00:03:12,750 --> 00:03:14,052
in the domain of sentiment.

88
00:03:14,052 --> 00:03:15,510
And it's kind of
encouraging to see

89
00:03:15,510 --> 00:03:17,160
that this model
is able to capture

90
00:03:17,160 --> 00:03:19,050
at least some aspects of it.

91
00:03:19,050 --> 00:03:21,540
Here's a similar case that I
think is pretty good as well.

92
00:03:21,540 --> 00:03:24,160
Although, maybe not as
strikingly positive in the end

93
00:03:24,160 --> 00:03:24,660
here.

94
00:03:24,660 --> 00:03:27,630
I've just changed from
the previous example,

95
00:03:27,630 --> 00:03:29,970
"they were wrong,"
to "they were right."

96
00:03:29,970 --> 00:03:31,590
It knows that right is correct.

97
00:03:31,590 --> 00:03:34,500
And it seems to get that
this is middle of the scale.

98
00:03:34,500 --> 00:03:36,660
And I'd hope this
was a 3 or a 4.

99
00:03:36,660 --> 00:03:38,310
But I think that
still we're seeing

100
00:03:38,310 --> 00:03:40,410
some interesting
interactions between what's

101
00:03:40,410 --> 00:03:43,200
happening in subconstituents
in these examples

102
00:03:43,200 --> 00:03:45,430
and the prediction that's
made at the root level.

103
00:03:45,430 --> 00:03:47,960
So it's very encouraging.

104
00:03:47,960 --> 00:03:51,655
There are a bunch of ways that
you can formulate the SST task.

105
00:03:51,655 --> 00:03:53,830
Kind of the raw one that
comes from the paper would

106
00:03:53,830 --> 00:03:56,980
be a 5-way classification
problem where we have

107
00:03:56,980 --> 00:04:00,430
these numerical labels here
with the meaning of kind of 0

108
00:04:00,430 --> 00:04:04,600
is very negative, 1 is negative,
2 is neutral, 3 is positive,

109
00:04:04,600 --> 00:04:06,530
and 4 is very positive.

110
00:04:06,530 --> 00:04:08,830
I think this is fine,
but there are two gotchas

111
00:04:08,830 --> 00:04:10,300
underlying this kind of scheme.

112
00:04:10,300 --> 00:04:13,930
First, it's not really a fully
ordered scale in the sense

113
00:04:13,930 --> 00:04:18,970
that 4 is stronger than 3,
but 0 is stronger than 1,

114
00:04:18,970 --> 00:04:20,860
because we have kind
of this polarity split

115
00:04:20,860 --> 00:04:23,250
with neutral in the center.

116
00:04:23,250 --> 00:04:25,000
So that's a kind of
conceptual difficulty.

117
00:04:25,000 --> 00:04:28,030
And then the other part is that,
by and large, classifier models

118
00:04:28,030 --> 00:04:31,510
that you pick will not give you
partial credit for being close.

119
00:04:31,510 --> 00:04:35,770
We might hope that a model
that predicted a 1, negative,

120
00:04:35,770 --> 00:04:38,470
was kind of right or
certainly more right

121
00:04:38,470 --> 00:04:41,765
if the true label is 0 than
a model that had predicted 4.

122
00:04:41,765 --> 00:04:43,390
But of course, if
these are all treated

123
00:04:43,390 --> 00:04:45,730
as independent
classification bins,

124
00:04:45,730 --> 00:04:48,850
then you're just
equally wrong no matter

125
00:04:48,850 --> 00:04:51,700
which prediction you made
relative to the gold label.

126
00:04:51,700 --> 00:04:54,942
And that seems
unfair to our models.

127
00:04:54,942 --> 00:04:56,400
We are going to
work with what I've

128
00:04:56,400 --> 00:04:57,820
called the ternary problem.

129
00:04:57,820 --> 00:05:00,450
I think this is the minimal
problem that really makes sense

130
00:05:00,450 --> 00:05:01,530
conceptually.

131
00:05:01,530 --> 00:05:04,860
For this one, we grouped 0 and
1 into a negative category,

132
00:05:04,860 --> 00:05:07,020
3 and 4 into a
positive category,

133
00:05:07,020 --> 00:05:12,120
and reserved 2, as before, for
what we're calling neutral.

134
00:05:12,120 --> 00:05:14,790
And this kind of avoids
the false presupposition

135
00:05:14,790 --> 00:05:16,950
that every sentence is
either negative or positive,

136
00:05:16,950 --> 00:05:19,230
because it does allow
us to make predictions

137
00:05:19,230 --> 00:05:24,042
into this neutral or
non-sentiment laden space.

138
00:05:24,042 --> 00:05:26,000
It's very common, and
you see this in the paper

139
00:05:26,000 --> 00:05:27,770
as well as in a lot
of work on the SST,

140
00:05:27,770 --> 00:05:29,930
to formulate this
as a binary problem.

141
00:05:29,930 --> 00:05:31,340
For the binary
problem, we simply

142
00:05:31,340 --> 00:05:33,770
remove the middle of the
scale and treat 0 and 1

143
00:05:33,770 --> 00:05:36,830
as negative and 3 and 4
as positive, as before.

144
00:05:36,830 --> 00:05:38,160
I think that has two drawbacks.

145
00:05:38,160 --> 00:05:39,785
First, we have to
throw away some data.

146
00:05:39,785 --> 00:05:42,380
And second, then we're making
this false presupposition

147
00:05:42,380 --> 00:05:45,200
that every sentence is either
classified as negative or as

148
00:05:45,200 --> 00:05:48,710
positive when for a wide
range of cases in the world,

149
00:05:48,710 --> 00:05:51,860
that might be inappropriate.

150
00:05:51,860 --> 00:05:53,990
Now, I focused here on
the root level problem.

151
00:05:53,990 --> 00:05:56,140
You can see that the numbers
here for train and dev

152
00:05:56,140 --> 00:05:58,870
are small, and the test set
numbers are a little bit larger

153
00:05:58,870 --> 00:05:59,520
than for devs.

154
00:05:59,520 --> 00:06:01,090
So they're comparable.

155
00:06:01,090 --> 00:06:03,460
But we can also think of
this as the all nodes task,

156
00:06:03,460 --> 00:06:07,150
because recall that a
hallmark feature of the SST

157
00:06:07,150 --> 00:06:09,190
is that every single
subconstituent

158
00:06:09,190 --> 00:06:11,830
in these examples has been
labeled by crowd workers.

159
00:06:11,830 --> 00:06:13,390
So we could treat
each one of those

160
00:06:13,390 --> 00:06:16,060
as a kind of independent
classification problem.

161
00:06:16,060 --> 00:06:18,393
We have the same range
for all of the values

162
00:06:18,393 --> 00:06:19,310
that they can take on.

163
00:06:19,310 --> 00:06:21,580
So we can do similar
kind of collapsing down

164
00:06:21,580 --> 00:06:24,765
into the ternary problem
or the binary problem.

165
00:06:24,765 --> 00:06:26,890
And of course, here, we
have a much larger dataset.

166
00:06:26,890 --> 00:06:29,600


167
00:06:29,600 --> 00:06:32,960
For us, we're going
to, by and large,

168
00:06:32,960 --> 00:06:35,390
work with the data in one
particular way, which I think

169
00:06:35,390 --> 00:06:36,740
is common in the literature.

170
00:06:36,740 --> 00:06:39,240
As I said, we're going to
have the ternary formulations.

171
00:06:39,240 --> 00:06:42,770
Our labels will be positive,
negative, and neutral.

172
00:06:42,770 --> 00:06:45,020
When we do the
dev and test step,

173
00:06:45,020 --> 00:06:47,400
we are going to test
only on full examples.

174
00:06:47,400 --> 00:06:49,700
So for them, we will
not make predictions

175
00:06:49,700 --> 00:06:53,210
into the subconstituent space.

176
00:06:53,210 --> 00:06:56,000
And then as a default for
the code, as you'll see,

177
00:06:56,000 --> 00:06:59,370
it is set up to train
only on full examples.

178
00:06:59,370 --> 00:07:01,322
So for these two cases,
NLU is enlightening

179
00:07:01,322 --> 00:07:02,780
and not enlightening
here, if those

180
00:07:02,780 --> 00:07:05,150
were two independent
sentences in the corpus,

181
00:07:05,150 --> 00:07:07,970
we would train just on those
two independent examples,

182
00:07:07,970 --> 00:07:11,210
one negative labeled positive
and the other labeled negative.

183
00:07:11,210 --> 00:07:15,170
However, you might imagine that
you'll get a lot more strength

184
00:07:15,170 --> 00:07:18,860
in training if you also trained
on all the subconstituents,

185
00:07:18,860 --> 00:07:20,630
which would mean
essentially expanding

186
00:07:20,630 --> 00:07:23,000
this example into its
full root version,

187
00:07:23,000 --> 00:07:25,100
NLU is enlightening,
but also all

188
00:07:25,100 --> 00:07:27,250
of the sub-pieces that
are captured and labeled

189
00:07:27,250 --> 00:07:28,118
in the corpus.

190
00:07:28,118 --> 00:07:30,410
So that would give you many
more examples and much more

191
00:07:30,410 --> 00:07:31,647
diversity.

192
00:07:31,647 --> 00:07:33,230
And then of course,
"not enlightening"

193
00:07:33,230 --> 00:07:35,047
would be split apart as well.

194
00:07:35,047 --> 00:07:37,130
And then you could decide
for yourself in addition

195
00:07:37,130 --> 00:07:39,320
whether you want to treat
this as two instances

196
00:07:39,320 --> 00:07:41,300
of "enlightening" or one.

197
00:07:41,300 --> 00:07:42,850
And the code
facilitates all this.

198
00:07:42,850 --> 00:07:45,620
So you can formulate it as a
root only training scenario

199
00:07:45,620 --> 00:07:47,780
or as a subconstituent
training scenario.

200
00:07:47,780 --> 00:07:50,113
And you can keep or
remove duplicates.

201
00:07:50,113 --> 00:07:51,530
This is going to
impact the amount

202
00:07:51,530 --> 00:07:54,680
of computational resources that
you need for training models.

203
00:07:54,680 --> 00:07:57,350
But of course, bigger could
be better in this space,

204
00:07:57,350 --> 00:08:02,272
because you're just seeing much
more gold labeled information.

205
00:08:02,272 --> 00:08:03,230
So that's the overview.

206
00:08:03,230 --> 00:08:04,460
And for much more
on this, and how

207
00:08:04,460 --> 00:08:06,320
to work with our
distribution of the corpus,

208
00:08:06,320 --> 00:08:07,880
and so forth, I
would encourage you

209
00:08:07,880 --> 00:08:10,380
to work through this notebook
that I've linked at the bottom

210
00:08:10,380 --> 00:08:11,650
here.

211
00:08:11,650 --> 00:08:16,000


