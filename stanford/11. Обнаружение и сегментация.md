# 11\. Обнаружение и сегментация

Сегодня мы поговорим о различных типах других задач компьютерного зрения и расскажем о пространственных пикселях внутри ваших изображений. Мы увидим **сегментацию, локализацию, обнаружение**.

При классификации изображений, у нас будет приходить какое-то входное изображение и проходить через какую-то глубокую сверточную сеть. Эта сеть даст нам некоторый вектор признаков, возможно, 4096 измерений в случае AlexNet RGB. Дальше подавать эти признаки на полносвязный слой с 1000 выходами - разными оценками классов. Это, пожалуй, самая простая из возможных задач.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ml/main/stanford/images/cs231n_2017_lecture11_page-0017.jpg)

В задаче семантической сегментации мы хотим ввести изображение, а затем вывести решение категории для каждого пикселя в этом изображении. И потом сказать: это кот ходит по полю, он очень милый.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ml/main/stanford/images/cs231n_2017_lecture11_page-0019.jpg)

Есть одна интересная вещь при семантической сегментации, она не различает экземпляры. На примере справа у нас есть изображение с двумя коровами, где они стоят рядом друг к другу. И когда мы говорим о семантических сегментация мы просто маркируем все пиксели независимо от того, к какой категории относится этот пиксель. Вывод не делает различий между этими двумя коровами. Вместо этого мы просто получаем массу пикселей, которые все помечены как корова.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ml/main/stanford/images/cs231n_2017_lecture11_page-0021.jpg)

 Cемантическая сегментация может осуществляться посредством классификации. Итак, вы можете использовать идею скользящего окна. Мы берем наше входное изображение и разбиваем его на множество мелких крошечных локальных изображений. В этом примере мы взяли может быть, три обрезанных изображения головы коровы и применили к ним алгоритмы классификации, которые применяли к целым изображениям.

Возможно окно будет супер-супер долго бегать вперед и назад.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ml/main/stanford/images/cs231n_2017_lecture11_page-0023.jpg)

Поэтому вместо извлечения отдельных участков изображения, мы можем представить себе, что наша сеть станет огромной гигантской стопкой сверточных слоев без полностью связанных слоёв или что-то ещё, поэтому в этом случае у нас просто куча сверточных слоев.

Проблема в тренировочных данных для этого. Это очень дорого, правда. Нам нужно пометить каждый пиксель в этих входных изображениях: нарисовать контуры и заполнить области.

Если вы хотите сделать свертки, которые, возможно, с 64, 128 или 256 каналами для сверточных фильтров, что довольно часто встречается во многих таких сетях, затем запустите эти свертки в высоком разрешении, то будет чрезвычайно затратно в вычислительном отношении и потребуется огромное количество памяти. На практике вы обычно не видите сети с этой архитектурой. Вместо этого вы видите сети, которые что-то ищут. У нас есть понижающая дискретизация.

Одна из стратегий повышения частоты дискретизации выглядит примерно так:

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ml/main/stanford/images/cs231n_2017_lecture11_page-0027.jpg)

Чтобы уменьшить выборку, мы говорим о среднем объединении. Мы как бы берем пространственное среднее.

## Транспонированная свертка

 Когда вы делаете шаговую свертку с шагом два, это заканчивается понижением дискретизации изображения или карты функций в два раза.
А теперь транспонированная свертка - это как бы противоположное в некотором роде. Наш ввод будет два на два региона, а наш результат будет размером четыре на четыре.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ml/main/stanford/images/cs231n_2017_lecture11_page-0039.jpg)

Мы делаем транспонированную свертку три на один. Наш фильтр - это всего лишь три числа. Наш ввод - это два числа.

![](https://raw.githubusercontent.com/AlexandrParkhomenko/ml/main/stanford/images/cs231n_2017_lecture11_page-0041.jpg)
_В свертке слева опечатка: Первую матрицу в умножении читать как x, y, z (вместо x)_ 

У этой операции много разных имен в литературе. Иногда её называют деконволюцией. Это плохое имя. Иногда её называют сверткой с дробным шагом.


С оригинальной лекцией можно ознакомиться на [YouTube](https://youtu.be/nDPWywWRIRo).
