1
00:00:04,580 --> 00:00:08,460
So let me now tell you about position-aware

2
00:00:08,460 --> 00:00:11,705
graph neural networks that are going to solve,

3
00:00:11,705 --> 00:00:13,810
uh, part of the- part of the problem.

4
00:00:13,810 --> 00:00:18,450
So imagine there are two types of tasks on the graphs, right?

5
00:00:18,450 --> 00:00:19,860
There is what we are going to call

6
00:00:19,860 --> 00:00:23,785
structure-aware tasks and there is position-aware tasks, and, again,

7
00:00:23,785 --> 00:00:26,620
this is just to illustrate this concept, um,

8
00:00:26,620 --> 00:00:31,090
about how graph structure may affect the underlying labels.

9
00:00:31,090 --> 00:00:33,545
And in reality, in the real world, you know,

10
00:00:33,545 --> 00:00:36,530
every task is a bit of a structure-aware and a bit of a

11
00:00:36,530 --> 00:00:39,725
position-aware but some tasks will be more position-aware,

12
00:00:39,725 --> 00:00:41,430
some will be more structure-aware,

13
00:00:41,430 --> 00:00:45,275
and we'd like to have models that can operate in both regimes, right?

14
00:00:45,275 --> 00:00:49,640
When structure-aware- in structure-aware tasks, uh, for example,

15
00:00:49,640 --> 00:00:51,560
labeling of the nodes, uh,

16
00:00:51,560 --> 00:00:52,955
for this simple, uh,

17
00:00:52,955 --> 00:00:54,890
graph with two connected triangles,

18
00:00:54,890 --> 00:00:59,225
if nodes are labeled according to these labels A and B here, then, um,

19
00:00:59,225 --> 00:01:02,630
this is one way because the- the r- the structure

20
00:01:02,630 --> 00:01:06,460
of the node and the neighborhood basically defines its label.

21
00:01:06,460 --> 00:01:11,119
A different type of a task is what we call position-aware task,

22
00:01:11,119 --> 00:01:14,300
where, for example, if you think about community detection,

23
00:01:14,300 --> 00:01:18,755
community detection is a position-aware task right here, uh, you know,

24
00:01:18,755 --> 00:01:21,320
nodes on one side have one label and nodes on

25
00:01:21,320 --> 00:01:23,980
the other side have the other label even though their,

26
00:01:23,980 --> 00:01:26,980
uh, uh, uh, local structures are,

27
00:01:26,980 --> 00:01:29,890
uh, are comparable or iso- isomorphic, right?

28
00:01:29,890 --> 00:01:32,330
Like, uh, Node 1 and Node, uh, 2,

29
00:01:32,330 --> 00:01:35,585
um, they basically have the same neighborhood structure surrounding them.

30
00:01:35,585 --> 00:01:38,615
So instructure-aware tasks, they should be labeled.

31
00:01:38,615 --> 00:01:40,625
With the same label in position-aware,

32
00:01:40,625 --> 00:01:42,890
they might be labeled with different labels because they

33
00:01:42,890 --> 00:01:46,255
are in different parts, uh, of the network.

34
00:01:46,255 --> 00:01:49,580
And, uh, the point is that the GNNs,

35
00:01:49,580 --> 00:01:50,780
the graph neural networks,

36
00:01:50,780 --> 00:01:52,700
the GCN, GraphSAGE, uh,

37
00:01:52,700 --> 00:01:57,410
graph attention network, they work well for, uh, structure-aware tasks.

38
00:01:57,410 --> 00:02:02,150
Right here, basically, we can differentiate v_1 and- and v_2, um,

39
00:02:02,150 --> 00:02:04,910
because we are using- because they will have different,

40
00:02:04,910 --> 00:02:07,560
uh, computational graphs as illustrated here, right?

41
00:02:07,560 --> 00:02:10,400
v_1 has the following computation graph,

42
00:02:10,400 --> 00:02:13,910
v_2 has a different computation graph just because v_2 has

43
00:02:13,910 --> 00:02:17,810
three neighbors and v_1 has two neighbors even at the first hop so we are

44
00:02:17,810 --> 00:02:21,560
able to distinguish them and meaning we are able to assign them different labels

45
00:02:21,560 --> 00:02:26,095
because they'll have different embeddings because they have different computation graphs.

46
00:02:26,095 --> 00:02:31,320
How about position-aware tasks where now we change the labeling of the nodes,

47
00:02:31,320 --> 00:02:33,465
you know, let's say, according to the communities?

48
00:02:33,465 --> 00:02:39,230
In this case, a plain GNN is going to fail because nodes v_1 and v_2, these, uh,

49
00:02:39,230 --> 00:02:40,805
labeled here in the graph,

50
00:02:40,805 --> 00:02:42,770
have the same computation graphs

51
00:02:42,770 --> 00:02:45,740
because they're kind of symmetric with each other, right?

52
00:02:45,740 --> 00:02:47,915
So the point is that now, um,

53
00:02:47,915 --> 00:02:51,110
because they have the same computation graphs and, again,

54
00:02:51,110 --> 00:02:55,885
because we are assuming there is no discriminative node feature information given to us,

55
00:02:55,885 --> 00:02:57,810
the two nodes have the same, uh,

56
00:02:57,810 --> 00:03:01,295
local neighborhood structure, they have the same computation graph,

57
00:03:01,295 --> 00:03:04,504
which means they will be- they will have the same embedding,

58
00:03:04,504 --> 00:03:08,275
which means they will- the classifier will have to assign them the same label.

59
00:03:08,275 --> 00:03:10,500
Um, and in this case, we want them to,

60
00:03:10,500 --> 00:03:12,390
uh, label them differently.

61
00:03:12,390 --> 00:03:14,270
So the question is,

62
00:03:14,270 --> 00:03:17,030
how can we extend graph neural networks,

63
00:03:17,030 --> 00:03:20,360
deep learning methods that are- that would be able to, uh,

64
00:03:20,360 --> 00:03:23,405
solve or work well in this, uh, you know,

65
00:03:23,405 --> 00:03:25,490
toy example that kind of tries to

66
00:03:25,490 --> 00:03:29,170
illustrate this notion of position-aware prediction tasks.

67
00:03:29,170 --> 00:03:31,800
Um, and the key idea, uh,

68
00:03:31,800 --> 00:03:34,995
for this part is the notion of an anchor

69
00:03:34,995 --> 00:03:39,015
because the way you know your location is to- to know,

70
00:03:39,015 --> 00:03:41,430
um, what is your position or,

71
00:03:41,430 --> 00:03:44,180
uh, uh, against some reference point, right?

72
00:03:44,180 --> 00:03:47,660
And we are going to call these anchors to be a reference points.

73
00:03:47,660 --> 00:03:50,570
And if I know how far away from, uh,

74
00:03:50,570 --> 00:03:53,000
reference points I am and you know kind of

75
00:03:53,000 --> 00:03:55,970
how far away you are from different reference points,

76
00:03:55,970 --> 00:03:58,490
then we can, uh, distinguish our locations.

77
00:03:58,490 --> 00:04:02,480
It's almost like you wanna triangulate the position of the node inside

78
00:04:02,480 --> 00:04:06,695
the graph by- by characterizing some kind of a distance to the anchor node.

79
00:04:06,695 --> 00:04:08,060
So that's- that's the idea.

80
00:04:08,060 --> 00:04:11,410
The idea is we wanna have a reference point, um,

81
00:04:11,410 --> 00:04:15,740
and to quantify the location so we are going to use this notion of anchor,

82
00:04:15,740 --> 00:04:20,000
uh, anchor nodes to give us these, uh, locations, right?

83
00:04:20,000 --> 00:04:24,635
So we are going to basically pick these r- anchors at random and we are going to say,

84
00:04:24,635 --> 00:04:26,030
let's pick a node,

85
00:04:26,030 --> 00:04:28,010
let's say S_1 in this case, uh,

86
00:04:28,010 --> 00:04:31,925
and let's call it an anchor node and then we are going to represent

87
00:04:31,925 --> 00:04:37,225
the position of v_1 and v_2 by their relative distance to the, uh,

88
00:04:37,225 --> 00:04:40,765
anchor node and because these two- this- the distance, uh,

89
00:04:40,765 --> 00:04:45,510
of v_1 and v_2 in this case to the anchor node s_1 will be different, uh,

90
00:04:45,510 --> 00:04:48,320
this basically means that we'll allow- this will allow us to

91
00:04:48,320 --> 00:04:52,380
differentiate or distinguish v_1 from v_2, right?

92
00:04:52,380 --> 00:04:56,270
So intuitively, the anchor node serves almost like as a reference point,

93
00:04:56,270 --> 00:04:59,300
as a coordinate axis that tells us, um,

94
00:04:59,300 --> 00:05:00,950
how far away from, uh,

95
00:05:00,950 --> 00:05:04,770
each different nodes are and this basically allows us to, kind of,

96
00:05:04,770 --> 00:05:09,560
triangulate or locate the position of the node, uh, in the graph.

97
00:05:09,560 --> 00:05:14,075
Um, of course, we are not only- only going to use one anchor node,

98
00:05:14,075 --> 00:05:16,670
we are actually going to use multiple anchor nodes

99
00:05:16,670 --> 00:05:19,610
because if we can- if we use multiple anchor nodes,

100
00:05:19,610 --> 00:05:22,340
we can better characterize the position of

101
00:05:22,340 --> 00:05:25,330
a node in different region- regions on- of the graph.

102
00:05:25,330 --> 00:05:27,755
So kind of if you have multiple anchor nodes,

103
00:05:27,755 --> 00:05:28,970
we are able to better,

104
00:05:28,970 --> 00:05:31,085
um, distinguish or, uh,

105
00:05:31,085 --> 00:05:33,020
set, uh, our position.

106
00:05:33,020 --> 00:05:35,825
Of course, we don't wanna have too many becomes- beco-

107
00:05:35,825 --> 00:05:39,065
because then it becomes computationally hard, but, you know,

108
00:05:39,065 --> 00:05:41,060
having some number of them and there is actually,

109
00:05:41,060 --> 00:05:43,625
uh, a theory how many we wanna have, um,

110
00:05:43,625 --> 00:05:44,795
then, uh, we can, uh,

111
00:05:44,795 --> 00:05:48,335
characterize node's position in the network, uh, quite well.

112
00:05:48,335 --> 00:05:49,985
Here, in this case, I- you know,

113
00:05:49,985 --> 00:05:52,190
s_1 and s_2 are anchor nodes.

114
00:05:52,190 --> 00:05:55,575
Um, v_1 and v_2 are nodes of interest and I'm simply saying, you know,

115
00:05:55,575 --> 00:05:59,505
v_1 is one hop away from s_1 and two hops away from s_2,

116
00:05:59,505 --> 00:06:03,945
while v_2 is two hops away from s_1 and one hop away from, uh, s_2.

117
00:06:03,945 --> 00:06:07,725
And now, this kind of allows us to distinguish v_1 from, uh,

118
00:06:07,725 --> 00:06:12,415
v_2 because they are at different distances from these, uh, anchor nodes.

119
00:06:12,415 --> 00:06:14,680
Um, there is another, um,

120
00:06:14,680 --> 00:06:18,020
generalization that turns out to be important is

121
00:06:18,020 --> 00:06:21,260
that we don't wanna really only talk about anchor nodes,

122
00:06:21,260 --> 00:06:24,240
we wanna talk about anchor sets, right?

123
00:06:24,240 --> 00:06:26,870
So, uh, we are going to generalize this notion of

124
00:06:26,870 --> 00:06:30,710
an anchor node from a single node to a set of nodes and then we

125
00:06:30,710 --> 00:06:33,530
are going to define the distance between the node of interest and

126
00:06:33,530 --> 00:06:37,415
the anchor set as the minimum distance to any of the nodes,

127
00:06:37,415 --> 00:06:39,645
uh, in the anchor set, right?

128
00:06:39,645 --> 00:06:41,725
Um, and the idea here is that, uh,

129
00:06:41,725 --> 00:06:45,920
this will allow us to even triangulate the position of the node at

130
00:06:45,920 --> 00:06:49,940
a much more fine-grained level because anchor sets will allow us,

131
00:06:49,940 --> 00:06:52,130
uh, to provide more precise,

132
00:06:52,130 --> 00:06:54,170
uh, position information, right?

133
00:06:54,170 --> 00:06:59,430
Um, and it will allow us to keep the total number of anchors to be still small.

134
00:06:59,430 --> 00:07:01,590
So what I mean by this is that, for example,

135
00:07:01,590 --> 00:07:03,930
I could say, let's- let's have,

136
00:07:03,930 --> 00:07:05,370
uh, now anchor sets.

137
00:07:05,370 --> 00:07:07,590
I have, uh, anchor node s_1,

138
00:07:07,590 --> 00:07:09,165
I have anchor node s_2,

139
00:07:09,165 --> 00:07:11,310
but then also have an anchor set,

140
00:07:11,310 --> 00:07:16,575
I'll denote it as s_3 that includes node v_3 and, uh, s_1.

141
00:07:16,575 --> 00:07:19,835
And now, I'm going to characterize the distance of- uh,

142
00:07:19,835 --> 00:07:22,205
of a given node,

143
00:07:22,205 --> 00:07:25,470
uh, towards, uh, against that anchor set.

144
00:07:25,470 --> 00:07:27,170
Um, and in this case,

145
00:07:27,170 --> 00:07:30,125
for example, if I'm interested in position of v_3, uh,

146
00:07:30,125 --> 00:07:33,455
v_3 will have a distance of 0 to the anchor set

147
00:07:33,455 --> 00:07:36,690
s_3 because it is part of the anchor set while

148
00:07:36,690 --> 00:07:39,350
v_2 is going to have a distance of 1 because

149
00:07:39,350 --> 00:07:43,595
the closest node in the anchor set to v_1 is- is,

150
00:07:43,595 --> 00:07:45,205
uh, one hop away.

151
00:07:45,205 --> 00:07:48,690
Um, so, uh, what does this mean that,

152
00:07:48,690 --> 00:07:52,265
um, for example, if we would, as we had before,

153
00:07:52,265 --> 00:07:55,385
if I only use s_1 and s_2 as my anchor, uh,

154
00:07:55,385 --> 00:07:56,930
nodes or anchor sets,

155
00:07:56,930 --> 00:07:58,400
then v_3 and v- uh,

156
00:07:58,400 --> 00:08:01,265
uh, v_1 cannot be differentiated with each other.

157
00:08:01,265 --> 00:08:02,675
They have the same distances.

158
00:08:02,675 --> 00:08:05,360
But now if I use this anchor set of Size 2,

159
00:08:05,360 --> 00:08:07,270
I can actually just differentiate,

160
00:08:07,270 --> 00:08:09,150
uh, v_1 and v_3.

161
00:08:09,150 --> 00:08:13,760
And, again, there is a nice theory that says that it- it

162
00:08:13,760 --> 00:08:18,120
is beneficial to use anchor sets of, uh,

163
00:08:18,120 --> 00:08:21,150
different sizes because then the number of,

164
00:08:21,150 --> 00:08:23,270
uh, anchor sets, the number of coordinates,

165
00:08:23,270 --> 00:08:24,905
the number of reference points,

166
00:08:24,905 --> 00:08:26,190
uh, you need, uh,

167
00:08:26,190 --> 00:08:29,475
to locate a node in the graph is, uh, relatively small.

168
00:08:29,475 --> 00:08:31,365
It's smaller than if you would just use, uh,

169
00:08:31,365 --> 00:08:34,080
anchor nodes like s_1 and s_2 and add,

170
00:08:34,080 --> 00:08:36,250
uh, multiple, uh, anchor nodes.

171
00:08:36,250 --> 00:08:39,485
So what is the summary so far?

172
00:08:39,485 --> 00:08:41,570
Uh, we are going to de- we have just developed

173
00:08:41,570 --> 00:08:44,585
this positional encoding of a node in the graph,

174
00:08:44,585 --> 00:08:47,930
where we are going to represent a node's position by

175
00:08:47,930 --> 00:08:53,310
its distance to randomly selected anchor sets and each dimension in this,

176
00:08:53,310 --> 00:08:54,705
um, in this, uh,

177
00:08:54,705 --> 00:08:57,870
encoding will, uh, tell me the, uh,

178
00:08:57,870 --> 00:09:01,855
the- will be tied to a given anchor set and will be

179
00:09:01,855 --> 00:09:07,100
the minimum distance from a node of interest to any of the nodes in the anchor set.

180
00:09:07,100 --> 00:09:11,390
Uh, that is the- that is the idea of how we are going to,

181
00:09:11,390 --> 00:09:13,295
uh, uh, create this,

182
00:09:13,295 --> 00:09:15,460
uh, positional, uh, encoding.

183
00:09:15,460 --> 00:09:20,105
Now, uh, before I move on and use- how this position information is used,

184
00:09:20,105 --> 00:09:21,320
the way- of course,

185
00:09:21,320 --> 00:09:24,950
you can ask how many of these sets do you need and how big they need to be?

186
00:09:24,950 --> 00:09:28,100
And what we are going to do is we are going to do the following.

187
00:09:28,100 --> 00:09:31,205
We are going to have an e- expone- er,

188
00:09:31,205 --> 00:09:34,805
anchor sets of exponentially increasing size,

189
00:09:34,805 --> 00:09:38,820
but we are going to use exponentially fewer of them, right?

190
00:09:38,820 --> 00:09:40,560
So we will have a lot of, uh,

191
00:09:40,560 --> 00:09:42,290
anchor sets of Size 1,

192
00:09:42,290 --> 00:09:45,460
we'll have half that number of anchor sets of Size 2,

193
00:09:45,460 --> 00:09:47,415
we'll have, you know, uh,

194
00:09:47,415 --> 00:09:50,240
half of that number of anchor sets of Size 4,

195
00:09:50,240 --> 00:09:53,000
Size 8, Size 16, and so on.

196
00:09:53,000 --> 00:09:56,060
Um, so this- this means we'll have, you know,

197
00:09:56,060 --> 00:09:58,715
some relatively small number of anchor sets where

198
00:09:58,715 --> 00:10:02,185
each next anchor set size is going to be doubled,

199
00:10:02,185 --> 00:10:05,760
but the number of them will be half of what we had before.

200
00:10:05,760 --> 00:10:08,870
And that's usually a good way how to generate these, uh,

201
00:10:08,870 --> 00:10:11,930
anchor sets and the- the nodes that belong to anchor sets,

202
00:10:11,930 --> 00:10:13,535
we simply select them, uh,

203
00:10:13,535 --> 00:10:15,910
uniformly, uh, at random.

204
00:10:15,910 --> 00:10:19,815
And then we charac- as I said, we characterize, uh,

205
00:10:19,815 --> 00:10:25,720
this positional encoding of a node by simply the minimum distance from the node to the,

206
00:10:25,720 --> 00:10:27,220
uh, any of the nodes,

207
00:10:27,220 --> 00:10:30,005
uh, in the given, uh, anchor set.

208
00:10:30,005 --> 00:10:33,840
So now, how do we use this positional information?

209
00:10:33,840 --> 00:10:35,450
A simple way of using

210
00:10:35,450 --> 00:10:39,950
the positional information is to use it as an augmented node feature.

211
00:10:39,950 --> 00:10:42,125
And this works really well- well in practice.

212
00:10:42,125 --> 00:10:47,885
So basically, we just enrich the feature descript- descriptor of a node with this,

213
00:10:47,885 --> 00:10:49,970
uh, positional information, uh,

214
00:10:49,970 --> 00:10:52,420
characterized by the shortest path distance,

215
00:10:52,420 --> 00:10:53,730
uh, to the anchor sets.

216
00:10:53,730 --> 00:10:56,510
Uh, the issue here is that since

217
00:10:56,510 --> 00:11:01,445
each posi- dimension of position encoding is tied to a random anchor,

218
00:11:01,445 --> 00:11:03,440
dimensions of positional encoding,

219
00:11:03,440 --> 00:11:08,000
um, can be randomly permuted and the encoding, uh, could be,

220
00:11:08,000 --> 00:11:10,785
uh, basically is semantically the same meaning,

221
00:11:10,785 --> 00:11:13,335
um, er, er, without changing it- its meaning.

222
00:11:13,335 --> 00:11:15,600
So, uh, and- and what this means, uh,

223
00:11:15,600 --> 00:11:19,230
imagine you permute the input dimensions of a normal, uh, er, uh,

224
00:11:19,230 --> 00:11:22,995
er, neural network, the output will, uh, change.

225
00:11:22,995 --> 00:11:25,190
So what is, um,

226
00:11:25,190 --> 00:11:29,540
what is a more rigorous solution than just using these positional encodings as they are

227
00:11:29,540 --> 00:11:34,220
is to design a special set of neural network operators that can maintain this,

228
00:11:34,220 --> 00:11:38,150
uh, permutational invariant property of positional encoding.

229
00:11:38,150 --> 00:11:42,605
So basically, uh, that- the position encoding is order invariant,

230
00:11:42,605 --> 00:11:44,090
which you can achieve through,

231
00:11:44,090 --> 00:11:45,455
let's say, some kind of, uh,

232
00:11:45,455 --> 00:11:47,240
some aggregator or, um,

233
00:11:47,240 --> 00:11:50,605
uh, aggregators that are uh, order invariant.

234
00:11:50,605 --> 00:11:54,485
Uh, because, uh, permuting the input feature dimension

235
00:11:54,485 --> 00:11:58,490
will only result in the permutation of the ou- output dimension,

236
00:11:58,490 --> 00:12:01,520
uh, but the value of each dimension shouldn't change.

237
00:12:01,520 --> 00:12:04,085
And, uh, you know, there is a paper, er,

238
00:12:04,085 --> 00:12:07,160
that introduces position-aware graph neural networks, uh,

239
00:12:07,160 --> 00:12:12,440
to say how you can do this in a more rigorous way but the key here is this notion of

240
00:12:12,440 --> 00:12:15,230
an anchor and the notion that you can

241
00:12:15,230 --> 00:12:18,905
quantify the position of a node in the graph by the distance,

242
00:12:18,905 --> 00:12:23,630
uh, to the anchor and that allows us to now improve the expressiveness of

243
00:12:23,630 --> 00:12:26,510
graph neural networks because nodes won't

244
00:12:26,510 --> 00:12:30,185
only know what is their local neighborhood structure around them,

245
00:12:30,185 --> 00:12:32,515
but they will also know what is their location,

246
00:12:32,515 --> 00:12:34,095
uh, or position, uh,

247
00:12:34,095 --> 00:12:36,130
in the neural network.

