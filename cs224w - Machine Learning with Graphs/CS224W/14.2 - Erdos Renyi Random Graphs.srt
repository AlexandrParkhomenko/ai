1
00:00:04,100 --> 00:00:08,640
So now let's start talking about these null-models,

2
00:00:08,640 --> 00:00:13,155
generative models for graphs that can serve as reference points.

3
00:00:13,155 --> 00:00:18,570
So the first- ah, we are going to talk about is the Erdős-Rényi ah, random graph model.

4
00:00:18,570 --> 00:00:24,710
Basically mention- named after two famous Hungarian mathematicians who

5
00:00:24,710 --> 00:00:31,640
developed a lot of mathematical theory around the random graph generation, er, processes.

6
00:00:31,640 --> 00:00:33,590
And random graph model-

7
00:00:33,590 --> 00:00:38,010
Erdős-Rényi random graph model is kind of the simplest way to generate the graph, right?

8
00:00:38,010 --> 00:00:39,720
We have two variants of it.

9
00:00:39,720 --> 00:00:43,710
One called G_np and the other one called G_nm.

10
00:00:43,710 --> 00:00:48,110
G_np says it is an undirected graph on n nodes where

11
00:00:48,110 --> 00:00:53,990
every edge appear iid with probability p. So basically for every pair of nodes,

12
00:00:53,990 --> 00:00:56,110
I get to flip this biased coin p,

13
00:00:56,110 --> 00:01:00,150
and I get to observe whether the edge is created.

14
00:01:00,150 --> 00:01:04,280
And then a different version of this model is called G_nm,

15
00:01:04,280 --> 00:01:09,665
where it's an undirected graph with n nodes and m edges picked uniformly at random.

16
00:01:09,665 --> 00:01:11,885
What's the difference between the two models?

17
00:01:11,885 --> 00:01:14,670
They both have the same number of nodes, um,

18
00:01:14,670 --> 00:01:19,230
they both have the same number of edges in expectation,

19
00:01:19,230 --> 00:01:23,165
ah, and they both have edges placed at random between the nodes.

20
00:01:23,165 --> 00:01:28,745
So the point being because in G_np the edge creation is stochastic,

21
00:01:28,745 --> 00:01:34,235
you know, in expectation I will have n times- n times p number of edges.

22
00:01:34,235 --> 00:01:36,710
But because of some variance of this random process,

23
00:01:36,710 --> 00:01:40,220
I may have a bit less or I may have a bit more while in G_nm,

24
00:01:40,220 --> 00:01:43,145
I always have the same number of edges.

25
00:01:43,145 --> 00:01:44,510
So now with this,

26
00:01:44,510 --> 00:01:46,670
ah, simple generative model,

27
00:01:46,670 --> 00:01:51,270
let's look at what kind of networks does this model produce, right?

28
00:01:51,270 --> 00:01:55,520
So basically, the point is that these models are stochastic.

29
00:01:55,520 --> 00:02:00,935
So it means that these random graph models do not uniquely determine the graph, right?

30
00:02:00,935 --> 00:02:03,830
The graph is a result of a random process.

31
00:02:03,830 --> 00:02:09,590
So we can have many different realizations for the same n and p value.

32
00:02:09,590 --> 00:02:13,695
So here for example, I show you different random graphs, um,

33
00:02:13,695 --> 00:02:15,375
generated by, you know,

34
00:02:15,375 --> 00:02:19,935
n equals 10 and p equals 1 over 6.

35
00:02:19,935 --> 00:02:22,530
So what we wanna do next we're gonna say,

36
00:02:22,530 --> 00:02:24,375
okay, if I take this um,

37
00:02:24,375 --> 00:02:27,350
G_np model and I generate random graphs from it,

38
00:02:27,350 --> 00:02:29,420
you know, what would be the degree distribution?

39
00:02:29,420 --> 00:02:31,135
What would be clustering coefficient?

40
00:02:31,135 --> 00:02:33,435
What would be the average path length?

41
00:02:33,435 --> 00:02:35,055
What would be the connectivity?

42
00:02:35,055 --> 00:02:37,395
Do I get the giant connected component?

43
00:02:37,395 --> 00:02:40,230
And what is beautiful about G_np,

44
00:02:40,230 --> 00:02:42,900
the Erdős-Rényi random graph model,

45
00:02:42,900 --> 00:02:45,590
it's that- it is that it is kind of so

46
00:02:45,590 --> 00:02:49,130
simple that you can mathematically analyze its properties, right?

47
00:02:49,130 --> 00:02:54,810
You can mathematically derive these quantities using algebra alone,

48
00:02:54,810 --> 00:02:56,900
you don't have to do simulations and measurements.

49
00:02:56,900 --> 00:02:58,910
So it's kind of the simplest model,

50
00:02:58,910 --> 00:03:01,755
but it's very- leads to very rich, er,

51
00:03:01,755 --> 00:03:05,780
mathematical literature, um, and very rich mathematical analysis.

52
00:03:05,780 --> 00:03:08,435
So there are kind of- and it's an entire sub field

53
00:03:08,435 --> 00:03:11,605
that studies random graphs arising from this model.

54
00:03:11,605 --> 00:03:13,120
So, er, first, you know,

55
00:03:13,120 --> 00:03:16,715
what would be the degree distribution of the G_np model?

56
00:03:16,715 --> 00:03:20,439
The degree distribution of G_np model would- is binomial.

57
00:03:20,439 --> 00:03:24,600
So if you diff- you say y here is like an argument, you know,

58
00:03:24,600 --> 00:03:28,250
let P of k denote the fraction of nodes with a given degree k. Then if

59
00:03:28,250 --> 00:03:32,000
you see how many nodes do I- would I have in the given degree?

60
00:03:32,000 --> 00:03:36,620
You say, ah-ha, out of n minus 1 possible members of a given node,

61
00:03:36,620 --> 00:03:39,020
I get to sample or pick k of them.

62
00:03:39,020 --> 00:03:45,205
So n minus 1 choose k is the number of times I can select k nodes of out of n minus 1.

63
00:03:45,205 --> 00:03:49,575
And then, you know, because I'm saying my deg- my node has to have degree k,

64
00:03:49,575 --> 00:03:53,580
it has to have k edges, er, be created.

65
00:03:53,580 --> 00:03:56,800
So the likelihood of that is p raised to the power of k,

66
00:03:56,800 --> 00:04:01,130
and then the other coin flips have to result in not-edges so that would

67
00:04:01,130 --> 00:04:05,150
mean it's 1 minus n minus 1 minus k, right?

68
00:04:05,150 --> 00:04:06,710
So that's the probability of,

69
00:04:06,710 --> 00:04:08,840
er, missing the rest of the edges.

70
00:04:08,840 --> 00:04:10,250
And if you look at this formula,

71
00:04:10,250 --> 00:04:13,445
this is exactly the formula for a binomial distribution.

72
00:04:13,445 --> 00:04:15,770
If you look at binomial distribution,

73
00:04:15,770 --> 00:04:18,050
it has this kind of bell-like shape.

74
00:04:18,050 --> 00:04:21,890
So essentially, it's like a discrete analog of our Gaussian distribution.

75
00:04:21,890 --> 00:04:23,150
It has, you know,

76
00:04:23,150 --> 00:04:28,410
average- average or mean of the distribution is simply p times,

77
00:04:28,410 --> 00:04:29,480
er, n minus 1.

78
00:04:29,480 --> 00:04:32,950
So average degree in a G_np network will be,

79
00:04:32,950 --> 00:04:35,240
er, p times n minus 1.

80
00:04:35,240 --> 00:04:36,785
And if n is massive,

81
00:04:36,785 --> 00:04:38,330
then this is essentially, er,

82
00:04:38,330 --> 00:04:42,710
n times p. So this is about binomi- er,

83
00:04:42,710 --> 00:04:44,060
about the degree distribution.

84
00:04:44,060 --> 00:04:45,515
And again, notice that,

85
00:04:45,515 --> 00:04:47,330
you know, in MSN network,

86
00:04:47,330 --> 00:04:52,010
we didn't see like this bell-shaped like curve, we saw something very skewed.

87
00:04:52,010 --> 00:04:55,200
So clearly, er, G_np does not

88
00:04:55,200 --> 00:05:00,695
generate graphs with the degree distribution that is similar to the MSN network.

89
00:05:00,695 --> 00:05:03,420
How about clustering coefficient, right?

90
00:05:03,420 --> 00:05:06,200
Um, remember the definition of clustering coefficient;

91
00:05:06,200 --> 00:05:09,080
it is twice the number of edges between the neighbors of

92
00:05:09,080 --> 00:05:12,530
a given node divided by k times k minus 1,

93
00:05:12,530 --> 00:05:14,240
where k is the degree of that node.

94
00:05:14,240 --> 00:05:18,140
And remember also that edges in G_np appear iid with probability

95
00:05:18,140 --> 00:05:24,500
p. So the expected number of edges between, um,

96
00:05:24,500 --> 00:05:29,585
um, these neighbors, e sub i of a given node i is simply, er,

97
00:05:29,585 --> 00:05:34,085
the total number of possible edges times the probability that, you know,

98
00:05:34,085 --> 00:05:36,460
each one of them comes- comes up,

99
00:05:36,460 --> 00:05:38,600
er, and actually materializes.

100
00:05:38,600 --> 00:05:40,610
So the expected number of edges,

101
00:05:40,610 --> 00:05:45,745
so the expected e sub i is simply k times k minus 1 divided by 2,

102
00:05:45,745 --> 00:05:48,500
where k is the degree of node i times the probability

103
00:05:48,500 --> 00:05:52,010
that actually this- this particular pair of nodes,

104
00:05:52,010 --> 00:05:53,855
this particular edge appears,

105
00:05:53,855 --> 00:05:59,110
and that is k choose 2 type number of such pairs, er, as written here.

106
00:05:59,110 --> 00:06:01,250
So now if you put these two together, er,

107
00:06:01,250 --> 00:06:04,800
what you get is you get the- the- the, um, ah,

108
00:06:04,800 --> 00:06:08,940
clustering coefficient is er, er,

109
00:06:08,940 --> 00:06:10,380
er relates to, er,

110
00:06:10,380 --> 00:06:13,900
to the graph as average degree divided by the number of nodes.

111
00:06:13,900 --> 00:06:15,750
So what does this mean,

112
00:06:15,750 --> 00:06:17,250
is that the average- what,

113
00:06:17,250 --> 00:06:19,790
we can conclude is that the average clustering coefficient

114
00:06:19,790 --> 00:06:21,860
of a random graph will be small, right?

115
00:06:21,860 --> 00:06:23,090
So basically, if you generate

116
00:06:23,090 --> 00:06:26,890
bigger and bigger graphs and keep the average degree constant,

117
00:06:26,890 --> 00:06:32,060
um, then, er, the clustering will decrease with the size of the graph, right?

118
00:06:32,060 --> 00:06:37,010
And we could even take the values from MSN network and plug them here, right?

119
00:06:37,010 --> 00:06:39,800
So average degree was 14, number of nodes

120
00:06:39,800 --> 00:06:41,860
was 180 million, right?

121
00:06:41,860 --> 00:06:44,250
So this means that, um, our,

122
00:06:44,250 --> 00:06:47,910
er, clustering coefficient should be 10 to the minus 6, right?

123
00:06:47,910 --> 00:06:51,000
It's 14 divided by 180 million.

124
00:06:51,000 --> 00:06:55,640
Um, so, um, that's kind of what is the clustering coefficient of,

125
00:06:55,640 --> 00:06:57,920
a Erdős-Rényi random graph.

126
00:06:57,920 --> 00:07:03,325
So this means that clearly our MSN network is not a random graph.

127
00:07:03,325 --> 00:07:09,450
And then the third property I wanna comment on is connected components, um,

128
00:07:09,450 --> 00:07:13,810
and this is very interesting because in, er, um,

129
00:07:13,810 --> 00:07:17,690
in G_np you can actually analyze how is the graph going to be

130
00:07:17,690 --> 00:07:22,290
connected as a function of the edge probability p, right?

131
00:07:22,290 --> 00:07:23,550
If the p is 0,

132
00:07:23,550 --> 00:07:24,870
then the graph will be empty.

133
00:07:24,870 --> 00:07:26,190
No, there would be no edges.

134
00:07:26,190 --> 00:07:28,155
It could be just a set of isolated nodes.

135
00:07:28,155 --> 00:07:29,935
If the p equals 1,

136
00:07:29,935 --> 00:07:33,415
then every pair of nodes will be connected and that's a complete graph.

137
00:07:33,415 --> 00:07:40,385
What the result is that the- the connected component is going to appear when p is,

138
00:07:40,385 --> 00:07:44,335
um, is of the order 1 over n.

139
00:07:44,335 --> 00:07:49,220
Which basically means as soon as the average degree gets above 1,

140
00:07:49,220 --> 00:07:52,000
the giant component will start to appear.

141
00:07:52,000 --> 00:07:54,140
And if the average degree is below 1,

142
00:07:54,140 --> 00:07:56,510
there won't be this large giant component.

143
00:07:56,510 --> 00:08:00,965
So we get these kind of phase transition behavior, uh, in G_np.

144
00:08:00,965 --> 00:08:05,370
And then of course, you can also analyze what is happening as the,

145
00:08:05,370 --> 00:08:07,340
er, edge probability is increasing.

146
00:08:07,340 --> 00:08:10,379
And for example, you can find out if you know, er,

147
00:08:10,379 --> 00:08:14,810
edge probabilities of the order 2 times log n divided by n minus 1.

148
00:08:14,810 --> 00:08:15,950
Then at that point in time,

149
00:08:15,950 --> 00:08:17,930
your graph will be- um, um,

150
00:08:17,930 --> 00:08:20,210
er, won't have any isolated nodes.

151
00:08:20,210 --> 00:08:23,120
It may still have a couple of disconnected components,

152
00:08:23,120 --> 00:08:27,310
but every- every node in- will have some edges.

153
00:08:27,310 --> 00:08:29,190
So the point being,

154
00:08:29,190 --> 00:08:31,080
is that in G_np,

155
00:08:31,080 --> 00:08:38,409
the largest connected component occurs exactly when the average degree is greater than 1.

156
00:08:38,409 --> 00:08:42,859
And here's the result of a simulation where we change the average degree.

157
00:08:42,860 --> 00:08:46,590
And here we are asking what is the fraction of nodes in the largest connected component?

158
00:08:46,590 --> 00:08:50,330
And you see how largest connected component is kind of small, small, small.

159
00:08:50,330 --> 00:08:54,290
But as soon as the average degree hits value 1,

160
00:08:54,290 --> 00:08:55,430
which means that, er,

161
00:08:55,430 --> 00:09:00,200
p is greater than 1 minus 1 over n minus 1,

162
00:09:00,200 --> 00:09:03,200
this giant component starts to emerge, and you know what?

163
00:09:03,200 --> 00:09:05,285
When the average degree is 2,

164
00:09:05,285 --> 00:09:09,995
it's already 80% of the nodes in- is in the big, er, largest component.

165
00:09:09,995 --> 00:09:16,455
So the point being, G_np is connected as soon as or has a large component,

166
00:09:16,455 --> 00:09:19,440
as soon as, er, average degree is greater than 1.

167
00:09:19,440 --> 00:09:22,365
So, er, what have we learned so far?

168
00:09:22,365 --> 00:09:25,900
We learned that G_np has a binomial degree distribution.

169
00:09:25,900 --> 00:09:31,445
We learned that clustering coefficient of G_np is average degree divided by

170
00:09:31,445 --> 00:09:34,640
n. We learned that large connected component will

171
00:09:34,640 --> 00:09:37,970
exist if average degree is greater than 1.

172
00:09:37,970 --> 00:09:40,000
So now, let's talk about,

173
00:09:40,000 --> 00:09:43,025
er, average, uh, path length, so the diameter.

174
00:09:43,025 --> 00:09:45,950
So to be able to talk about diameter,

175
00:09:45,950 --> 00:09:49,290
we need to define this notion of expansion.

176
00:09:49,290 --> 00:09:54,640
And the way expansion is defined mathematically is to say for a given graph,

177
00:09:54,640 --> 00:09:57,175
uh, it will have expansion Alpha.

178
00:09:57,175 --> 00:10:00,850
If for every subset of, uh, vertices S,

179
00:10:00,850 --> 00:10:04,060
the number of edges leaving S is,

180
00:10:04,060 --> 00:10:06,160
um, greater than Alpha times,

181
00:10:06,160 --> 00:10:07,915
uh, size of the S, right?

182
00:10:07,915 --> 00:10:10,975
Uh, and here, uh, I have the- this minimum here,

183
00:10:10,975 --> 00:10:15,670
just to account for the fact that S can be more than half of the size of the graph,

184
00:10:15,670 --> 00:10:17,725
but if I assume that S is, uh,

185
00:10:17,725 --> 00:10:20,035
less than, uh, half of the nodes of the graph,

186
00:10:20,035 --> 00:10:22,615
so it's, er, the smaller part of the graph,

187
00:10:22,615 --> 00:10:26,680
then the- the- the point is that if I pick any set of S nodes,

188
00:10:26,680 --> 00:10:31,240
there would be at least Alpha times S edges sticking out of that set.

189
00:10:31,240 --> 00:10:37,360
So, uh, equivalently, Alpha is the minimum over all possible subsets of nodes,

190
00:10:37,360 --> 00:10:42,190
number of edges leaving that subset dividing by the size of the set,

191
00:10:42,190 --> 00:10:47,035
and the point is that this is min- this is defined as the minimum overall, uh, subsets.

192
00:10:47,035 --> 00:10:50,635
Um, so the way to think of this is to say here is a set S,

193
00:10:50,635 --> 00:10:53,605
here's- here are the rest of the nodes that are not in S,

194
00:10:53,605 --> 00:10:57,340
and we a- we ask how many edges cross between S,

195
00:10:57,340 --> 00:10:58,915
uh, and the rest of the graph,

196
00:10:58,915 --> 00:11:04,870
and this ratio between edges crossing and the size of S is called, uh, expansion.

197
00:11:04,870 --> 00:11:06,370
So, uh, you know,

198
00:11:06,370 --> 00:11:07,990
and the way you think of expansion,

199
00:11:07,990 --> 00:11:11,140
you can think of it as a measure of robustness, right?

200
00:11:11,140 --> 00:11:13,120
Uh, for example, Uh,

201
00:11:13,120 --> 00:11:18,100
do I do mean- it would mean that if you want to disconnect l nodes, uh,

202
00:11:18,100 --> 00:11:23,800
from the graph, well that means you need to- to cut alpha times l, uh, edges, right?

203
00:11:23,800 --> 00:11:27,745
Because if you say I want to disconnect a set S from the graph,

204
00:11:27,745 --> 00:11:32,200
then I need to- I need to cut alpha times, uh, uh,

205
00:11:32,200 --> 00:11:34,630
size of that set number of edges so that

206
00:11:34,630 --> 00:11:39,070
that- piece that set of nodes is disconnected from the rest of the graph.

207
00:11:39,070 --> 00:11:41,770
Um, that's another way to think of a-

208
00:11:41,770 --> 00:11:46,135
a- a- notion of expansion because it tells me how robust is the network.

209
00:11:46,135 --> 00:11:50,170
So let me now give you some examples of networks with high expansion,

210
00:11:50,170 --> 00:11:52,600
low expansion, and show you some- you know,

211
00:11:52,600 --> 00:11:54,010
some- something in between.

212
00:11:54,010 --> 00:11:59,140
So this would be a network of low expansion because I had this one bridge edge, right?

213
00:11:59,140 --> 00:12:03,310
So basically, because Alpha is defined as a minimum over all, uh,

214
00:12:03,310 --> 00:12:07,295
subsets of nodes, basically if I pick this as a set of S,

215
00:12:07,295 --> 00:12:10,215
then, uh, this is the edge that sticks out of the set.

216
00:12:10,215 --> 00:12:13,830
So this is an example of a graph with low expansion.

217
00:12:13,830 --> 00:12:17,190
Uh, this is an example of a graph with high expansion, right?

218
00:12:17,190 --> 00:12:19,410
Kind of everything connected to everything, uh,

219
00:12:19,410 --> 00:12:21,450
out of every set S,

220
00:12:21,450 --> 00:12:24,035
there is a lot of edges, uh, sticking out.

221
00:12:24,035 --> 00:12:26,650
Um, and then, you know, something that's kind of in-between at

222
00:12:26,650 --> 00:12:29,200
these types of networks with community structure where

223
00:12:29,200 --> 00:12:31,480
you have the subsets with high expansion

224
00:12:31,480 --> 00:12:34,195
and then perhaps the expansion between the clusters,

225
00:12:34,195 --> 00:12:36,025
uh, is a bit, uh, lower.

226
00:12:36,025 --> 00:12:37,390
So, um, you know,

227
00:12:37,390 --> 00:12:42,070
so real networks will be kind of somewhere in-between these two extremes.

228
00:12:42,070 --> 00:12:44,980
Um, that is a fact, um,

229
00:12:44,980 --> 00:12:51,970
or one can mathematically show that for a graph on n nodes with expansion alpha for, um,

230
00:12:51,970 --> 00:12:53,740
between all pairs of nodes,

231
00:12:53,740 --> 00:12:55,360
then it means that, um,

232
00:12:55,360 --> 00:12:57,040
for any pair of nodes in the graph,

233
00:12:57,040 --> 00:12:58,855
there is a path length,

234
00:12:58,855 --> 00:13:01,240
the shortest path length order,

235
00:13:01,240 --> 00:13:03,550
uh, log n divided by Alpha.

236
00:13:03,550 --> 00:13:05,440
So basically it means, um,

237
00:13:05,440 --> 00:13:06,700
the bigger the graph,

238
00:13:06,700 --> 00:13:08,275
the longer the the path, right?

239
00:13:08,275 --> 00:13:12,775
We have log n, but also the bigger the expansion,

240
00:13:12,775 --> 00:13:18,415
bigger Alpha, the shorter the path length will be, and, uh,

241
00:13:18,415 --> 00:13:21,910
now given this fact what you can then, uh,

242
00:13:21,910 --> 00:13:24,640
what is then also been shown is that for, uh,

243
00:13:24,640 --> 00:13:28,450
graphs where, um, log n is greater than, uh,

244
00:13:28,450 --> 00:13:29,965
n times p is,

245
00:13:29,965 --> 00:13:31,630
er, greater than some constant,

246
00:13:31,630 --> 00:13:33,760
the diameter of, uh,

247
00:13:33,760 --> 00:13:38,260
G_np will be log n divided by log, uh, np, right?

248
00:13:38,260 --> 00:13:40,360
So basically the way to think of this, if,

249
00:13:40,360 --> 00:13:42,669
uh, the average degree,

250
00:13:42,669 --> 00:13:44,215
right- sorry, if, uh,

251
00:13:44,215 --> 00:13:46,270
average degree is greater than,

252
00:13:46,270 --> 00:13:48,055
um, uh, log n,

253
00:13:48,055 --> 00:13:52,075
uh, then the, um, then the, um,

254
00:13:52,075 --> 00:13:57,265
diameter, uh, will- diameter of the graph will be, uh, order log n,

255
00:13:57,265 --> 00:14:00,460
and this means that random graphs have good expansion,

256
00:14:00,460 --> 00:14:03,940
so it takes a logarithmic number of steps of- from- of

257
00:14:03,940 --> 00:14:05,140
a breadth-first search from

258
00:14:05,140 --> 00:14:07,990
a given node to basically visit all nodes of the graph, right?

259
00:14:07,990 --> 00:14:12,535
So basically the diameter is logarithmic in the number of nodes.

260
00:14:12,535 --> 00:14:15,295
Um, and this is interesting because it means the diameter is

261
00:14:15,295 --> 00:14:18,700
exponentially smaller than the number of nodes, right?

262
00:14:18,700 --> 00:14:21,760
Because n- log n is kind of a,

263
00:14:21,760 --> 00:14:23,260
er, is exponentially less.

264
00:14:23,260 --> 00:14:25,930
Log n is- is exponentially less, um,

265
00:14:25,930 --> 00:14:30,805
than m. So it means that shortest paths are in G_np, are very short.

266
00:14:30,805 --> 00:14:32,290
They are only logarithmic,

267
00:14:32,290 --> 00:14:33,910
uh, in the size of the graph.

268
00:14:33,910 --> 00:14:36,490
So, um, this is the notion, uh,

269
00:14:36,490 --> 00:14:40,330
of expansion, and it turns out that G_np,

270
00:14:40,330 --> 00:14:43,045
random graphs have high expansion and that's why,

271
00:14:43,045 --> 00:14:44,365
uh, the diameter is, uh,

272
00:14:44,365 --> 00:14:46,570
order log n. Um, again,

273
00:14:46,570 --> 00:14:48,760
there is, um, a super cool,

274
00:14:48,760 --> 00:14:51,370
uh, theory and ways to prove this.

275
00:14:51,370 --> 00:14:53,620
Uh, we can link to some papers, uh,

276
00:14:53,620 --> 00:14:56,605
where you could kind of work out and- and learn how to make, uh,

277
00:14:56,605 --> 00:15:01,000
these proofs, but doing them is kind of outside the scope, uh, of this class.

278
00:15:01,000 --> 00:15:04,345
So to give you an example, here is the, uh,

279
00:15:04,345 --> 00:15:06,670
number of nodes in a- in a,

280
00:15:06,670 --> 00:15:08,620
uh, G_np graph here.

281
00:15:08,620 --> 00:15:11,350
Um, uh, and this is the length of the average, uh,

282
00:15:11,350 --> 00:15:14,800
shortest path, and here we keep the average degree constant.

283
00:15:14,800 --> 00:15:16,990
So all these graphs have,

284
00:15:16,990 --> 00:15:19,000
um, ah, different number of nodes,

285
00:15:19,000 --> 00:15:21,160
but average degree in all of them is constant and you

286
00:15:21,160 --> 00:15:23,290
see how basically the diameter grows very,

287
00:15:23,290 --> 00:15:26,395
very slowly as the graph sizes, uh,

288
00:15:26,395 --> 00:15:30,700
increases, and you see this- this basically is like a logarithmic, uh, shape.

289
00:15:30,700 --> 00:15:32,860
So now that we have seen, uh,

290
00:15:32,860 --> 00:15:36,175
what the G_np is and we've kind of worked out these, uh,

291
00:15:36,175 --> 00:15:40,045
properties of it, let's compare it to the MSN network.

292
00:15:40,045 --> 00:15:41,770
So, uh, let's compare.

293
00:15:41,770 --> 00:15:43,540
For example, in the MSN network,

294
00:15:43,540 --> 00:15:45,550
the degree distribution is heavily skewed, right?

295
00:15:45,550 --> 00:15:47,095
If I plot a histogram,

296
00:15:47,095 --> 00:15:49,135
it is just kind of axis aligned.

297
00:15:49,135 --> 00:15:53,080
A G_np degree distribution would- has this nice bell shape.

298
00:15:53,080 --> 00:15:55,525
So clearly the two don't match.

299
00:15:55,525 --> 00:15:59,845
The average shortest path length in MSN network is 6.6.

300
00:15:59,845 --> 00:16:02,440
In, uh, in G_np,

301
00:16:02,440 --> 00:16:04,885
we said the average shortest path length will be,

302
00:16:04,885 --> 00:16:06,985
uh, order log n, right?

303
00:16:06,985 --> 00:16:11,860
Log, you know, let's say log base 10 of 180 million is,

304
00:16:11,860 --> 00:16:13,090
you know, 6, 7, 8.

305
00:16:13,090 --> 00:16:14,650
So it's close, right?

306
00:16:14,650 --> 00:16:15,790
So we say, yes,

307
00:16:15,790 --> 00:16:21,130
the MSN network has short paths and the G_np also has, uh, short paths.

308
00:16:21,130 --> 00:16:24,310
So that sounds great. How about clustering coefficient?

309
00:16:24,310 --> 00:16:27,610
Clustering coefficient of MSN network was 0.11,

310
00:16:27,610 --> 00:16:30,640
and we've worked out that, um,

311
00:16:30,640 --> 00:16:36,850
that the, um, clust- that clustering of a G_np graph would be average degree divided by,

312
00:16:36,850 --> 00:16:38,800
uh, n, where n is the number of nodes.

313
00:16:38,800 --> 00:16:44,935
If we- if we enter the average degree of MSN which is 14 and divide by 180 million,

314
00:16:44,935 --> 00:16:48,970
we get, uh, we get average clustering coefficient to be,

315
00:16:48,970 --> 00:16:51,730
um, 10, uh, 10 to the minus 8.

316
00:16:51,730 --> 00:16:54,940
So clearly we are nowhere close, right?

317
00:16:54,940 --> 00:16:56,950
We are, you know, uh, six,

318
00:16:56,950 --> 00:17:00,175
er, orders of magnitude apart.

319
00:17:00,175 --> 00:17:01,810
We are a million- you know,

320
00:17:01,810 --> 00:17:04,359
we have missed the mark by a million times.

321
00:17:04,359 --> 00:17:07,989
I mean, um, you coul- you cannot miss smaller, right?

322
00:17:07,990 --> 00:17:10,810
It's like as- as different as possible,

323
00:17:10,810 --> 00:17:12,805
so clearly totally different,

324
00:17:12,805 --> 00:17:15,265
and then in terms of largest connected component,

325
00:17:15,265 --> 00:17:16,660
we saw that in MSN,

326
00:17:16,660 --> 00:17:20,859
largest connected component has 99.9% of the nodes, um,

327
00:17:20,859 --> 00:17:24,069
in- in Erdos-Renyi, the largest connected component

328
00:17:24,069 --> 00:17:26,874
starts existing when average degree is greater than 1,

329
00:17:26,875 --> 00:17:29,380
MSN, average degree is around 14.

330
00:17:29,380 --> 00:17:33,445
So yes, uh, you know that- that is something that is matched.

331
00:17:33,445 --> 00:17:36,970
So basically what we can conclude is MSN,

332
00:17:36,970 --> 00:17:39,400
um, and the G_np, uh,

333
00:17:39,400 --> 00:17:43,645
can- G_np can match MSN in terms of shortest path lengths,

334
00:17:43,645 --> 00:17:45,385
in terms of connectivity,

335
00:17:45,385 --> 00:17:47,305
it totally misses clustering,

336
00:17:47,305 --> 00:17:50,035
it totally misses degree distribution.

337
00:17:50,035 --> 00:17:53,800
So why- why this was interesting is because is

338
00:17:53,800 --> 00:17:57,415
now we know that MSN network is not a random network.

339
00:17:57,415 --> 00:18:01,255
It's fundamentally different from the, uh, random graph.

340
00:18:01,255 --> 00:18:03,130
So let's now, um,

341
00:18:03,130 --> 00:18:06,370
see if we can extend or fix this G_np model to

342
00:18:06,370 --> 00:18:09,820
match more of the properties of our MSN network.

343
00:18:09,820 --> 00:18:12,430
Um, and one sentence I will add here it is,

344
00:18:12,430 --> 00:18:17,050
even though we know we've worked with a single instance of a network, this MSN network,

345
00:18:17,050 --> 00:18:22,075
it turns out that these properties are quite shared across huge class of

346
00:18:22,075 --> 00:18:23,980
networks in a sense that you have skewed

347
00:18:23,980 --> 00:18:27,070
degree distribution, that you have short- shortest path lengths,

348
00:18:27,070 --> 00:18:28,840
that you have clustering coefficients that are

349
00:18:28,840 --> 00:18:31,120
quite high and that the graphs are connected.

350
00:18:31,120 --> 00:18:36,640
So these properties that the MSN network has are kind of universal across,

351
00:18:36,640 --> 00:18:38,485
uh, real-world graphs.

352
00:18:38,485 --> 00:18:41,125
Okay, so, uh, to summarize,

353
00:18:41,125 --> 00:18:42,865
what have we learned so far?

354
00:18:42,865 --> 00:18:46,990
You know, if you ask, are real networks like random graphs?

355
00:18:46,990 --> 00:18:49,450
Uh, the answer is giant component,

356
00:18:49,450 --> 00:18:53,065
yes, they- they- it behaves like in a random graph.

357
00:18:53,065 --> 00:18:57,235
Every shortest path length also behaves like in a random graph.

358
00:18:57,235 --> 00:19:00,085
Clustering coefficient, totally different,

359
00:19:00,085 --> 00:19:02,440
degree distribution, totally different, right?

360
00:19:02,440 --> 00:19:05,260
So the problem with the random graph model is

361
00:19:05,260 --> 00:19:08,920
that the degree distribution differs significantly from real network,

362
00:19:08,920 --> 00:19:12,340
that, um, and also that in real networks,

363
00:19:12,340 --> 00:19:17,230
giant component, uh, does not emerge through some kind of phase transition, um,

364
00:19:17,230 --> 00:19:20,155
and the other biggest problem is that,

365
00:19:20,155 --> 00:19:23,080
um, random graphs have no local structure, right?

366
00:19:23,080 --> 00:19:26,830
Like there is no friend of a friend is- is my friend type effect,

367
00:19:26,830 --> 00:19:28,240
so there is no triangles.

368
00:19:28,240 --> 00:19:30,655
The- the clustering coefficient is way too low.

369
00:19:30,655 --> 00:19:32,440
So the question is,

370
00:19:32,440 --> 00:19:35,845
are real- real world networks random?

371
00:19:35,845 --> 00:19:37,315
Do they look like G_np?

372
00:19:37,315 --> 00:19:39,970
The answer is no, no way.

373
00:19:39,970 --> 00:19:42,980
However, this model is still very useful because it

374
00:19:42,980 --> 00:19:46,140
serves as a first basic reference point,

375
00:19:46,140 --> 00:19:48,110
whenever you wanna generate,

376
00:19:48,110 --> 00:19:49,280
uh, a graph and,

377
00:19:49,280 --> 00:19:51,680
uh, compare it to something,

378
00:19:51,680 --> 00:19:54,720
you- you would use a G_np model.

