1
00:00:05,120 --> 00:00:06,720
приветствую всех, это вторая часть

2
00:00:06,720 --> 00:00:08,400
нашей серии статей о методах и метриках,

3
00:00:08,400 --> 00:00:09,440
мы будем говорить о

4
00:00:09,440 --> 00:00:12,000
метриках классификатора, я как бы предполагаю,

5
00:00:12,000 --> 00:00:13,759
что метрики, которые я буду обсуждать, в

6
00:00:13,759 --> 00:00:15,679
целом нам знакомы,

7
00:00:15,679 --> 00:00:17,680
я думаю, это шанс для нас.  сделать шаг

8
00:00:17,680 --> 00:00:20,240
назад и подумать о том, какие значения на

9
00:00:20,240 --> 00:00:22,960
самом деле кодируют эти знакомые метрики,

10
00:00:22,960 --> 00:00:24,720
потому что это действительно название

11
00:00:24,720 --> 00:00:26,400
игры здесь, независимо от того, над какой задачей

12
00:00:26,400 --> 00:00:27,920
вы работаете или какова

13
00:00:27,920 --> 00:00:29,760
структура вашей модели.

14
00:00:29,760 --> 00:00:31,359


15
00:00:31,359 --> 00:00:33,680
оценочные метрики будут кодировать разные

16
00:00:33,680 --> 00:00:35,920
значения разные цели, которые вы ставите перед своей

17
00:00:35,920 --> 00:00:38,320
системой, и разные виды гипотез,

18
00:00:38,320 --> 00:00:40,160
которые вы можете преследовать, вы могли

19
00:00:40,160 --> 00:00:42,559
слышать, что

20
00:00:42,559 --> 00:00:44,719
выбор метрики на самом деле является решающим аспектом

21
00:00:44,719 --> 00:00:46,719
любой экспериментальной работы, это

22
00:00:46,719 --> 00:00:48,239
фундаментальный шаг в том, как  мы

23
00:00:48,239 --> 00:00:51,039
реализуем гипотезы с точки зрения

24
00:00:51,039 --> 00:00:54,559
данных, моделей и сравнения моделей

25
00:00:54,559 --> 00:00:56,719
, поэтому вы должны чувствовать себя свободными для

26
00:00:56,719 --> 00:00:58,640
любой задачи, над которой вы работаете, чтобы

27
00:00:58,640 --> 00:01:01,120
мотивировать  новые метрики или конкретное использование

28
00:01:01,120 --> 00:01:03,600
существующих метрик в зависимости от того, каковы ваши

29
00:01:03,600 --> 00:01:05,438
фактические цели для ваших экспериментов на

30
00:01:05,438 --> 00:01:07,200
самом деле,

31
00:01:07,200 --> 00:01:09,200
связанные с установленными задачами, вы,

32
00:01:09,200 --> 00:01:11,680
вероятно, почувствуете некоторое давление, чтобы использовать

33
00:01:11,680 --> 00:01:14,400
определенные хорошо зарекомендовавшие себя метрики, но

34
00:01:14,400 --> 00:01:16,720
вы, как ученый, всегда должны чувствовать себя в

35
00:01:16,720 --> 00:01:18,960
силах дать отпор, если  вы чувствуете,

36
00:01:18,960 --> 00:01:20,799
что принятые

37
00:01:20,799 --> 00:01:23,280
метрики не отражают вашу гипотезу или

38
00:01:23,280 --> 00:01:25,200


39
00:01:25,200 --> 00:01:27,600
каким-то образом искажают наши представления о прогрессе, потому что помните, что

40
00:01:27,600 --> 00:01:29,759
области исследований могут застопориться из-за

41
00:01:29,759 --> 00:01:31,360
плохих метрик, и поэтому мы должны быть

42
00:01:31,360 --> 00:01:32,960
бдительными, мы должны следить

43
00:01:32,960 --> 00:01:34,880
за случаями, в которых  метрики, которые мы

44
00:01:34,880 --> 00:01:37,119
приняли, могут расходиться с

45
00:01:37,119 --> 00:01:39,119
реальными целями исследования, которое мы

46
00:01:39,119 --> 00:01:41,840


47
00:01:42,560 --> 00:01:44,479
проводим. давайте начнем обсуждение метрик классификатора

48
00:01:44,479 --> 00:01:46,399
с разговора о матрицах путаницы,

49
00:01:46,399 --> 00:01:48,399
довольно фундаментальной

50
00:01:48,399 --> 00:01:50,640
структуре данных для многих вычислений,

51
00:01:50,640 --> 00:01:52,159
которые мы будем выполнять.

52
00:01:52,159 --> 00:01:53,759
поэтому по соглашению для моих матриц путаницы у

53
00:01:53,759 --> 00:01:56,079
меня будут фактические метки,

54
00:01:56,079 --> 00:01:58,560
идущие по строкам здесь, а

55
00:01:58,560 --> 00:02:00,320
по столбцам у меня будет  предсказания

56
00:02:00,320 --> 00:02:02,560
из некоторой модели классификатора, поэтому вы можете

57
00:02:02,560 --> 00:02:04,640
видеть в этой матрице путаницы, что

58
00:02:04,640 --> 00:02:06,640
было 15 случаев, в которых модель

59
00:02:06,640 --> 00:02:09,038
предсказывала положительный результат, а фактическая метка

60
00:02:09,038 --> 00:02:11,520
была положительной, тогда как

61
00:02:11,520 --> 00:02:13,440
есть 10 случаев, когда фактическая метка была

62
00:02:13,440 --> 00:02:15,120
положительной, а модель предсказывала

63
00:02:15,120 --> 00:02:17,040
отрицательный и так далее.  вперед для других

64
00:02:17,040 --> 00:02:19,280
значений в этой таблице,

65
00:02:19,280 --> 00:02:20,879
я думаю, что это кажется знакомым, это

66
00:02:20,879 --> 00:02:22,560
то, что мы можем принять как должное, но мы

67
00:02:22,560 --> 00:02:24,080
должны помнить,

68
00:02:24,080 --> 00:02:26,239
что за кулисами здесь

69
00:02:26,239 --> 00:02:28,160
был установлен порог для создания этих

70
00:02:28,160 --> 00:02:30,000
категориальных

71
00:02:30,000 --> 00:02:32,080
прогнозов с помощью больших моделей классификаторов, которые мы

72
00:02:32,080 --> 00:02:33,280
используем сегодня,

73
00:02:33,280 --> 00:02:35,599
прогнозируют  распределения вероятностей

74
00:02:35,599 --> 00:02:37,920
по меткам, и поэтому, чтобы создать

75
00:02:37,920 --> 00:02:40,239
фактический категориальный прогноз, мы решили,

76
00:02:40,239 --> 00:02:42,400
например, что метка с

77
00:02:42,400 --> 00:02:44,800
максимальной вероятностью будет истинной

78
00:02:44,800 --> 00:02:47,120
, и это был результат этого

79
00:02:47,120 --> 00:02:48,800
решения, который использовался для агрегирования этой

80
00:02:48,800 --> 00:02:51,200
таблицы, но, конечно, разные варианты

81
00:02:51,200 --> 00:02:52,959
этого порога может дать очень разные

82
00:02:52,959 --> 00:02:55,280
результаты, и может быть контекст, в

83
00:02:55,280 --> 00:02:57,360
котором мы хотим  чтобы изучить весь

84
00:02:57,360 --> 00:02:59,440
спектр вероятностных прогнозов, к

85
00:02:59,440 --> 00:03:01,120
чему я вернусь в конце

86
00:03:01,120 --> 00:03:02,959


87
00:03:02,959 --> 00:03:04,720
финальной заметки скринкаста об этом,

88
00:03:04,720 --> 00:03:06,720
в контексте матриц путаницы может быть полезно

89
00:03:06,720 --> 00:03:08,959
добавить столбец или то, что называется поддержкой,

90
00:03:08,959 --> 00:03:11,440
которая представляет собой просто количество фактических

91
00:03:11,440 --> 00:03:13,440
истинные экземпляры, которые попадают в каждый класс,

92
00:03:13,440 --> 00:03:16,319
поэтому в этом корпусе 125 положительных примеров,

93
00:03:16,319 --> 00:03:19,280
35 отрицательных и более

94
00:03:19,280 --> 00:03:20,640
тысячи, которые попадают в нейтральную

95
00:03:20,640 --> 00:03:22,560
категорию, и это уже проливает свет

96
00:03:22,560 --> 00:03:25,280
на то, как конкретные показатели могут иметь дело

97
00:03:25,280 --> 00:03:27,760
с этим чрезвычайно несбалансированным

98
00:03:27,760 --> 00:03:31,720
вектором значений поддержки,

99
00:03:31,840 --> 00:03:33,760
давайте начнем с точности  безусловно,

100
00:03:33,760 --> 00:03:35,519
самая известная и знакомая из всех

101
00:03:35,519 --> 00:03:38,000
метрик классификатора точность — это

102
00:03:38,000 --> 00:03:39,519
просто количество правильных предсказаний,

103
00:03:39,519 --> 00:03:42,239
деленное на общее количество примеров

104
00:03:42,239 --> 00:03:44,319
с точки зрения наших матриц путаницы, то

105
00:03:44,319 --> 00:03:46,159
есть просто сумма всех значений

106
00:03:46,159 --> 00:03:48,560
по диагонали, деленная на сумму

107
00:03:48,560 --> 00:03:51,599
все значения, которые находятся в этой таблице,

108
00:03:51,599 --> 00:03:53,360
равны нулю, и одно, конечно,

109
00:03:53,360 --> 00:03:56,080
с нулем наихудшим и одним лучшим

110
00:03:56,080 --> 00:03:58,080
в те  Среднеквадратичное значение значения, закодированное

111
00:03:58,080 --> 00:03:59,920
точностью, я бы сказал, что это попытка

112
00:03:59,920 --> 00:04:02,480
ответить на вопрос, как часто

113
00:04:02,480 --> 00:04:04,159
система является правильной,

114
00:04:04,159 --> 00:04:05,599
и что это приводит к

115
00:04:05,599 --> 00:04:07,360
недостаткам здесь, так что недостатки в

116
00:04:07,360 --> 00:04:09,760
первую очередь, нет понятия точности для каждого класса, а

117
00:04:09,760 --> 00:04:12,000
не напрямую, мы просто получаем

118
00:04:12,000 --> 00:04:14,799
единственное целостное число, и, соответственно,

119
00:04:14,799 --> 00:04:16,798
здесь просто полная неспособность

120
00:04:16,798 --> 00:04:19,040
контролировать размер класса,

121
00:04:19,040 --> 00:04:20,639
поэтому вы можете видеть, например, в этой

122
00:04:20,639 --> 00:04:23,199
матрице путаницы, что производительность в

123
00:04:23,199 --> 00:04:25,600
нейтральном классе будет полностью доминировать

124
00:04:25,600 --> 00:04:27,280
над значениями точности,

125
00:04:27,280 --> 00:04:29,520
и это доходит до точки в этой

126
00:04:29,520 --> 00:04:30,960
таблице, где

127
00:04:30,960 --> 00:04:32,639
независимо от того, как  большой прогресс, которого мы достигаем

128
00:04:32,639 --> 00:04:34,320
в положительных и отрицательных классах,

129
00:04:34,320 --> 00:04:35,919
потому что они намного меньше с

130
00:04:35,919 --> 00:04:38,240
точки зрения их поддержки, чем нейтральные, что

131
00:04:38,240 --> 00:04:40,240
такой прогресс вряд ли будет

132
00:04:40,240 --> 00:04:42,800
отражен в наших значениях точности, и

133
00:04:42,800 --> 00:04:44,320
поэтому, если вы вернетесь к закодированному значению,

134
00:04:44,320 --> 00:04:46,240
вы увидите, что  просто на исходном

135
00:04:46,240 --> 00:04:48,479
фундаментальном уровне это просто ответ на вопрос,

136
00:04:48,479 --> 00:04:52,080
как часто система оказывается правильной.

137
00:04:52,080 --> 00:04:54,400
Еще одна вещь, которую следует иметь в виду, это то, что

138
00:04:54,400 --> 00:04:57,120
для многих моделей классификаторов

139
00:04:57,120 --> 00:04:59,199
потеря для этих моделей - это то, что

140
00:04:59,199 --> 00:05:01,280
называется потерей перекрестной энтропии, она также

141
00:05:01,280 --> 00:05:04,080
называется отрицательной логарифмической потерей

142
00:05:04,080 --> 00:05:05,600
внутри набора,

143
00:05:05,600 --> 00:05:08,479
и это значение обратно

144
00:05:08,479 --> 00:05:10,560
пропорционально точности,

145
00:05:10,560 --> 00:05:12,800
вывод заключается в том, что даже если мы

146
00:05:12,800 --> 00:05:14,800
можем выбрать другие показатели для сравнения

147
00:05:14,800 --> 00:05:16,880
моделей и оценки моделей, мы должны

148
00:05:16,880 --> 00:05:18,720
имейте в виду, что наши классификаторы

149
00:05:18,720 --> 00:05:21,039
сами по себе являются своего рода механизмами,

150
00:05:21,039 --> 00:05:23,840
пытающимися максимизировать точность, и поэтому они

151
00:05:23,840 --> 00:05:26,000
, вероятно, наследуют любые

152
00:05:26,000 --> 00:05:27,919
свойства и значения, сильные и

153
00:05:27,919 --> 00:05:30,479
слабые стороны, присущие расчету точности,

154
00:05:30,479 --> 00:05:32,880
который, как мы увидим,

155
00:05:32,880 --> 00:05:35,039
может расходиться с нашим фактическим  значения для

156
00:05:35,039 --> 00:05:38,400
системы, которую мы разрабатываем,

157
00:05:38,400 --> 00:05:40,240
и этот вид прекрасно вписывается в

158
00:05:40,240 --> 00:05:42,880
точность отзыва и оценки f, которые являются

159
00:05:42,880 --> 00:05:45,039
попытками компенсировать некоторые

160
00:05:45,039 --> 00:05:47,280
недостатки, которые вы видите в точности,

161
00:05:47,280 --> 00:05:49,360
мы начнем с точности, это

162
00:05:49,360 --> 00:05:51,919
понятие для каждого класса для  класс k — это

163
00:05:51,919 --> 00:05:54,400
правильные прогнозы для k, деленные на

164
00:05:54,400 --> 00:05:56,479
сумму всех предположений для k, которые были

165
00:05:56,479 --> 00:05:58,720
сделаны вашей моделью,

166
00:05:58,720 --> 00:06:00,639
поэтому с точки зрения этой путаницы ma  trix, если

167
00:06:00,639 --> 00:06:02,560
мы сосредоточимся здесь на положительном классе,

168
00:06:02,560 --> 00:06:04,240
числитель — это количество правильных

169
00:06:04,240 --> 00:06:06,880
прогнозов для этого класса, деленное

170
00:06:06,880 --> 00:06:08,639
на сумму всех значений, которые находятся в

171
00:06:08,639 --> 00:06:09,840
этом столбце,

172
00:06:09,840 --> 00:06:11,360
а для отрицательного класса мы

173
00:06:11,360 --> 00:06:13,600
повторим, что числитель будет равен 15,

174
00:06:13,600 --> 00:06:15,360
и мы бы  сумма по столбцу и,

175
00:06:15,360 --> 00:06:16,960
наконец, для нейтрального числитель

176
00:06:16,960 --> 00:06:18,720
будет тысяча, и мы снова суммируем

177
00:06:18,720 --> 00:06:20,800
по этому столбцу, и это приводит к этому

178
00:06:20,800 --> 00:06:22,880
вектору значений точности, который вы видите

179
00:06:22,880 --> 00:06:25,919
внизу здесь,

180
00:06:26,000 --> 00:06:28,319
границы точности равны нулю и единице

181
00:06:28,319 --> 00:06:29,919
приблизительно с нулем  худший и

182
00:06:29,919 --> 00:06:31,280
один из лучших, здесь есть важное

183
00:06:31,280 --> 00:06:32,880
предостережение, хотя

184
00:06:32,880 --> 00:06:35,600
точность технически не определена в

185
00:06:35,600 --> 00:06:37,360
ситуациях, когда модель не делает

186
00:06:37,360 --> 00:06:39,199
прогнозов относительно данного класса, потому что

187
00:06:39,199 --> 00:06:41,440
в этой ситуации вы делите на

188
00:06:41,440 --> 00:06:44,240
ноль, а это технически неопределенно.

189
00:06:44,240 --> 00:06:46,880
ноль,

190
00:06:46,880 --> 00:06:48,240
но мы должны помнить, что мы

191
00:06:48,240 --> 00:06:50,319
принимали это дополнительное решение,

192
00:06:50,319 --> 00:06:52,000
закодированное значение является своего рода

193
00:06:52,000 --> 00:06:54,720
консервативным, и мы собираемся оштрафовать

194
00:06:54,720 --> 00:06:58,560
неправильное  догадки для определенного класса,

195
00:06:58,560 --> 00:07:00,319
поэтому вы можете представить, что режим отказа

196
00:07:00,319 --> 00:07:02,880
заключается в том, чтобы просто редко угадывать определенный

197
00:07:02,880 --> 00:07:04,960
класс, который является основной слабостью, вы можете

198
00:07:04,960 --> 00:07:06,720
достичь высокой точности

199
00:07:06,720 --> 00:07:09,440
для класса k, просто редко угадывая

200
00:07:09,440 --> 00:07:10,400
k,

201
00:07:10,400 --> 00:07:12,080
поэтому нам, очевидно, нужно компенсировать это

202
00:07:12,080 --> 00:07:13,680
с некоторым другим давлением,

203
00:07:13,680 --> 00:07:16,080
и, в общем и целом, давление смещения - это

204
00:07:16,080 --> 00:07:17,360
отзыв,

205
00:07:17,360 --> 00:07:19,599
отзыв - это снова понятие для каждого класса для

206
00:07:19,599 --> 00:07:21,120
класса k, это будут правильные

207
00:07:21,120 --> 00:07:23,759
предсказания для k, разделенного на сумму

208
00:07:23,759 --> 00:07:26,000
всех истинных членов k,

209
00:07:26,000 --> 00:07:28,080
так что теперь мы собираемся  чтобы оперировать строкой по

210
00:07:28,080 --> 00:07:30,720
строке, мы фокусируемся на положительном классе,

211
00:07:30,720 --> 00:07:32,960
наш числитель равен 15, количество истинных

212
00:07:32,960 --> 00:07:35,199
прогнозов для положительного класса,

213
00:07:35,199 --> 00:07:36,880
деленное на сумму всех значений

214
00:07:36,880 --> 00:07:39,120
в строках, которые являются всеми истинными

215
00:07:39,120 --> 00:07:41,520
членами этого класса для положительного, что

216
00:07:41,520 --> 00:07:44,080
дает нам  значение отзыва 0,12, и мы

217
00:07:44,080 --> 00:07:47,120
можем повторить, что для двух других

218
00:07:47,120 --> 00:07:48,879
строк границы равны нулю, а одна из них

219
00:07:48,879 --> 00:07:50,800
- наихудшая, а одна - наилучшая,

220
00:07:50,800 --> 00:07:53,280
закодированное значение является разрешительным, мы

221
00:07:53,280 --> 00:07:56,800
хотим наказать пропущенные истинные случаи, которые мы

222
00:07:56,800 --> 00:07:58,240
хотели бы  o делать много прогнозов

223
00:07:58,240 --> 00:08:00,720
о классе, чтобы

224
00:08:00,720 --> 00:08:02,879
, так сказать, не упустить ни одного, и это

225
00:08:02,879 --> 00:08:04,479
ведет к основной слабости, мы можем

226
00:08:04,479 --> 00:08:07,759
добиться высокого отзыва для класса k,

227
00:08:07,759 --> 00:08:09,840
просто всегда угадывая k

228
00:08:09,840 --> 00:08:11,680
не обращая внимания на ошибки, пока мы

229
00:08:11,680 --> 00:08:13,520
включить все фактические случаи в наши

230
00:08:13,520 --> 00:08:15,919
прогнозы, у нас все хорошо, благодаря отзыву,

231
00:08:15,919 --> 00:08:17,280
и вы можете услышать, что

232
00:08:17,280 --> 00:08:19,599
важно компенсировать это давление

233
00:08:19,599 --> 00:08:23,440
чем-то еще, не являющимся стандартной точностью,

234
00:08:23,440 --> 00:08:24,800
и способ, которым мы компенсируем эти два

235
00:08:24,800 --> 00:08:27,440
давления, обычно с f баллами,

236
00:08:27,440 --> 00:08:30,160
поэтому f баллами  являются гармоническим средним значением

237
00:08:30,160 --> 00:08:32,080
точности и отзыва, это снова

238
00:08:32,080 --> 00:08:34,159
понятие для каждого класса, и оно имеет это

239
00:08:34,159 --> 00:08:36,320
значение бета, если мы хотим

240
00:08:36,320 --> 00:08:38,479
равномерно сбалансировать точность и отзыв, тогда

241
00:08:38,479 --> 00:08:41,360
мы устанавливаем бета равным 1.

242
00:08:41,360 --> 00:08:43,200
так что вот эта матрица путаницы снова

243
00:08:43,200 --> 00:08:44,800
и вдоль этого столбца здесь  я

244
00:08:44,800 --> 00:08:48,160
дал значения f1 для каждого класса,

245
00:08:48,160 --> 00:08:51,120
здесь границы равны 0 и 1, как и раньше, с

246
00:08:51,120 --> 00:08:53,120
0 худшим и одним лучшим, и вы можете

247
00:08:53,120 --> 00:08:54,959
рассчитывать на тот факт, что оценка f1

248
00:08:54,959 --> 00:08:56,959
для класса всегда будет находиться между

249
00:08:56,959 --> 00:08:58,640
точностью  и вспомнить классы, потому

250
00:08:58,640 --> 00:09:00,480
что это своего рода среднее значение, это

251
00:09:00,480 --> 00:09:02,800
среднее гармоническое,

252
00:09:02,800 --> 00:09:04,720
какое значение закодировано наилучшим образом, я

253
00:09:04,720 --> 00:09:06,720
могу сказать, что мы, по сути,

254
00:09:06,720 --> 00:09:08,160
пытаемся ответить на вопрос для

255
00:09:08,160 --> 00:09:10,560
данного класса k, насколько прогнозы

256
00:09:10,560 --> 00:09:13,680
для k совпадают с истинными  экземпляры k,

257
00:09:13,680 --> 00:09:16,240
которые выравниваются как с точностью, так и с

258
00:09:16,240 --> 00:09:18,480
отзывом, как давление, а затем мы можем

259
00:09:18,480 --> 00:09:20,399
использовать бета-значение, чтобы контролировать, какое

260
00:09:20,399 --> 00:09:22,800
значение мы придаем точности по сравнению с

261
00:09:22,800 --> 00:09:24,080
отзывом,

262
00:09:24,080 --> 00:09:25,760
каковы слабые стороны f-показателей,

263
00:09:25,760 --> 00:09:27,440
я действительно могу думать о двух,

264
00:09:27,440 --> 00:09:28,640
первый  что нет

265
00:09:28,640 --> 00:09:30,880
нормализации размера набора данных

266
00:09:30,880 --> 00:09:32,240
из-за того, как мы используем

267
00:09:32,240 --> 00:09:35,680
знаменатели для сумм строк

268
00:09:35,680 --> 00:09:37,920
и столбцов и, соответственно, для данного класса, на котором мы

269
00:09:37,920 --> 00:09:40,240
решили сосредоточиться, мы фактически игнорируем

270
00:09:40,240 --> 00:09:42,080
большую часть данных, которые находятся в таблице,

271
00:09:42,080 --> 00:09:44,240
рассмотрим  тот факт, что если мы решим

272
00:09:44,240 --> 00:09:46,320
рассчитать оценку f1 для положительного

273
00:09:46,320 --> 00:09:48,160
класса, мы обращаем внимание на эти

274
00:09:48,160 --> 00:09:50,480
значения столбца и эти значения строки, но мы

275
00:09:50,480 --> 00:09:52,880
полностью игнорируем эти четыре значения здесь,

276
00:09:52,880 --> 00:09:54,160
они просто не участвуют в

277
00:09:54,160 --> 00:09:56,880
расчет вообще и, как результат,

278
00:09:56,880 --> 00:10:00,240
положительная оценка класса f1 может дать

279
00:10:00,240 --> 00:10:02,160
искаженную картину того, на что на

280
00:10:02,160 --> 00:10:04,240
самом деле похожи предсказания модели, в

281
00:10:04,240 --> 00:10:06,480
силу того факта, что они пропускают здесь так

282
00:10:06,480 --> 00:10:10,000
много данных, как вы можете видеть

283
00:10:10,560 --> 00:10:11,440
сейчас,

284
00:10:11,440 --> 00:10:14,079
потому что оценки f  понятие для каждого класса,

285
00:10:14,079 --> 00:10:15,440
я думаю, что это полезно в том смысле, что

286
00:10:15,440 --> 00:10:17,120
оно дает нам представление о каждом

287
00:10:17,120 --> 00:10:19,120
из классов в отдельности, но для многих

288
00:10:19,120 --> 00:10:20,959
видов оценок моделей нам нужно

289
00:10:20,959 --> 00:10:22,720
итоговое число — единственное число, которое мы

290
00:10:22,720 --> 00:10:24,959
можем использовать для сравнения моделей и оценки в

291
00:10:24,959 --> 00:10:26,480
целом.  прогресса,

292
00:10:26,480 --> 00:10:27,600
поэтому мы собираемся сделать какое-то

293
00:10:27,600 --> 00:10:29,200
усреднение, и я хотел бы предложить вам

294
00:10:29,200 --> 00:10:31,200
три способа, которыми мы могли бы усреднить эти значения f

295
00:10:31,200 --> 00:10:33,839
макроусреднение взвешенное

296
00:10:33,839 --> 00:10:35,760
усреднение и микроусреднение, и, как

297
00:10:35,760 --> 00:10:37,680
вы увидите, они кодируют совершенно разные

298
00:10:37,680 --> 00:10:40,079
значения о том, как мы  хочу подумать

299
00:10:40,079 --> 00:10:42,480
о баллах f

300
00:10:42,480 --> 00:10:44,399
макроусреднение — это своего рода усреднение,

301
00:10:44,399 --> 00:10:45,600
которое мы проводили

302
00:10:45,600 --> 00:10:47,680
в различные моменты в течение квартала,

303
00:10:47,680 --> 00:10:50,320
это просто среднее

304
00:10:50,320 --> 00:10:53,279
арифметическое всех баллов f1 по каждой категории, так

305
00:10:53,279 --> 00:10:55,040
что это просто t  Среднее значение значений в

306
00:10:55,040 --> 00:10:56,800
этом столбце,

307
00:10:56,800 --> 00:10:58,640
его границы равны нулю, а единица с

308
00:10:58,640 --> 00:11:00,880
нулем — наихудшее, а единица — наилучшее,

309
00:11:00,880 --> 00:11:02,720
какое значение действительно хорошо кодируется. Это те

310
00:11:02,720 --> 00:11:05,440
же значения, которые мы получаем из оценок f,

311
00:11:05,440 --> 00:11:07,519
плюс дополнительное и нетривиальное

312
00:11:07,519 --> 00:11:09,440
предположение, что все классы

313
00:11:09,440 --> 00:11:12,240
равны, независимо от различий в размерах

314
00:11:12,240 --> 00:11:13,519
между ними,

315
00:11:13,519 --> 00:11:14,880
и такого рода подпитывает

316
00:11:14,880 --> 00:11:17,120
слабые стороны классификатора, который

317
00:11:17,120 --> 00:11:20,000
хорошо работает только с небольшими классами, может на

318
00:11:20,000 --> 00:11:22,000
самом деле не работать хорошо в реальном мире, если

319
00:11:22,000 --> 00:11:24,320
вы контрфактически представляете, что для

320
00:11:24,320 --> 00:11:26,000
нашей данной модели здесь у нас действительно было

321
00:11:26,000 --> 00:11:28,240
выдающиеся оценки f1 для положительных и

322
00:11:28,240 --> 00:11:31,120
отрицательных и очень низкие для нейтральных, что

323
00:11:31,120 --> 00:11:32,880
может действительно противоречить тому, как этот

324
00:11:32,880 --> 00:11:35,360
классификатор будет вести себя в мире,

325
00:11:35,360 --> 00:11:37,279
предполагая, что большинство примеров,

326
00:11:37,279 --> 00:11:39,120
которые потоком поступают, относятся к нейтральной

327
00:11:39,120 --> 00:11:40,880
категории,

328
00:11:40,880 --> 00:11:43,200
соответственно, классификатор, который хорошо работает

329
00:11:43,200 --> 00:11:46,240
только на  большие классы могут плохо справляться

330
00:11:46,240 --> 00:11:48,640
с небольшими, но тем не менее жизненно важными классами,

331
00:11:48,640 --> 00:11:50,399
которые есть в наших данных, и это просто

332
00:11:50,399 --> 00:11:53,120
отражает тот факт, что очень часто в nlp

333
00:11:53,120 --> 00:11:55,040
это  s малые классы, которые являются наиболее

334
00:11:55,040 --> 00:11:56,800
ценными, те, о которых мы заботимся больше

335
00:11:56,800 --> 00:11:59,360
всего, и мы не отражаем

336
00:11:59,360 --> 00:12:01,600
подобную асимметрию в наших ценностях, просто

337
00:12:01,600 --> 00:12:05,600
взяв среднее значение всех этих f-баллов;

338
00:12:05,600 --> 00:12:07,519
средневзвешенные f-баллы дадут

339
00:12:07,519 --> 00:12:09,440
совсем другую перспективу  по производительности модели,

340
00:12:09,440 --> 00:12:10,480


341
00:12:10,480 --> 00:12:12,240
в этом случае мы снова собираемся просто

342
00:12:12,240 --> 00:12:14,480
взять среднее значение оценок f1, но теперь

343
00:12:14,480 --> 00:12:16,240
взвешенное по количеству поддержки для

344
00:12:16,240 --> 00:12:18,399
каждого из классов,

345
00:12:18,399 --> 00:12:20,320
которые снова связали ноль с

346
00:12:20,320 --> 00:12:22,560
единицей, где ноль — худшее, а один —

347
00:12:22,560 --> 00:12:24,560
лучшее значение.  encoded совпадает со

348
00:12:24,560 --> 00:12:26,959
значениями, которые мы получаем для оценок f, но

349
00:12:26,959 --> 00:12:28,720
теперь с добавленным предположением о том, что

350
00:12:28,720 --> 00:12:30,160
размер классов и объем

351
00:12:30,160 --> 00:12:32,720
поддержки действительно имеют значение,

352
00:12:32,720 --> 00:12:33,839
и это будет способствовать

353
00:12:33,839 --> 00:12:35,440
ослаблению, и фундаментальная вещь

354
00:12:35,440 --> 00:12:38,399
здесь заключается в том, что большие классы  будет доминировать

355
00:12:38,399 --> 00:12:40,800
точно так же, как с точностью, чем больше наш

356
00:12:40,800 --> 00:12:42,079
класс, тем больше он будет

357
00:12:42,079 --> 00:12:44,480
способствовать нашему общему итоговому числу,

358
00:12:44,480 --> 00:12:45,839
и это может привести к

359
00:12:45,839 --> 00:12:48,800
проблемной ситуации, когда маленький

360
00:12:48,800 --> 00:12:50,800
класс  ses просто не имеют отношения к

361
00:12:50,800 --> 00:12:52,399
метрике оценки,

362
00:12:52,399 --> 00:12:54,320
которая может отражать ваши значения, потому что,

363
00:12:54,320 --> 00:12:56,160
если вас действительно волнует необработанная

364
00:12:56,160 --> 00:12:58,320
скорость правильных прогнозов, вы можете

365
00:12:58,320 --> 00:12:59,920
захотеть более взвешивать более крупные классы,

366
00:12:59,920 --> 00:13:00,959


367
00:13:00,959 --> 00:13:03,200
но опять же для многих контекстов в nlp нас

368
00:13:03,200 --> 00:13:05,040
действительно волнует, насколько  мы

369
00:13:05,040 --> 00:13:07,360
можем добиться прогресса в небольших, но, тем не менее,

370
00:13:07,360 --> 00:13:09,600
важных классах, и поэтому в этих

371
00:13:09,600 --> 00:13:11,519
контекстах взвешенное усреднение, вероятно,

372
00:13:11,519 --> 00:13:14,480
не является правильным выбором.

373
00:13:14,480 --> 00:13:16,240
Окончательная схема усреднения, которую я хотел

374
00:13:16,240 --> 00:13:18,800
бы рассмотреть, - это микроусредненные f-показатели,

375
00:13:18,800 --> 00:13:20,959
которые будут очень похожи на взвешенное

376
00:13:20,959 --> 00:13:23,440
усреднение  f1 забивает и напрямую

377
00:13:23,440 --> 00:13:25,680
связан с точностью. То,

378
00:13:25,680 --> 00:13:27,120
как это работает, немного сложно,

379
00:13:27,120 --> 00:13:29,120
мы начнем с этой основной

380
00:13:29,120 --> 00:13:31,200
матрицы путаницы, и мы собираемся

381
00:13:31,200 --> 00:13:33,440
разбить ее на три

382
00:13:33,440 --> 00:13:36,639
меньшие матрицы путаницы, по одной на класс,

383
00:13:36,639 --> 00:13:38,240
чтобы вы могли видеть это слева

384
00:13:38,240 --> 00:13:40,800
вот для положительного класса да

385
00:13:40,800 --> 00:13:43,680
15, а нет сумма этих двух

386
00:13:43,680 --> 00:13:46,000
значений здесь вдоль этой

387
00:13:46,000 --> 00:13:48,000
строки нос или 20 который является суммой

388
00:13:48,000 --> 00:13:50,399
этих двух va  lues, а затем эта категория «нет-нет

389
00:13:50,399 --> 00:13:52,480
» — это все оставшиеся данные в

390
00:13:52,480 --> 00:13:54,240
этом квадранте. Здесь

391
00:13:54,240 --> 00:13:56,240
мы повторяем ту же процедуру для

392
00:13:56,240 --> 00:13:59,279
отрицательного класса и для нейтрального класса,

393
00:13:59,279 --> 00:14:01,120
а затем мы просто суммируем эти три

394
00:14:01,120 --> 00:14:04,480
меньшие таблицы в одну большую матрицу «да-нет»

395
00:14:04,480 --> 00:14:07,199
и вычисляем  баллы f1 для

396
00:14:07,199 --> 00:14:09,440
каждой категории,

397
00:14:09,440 --> 00:14:11,199
что дает нам здесь два балла один для

398
00:14:11,199 --> 00:14:14,000
да и один для

399
00:14:14,000 --> 00:14:15,839
нет границы этого равны нулю и один с

400
00:14:15,839 --> 00:14:18,079
нулем худший и один

401
00:14:18,079 --> 00:14:20,320
лучший закодированное значение очень легко указать

402
00:14:20,320 --> 00:14:21,680


403
00:14:21,680 --> 00:14:24,079
макроусредненные баллы f1 для категории да

404
00:14:24,079 --> 00:14:26,639


405
00:14:26,639 --> 00:14:28,959
численно эквивалентны показателям точности, так что это идентично

406
00:14:28,959 --> 00:14:31,040
с точки зрения этой метрики, и у нас есть эта

407
00:14:31,040 --> 00:14:33,920
дополнительная проблема теперь, когда у нас есть

408
00:14:33,920 --> 00:14:35,680
то же самое значение, что

409
00:14:35,680 --> 00:14:37,519
и для взвешенных f-показателей или для

410
00:14:37,519 --> 00:14:39,600
точности, но теперь мы ввели

411
00:14:39,600 --> 00:14:41,360
дополнительный источник  неопределенности, которая

412
00:14:41,360 --> 00:14:43,839
заключается в том, что у нас есть число для категории «да»

413
00:14:43,839 --> 00:14:47,040
и категории «нет», и, следовательно, нет единого

414
00:14:47,040 --> 00:14:48,720
итогового числа, принятое в

415
00:14:48,720 --> 00:14:50,800
литературе соглашение состоит в том, чтобы сосредоточиться на категории «да».

416
00:14:50,800 --> 00:14:53,040
y, но это просто возвращает нас

417
00:14:53,040 --> 00:14:55,279
к точности с более сложными

418
00:14:55,279 --> 00:14:57,199
вычислениями, так что это, очевидно, не очень

419
00:14:57,199 --> 00:14:58,880
продуктивно, и я бы сказал, что в результате

420
00:14:58,880 --> 00:15:01,199
здесь два реальных выбора, которые вы

421
00:15:01,199 --> 00:15:03,600
хотите сделать, — это между макроусреднением

422
00:15:03,600 --> 00:15:06,480
и взвешенным усреднением ваших результатов f1

423
00:15:06,480 --> 00:15:08,399
и снова  это будет сводиться к тому, каковы

424
00:15:08,399 --> 00:15:10,560
ваши фундаментальные ценности и какие

425
00:15:10,560 --> 00:15:13,839
гипотезы вы преследуете.

426
00:15:13,839 --> 00:15:15,360
Последнее, что я хочу сделать, это то, что

427
00:15:15,360 --> 00:15:17,360
до сих пор мы действовали в терминах

428
00:15:17,360 --> 00:15:19,519
матрицы путаницы, которая включала

429
00:15:19,519 --> 00:15:21,760
наложение порога на вероятностные

430
00:15:21,760 --> 00:15:23,519
прогнозы, чтобы создать

431
00:15:23,519 --> 00:15:25,920
категориальные  значения, которые мы могли бы затем

432
00:15:25,920 --> 00:15:27,839
сравнить с точностью и полнотой и т. д.

433
00:15:27,839 --> 00:15:28,720


434
00:15:28,720 --> 00:15:31,279
Кривые точности и полноты предлагают

435
00:15:31,279 --> 00:15:33,519
принципиально иную перспективу,

436
00:15:33,519 --> 00:15:35,360
в этом случае вместо того, чтобы навязывать один

437
00:15:35,360 --> 00:15:38,639
порог, мы возьмем каждое возможное

438
00:15:38,639 --> 00:15:41,120
значение, которое предсказано нашим

439
00:15:41,120 --> 00:15:43,120
классификатором как потенциальный порог и, по

440
00:15:43,120 --> 00:15:44,880
сути,  создайте кучу матриц путаницы

441
00:15:44,880 --> 00:15:47,839
на основе этой последовательной

442
00:15:47,839 --> 00:15:49,440
серии порогов,

443
00:15:49,440 --> 00:15:51,279
а затем мы можем построить график  компромисс

444
00:15:51,279 --> 00:15:53,759
между точностью здесь по оси y

445
00:15:53,759 --> 00:15:56,240
и полнотой по оси x для всех

446
00:15:56,240 --> 00:15:58,399
этих различных понятий порога, и

447
00:15:58,399 --> 00:16:00,480
это может быть действительно полезным с точки

448
00:16:00,480 --> 00:16:02,560
зрения помощи нам в том, чтобы помочь нам увидеть, как наша система торгует

449
00:16:02,560 --> 00:16:04,959
точностью и полнотой друг против друга,

450
00:16:04,959 --> 00:16:07,600
и помочь нам  найдите на основе значений, которые у нас

451
00:16:07,600 --> 00:16:10,000
есть о нашей проблеме и наших целях,

452
00:16:10,000 --> 00:16:11,759
каков на самом деле оптимальный баланс между

453
00:16:11,759 --> 00:16:14,160
точностью и отзывом,

454
00:16:14,160 --> 00:16:15,920
а затем, если вам действительно нужно итоговое

455
00:16:15,920 --> 00:16:17,519
число всей этой

456
00:16:17,519 --> 00:16:19,440
средней точности таблицы, которая реализована

457
00:16:19,440 --> 00:16:21,759
в scikit-learn, является стандартным способом

458
00:16:21,759 --> 00:16:24,000
суммируя всю кривую с помощью

459
00:16:24,000 --> 00:16:26,720
одного числа, хотя и не навязывая

460
00:16:26,720 --> 00:16:29,199
тот единственный порог, который так сильно

461
00:16:29,199 --> 00:16:31,680
формировал все предыдущие показатели, которые

462
00:16:31,680 --> 00:16:34,839
мы обсуждали с

463
00:16:37,600 --> 00:16:39,680
вами.

