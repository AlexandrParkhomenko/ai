1
00:00:04,960 --> 00:00:06,480
приветствую всех, это пятая часть

2
00:00:06,480 --> 00:00:07,839
нашей серии статей о контекстуальных представлениях слов, в которой

3
00:00:07,839 --> 00:00:08,960
мы будем

4
00:00:08,960 --> 00:00:10,880
говорить о модели электры.

5
00:00:10,880 --> 00:00:12,559


6
00:00:12,559 --> 00:00:14,080


7
00:00:14,080 --> 00:00:15,759


8
00:00:15,759 --> 00:00:17,440


9
00:00:17,440 --> 00:00:19,760


10
00:00:19,760 --> 00:00:21,279
закончил

11
00:00:21,279 --> 00:00:23,119
скринкаст bert, определив некоторые известные

12
00:00:23,119 --> 00:00:25,199
ограничения модели

13
00:00:25,199 --> 00:00:26,880
отрыжки, elektra действительно использует два и

14
00:00:26,880 --> 00:00:29,039
три в этом списке, поэтому второе,

15
00:00:29,039 --> 00:00:31,199
идентифицированное авторами bert, как раз

16
00:00:31,199 --> 00:00:33,520
и есть цель млм, они говорят, что мы

17
00:00:33,520 --> 00:00:35,680
создаем несоответствие между предварительными  -обучение

18
00:00:35,680 --> 00:00:37,600
и тонкая настройка, поскольку токен маски,

19
00:00:37,600 --> 00:00:39,760
который мы используем, никогда не виден во время тонкой

20
00:00:39,760 --> 00:00:41,440
настройки, поэтому в идеале для модели, которую мы

21
00:00:41,440 --> 00:00:43,440
точно настроили, мы не будем использовать

22
00:00:43,440 --> 00:00:45,600
массовый токен

23
00:00:45,600 --> 00:00:47,600
devlin, и я также буду наблюдать

24
00:00:47,600 --> 00:00:50,399
за целью млм  что у этого есть обратная сторона,

25
00:00:50,399 --> 00:00:53,440
мы делаем прогнозы только о 15

26
00:00:53,440 --> 00:00:55,680
токенах в каждой партии,

27
00:00:55,680 --> 00:00:56,960
у нас есть интуиция, что это

28
00:00:56,960 --> 00:00:58,559
довольно неэффективное использование данных, которые у нас есть.

29
00:00:58,559 --> 00:01:00,399
В идеале, если бы мы были доступны для нас, мы бы

30
00:01:00,399 --> 00:01:02,320
сделали больше прогнозов, и elektra также

31
00:01:02,320 --> 00:01:05,199
стремится реализовать эту интуицию,

32
00:01:05,199 --> 00:01:06,720
поэтому давайте погрузимся в структуру базовой модели.

33
00:01:06,720 --> 00:01:08,080
Здесь мы будем использовать простой

34
00:01:08,080 --> 00:01:10,240
пример: у нас есть последовательность входных токенов

35
00:01:10,240 --> 00:01:12,799
x шеф-повар приготовил еду

36
00:01:12,799 --> 00:01:15,119
и  как обычно с bert, мы можем замаскировать

37
00:01:15,119 --> 00:01:17,439
некоторые из этих токенов, а затем заставить

38
00:01:17,439 --> 00:01:19,280
модель, подобную отрыжке или bert, попытаться

39
00:01:19,280 --> 00:01:21,439
восстановить эти токены маски, однако

40
00:01:21,439 --> 00:01:23,280
мы собираемся сделать это с изюминкой,

41
00:01:23,280 --> 00:01:25,200
вместо того, чтобы всегда пытаться узнать

42
00:01:25,200 --> 00:01:28,400
фактический входной токен, который мы '  re собираемся отбирать

43
00:01:28,400 --> 00:01:30,400
токены, пропорциональные вероятностям генератора,

44
00:01:30,400 --> 00:01:32,960
так что иногда

45
00:01:32,960 --> 00:01:34,880
фактический токен будет вводиться, как в

46
00:01:34,880 --> 00:01:37,040
случае без здесь, а иногда это

47
00:01:37,040 --> 00:01:38,880
будет какой-то другой токен, как в случае с

48
00:01:38,880 --> 00:01:41,680
приготовленным переходом к восьмерке в этой позиции,

49
00:01:41,680 --> 00:01:44,079
теперь работа Электры  дискриминатор

50
00:01:44,079 --> 00:01:46,479
здесь должен выяснить, какие из этих

51
00:01:46,479 --> 00:01:48,240
токенов были в исходной входной

52
00:01:48,240 --> 00:01:50,479
последовательности, а какие были заменены, так

53
00:01:50,479 --> 00:01:52,399
что это задача бинарного прогнозирования, и мы

54
00:01:52,399 --> 00:01:54,320
можем сделать это для всех токенов в

55
00:01:54,320 --> 00:01:57,280
нашем i  входная последовательность, если мы

56
00:01:57,280 --> 00:01:59,280
выбираем фактические потери для

57
00:01:59,280 --> 00:02:01,759
электры, представляет собой сумму потерь генератора

58
00:02:01,759 --> 00:02:03,439
и взвешенной версии электры,

59
00:02:03,439 --> 00:02:05,680
которая является потерями дискриминатора, однако

60
00:02:05,680 --> 00:02:07,600
это как бы маскирует важную

61
00:02:07,600 --> 00:02:09,679
асимметрию в этой модели, как

62
00:02:09,679 --> 00:02:11,520
только мы обучим генератор, мы

63
00:02:11,520 --> 00:02:13,520
можем  пусть он отпадет и выполнит всю нашу

64
00:02:13,520 --> 00:02:15,840
тонкую настройку дискриминатора, который находится

65
00:02:15,840 --> 00:02:18,239
на самой электре, что означает, что мы

66
00:02:18,239 --> 00:02:20,160
будем точно настраивать модель, которая никогда не видела

67
00:02:20,160 --> 00:02:22,400
ни одного из этих токенов маски, поэтому мы устранили

68
00:02:22,400 --> 00:02:24,400
это первое ограничение bert, и мы  мы

69
00:02:24,400 --> 00:02:26,000
также собираемся сделать прогноз

70
00:02:26,000 --> 00:02:27,920
с помощью elektra о каждом

71
00:02:27,920 --> 00:02:29,440
из входных токенов, что означает, что мы

72
00:02:29,440 --> 00:02:34,080
больше используем доступные данные.

73
00:02:34,319 --> 00:02:35,519
Одна вещь, которая мне действительно нравится в

74
00:02:35,519 --> 00:02:37,519
статье об электре, это то, что она предлагает действительно

75
00:02:37,519 --> 00:02:39,680
богатый набор  анализ

76
00:02:39,680 --> 00:02:41,599
эффективности модели и ее оптимального дизайна,

77
00:02:41,599 --> 00:02:43,040
поэтому я собираюсь выделить некоторые из этих

78
00:02:43,040 --> 00:02:44,640
результатов здесь, начиная с этого

79
00:02:44,640 --> 00:02:46,640


80
00:02:46,640 --> 00:02:47,599
результата отношения дискриминатора генератора,

81
00:02:47,599 --> 00:02:49,200
поэтому авторы отмечают, что где

82
00:02:49,200 --> 00:02:51,280
g  Генератор и дискриминатор имеют одинаковый

83
00:02:51,280 --> 00:02:52,239
размер,

84
00:02:52,239 --> 00:02:54,319
они могут совместно использовать все свои параметры преобразователя,

85
00:02:54,319 --> 00:02:56,480
они могут быть одной моделью

86
00:02:56,480 --> 00:02:58,560
по сути, и они считают, что большее

87
00:02:58,560 --> 00:03:00,239
совместное использование действительно лучше, что

88
00:03:00,239 --> 00:03:01,519
обнадеживает,

89
00:03:01,519 --> 00:03:03,760
однако они также отмечают, что наилучшие

90
00:03:03,760 --> 00:03:05,599
результаты достигаются при наличии

91
00:03:05,599 --> 00:03:08,080
генератора, который  мал по сравнению с

92
00:03:08,080 --> 00:03:10,239
дискриминатором, и этот график как бы

93
00:03:10,239 --> 00:03:12,400
обобщает имеющиеся доказательства, поэтому

94
00:03:12,400 --> 00:03:14,239
у нас есть наша оценка клея в качестве цели,

95
00:03:14,239 --> 00:03:15,680
которую мы собираемся использовать для оценки

96
00:03:15,680 --> 00:03:17,920
этих моделей, расположенных вдоль оси Y

97
00:03:17,920 --> 00:03:20,080
вдоль оси X, которую мы имеем  размер генератора,

98
00:03:20,080 --> 00:03:22,400
а затем мы начертили несколько

99
00:03:22,400 --> 00:03:24,239
размеров для дискриминатора, и я думаю,

100
00:03:24,239 --> 00:03:25,920
что вы можете ясно видеть, что

101
00:03:25,920 --> 00:03:28,319
в целом вы получаете наилучшие результаты на

102
00:03:28,319 --> 00:03:30,640
клее, где дискриминатор в два-

103
00:03:30,640 --> 00:03:33,200
три раза больше, чем генератор,

104
00:03:33,200 --> 00:03:35,040
и это  верно, даже для этого очень маленького

105
00:03:35,040 --> 00:03:36,720
моделирования здесь результаты в

106
00:03:36,720 --> 00:03:38,879
целом не очень хорошие, но мы видим то

107
00:03:38,879 --> 00:03:40,640
же самое соотношение, когда оптимальный

108
00:03:40,640 --> 00:03:43,599
дискриминатор имеет размер 256,

109
00:03:43,599 --> 00:03:45,599
а сгенерированный  или при размере 64. именно

110
00:03:45,599 --> 00:03:47,120
здесь мы достигаем наших пиковых результатов, и

111
00:03:47,120 --> 00:03:48,560
это можно сравнить с этой очень

112
00:03:48,560 --> 00:03:51,040
большой моделью синего цвета, где оптимальный размер

113
00:03:51,040 --> 00:03:53,680
для дискриминатора составляет 768 по сравнению с

114
00:03:53,680 --> 00:03:57,360
256 для генератора,

115
00:03:57,680 --> 00:03:58,959
они также проводят кучу действительно

116
00:03:58,959 --> 00:04:00,720
интересных анализов эффективности.

117
00:04:00,720 --> 00:04:02,159
мне нравится в статье то, что

118
00:04:02,159 --> 00:04:04,560
она как бы ориентирована на выяснение того

119
00:04:04,560 --> 00:04:06,159
, как мы можем более эффективно обучать эти модели

120
00:04:06,159 --> 00:04:08,959
с меньшими вычислительными ресурсами,

121
00:04:08,959 --> 00:04:10,799
и это своего рода резюме основных

122
00:04:10,799 --> 00:04:12,879
доказательств того, что они предлагают, что электра

123
00:04:12,879 --> 00:04:15,120
может быть эффективной моделью, так что снова мы  мы

124
00:04:15,120 --> 00:04:16,798
собираемся использовать по оси y оценку клея в

125
00:04:16,798 --> 00:04:19,040
качестве нашей цели, но по

126
00:04:19,040 --> 00:04:21,279
оси x здесь у нас есть предварительный флоп, так что

127
00:04:21,279 --> 00:04:22,720
это будет количество вычислительных

128
00:04:22,720 --> 00:04:24,479
операций, которые вам нужно для предварительного

129
00:04:24,479 --> 00:04:25,840
обучения модели

130
00:04:25,840 --> 00:04:27,759
, выделенной синим цветом вдоль  верхняя часть здесь — электра,

131
00:04:27,759 --> 00:04:29,600
это самая лучшая

132
00:04:29,600 --> 00:04:31,919
модель оранжевого цвета, чуть ниже — состязательная

133
00:04:31,919 --> 00:04:32,960
электра,

134
00:04:32,960 --> 00:04:34,479
что представляет собой интересный подход к

135
00:04:34,479 --> 00:04:36,400
электре, где мы, по сути, обучаем

136
00:04:36,400 --> 00:04:37,919
генератор, чтобы он пытался обмануть

137
00:04:37,919 --> 00:04:39,520
дискриминатор.  в отличие от того, чтобы

138
00:04:39,520 --> 00:04:41,840
два сотрудничали, как в кор-электро, и

139
00:04:41,840 --> 00:04:43,600
это оказывается довольно хорошим, а

140
00:04:43,600 --> 00:04:45,040
также эти зеленые линии действительно

141
00:04:45,040 --> 00:04:46,320
интересны, поэтому

142
00:04:46,320 --> 00:04:48,800
двухэтапная электра - это то, где я начинаю с

143
00:04:48,800 --> 00:04:50,880
тренировки только против цели берта

144
00:04:50,880 --> 00:04:53,040
и в определенный момент переключаюсь на

145
00:04:53,040 --> 00:04:54,639
тренируя цель электро, и вы

146
00:04:54,639 --> 00:04:56,320
можете видеть, что даже это лучше, чем

147
00:04:56,320 --> 00:04:58,560
просто продолжать с bert

148
00:04:58,560 --> 00:05:00,639
до максимума для нашего вычислительного бюджета

149
00:05:00,639 --> 00:05:02,960
здесь,

150
00:05:03,680 --> 00:05:05,520
в документе также исследуется множество

151
00:05:05,520 --> 00:05:07,680
вариантов самой цели электро

152
00:05:07,680 --> 00:05:09,919
, поэтому я представил вам полный

153
00:05:09,919 --> 00:05:12,080
электра, и это полная электра в том

154
00:05:12,080 --> 00:05:13,840
смысле, что здесь справа мы

155
00:05:13,840 --> 00:05:15,520
делаем прогнозы относительно

156
00:05:15,520 --> 00:05:18,000
каждого из токенов во входных данных,

157
00:05:18,000 --> 00:05:19,680
мы также можем исследовать что-то

158
00:05:19,680 --> 00:05:22,880
похожее на электру птиц 15

159
00:05:22,880 --> 00:05:25,280
будет случай, когда мы делаем только прогнозы

160
00:05:25,280 --> 00:05:27,280
о токенах, которые были здесь

161
00:05:27,280 --> 00:05:31,680
во входной массе x, на самом деле маскировали

162
00:05:31,680 --> 00:05:33,280
другой вариант, который, по мнению команды, на

163
00:05:33,280 --> 00:05:34,960
самом деле связан с тем, как мы дрессируем птиц,

164
00:05:34,960 --> 00:05:37,280
так что вспомните, что для  bert мы тренируем как

165
00:05:37,280 --> 00:05:40,000
маскируя, так и заменяя некоторые

166
00:05:40,000 --> 00:05:42,400
токены другими случайно выбранными токенами, и мы

167
00:05:42,400 --> 00:05:44,240
могли бы попробовать обучить генератор только

168
00:05:44,240 --> 00:05:46,320
с таким подходом, который бы

169
00:05:46,320 --> 00:05:48,320
полностью исключил массовый токен, так что этот

170
00:05:48,320 --> 00:05:50,160
вариант здесь, где у нас нет маскировки на

171
00:05:50,160 --> 00:05:52,639
x-max masked, но  скорее просто случайным образом

172
00:05:52,639 --> 00:05:54,720
замените токены из фактического

173
00:05:54,720 --> 00:05:56,479
словаря,

174
00:05:56,479 --> 00:05:58,479
и тогда, наконец, все токены млм

175
00:05:58,479 --> 00:06:00,880
примут некоторые идеи из Электры в

176
00:06:00,880 --> 00:06:02,960
модель отрыжки, так что помните, что для

177
00:06:02,960 --> 00:06:04,800
цели млм мы по существу отключили его

178
00:06:04,800 --> 00:06:06,160
для токенов, которые не были замаскированы, но

179
00:06:06,160 --> 00:06:07,680
нет принципиальной причины, почему  мы

180
00:06:07,680 --> 00:06:09,039
делаем это, конечно, мы могли бы

181
00:06:09,039 --> 00:06:11,039
применить потери к каждому из

182
00:06:11,039 --> 00:06:13,199
токенов во входном потоке, и это

183
00:06:13,199 --> 00:06:15,759
дает нам все токены млм на стороне

184
00:06:15,759 --> 00:06:17,120


185
00:06:17,120 --> 00:06:18,400
генератора центральный вывод статьи, я

186
00:06:18,400 --> 00:06:20,080
полагаю, заключается в том, что электра является лучшим из

187
00:06:20,080 --> 00:06:22,000
все эти модели у вас также есть

188
00:06:22,000 --> 00:06:23,759
действительно хорошая модель, если вы делаете все токены

189
00:06:23,759 --> 00:06:25,600
млм, что может дать информацию о

190
00:06:25,600 --> 00:06:27,520
разработке на стороне бура

191
00:06:27,520 --> 00:06:29,199
в дополнение к отрыжке в  контекст

192
00:06:29,199 --> 00:06:30,400
электро

193
00:06:30,400 --> 00:06:33,520
заменить млм менее хорош, а электрический 15

194
00:06:33,520 --> 00:06:35,120
вроде там, внизу, рядом с

195
00:06:35,120 --> 00:06:37,120
буром, я думаю, это как бы показывает нам,

196
00:06:37,120 --> 00:06:38,720
что мы должны делать больше прогнозов,

197
00:06:38,720 --> 00:06:40,720
которые были направляющей интуицией для Электры,

198
00:06:40,720 --> 00:06:42,240
и это, кажется, подтверждается этими

199
00:06:42,240 --> 00:06:44,400
результаты

200
00:06:44,400 --> 00:06:46,240
и, наконец, как это обычно бывает в этом

201
00:06:46,240 --> 00:06:48,000
пространстве, электрическая команда сделала несколько

202
00:06:48,000 --> 00:06:49,759
релизов моделей с предварительно обученными параметрами, которые

203
00:06:49,759 --> 00:06:51,680
вы можете использовать, они сделали электро-

204
00:06:51,680 --> 00:06:53,360
бас и электро-крупный, которые отчасти

205
00:06:53,360 --> 00:06:55,039
сопоставимы с соответствующими релизами отрыжки,

206
00:06:55,039 --> 00:06:56,880
я думаю, это интересная вещь, которую

207
00:06:56,880 --> 00:06:58,880
они  did также выпущена эта

208
00:06:58,880 --> 00:07:01,599
маленькая электрическая модель, которая предназначена

209
00:07:01,599 --> 00:07:03,840
для быстрого обучения на одном графическом процессоре, что

210
00:07:03,840 --> 00:07:06,319
снова связано с идеей о том, что мы

211
00:07:06,319 --> 00:07:08,240
должны думать о том, как мы можем обучать

212
00:07:08,240 --> 00:07:10,160
такие модели, когда у нас сильно

213
00:07:10,160 --> 00:07:12,720
ограничены вычислительные ресурсы.

214
00:07:12,720 --> 00:07:14,160
в эту идею с самого

215
00:07:14,160 --> 00:07:16,160
начала, я думаю, что маленькая модель показывает,

216
00:07:16,160 --> 00:07:19,639
что она может быть продуктивной

