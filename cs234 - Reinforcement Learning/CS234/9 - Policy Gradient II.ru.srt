1
00:00:05,090 --> 00:00:08,610
Хорошо, приветствую всех, прежде чем

2
00:00:08,610 --> 00:00:11,400
мы начнем сегодня. У меня

3
00:00:11,400 --> 00:00:13,200
нет никаких вопросов по логистике,

4
00:00:13,200 --> 00:00:14,849
промежуточным срокам или чему-то подобному. Мы будем

5
00:00:14,849 --> 00:00:16,920
проводить промежуточный обзор в понедельник,

6
00:00:16,920 --> 00:00:19,500
промежуточный будет в среду, потому

7
00:00:19,500 --> 00:00:20,610
что в нем много людей.  класса

8
00:00:20,610 --> 00:00:22,020
мы собираемся распределить всех

9
00:00:22,020 --> 00:00:23,849
по нескольким комнатам, и мы будем

10
00:00:23,849 --> 00:00:26,820
разосылать инструкции о том, что у них

11
00:00:26,820 --> 00:00:30,770
могут быть любые другие вопросы по логистике,

12
00:00:34,550 --> 00:00:36,600
инструкции также будут в Интернете, но

13
00:00:36,600 --> 00:00:39,059
вам разрешено принести одну страницу

14
00:00:39,059 --> 00:00:41,399
письменного  примечания кроме того, что все

15
00:00:41,399 --> 00:00:46,579
это закрытая книга, да, в то время как поведение

16
00:00:46,579 --> 00:00:48,870
может быть уже выдано пульс, независимо от того,

17
00:00:48,870 --> 00:00:56,879
просто перепроверил болезнь, хорошо,

18
00:00:56,879 --> 00:00:58,079
хорошо, ладно, давайте продолжим и

19
00:00:58,079 --> 00:00:58,760


20
00:00:58,760 --> 00:01:01,559
начнем, прежде чем мы это сделаем, я просто хочу сказать

21
00:01:01,559 --> 00:01:02,640
спасибо всем  вы, которые

22
00:01:02,640 --> 00:01:04,409
участвовали в опросе обратной связи класса,

23
00:01:04,409 --> 00:01:06,240
это действительно полезно для меня и для

24
00:01:06,240 --> 00:01:07,409
всех остальных, чтобы понять, что

25
00:01:07,409 --> 00:01:08,970
помогает вам учиться, а что не помогает

26
00:01:08,970 --> 00:01:14,250
вам учиться, о, ладно, с точки зрения

27
00:01:14,250 --> 00:01:16,049
ответов, так что  обратите внимание, что вы знаете все эти

28
00:01:16,049 --> 00:01:17,729
вещи,

29
00:01:17,729 --> 00:01:19,619
в классе зарегистрировано около двухсот тридцати человек, поэтому

30
00:01:19,619 --> 00:01:20,700
для некоторых из вас, если вы не дали мне

31
00:01:20,700 --> 00:01:22,409
отзыв, мне трудно понять,

32
00:01:22,409 --> 00:01:23,909
что помогает вам или не помогает вам

33
00:01:23,909 --> 00:01:25,320
учиться, поэтому мы  просто будем придерживаться того, что

34
00:01:25,320 --> 00:01:29,159
люди дали нам отзывы о том, что примерно шестьдесят

35
00:01:29,159 --> 00:01:30,180
пять процентов из вас считают, что это

36
00:01:30,180 --> 00:01:32,280
правильный темп примерно двадцать семь процентов из

37
00:01:32,280 --> 00:01:33,630
вас считают, что это происходит слишком быстро,

38
00:01:33,630 --> 00:01:34,770
и только около восьми процентов

39
00:01:34,770 --> 00:01:37,280
людей считают, что это происходит слишком медленно,

40
00:01:37,280 --> 00:01:40,259
поэтому мы  будем продолжать примерно в том же

41
00:01:40,259 --> 00:01:43,500
темпе, что и раньше,

42
00:01:43,500 --> 00:01:45,060
некоторые люди отметили, что они хотели бы, чтобы это было

43
00:01:45,060 --> 00:01:47,399
похоже на семестровый курс. Я

44
00:01:47,399 --> 00:01:48,509
упомяну, что есть ряд других

45
00:01:48,509 --> 00:01:50,159
классов, которые изучают их с подкреплением,

46
00:01:50,159 --> 00:01:51,899
и я настоятельно рекомендую вам пройти

47
00:01:51,899 --> 00:01:54,359
им я предлагаю продвинутый класс, а

48
00:01:54,359 --> 00:01:56,219
также Ван Рой обычно предлагает класс

49
00:01:56,219 --> 00:01:59,189
весной, который более теоретический, это

50
00:01:59,189 --> 00:02:00,810
было очень спорно, я не думал, что

51
00:02:00,810 --> 00:02:03,210
это будет такое разделение, поэтому мы предлагаем

52
00:02:03,210 --> 00:02:04,619
занятия в четверг и пт  дневная

53
00:02:04,619 --> 00:02:07,020
посещаемость была очень низкой, я думаю,

54
00:02:07,020 --> 00:02:09,600
у нас было от трех до семи

55
00:02:09,600 --> 00:02:12,030
человек, пришедших на сеансы, поэтому мы

56
00:02:12,030 --> 00:02:13,770
думали, что это будет что-то,

57
00:02:13,770 --> 00:02:14,970
что все хотели взять,

58
00:02:14,970 --> 00:02:17,010
потому что это примерно поровну.

59
00:02:17,010 --> 00:02:18,440
Я попросил всех

60
00:02:18,440 --> 00:02:20,150
C сравнить  люди, которые приходят в

61
00:02:20,150 --> 00:02:21,560
свои рабочие часы, по сравнению с людьми

62
00:02:21,560 --> 00:02:24,230
, которые приходят на сеансы, у нас, вероятно

63
00:02:24,230 --> 00:02:27,170
, от 4 до 5 X человек, пытающихся пойти

64
00:02:27,170 --> 00:02:28,490
в рабочие часы и пытающихся пойти на

65
00:02:28,490 --> 00:02:30,320
сеансы, поэтому мы собираемся переключиться на

66
00:02:30,320 --> 00:02:33,260
рабочие часы просто так  что мы можем

67
00:02:33,260 --> 00:02:37,490
обслужить как можно больше людей, так что просто

68
00:02:37,490 --> 00:02:39,800
напишите, что там, так что мы собираемся перейти

69
00:02:39,800 --> 00:02:42,950
на рабочие часы, теперь сеансы по-

70
00:02:42,950 --> 00:02:44,750
прежнему будут предлагаться в другие дни, и

71
00:02:44,750 --> 00:02:46,550
они по-прежнему будут записываться, так что для всех,

72
00:02:46,550 --> 00:02:48,020
кто хотел  идите к ним в четверг и

73
00:02:48,020 --> 00:02:49,910
пятницу, вы все еще можете пойти, вы все еще можете

74
00:02:49,910 --> 00:02:51,950
участвовать в Zoom' или вы можете

75
00:02:51,950 --> 00:02:53,960
посмотреть записанную лекцию, но мы собираемся

76
00:02:53,960 --> 00:02:56,630
переключить это на рабочие часы, потому что мой

77
00:02:56,630 --> 00:02:57,680
CAS сказал, что у них было

78
00:02:57,680 --> 00:02:59,030
несколько рабочих часов.  где й  им

79
00:02:59,030 --> 00:03:00,440
либо пришлось остаться очень поздно, им

80
00:03:00,440 --> 00:03:01,640
кажется, что они не доходят до некоторых

81
00:03:01,640 --> 00:03:03,500
людей, и, опять же, просто с точки зрения

82
00:03:03,500 --> 00:03:06,260
обслуживания, чем у большинства людей, я скажу, когда

83
00:03:06,260 --> 00:03:08,390
я просматривал эти ответы, это

84
00:03:08,390 --> 00:03:09,740
действительно заставило меня задуматься о том факте, что

85
00:03:09,740 --> 00:03:11,390
в обучении с подкреплением и своего рода

86
00:03:11,390 --> 00:03:12,860
последовательном принятии решений в целом

87
00:03:12,860 --> 00:03:15,590
мы всегда оптимизируем ожидаемое

88
00:03:15,590 --> 00:03:17,720
вознаграждение, и поэтому это

89
00:03:17,720 --> 00:03:19,190
то же самое, что мы делаем здесь,

90
00:03:19,190 --> 00:03:21,050
я знаю, что всем нужны немного

91
00:03:21,050 --> 00:03:22,340
разные вещи, и мы просто пытаемся

92
00:03:22,340 --> 00:03:25,040
чтобы делать нашу работу как можно лучше и выполнять ожидания, но

93
00:03:25,040 --> 00:03:27,110
именно поэтому такие вещи, как интеллектуальные

94
00:03:27,110 --> 00:03:28,580
системы обучения и другие вещи, могут

95
00:03:28,580 --> 00:03:31,880
быть лучше с точки зрения вещей, которые, по

96
00:03:31,880 --> 00:03:33,200
мнению людей, хорошо работают для

97
00:03:33,200 --> 00:03:34,760
них, у нас есть ряд положительных

98
00:03:34,760 --> 00:03:37,550
отзывов о выполнении отработанных примеров в

99
00:03:37,550 --> 00:03:40,160
классе  Делая выводы Многим людям

100
00:03:40,160 --> 00:03:42,680
очень нравится тот факт, что

101
00:03:42,680 --> 00:03:45,080
в понедельник у моего iPad были проблемы, и поэтому мы сделали

102
00:03:45,080 --> 00:03:47,510
что-то на доске, поэтому мы постараемся продолжать

103
00:03:47,510 --> 00:03:49,519
делать такое же или большее количество

104
00:03:49,519 --> 00:03:51,920
выводов.  так что люди также в целом

105
00:03:51,920 --> 00:03:54,560
очень положительно относились к домашним заданиям с

106
00:03:54,560 --> 00:03:57,650
точки зрения вещей, которые мы видели неоднократно, так

107
00:03:57,650 --> 00:03:59,989
что я сделал, я просто сопоставил

108
00:03:59,989 --> 00:04:01,640
все бесплатные ответы и попытался

109
00:04:01,640 --> 00:04:03,709
найти общие темы и все, что

110
00:04:03,709 --> 00:04:06,680
возникло, вы знаете, 3 или  5 или более раз я

111
00:04:06,680 --> 00:04:08,420
считал, что это обычная проблема, которую

112
00:04:08,420 --> 00:04:11,360
люди хотели бы обсудить, люди хотели

113
00:04:11,360 --> 00:04:12,800
бы еще больше сосредоточиться на объяснении общей картины,

114
00:04:12,800 --> 00:04:15,290
а также на

115
00:04:15,290 --> 00:04:17,180
соединении игрушечных примеров с примерами из реального мира,

116
00:04:17,180 --> 00:04:18,850
поэтому мы постараемся сделать это там, где мы  могу

117
00:04:18,850 --> 00:04:21,410
ли я также попытаться убедиться, что я

118
00:04:21,410 --> 00:04:23,030
говорю громко, несколько

119
00:04:23,030 --> 00:04:24,710
человек сказали, что иногда было

120
00:04:24,710 --> 00:04:26,330
плохо слышно, поэтому я постараюсь

121
00:04:26,330 --> 00:04:28,340
сделать это лучше, если вы не

122
00:04:28,340 --> 00:04:29,600
слышите меня сзади, пожалуйста  не стесняйтесь

123
00:04:29,600 --> 00:04:31,010
поднимать руку,

124
00:04:31,010 --> 00:04:33,350
и люди хотели бы получить еще больше

125
00:04:33,350 --> 00:04:35,720
примеров отработанных примеров, и поэтому, в частности,

126
00:04:35,720 --> 00:04:37,490
мы постараемся убедиться, что на

127
00:04:37,490 --> 00:04:40,160
сессиях мы еще больше подчеркиваем отработанные примеры,

128
00:04:40,160 --> 00:04:46,220
и позвольте мне еще раз повторить, если

129
00:04:46,220 --> 00:04:48,080
это не было одним из  то, что  вы

130
00:04:48,080 --> 00:04:49,610
больше всего беспокоились о том, что я сожалею, что мы

131
00:04:49,610 --> 00:04:52,610
не можем рассмотреть их все в этом термине, мы

132
00:04:52,610 --> 00:04:54,350
определенно, и это было довольно забавно

133
00:04:54,350 --> 00:04:55,640
пройти через это, люди говорили

134
00:04:55,640 --> 00:04:57,920
прямо противоположные вещи, иногда прямо

135
00:04:57,920 --> 00:04:59,450
подряд, с точки зрения того, как это было

136
00:04:59,450 --> 00:05:01,610
сопоставил о таких вещах, как некоторым людям

137
00:05:01,610 --> 00:05:03,380
не нравится тот факт, что слайды имеют

138
00:05:03,380 --> 00:05:05,840
пробелы, и я делаю выводы в классе, а

139
00:05:05,840 --> 00:05:07,640
ряду других людей действительно нравится, что

140
00:05:07,640 --> 00:05:10,490
я делаю задержку в классе некоторые люди

141
00:05:10,490 --> 00:05:12,050
чувствовали, что это движется слишком медленно другие

142
00:05:12,050 --> 00:05:13,420
люди говорили  это двигалось слишком быстро,

143
00:05:13,420 --> 00:05:15,800
поэтому мы снова попытаемся сделать

144
00:05:15,800 --> 00:05:17,570
все возможное, чтобы удовлетворить все

145
00:05:17,570 --> 00:05:21,830
потребности, хорошо, поэтому сегодня мы

146
00:05:21,830 --> 00:05:23,210
продолжим говорить о поиске политики,

147
00:05:23,210 --> 00:05:25,580
который, как я сказал ранее, вероятно, является

148
00:05:25,580 --> 00:05:27,700
самым важным обучением с подкреплением.

149
00:05:27,700 --> 00:05:30,860
вы выучите этот термин. Я думаю,

150
00:05:30,860 --> 00:05:33,320
что сейчас он очень широко используется

151
00:05:33,320 --> 00:05:36,290
для оптимизации функций, и

152
00:05:36,290 --> 00:05:38,120
мы снова можем подумать о поиске политики.

153
00:05:38,120 --> 00:05:40,430
Здесь многое будет звучать

154
00:05:40,430 --> 00:05:41,900
похоже на то, когда мы делали va

155
00:05:41,900 --> 00:05:43,940
приближение функции lue, и то, о чем мы

156
00:05:43,940 --> 00:05:45,260
здесь думаем, это

157
00:05:45,260 --> 00:05:47,660
параметризованная политика, часто мы собираемся

158
00:05:47,660 --> 00:05:49,820
использовать тета для ее параметризации, но мы

159
00:05:49,820 --> 00:05:51,710
могли бы использовать w или что-то еще, но у нас

160
00:05:51,710 --> 00:05:54,860
есть параметризованная политика, а затем

161
00:05:54,860 --> 00:05:57,380
у нас есть некоторое значение этой политики  и

162
00:05:57,380 --> 00:05:58,760
то, что мы собираемся сделать, это

163
00:05:58,760 --> 00:06:01,240
попытаться найти хороший оптимум,

164
00:06:01,240 --> 00:06:04,790
пытающийся максимизировать ценность этой

165
00:06:04,790 --> 00:06:07,820
политики, и одна из причин, почему мы сделали

166
00:06:07,820 --> 00:06:09,320
это сразу после имитационного обучения, заключалась в том,

167
00:06:09,320 --> 00:06:11,270
чтобы связать это с идеей, что у вас есть

168
00:06:11,270 --> 00:06:13,610
чтобы выбрать класс политики, способ

169
00:06:13,610 --> 00:06:16,490
указать эту параметризацию, и поэтому

170
00:06:16,490 --> 00:06:18,680
по своей сути это место

171
00:06:18,680 --> 00:06:22,310
для размещения в структуре, хорошо, так что в качестве

172
00:06:22,310 --> 00:06:24,320
резюме я упомянул, что

173
00:06:24,320 --> 00:06:26,390
до сих пор мы проделали большую работу над методами, основанными на свободных значениях модели,

174
00:06:26,390 --> 00:06:28,370
которые мы  мы сейчас начинаем работать над

175
00:06:28,370 --> 00:06:30,770
методами прямого поиска политики, и

176
00:06:30,770 --> 00:06:32,120
сегодня мы также начнем больше говорить

177
00:06:32,120 --> 00:06:33,770
о методах критики акторов, в которых

178
00:06:33,770 --> 00:06:35,990
мы поддерживаем как

179
00:06:35,990 --> 00:06:38,630
политику явной параметризации, так и функцию

180
00:06:38,630 --> 00:06:40,930
явной параметризации значения.  а

181
00:06:40,930 --> 00:06:43,910
также в течение последних

182
00:06:43,910 --> 00:06:44,630
нескольких недель и

183
00:06:44,630 --> 00:06:46,670
вчера или в понедельник, и сегодня

184
00:06:46,670 --> 00:06:47,990
мы в основном будем говорить о

185
00:06:47,990 --> 00:06:49,730
случаях, когда мы хотим иметь возможность работать

186
00:06:49,730 --> 00:06:54,170
в действительно очень больших пространствах состояний, поэтому

187
00:06:54,170 --> 00:06:55,910
я просто собираюсь сделать  краткое напоминание в

188
00:06:55,910 --> 00:06:57,650
прошлый раз, почему мы хотим сделать это хорошо,

189
00:06:57,650 --> 00:06:58,850
мы, как правило, сможем

190
00:06:58,850 --> 00:07:00,620
гарантировать, что мы сходимся к локальному

191
00:07:00,620 --> 00:07:02,420
оптимуму, у нас не всегда есть эти

192
00:07:02,420 --> 00:07:04,820
гарантии для методов, основанных на функции ценности,

193
00:07:04,820 --> 00:07:08,540
и это может быть важно,

194
00:07:08,540 --> 00:07:11,570
это  Недостатком хорошего свойства

195
00:07:11,570 --> 00:07:13,790
является то, что если вы используете

196
00:07:13,790 --> 00:07:15,140
методы градиента политики, обычно мы сходимся только

197
00:07:15,140 --> 00:07:17,570
к локальному оптимуму в последний раз, когда

198
00:07:17,570 --> 00:07:19,430
я показывал вам пример экзоскелета,

199
00:07:19,430 --> 00:07:21,560
где они используют глобальный подход Optima,

200
00:07:21,560 --> 00:07:24,170
поэтому есть другие методы, которые

201
00:07:24,170 --> 00:07:26,900
могут использовать политику.  основанный на RL не

202
00:07:26,900 --> 00:07:29,030
всегда приведет вас к локальному решению,

203
00:07:29,030 --> 00:07:30,920
но методы, основанные на градиенте, как правило,

204
00:07:30,920 --> 00:07:33,230
помогут, и другая проблема, о которой мы

205
00:07:33,230 --> 00:07:36,110
говорили, как способы попытаться решить

206
00:07:36,110 --> 00:07:39,110
эту проблему или инструменты для решения проблемы.  ct,

207
00:07:39,110 --> 00:07:40,910
что оценка самой политики может быть

208
00:07:40,910 --> 00:07:46,460
довольно неэффективной и иметь высокую дисперсию, поэтому

209
00:07:46,460 --> 00:07:48,590
то, что мы определяли раньше, является градиентом политики,

210
00:07:48,590 --> 00:07:52,490
где теперь я, прежде чем мы как бы

211
00:07:52,490 --> 00:07:53,780
думали о том, что эти вещи

212
00:07:53,780 --> 00:07:55,820
параметризуются тета, поэтому мы можем

213
00:07:55,820 --> 00:07:57,800
думать о том, что значение является политикой

214
00:07:57,800 --> 00:08:00,380
параметризуется тета или пи от

215
00:08:00,380 --> 00:08:02,630
тета, но мы также

216
00:08:02,630 --> 00:08:03,920
собираемся поговорить о функциях значений,

217
00:08:03,920 --> 00:08:06,230
потому что в конечном итоге функция значений

218
00:08:06,230 --> 00:08:07,700
зависит от политики, а политика

219
00:08:07,700 --> 00:08:13,130
зависит от параметров, и когда мы

220
00:08:13,130 --> 00:08:14,570
думаем о том, что мы хотим от этих

221
00:08:14,570 --> 00:08:16,550
алгоритмов, обычно  на самом деле мы

222
00:08:16,550 --> 00:08:18,260
хотели бы попытаться сходиться к действительно

223
00:08:18,260 --> 00:08:20,000
хорошему локальному оптимуму, часто у нас

224
00:08:20,000 --> 00:08:22,730
нет большого контроля над этим, но

225
00:08:22,730 --> 00:08:24,350
мы часто имеем контроль над

226
00:08:24,350 --> 00:08:26,330
такими вещами, как скорость сходимости к

227
00:08:26,330 --> 00:08:30,080
этому локальному оптимуму и так далее.  мы хотим использовать

228
00:08:30,080 --> 00:08:32,150
своего рода go как можно быстрее вниз по

229
00:08:32,150 --> 00:08:33,469
этому градиенту, если мы используем

230
00:08:33,469 --> 00:08:36,469
метод, основанный на градиенте, и используем наши данные так хорошо, как

231
00:08:36,469 --> 00:08:42,620
мы можем, поэтому одна из вещей, которые мы

232
00:08:42,620 --> 00:08:45,380
собираемся обсудить  о сегодняшнем дне, когда мы используем

233
00:08:45,380 --> 00:08:47,390
этот метод градиента политики

234
00:08:47,390 --> 00:08:48,920
, поэтому мы собираемся как бы

235
00:08:48,920 --> 00:08:52,130
двигаться вниз, теперь у нас будет наш

236
00:08:52,130 --> 00:08:54,710
градиент, который будет иметь нашу функцию, так что это B

237
00:08:54,710 --> 00:08:57,620
pi, это наш параметр I

238
00:08:57,620 --> 00:09:02,600
и как мы'  Если мы двигаемся вниз к какому-то

239
00:09:02,600 --> 00:09:06,320
локальному градиенту, было бы неплохо, если бы, когда

240
00:09:06,320 --> 00:09:09,200
мы обновляем нашу политику, она

241
00:09:09,200 --> 00:09:12,770
монотонно улучшалась, так что может ли кто-нибудь

242
00:09:12,770 --> 00:09:13,970
объяснить мне причину, по которой нам может понадобиться

243
00:09:13,970 --> 00:09:17,320
монотонное

244
00:09:17,320 --> 00:09:20,930


245
00:09:20,930 --> 00:09:21,860


246
00:09:21,860 --> 00:09:24,110
улучшение?  в то время как я люблю математику так же сильно,

247
00:09:24,110 --> 00:09:25,850
как и многие из вас, это отличная

248
00:09:25,850 --> 00:09:27,350
причина, но, возможно, я также

249
00:09:27,350 --> 00:09:28,970
думал об эмпирической причине, почему мы могли бы

250
00:09:28,970 --> 00:09:32,470
захотеть этого, да, сзади,

251
00:09:35,370 --> 00:09:37,530
поскольку вы собираетесь развернуть их как в

252
00:09:37,530 --> 00:09:39,960
высоко-  ситуация со ставками, так что мы видели

253
00:09:39,960 --> 00:09:43,250
раньше, на самом деле один из моих студентов

254
00:09:43,250 --> 00:09:45,570
вчера дал мне практическую работу,

255
00:09:45,570 --> 00:09:48,000
и он показывал этот график для dqn,

256
00:09:48,000 --> 00:09:52,890
который выглядит примерно так, где

257
00:09:52,890 --> 00:09:54,600
это похоже на производительность, это

258
00:09:54,600 --> 00:09:58,940
награда, а это время

259
00:10:01,699 --> 00:10:03,139
это выглядит так, и обычно

260
00:10:03,139 --> 00:10:05,179
, когда вы читаете газеты, люди

261
00:10:05,179 --> 00:10:07,999
сглаживают много-много прогонов, но часто это

262
00:10:07,999 --> 00:10:08,839
выглядит примерно так

263
00:10:08,839 --> 00:10:10,220
, когда вы проходите через несколько

264
00:10:10,220 --> 00:10:12,049
эпизодов или через несколько временных шагов,

265
00:10:12,049 --> 00:10:13,790
как будто вы действительно получаете очень неровный

266
00:10:13,790 --> 00:10:16,429
вверх и вниз по эффективности

267
00:10:16,429 --> 00:10:18,739
вашей политики, которую вы используете,

268
00:10:18,739 --> 00:10:21,889
когда делаете DQ n, так почему это может быть

269
00:10:21,889 --> 00:10:23,600
нехорошо в ситуации с высокими ставками,

270
00:10:23,600 --> 00:10:24,709
да, там

271
00:10:24,709 --> 00:10:28,519
это имя, а если это то, что

272
00:10:28,519 --> 00:10:30,619
я делаю, а вы  есть что-то хорошее, а

273
00:10:30,619 --> 00:10:31,970
потом оно падает, люди будут

274
00:10:31,970 --> 00:10:33,769
расстроены из-за того, что вы сейчас сделали

275
00:10:33,769 --> 00:10:35,959
что-то хуже, даже если они

276
00:10:35,959 --> 00:10:40,519
позже вернутся,

277
00:10:40,519 --> 00:10:42,829
если вы знаете, работает ли ваша политика

278
00:10:42,829 --> 00:10:44,509
довольно хорошо, а затем следующий следующий

279
00:10:44,509 --> 00:10:46,489
эпизод это  работает очень плохо, даже если он

280
00:10:46,489 --> 00:10:48,319
может подняться позже, вы знаете, что ваш босс

281
00:10:48,319 --> 00:10:50,029
все равно может вас уволить,

282
00:10:50,029 --> 00:10:51,649
я имею в виду, я шучу, но я думаю, что

283
00:10:51,649 --> 00:10:53,839
люди часто не терпят потерь, а

284
00:10:53,839 --> 00:10:57,109
также часто это невыносимо, это может

285
00:10:57,109 --> 00:10:58,939
быть не хорошо, вы знаете, в компании  хорошо сказать

286
00:10:58,939 --> 00:11:00,290
в этом квартале мы работали очень хорошо, а в

287
00:11:00,290 --> 00:11:01,609
следующем квартале мы собираемся сделать

288
00:11:01,609 --> 00:11:03,799
еще хуже, но потом, в конце концов, вы знаете, что после

289
00:11:03,799 --> 00:11:06,049
многих кварталов у нас все будет хорошо, как

290
00:11:06,049 --> 00:11:07,669
мы часто можем хотеть убедиться, что

291
00:11:07,669 --> 00:11:10,399
мы своего рода монотонно поднимаемся вверх и

292
00:11:10,399 --> 00:11:11,449
в  случае чего-то

293
00:11:11,449 --> 00:11:12,889
вроде лечения пациента или других сценариев с высокими ставками,

294
00:11:12,889 --> 00:11:14,809
или самолетов, или чего-то в этом роде

295
00:11:14,809 --> 00:11:16,669
, это просто, вероятно, будет

296
00:11:16,669 --> 00:11:18,769
нетерпимо для людей, если вы скажете, что мы

297
00:11:18,769 --> 00:11:20,449
будем делать намного хуже в течение этого периода

298
00:11:20,449 --> 00:11:23,509
времени теперь есть исключения для всех  это,

299
00:11:23,509 --> 00:11:24,919
но я думаю, что есть много случаев, когда

300
00:11:24,919 --> 00:11:26,569
вам действительно хотелось бы монотонного улучшения,

301
00:11:26,569 --> 00:11:29,480
если вы можете, поэтому я думаю, что это действительно в

302
00:11:29,480 --> 00:11:31,970
дополнение к теоретическим преимуществам, это

303
00:11:31,970 --> 00:11:34,339
может помочь нам доказать что-то, это также может

304
00:11:34,339 --> 00:11:36,829
быть чем-то таким привлекательным

305
00:11:36,829 --> 00:11:38,359
для людей.  на самом деле иметь возможность развертывания,

306
00:11:38,359 --> 00:11:40,579
и мы знаем, что в целом

307
00:11:40,579 --> 00:11:43,069
люди очень склонны к риску, как и очень не склонны к потерям, поэтому

308
00:11:43,069 --> 00:11:44,869
иметь политики, которые монотонно

309
00:11:44,869 --> 00:11:48,049
улучшаются, может быть очень приятно, и

310
00:11:48,049 --> 00:11:49,459
многие методы, основанные на ценности, не

311
00:11:49,459 --> 00:11:52,549
имеют  SE гарантирует, что мы можем больше поговорить

312
00:11:52,549 --> 00:11:53,929
также о том, всегда ли это

313
00:11:53,929 --> 00:11:56,989
возможно с точки зрения того, хотите ли

314
00:11:56,989 --> 00:12:03,079
вы получить глобальную Optima, да, на данных, к которым у

315
00:12:03,079 --> 00:12:05,269
вас есть доступ или которые вы видели правильно, так что

316
00:12:05,269 --> 00:12:07,129
технически, например, есть ли

317
00:12:07,129 --> 00:12:08,449
распределение с точки зрения вашей живой

318
00:12:08,449 --> 00:12:11,449
среды, где  это может несколько отличаться

319
00:12:11,449 --> 00:12:13,880
от вашей реальной симуляции, или

320
00:12:13,880 --> 00:12:16,579
вы можете не хотеть улучшать ее

321
00:12:16,579 --> 00:12:20,600
даже в условиях жесткой экономии, это правильно,

322
00:12:20,600 --> 00:12:22,100
то есть когда мы будем тем, что вы

323
00:12:22,100 --> 00:12:23,750
знаете, что это за монотонное улучшение,

324
00:12:23,750 --> 00:12:25,040
каковы условия, при которых это

325
00:12:25,040 --> 00:12:27,230
будет  быть гарантированным или возможным, и

326
00:12:27,230 --> 00:12:28,579
делаем ли мы это как бы на основе наших

327
00:12:28,579 --> 00:12:30,380
предыдущих данных и делаем некоторые предположения

328
00:12:30,380 --> 00:12:32,470
о будущих данных, которые собраны

329
00:12:32,470 --> 00:12:34,069
абсолютно, мы собираемся предположить, что

330
00:12:34,069 --> 00:12:35,690
мы все еще находимся в том же процессе принятия решений,

331
00:12:35,690 --> 00:12:37,519
и что он является стационарным и что я  Я имею в

332
00:12:37,519 --> 00:12:39,079
виду, что модель перехода и

333
00:12:39,079 --> 00:12:42,019
модель вознаграждения одинаковы для всех состояний, которые вы

334
00:12:42,019 --> 00:12:43,130
знаете, вы, возможно, еще не наблюдали все

335
00:12:43,130 --> 00:12:44,389
состояния, но они одинаковы для всех

336
00:12:44,389 --> 00:12:46,550
эпизодов, поэтому мы не де  Учитывая тот

337
00:12:46,550 --> 00:12:49,100
факт, что вы знаете, что предпочтения клиентов

338
00:12:49,100 --> 00:12:52,399
полностью изменились, или вы знаете, что изменение

339
00:12:52,399 --> 00:12:54,319
климата меняет вашу среду, мы

340
00:12:54,319 --> 00:12:55,759
имеем дело с тем фактом, что если

341
00:12:55,759 --> 00:12:57,769
мир стационарен, то мы

342
00:12:57,769 --> 00:12:59,300
гарантированно будем иметь монотонное

343
00:12:59,300 --> 00:13:01,370
улучшение.  или

344
00:13:01,370 --> 00:13:02,959
я собираюсь показать вам, что в некоторых случаях

345
00:13:02,959 --> 00:13:05,089
мы можем гарантировать, что другая действительно

346
00:13:05,089 --> 00:13:07,250
важная вещь, которую нужно знать, это

347
00:13:07,250 --> 00:13:09,019
то, что мы собираемся надеяться продемонстрировать монотонное

348
00:13:09,019 --> 00:13:12,319
улучшение ожидания, поэтому

349
00:13:12,319 --> 00:13:14,149
функция ценности является ожидаемой наградой, так

350
00:13:14,149 --> 00:13:15,500
что мы  мы можем надеяться

351
00:13:15,500 --> 00:13:17,600
сказать, что это серия политик, которые были

352
00:13:17,600 --> 00:13:19,579
развернуты в среде, что их

353
00:13:19,579 --> 00:13:22,370
функция ценности растет, так что

354
00:13:22,370 --> 00:13:24,560
это значит, что это означает, что V pi-1 мы

355
00:13:24,560 --> 00:13:26,779
хотели бы, чтобы он был меньше или равен

356
00:13:26,779 --> 00:13:30,860
к V PI меньше, чем равно B pi/3 точка,

357
00:13:30,860 --> 00:13:33,860
где они говорят, что это своего рода политика, которую мы

358
00:13:33,860 --> 00:13:42,040
развертываем на каждой итерации,

359
00:13:43,990 --> 00:13:48,740
все в порядке, но это не гарантирует, что

360
00:13:48,740 --> 00:13:51,189
для одного запуска эта политика лучше,

361
00:13:51,189 --> 00:13:54,230
поэтому вы могли бы легко  допустим, что в

362
00:13:54,230 --> 00:13:55,880
среднем вы используете политику,

363
00:13:55,880 --> 00:13:57,920
которая лучше вам известна для ваших самолетов или

364
00:13:57,920 --> 00:13:59,750
для лечения пациентов и т. д., но они предназначены

365
00:13:59,750 --> 00:14:01,009
для отдельных пациентов, которые могут быть

366
00:14:01,009 --> 00:14:03,709
хуже, и я думаю, что действительно интересная

367
00:14:03,709 --> 00:14:06,220
активная область исследований сейчас — это

368
00:14:06,220 --> 00:14:09,019
безопасное подкрепление.  обучение и безопасное

369
00:14:09,019 --> 00:14:10,730
исследование, и многие

370
00:14:10,730 --> 00:14:12,439
люди думают об этом, в том

371
00:14:12,439 --> 00:14:13,850
числе ряд людей здесь, в Стэнфорде, и

372
00:14:13,850 --> 00:14:15,050
одна из вещей, которую мы рассматриваем

373
00:14:15,050 --> 00:14:16,730
в нашей группе, это то, как вы действительно

374
00:14:16,730 --> 00:14:19,220
эффективно можете найти безопасное решение, какой

375
00:14:19,220 --> 00:14:20,630
препарат вы  под безопасным в этом случае я

376
00:14:20,630 --> 00:14:21,709
подразумеваю, что вы, возможно, не захотите соответствовать

377
00:14:21,709 --> 00:14:23,839
максимальному ожидаемому вознаграждению, вы можете

378
00:14:23,839 --> 00:14:25,290
захотеть иметь возможность максимизировать

379
00:14:25,290 --> 00:14:27,630
какие-то критерии избегания риска, и

380
00:14:27,630 --> 00:14:28,980
мы хотели бы найти способы действительно

381
00:14:28,980 --> 00:14:31,020
эффективно добраться до этого решения, но

382
00:14:31,020 --> 00:14:32,220
есть  много действительно интересных вещей,

383
00:14:32,220 --> 00:14:34,260
которые говорят, что вы знаете, как мы пытаемся выполнять

384
00:14:34,260 --> 00:14:35,850
поиск политики или как мы делаем это

385
00:14:35,850 --> 00:14:37,890
улучшение в случаях, когда нас не

386
00:14:37,890 --> 00:14:42,330
заботят только ожидаемые результаты, хорошо,

387
00:14:42,330 --> 00:14:43,590
так что мы идем  g, что мы пытаемся сделать сегодня,

388
00:14:43,590 --> 00:14:45,810
это движение в идеале не просто к

389
00:14:45,810 --> 00:14:47,130
монотонным улучшениям, а к большим

390
00:14:47,130 --> 00:14:49,500
монотонным улучшениям, как вы можете

391
00:14:49,500 --> 00:14:51,480
догадаться, легче попытаться добиться

392
00:14:51,480 --> 00:14:53,760
небольших монотонных улучшений,

393
00:14:53,760 --> 00:14:55,320
чем гарантировать действительно большие

394
00:14:55,320 --> 00:14:56,700
монотонные улучшения. У

395
00:14:56,700 --> 00:14:58,800
кого-нибудь есть интуиция?  почему

396
00:14:58,800 --> 00:15:01,550
это было бы правдой,

397
00:15:02,540 --> 00:15:06,080
я собираюсь быть сложнее, этот вид

398
00:15:06,080 --> 00:15:09,380
восходит к распределениям по штатам, поэтому, если

399
00:15:09,380 --> 00:15:13,130
вы сильно измените свою политику,

400
00:15:13,130 --> 00:15:15,140
может ли штат

401
00:15:15,140 --> 00:15:18,670
сильно измениться с точки зрения штатов, которые вы посещаете,

402
00:15:19,480 --> 00:15:21,980
настолько интуитивно, что должно  ответ

403
00:15:21,980 --> 00:15:23,480
должен быть да, поэтому мы говорили о

404
00:15:23,480 --> 00:15:26,330
том, как любая политика вызывает распределение состояний,

405
00:15:26,330 --> 00:15:28,250
например, если вы запускаете ее в течение

406
00:15:28,250 --> 00:15:29,360
длительного времени, у вас будет своего рода

407
00:15:29,360 --> 00:15:32,120
стационарное распределение по состояниям, и

408
00:15:32,120 --> 00:15:34,580
если ваша политика действительно отличается от

409
00:15:34,580 --> 00:15:36,170
вашей старой  политики, то это

410
00:15:36,170 --> 00:15:37,730
распределение состояний может выглядеть совсем иначе,

411
00:15:37,730 --> 00:15:39,410
что означает, что у вас может быть не очень много

412
00:15:39,410 --> 00:15:43,310
данных, тогда как если у вас почти точно

413
00:15:43,310 --> 00:15:45,230
такая же политика, как и раньше, вы

414
00:15:45,230 --> 00:15:46,610
вероятно, у нас будет действительно

415
00:15:46,610 --> 00:15:48,620
хорошее представление о том, что это за значение в

416
00:15:48,620 --> 00:15:50,150
оценке, но мы вернемся к этому

417
00:15:50,150 --> 00:15:52,370
позже, поэтому сегодня мы

418
00:15:52,370 --> 00:15:54,020
попытаемся подумать о том, чтобы выйти за рамки того, о чем мы

419
00:15:54,020 --> 00:15:55,130
говорили в прошлый раз.  там, где мы

420
00:15:55,130 --> 00:15:57,290
пытаемся использовать методы градиента политики, и

421
00:15:57,290 --> 00:15:59,000
мы пытаемся сделать это таким образом, чтобы это было в некотором

422
00:15:59,000 --> 00:16:00,410
роде эффективным, мы собираемся поговорить о

423
00:16:00,410 --> 00:16:03,080
других способах сделать его более эффективным и

424
00:16:03,080 --> 00:16:05,060
менее шумным, а затем попытаемся перейти к

425
00:16:05,060 --> 00:16:09,680
монотонному улучшению  хорошо, так что

426
00:16:09,680 --> 00:16:11,000
вещи, о которых мы говорили в прошлый раз,

427
00:16:11,000 --> 00:16:12,710
мы начали, и мы сказали, что мы могли бы

428
00:16:12,710 --> 00:16:14,990
сделать с точки зрения градиента политики, одна вещь, которую

429
00:16:14,990 --> 00:16:17,420
мы могли бы сделать, это то, что вы делаете

430
00:16:17,420 --> 00:16:19,700
отчеты по методу Монте-Карло, так что это отчеты по методу Монте-Карло,

431
00:16:19,700 --> 00:16:25,190
и иногда люди используют  большой

432
00:16:25,190 --> 00:16:29,410
R тау, где плитка это траектория,

433
00:16:29,590 --> 00:16:32,290
поэтому вы можете просто исчерпать свою политику

434
00:16:32,290 --> 00:16:35,180
до тех пор, пока мир не прекратится или H шагов, или как

435
00:16:35,180 --> 00:16:36,590
бы вы ни определяли свои эпизоды,

436
00:16:36,590 --> 00:16:39,290
а затем посмотрите на вознаграждение и посмотрите

437
00:16:39,290 --> 00:16:41,420
на вознаграждение, которое вы знаете, за временной шаг

438
00:16:41,420 --> 00:16:47,780
мы также можем использовать G I  T для обозначения

439
00:16:47,780 --> 00:16:50,060
вознаграждения, которое мы получаем от временного шага T и в

440
00:16:50,060 --> 00:16:53,210
эпизоде I, и то, что мы сказали ранее, заключается в то 

441
00:16:53,210 --> 00:16:55,760
, что это непредвзятая оценка гр 

442
00:16:55,760 --> 00:16:58,100
диента, но она действительно зашумлена, и поэтому мы на 

443
00:16:58,100 --> 00:16:59,420
али говорить о дополнительной ст 

444
00:16:59,420 --> 00:17:01,040
уктуре, которую мы могли бы использовать в по 

445
00:17:01,040 --> 00:17:02,570
креплении.  проблема обучения, в которой

446
00:17:02,570 --> 00:17:05,150
мы предполагаем, что мир является марковским, чтобы

447
00:17:05,150 --> 00:17:06,680
попытаться уменьшить дисперсию этой

448
00:17:06,680 --> 00:17:08,780
оценки, и поэтому в

449
00:17:08,780 --> 00:17:11,589
прошлый раз мы говорили об использовании временной структуры,

450
00:17:11,589 --> 00:17:13,970
которую мы сделали с кем-то на доске,

451
00:17:13,970 --> 00:17:15,980
и интуиция была

452
00:17:15,980 --> 00:17:19,609
наградой, которую вы получите в какое-то время  точка может

453
00:17:19,609 --> 00:17:21,859
быть не подвержена влиянию более поздних решений,

454
00:17:21,859 --> 00:17:24,859
которые вы примете, поэтому вам не нужно было принимать

455
00:17:24,859 --> 00:17:26,689
вид этого полного продукта

456
00:17:26,689 --> 00:17:28,339
вероятности действия с учетом состояний,

457
00:17:28,339 --> 00:17:30,919
потому что будущие действия не

458
00:17:30,919 --> 00:17:33,950
ретроактивно меняют ваши предыдущие награды за

459
00:17:33,950 --> 00:17:36,290
интуицию, поэтому мы'  мы собираемся начать говорить

460
00:17:36,290 --> 00:17:37,820
сейчас о других вещах, которые являются

461
00:17:37,820 --> 00:17:39,950
базовыми показателями и альтернативами Монте-

462
00:17:39,950 --> 00:17:46,040
Карло, так что же является базовым уровнем, ну,

463
00:17:46,040 --> 00:17:47,720
базовым уровнем, давайте еще

464
00:17:47,720 --> 00:17:49,730
подумаем о сумме вознаграждений, которые мы  получить

465
00:17:49,730 --> 00:17:52,040
от этого временного шага и далее, так что это

466
00:17:52,040 --> 00:17:53,950
то же самое, что мы часто называем

467
00:17:53,950 --> 00:17:58,340
GT, так что это награда, которую мы получаем от

468
00:17:58,340 --> 00:17:59,630
этого временного шага до конца эпизода,

469
00:17:59,630 --> 00:18:02,360
и мы собираемся вычесть базовый уровень,

470
00:18:02,360 --> 00:18:06,080
который зависит от состояния и того, что  Я

471
00:18:06,080 --> 00:18:08,120
собираюсь показать вкратце, что,

472
00:18:08,120 --> 00:18:10,010
вычитая эту базовую линию, которая зависит

473
00:18:10,010 --> 00:18:11,990
только от состояния, ваша результирующая

474
00:18:11,990 --> 00:18:13,640
оценка градиента все еще может быть несмещенной,

475
00:18:13,640 --> 00:18:15,260
но она может иметь не намного меньшую

476
00:18:15,260 --> 00:18:17,929
дисперсию, и, в частности, часто

477
00:18:17,929 --> 00:18:19,220
действительно хорошим выбором является ожидаемая

478
00:18:19,220 --> 00:18:20,809
доходность, которая в основном  функция значения,

479
00:18:20,809 --> 00:18:24,470
и поэтому, почему мы должны делать это

480
00:18:24,470 --> 00:18:26,240
хорошо, тогда мы можем как бы посмотреть, что мы

481
00:18:26,240 --> 00:18:28,190
увеличиваем логарифмическую вероятность

482
00:18:28,190 --> 00:18:30,080
действия пропорционально тому, насколько

483
00:18:30,080 --> 00:18:34,640
оно лучше, чем базовый уровень, который в

484
00:18:34,640 --> 00:18:36,169
целом может в конечном итоге быть немного  немного

485
00:18:36,169 --> 00:18:39,200
похоже на функцию преимущества, так почему

486
00:18:39,200 --> 00:18:43,549
это правда, хорошо, так что мы

487
00:18:43,549 --> 00:18:45,140
собираемся сделать здесь, мы собираемся сказать, что у нас есть

488
00:18:45,140 --> 00:18:47,570
эта высокая оценка дисперсии прямо сейчас, если

489
00:18:47,570 --> 00:18:49,640
у нас нет представьте, что у нас не было

490
00:18:49,640 --> 00:18:51,590
этого, мы не  у нас есть то, что мы  у нас есть

491
00:18:51,590 --> 00:18:53,030
стандартная оценка, о которой мы говорили в

492
00:18:53,030 --> 00:18:54,919
последнем типе, и я хочу убедить

493
00:18:54,919 --> 00:18:57,350
вас в том, что если мы вычтем эту

494
00:18:57,350 --> 00:18:58,960
вещь, которая является функцией состояния,

495
00:18:58,960 --> 00:19:01,790
то ожидание этого дополнительного члена, которое

496
00:19:01,790 --> 00:19:04,250
мы вычитаем, равно нулю, что означает,

497
00:19:04,250 --> 00:19:07,850
что наша оценка  по-прежнему несмещен, поэтому

498
00:19:07,850 --> 00:19:09,320
я сказал, что наша первоначальная оценка не

499
00:19:09,320 --> 00:19:09,950
смещена,

500
00:19:09,950 --> 00:19:11,510
теперь мы вычитаем эту странную

501
00:19:11,510 --> 00:19:12,890
вещь, которую мы хотим показать, что результирующая

502
00:19:12,890 --> 00:19:15,200
оценка по-прежнему несмещена, и

503
00:19:15,200 --> 00:19:17,840
мы делаем это, показывая, что цель состоит в том, чтобы

504
00:19:17,840 --> 00:19:25,990
показать, что это равно  ноль,

505
00:19:26,350 --> 00:19:27,490
так что это то, что мы попытаемся сделать,

506
00:19:27,490 --> 00:19:28,809
и если мы сможем это показать, то

507
00:19:28,809 --> 00:19:31,360
это оправдает, почему мы можем вычесть эту

508
00:19:31,360 --> 00:19:32,769
случайную вещь, а затем мы можем начать

509
00:19:32,769 --> 00:19:34,179
говорить о том, какой должна быть эта случайная вещь,

510
00:19:34,179 --> 00:19:35,559
но сначала мы просто покажем  независимо

511
00:19:35,559 --> 00:19:37,059
от того, что это за случайная вещь, если

512
00:19:37,059 --> 00:19:39,130
это функция только состояния, что это

513
00:19:39,130 --> 00:19:42,789
ожидание равно нулю, так как же нам сделать это

514
00:19:42,789 --> 00:19:44,740
хорошо, прежде всего обратите внимание снаружи,

515
00:19:44,740 --> 00:19:47,440
что есть ожидание по тау, которое является

516
00:19:47,440 --> 00:19:49,389
всеми траекториями, которые мы можем  я могу столкнуться

517
00:19:49,389 --> 00:19:53,230
, запустив нашу текущую политику, поэтому

518
00:19:53,230 --> 00:19:54,399
сначала я просто

519
00:19:54,399 --> 00:19:56,620
разделю ее на две части, так что это все еще

520
00:19:56,620 --> 00:20:00,250
тау, и все, что я здесь сделал, это то, что я разделил

521
00:20:00,250 --> 00:20:02,799
ее на первую часть, которая  весь

522
00:20:02,799 --> 00:20:04,720
путь до временного шага T и вторая

523
00:20:04,720 --> 00:20:08,230
часть, которая находится на временном шаге T, вплоть

524
00:20:08,230 --> 00:20:09,580
до конца, поэтому я просто как бы

525
00:20:09,580 --> 00:20:12,279
разложил, что я только что написал,

526
00:20:12,279 --> 00:20:15,039
что такое траектория, а затем разложил

527
00:20:15,039 --> 00:20:16,299
ее на две части.  поэтому я просто

528
00:20:16,299 --> 00:20:21,850
разлагаю траекторию, и как только мы

529
00:20:21,850 --> 00:20:23,919
это сделаем, мы увидим, что

530
00:20:23,919 --> 00:20:26,740
базовый член является только функцией s T,

531
00:20:26,740 --> 00:20:28,929
поэтому мы можем извлечь его из этого во внутреннем

532
00:20:28,929 --> 00:20:35,830
члене, поэтому мы собираемся вытащить это,

533
00:20:35,830 --> 00:20:37,480
потому что это не так.  не зависит ни от одной из

534
00:20:37,480 --> 00:20:41,110
этих будущих временных меток, она не

535
00:20:41,110 --> 00:20:43,980
зависит от них,

536
00:20:53,289 --> 00:20:55,519
то следующее, что мы собираемся сделать,

537
00:20:55,519 --> 00:21:00,470
это записать или отметить тот

538
00:21:00,470 --> 00:21:04,340
факт, что в этом случае все, что у нас есть

539
00:21:04,340 --> 00:21:08,570
в этом внутреннем термине, это  st и 80, так что

540
00:21:08,570 --> 00:21:12,019
мы можем снова отбросить все будущие термины

541
00:21:12,019 --> 00:21:14,179
this или the prone lis здесь

542
00:21:14,179 --> 00:21:15,890
есть вероятность действия  на временном

543
00:21:15,890 --> 00:21:19,039
шаге T с учетом состояния T и тета, поэтому нам

544
00:21:19,039 --> 00:21:20,480
не нужно беспокоиться о будущих

545
00:21:20,480 --> 00:21:22,070
состояниях или будущих действиях, которые были

546
00:21:22,070 --> 00:21:25,250
предприняты там, где они не зависели от них,

547
00:21:25,250 --> 00:21:26,960
поэтому сейчас мы просто вытащили первый, мы

548
00:21:26,960 --> 00:21:32,120
вытащили базовую линию, и теперь мы  мы собираемся

549
00:21:32,120 --> 00:21:33,860
отбросить те вещи, от которых нам не нужно

550
00:21:33,860 --> 00:21:39,409
зависеть, поэтому все, что у нас есть, это

551
00:21:39,409 --> 00:21:43,000
ожидание действий, которые были предприняты,

552
00:21:47,919 --> 00:21:50,750
и теперь я собираюсь сделать это, я

553
00:21:50,750 --> 00:21:52,130
собираюсь прочитать, так что это за

554
00:21:52,130 --> 00:21:54,490
ожидание, это  ожидание более 80, в

555
00:21:54,490 --> 00:21:56,510
чем проблема, вы знаете, что

556
00:21:56,510 --> 00:21:57,830
это за ожидание, мы просто запишем

557
00:21:57,830 --> 00:21:59,750
это явно, что зависит от

558
00:21:59,750 --> 00:22:07,549
политики, которая у нас есть, поэтому мы собираемся суммировать

559
00:22:07,549 --> 00:22:11,630
более 80 вероятность этих 80, которые,

560
00:22:11,630 --> 00:22:13,190
конечно, просто зависят от  политика,

561
00:22:13,190 --> 00:22:15,950
которой мы следуем, умножается на

562
00:22:15,950 --> 00:22:24,110
производную от журнала, так что я

563
00:22:24,110 --> 00:22:26,360
записываю ожидание, и теперь я собираюсь

564
00:22:26,360 --> 00:22:29,350
взять производную от журнала,

565
00:22:44,710 --> 00:22:47,060
так что это просто будет производная

566
00:22:47,060 --> 00:22:50,680
по отношению к самой политике,

567
00:22:52,330 --> 00:23:01,070
деленная на PI  80-х Т тета, но теперь мы

568
00:23:01,070 --> 00:23:02,510
отмечаем, что есть

569
00:23:02,510 --> 00:23:03,980
терма в числителе с точки зрения знаменателя,

570
00:23:03,980 --> 00:23:07,190
который мы можем отменить, так что это начинает

571
00:23:07,190 --> 00:23:14,630
упрощать его быть жилетом T, умноженным на сумму

572
00:23:14,630 --> 00:23:17,300
более 80, просто производная

573
00:23:17,300 --> 00:23:23,750
политики, только что отмененная числитель и

574
00:23:23,750 --> 00:23:25,700
знаменатель там, и теперь мы отмечаем, что

575
00:23:25,700 --> 00:23:28,880
мы можем обратить  сумма и

576
00:23:28,880 --> 00:23:35,600
производная это другая сторона

577
00:23:35,600 --> 00:23:39,950
критического шага этого доказательства, так

578
00:23:39,950 --> 00:23:41,000
что теперь мы собираемся сделать это, мы

579
00:23:41,000 --> 00:23:50,120
собираемся вывести производную хорошо

580
00:23:50,120 --> 00:23:52,580
это всего 1, потому что вероятность того,

581
00:23:52,580 --> 00:23:55,010
что мы выберем какое-то действие при  наша

582
00:23:55,010 --> 00:23:57,860
политика всегда должна быть 1, и теперь мы

583
00:23:57,860 --> 00:23:59,420
видим, что мы просто берем

584
00:23:59,420 --> 00:24:07,490
производную от 1, поэтому мы пытаемся

585
00:24:07,490 --> 00:24:09,230
взять производную от 1, и, конечно же,

586
00:24:09,230 --> 00:24:14,420
это константа, поэтому она равна 0, так что это

587
00:24:14,420 --> 00:24:15,620
довольно круто, так что  это означает, что мы

588
00:24:15,620 --> 00:24:18,470
добавили в эту базовую линию некоторую

589
00:24:18,470 --> 00:24:20,570
функцию, которая зависит от состояния, о котором

590
00:24:20,570 --> 00:24:21,830
мы не сказали, мы сказали мне, вы знаете, что мы

591
00:24:21,830 --> 00:24:23,150
еще не говорили обо всех различных

592
00:24:23,150 --> 00:24:24,740
способах, которыми мы могли бы вычислить это, или сказать, что это

593
00:24:24,740 --> 00:24:26,720
не имеет значения.  что это неважно, что

594
00:24:26,720 --> 00:24:32,860
вы добавляете в  re это всегда беспристрастно, так

595
00:24:32,860 --> 00:24:35,000
что просто чтобы проверить наше понимание на

596
00:24:35,000 --> 00:24:36,710
секунду, если мы вернемся к этому уравнению, если

597
00:24:36,710 --> 00:24:42,050
я установлю B of s T как константу

598
00:24:42,050 --> 00:24:45,140
везде, оценка градиента

599
00:24:45,140 --> 00:24:47,830
все еще беспристрастна,

600
00:24:52,100 --> 00:24:54,630
это всего восемь тарелок в минуту и

601
00:24:54,630 --> 00:24:57,570
нитесь вашего соседа, они дерутся  Итак, основываясь

602
00:24:57,570 --> 00:25:00,210
на том, что я только что сказал, если B of s T

603
00:25:00,210 --> 00:25:04,190
равно константе, это константа

604
00:25:04,190 --> 00:25:12,900
для всех s T является оценкой градиента

605
00:25:12,900 --> 00:25:17,580
и последней ставкой, как одна секунда, я хочу

606
00:25:17,580 --> 00:26:09,000
поговорить с вами правильно, поэтому давайте начнем со

607
00:26:09,000 --> 00:26:10,800
всеми, кто  думает, что это по-прежнему беспристрастное

608
00:26:10,800 --> 00:26:13,980
голосование да, отлично, да,

609
00:26:13,980 --> 00:26:15,690
теперь это будет беспристрастно, это функция даже не

610
00:26:15,690 --> 00:26:18,210
s, это просто константа, и поэтому это

611
00:26:18,210 --> 00:26:19,620
определенно функция NS, это

612
00:26:19,620 --> 00:26:21,660
тривиальная функция, где не имеет значения,

613
00:26:21,660 --> 00:26:23,250
какое значение  s есть, и поэтому все еще

614
00:26:23,250 --> 00:26:28,350
непредвзято просто отметить здесь, и если

615
00:26:28,350 --> 00:26:30,330
s не было забавно, если базовая линия была

616
00:26:30,330 --> 00:26:32,370
функцией состояния и действия, вы

617
00:26:32,370 --> 00:26:35,040
думаете, что это доказательство не будет иметь никакого

618
00:26:35,040 --> 00:26:36,300
права, потому что одна из вещей, которые мы

619
00:26:36,300 --> 00:26:37,920
сделали в самом  начало мы двигаем B

620
00:26:37,920 --> 00:26:40,740
из s T все  выход, и если это

621
00:26:40,740 --> 00:26:42,060
тоже зависит от действия, мы не могли бы этого сделать

622
00:26:42,060 --> 00:26:45,660
, так что это специфично для того, чтобы это было

623
00:26:45,660 --> 00:26:59,100
только функцией состояния да, используйте

624
00:26:59,100 --> 00:27:01,050
только функцию состояния, все они

625
00:27:01,050 --> 00:27:02,559
выполняются поэтапно,

626
00:27:02,559 --> 00:27:04,090
да, всегда есть некоторая предвзятость  может быть на

627
00:27:04,090 --> 00:27:06,389
самом деле, я имею в виду, как и то, что я написал здесь,

628
00:27:06,389 --> 00:27:09,129
вы можете просто ввести константу, и это

629
00:27:09,129 --> 00:27:10,870
может вообще не уменьшить вашу дисперсию, так

630
00:27:10,870 --> 00:27:12,669
что, безусловно, есть бесполезные

631
00:27:12,669 --> 00:27:14,710
определения базовой линии, но все они

632
00:27:14,710 --> 00:27:16,470
беспристрастны, поэтому они не повлияют на

633
00:27:16,470 --> 00:27:18,909
не ваш оценщик

634
00:27:18,909 --> 00:27:20,620
беспристрастен, они могут сделать вашу оценку

635
00:27:20,620 --> 00:27:22,120
потенциально хуже, если они действительно плохие

636
00:27:22,120 --> 00:27:25,210
или они сами потенциально очень плохие

637
00:27:25,210 --> 00:27:27,610
оценщики, и они,

638
00:27:27,610 --> 00:27:29,230
безусловно, могли бы сделать его лучше

639
00:27:29,230 --> 00:27:35,399
, выбрав хороший выбор, так что

640
00:27:35,399 --> 00:27:37,990
это в конечном итоге может позволить нам определить

641
00:27:37,990 --> 00:27:39,759
какой вид известен как алгоритм градиента ванильной политики

642
00:27:39,759 --> 00:27:42,460
, поэтому

643
00:27:42,460 --> 00:27:45,159
работает градиент ванильной политики, мы собираем

644
00:27:45,159 --> 00:27:46,960
кучу траекторий, используя нашу текущую политику,

645
00:27:46,960 --> 00:27:49,179
а затем для каждого временного шага

646
00:27:49,179 --> 00:27:51,009
внутри траектории  мы вычисляем доход

647
00:27:51,009 --> 00:27:53,769
от этого временного шага до конца, а затем

648
00:27:53,769 --> 00:27:58,690
вычисляем оценку преимущества, так что все в

649
00:27:58,690 --> 00:27:59,919
порядке, мы правы, градиент ванильной политики

650
00:27:59,919 --> 00:28:09,070
хорошо, так что градиент ванильной политики

651
00:28:09,070 --> 00:28:11,139
работает следующим образом: вы запускаете, вы

652
00:28:11,139 --> 00:28:12,759
инициализируете политику с некоторым

653
00:28:12,759 --> 00:28:14,919
параметром тета, и вы  нужно начать

654
00:28:14,919 --> 00:28:17,590
с некоторой оценки базовой линии, хорошо

655
00:28:17,590 --> 00:28:19,090
, что происходит с ванильным градиентом политики,

656
00:28:19,090 --> 00:28:22,330
это четыре итерации, я равен от 1

657
00:28:22,330 --> 00:28:25,869
до точки, мы собираемся собрать набор

658
00:28:25,869 --> 00:28:34,499
траекторий, используя вашу текущую политику,

659
00:28:34,499 --> 00:28:41,230
а затем для каждого временного шага для T равно

660
00:28:41,230 --> 00:28:44,970
1 точке  длина вашей траектории I,

661
00:28:44,970 --> 00:28:47,919
затем вы делаете две вещи: вычисляете

662
00:28:47,919 --> 00:28:52,090
отдачу, которая равна сумме

663
00:28:52,090 --> 00:28:54,999
всех отдач до конца

664
00:28:54,999 --> 00:28:59,169
эпизода, а затем вычисляете

665
00:28:59,169 --> 00:29:04,690
преимущество, которое

666
00:29:04,690 --> 00:29:06,850
равно этой отдаче I'  Я параметризую его с помощью

667
00:29:06,850 --> 00:29:08,379
I, чтобы показать, что это траектория I

668
00:29:08,379 --> 00:29:14,429
минус B из s T,

669
00:29:15,220 --> 00:29:18,990
поэтому просто отметим здесь на секунду, что

670
00:29:18,990 --> 00:29:21,790
это возврат суммы вознаграждений

671
00:29:21,790 --> 00:29:23,470
до конца эпизода, это

672
00:29:23,470 --> 00:29:27,360
базовая линия, которая  похоже на фиксированную функцию,

673
00:29:27,360 --> 00:29:29,620
так что это может быть вы знаете глубокую нейронную

674
00:29:29,620 --> 00:29:32,320
сеть, это может быть поиск по таблице, но

675
00:29:32,320 --> 00:29:34,750
это функция, и вы вводите

676
00:29:34,750 --> 00:29:37,750
состояние временного шага T в траектории I, и

677
00:29:37,750 --> 00:29:40,270
вы выводите скаляр, так что это то, что

678
00:29:40,270 --> 00:29:43,270
делает базовая линия  тут же то, что

679
00:29:43,270 --> 00:29:45,010
мы делаем в ванильном политическом градиенте, — это то, что мы

680
00:29:45,010 --> 00:29:50,500
переделываем базовый уровень, поэтому в этом случае

681
00:29:50,500 --> 00:29:52,630
базовый уровень будет

682
00:29:52,630 --> 00:29:55,390
оценкой среднего значения G, поэтому в ванильном

683
00:29:55,390 --> 00:29:58,900
базовом политическом градиенте ванильный политический градиент

684
00:29:58,900 --> 00:30:02,830
мы делаем следующее:  мы суммируем по

685
00:30:02,830 --> 00:30:04,420
всем траекториям, которые вы получили до сих пор,

686
00:30:04,420 --> 00:30:07,270
мы суммируем по всем временным шагам, и мы в

687
00:30:07,270 --> 00:30:16,360
основном просто подбираем метод наименьших квадратов, поэтому

688
00:30:16,360 --> 00:30:17,290
обратите внимание, что это можно сделать, например, со

689
00:30:17,290 --> 00:30:18,970
студентом, это контролируемое обучение, у нас

690
00:30:18,970 --> 00:30:22,300
просто есть базовая функция, которая

691
00:30:22,300 --> 00:30:24,400
может  быть параметризованным, я обязательно

692
00:30:24,400 --> 00:30:26,740
посмотрю на это, чтобы у нас была базовая

693
00:30:26,740 --> 00:30:28,600
функция, которую можно было бы параметризовать с

694
00:30:28,600 --> 00:30:30,310
некоторыми совершенно другими весами или параметрами,

695
00:30:30,310 --> 00:30:32,860
а затем у нас были бы наши результаты G, которые

696
00:30:32,860 --> 00:30:34,120
мы видели до сих пор, мы просто пытаемся

697
00:30:34,120 --> 00:30:36,550
минимизировать это d  Таким образом,

698
00:30:36,550 --> 00:30:38,500
базовый уровень действительно представляет собой

699
00:30:38,500 --> 00:30:41,130
ожидаемую сумму вознаграждения.

700
00:30:41,130 --> 00:30:43,270
Обратите внимание, что это в некотором смысле

701
00:30:43,270 --> 00:30:45,400
немного забавно, потому что мы используем

702
00:30:45,400 --> 00:30:48,250
все наши данные, которые мы когда-либо видели, так что это

703
00:30:48,250 --> 00:30:51,460
может быть сделано для всех  данные, которые

704
00:30:51,460 --> 00:30:53,230
вы когда-либо видели, или это можно

705
00:30:53,230 --> 00:30:55,690
сделать только за самый последний раунд, есть

706
00:30:55,690 --> 00:30:56,980
много вариантов того, как сделать

707
00:30:56,980 --> 00:31:01,270
базовый план, хорошо, если вы используете все данные, которые

708
00:31:01,270 --> 00:31:03,880
вы когда-либо видели, тогда что

709
00:31:03,880 --> 00:31:07,960
это будет делать, тогда вы  может быть

710
00:31:07,960 --> 00:31:09,160
усреднено по множеству разных

711
00:31:09,160 --> 00:31:11,350
политик, потому что у вас есть данные из

712
00:31:11,350 --> 00:31:13,270
разных политик, если вы просто сделаете это

713
00:31:13,270 --> 00:31:15,340
по самому последнему раунду, то вы

714
00:31:15,340 --> 00:31:17,280
просто получите оценку, по

715
00:31:17,280 --> 00:31:20,620
сути, бип, ага, бип. Мне нравится, что

716
00:31:20,620 --> 00:31:22,900
эта итерация закончится.

717
00:31:22,900 --> 00:31:25,370
аппроксимируя,

718
00:31:25,370 --> 00:31:29,660
если вы делаете это по их траекториям,

719
00:31:29,660 --> 00:31:31,400
если вы этого не делаете, но вы суммируете это

720
00:31:31,400 --> 00:31:35,360
по траекториям для этого раунда, я думаю,

721
00:31:35,360 --> 00:31:36,740
то, как я это написал,

722
00:31:36,740 --> 00:31:38,270
немного неясно, поэтому позвольте мне посмотреть, смогу ли я

723
00:31:38,270 --> 00:31:39,560
это  немного яснее, так что скажем, что мы

724
00:31:39,560 --> 00:31:45,950
у вас есть траектории D, поэтому мы делаем

725
00:31:45,950 --> 00:31:47,720
это таким образом, тогда это точно равно

726
00:31:47,720 --> 00:31:51,080
V PI I, поэтому I теперь итерация D -

727
00:31:51,080 --> 00:31:53,210
это траектории, которые мы собрали только на

728
00:31:53,210 --> 00:31:55,610
итерации I, так что это только усреднение

729
00:31:55,610 --> 00:31:58,820
по политикам для этого

730
00:31:58,820 --> 00:32:00,710
конкретного  траектории для этой конкретной

731
00:32:00,710 --> 00:32:06,980
политики, я говорю, что это немного странно, есть ли у кого-нибудь

732
00:32:06,980 --> 00:32:08,780
какие-либо вопросы о том, что именно

733
00:32:08,780 --> 00:32:11,030
мы делаем в этом случае, так что обычно в

734
00:32:11,030 --> 00:32:12,770
этой ситуации есть несколько

735
00:32:12,770 --> 00:32:15,740
серий коричневых, это для каждого, поэтому

736
00:32:15,740 --> 00:32:17,710
у нас будет  ряд PI в

737
00:32:17,710 --> 00:32:22,010
основном, а затем для каждой политики у нас

738
00:32:22,010 --> 00:32:23,630
будет набор траекторий, и для

739
00:32:23,630 --> 00:32:25,220
каждой траектории у нас есть набор временных

740
00:32:25,220 --> 00:32:27,710
шагов, и то, что здесь говорится, является

741
00:32:27,710 --> 00:32:29,870
средним по всем траекториям, которые

742
00:32:29,870 --> 00:32:31,970
у вас есть для текущей политики, и соответствует

743
00:32:31,970 --> 00:32:35,720
от базового уровня к этому хорошо, а затем, когда он у

744
00:32:35,720 --> 00:32:37,190
вас есть, это дает вам

745
00:32:37,190 --> 00:32:41,150
базовый уровень, а затем мы обновляем

746
00:32:41,150 --> 00:32:53,840
политику, используя ваш градиент, и это

747
00:32:53,840 --> 00:32:56,150
будет сумма условий, которые включают

748
00:32:56,150 --> 00:32:58,610
эти производные в отношении

749
00:32:58,610 --> 00:33:06,950
политики и лет.  ваша функция преимущества, так

750
00:33:06,950 --> 00:33:08,120
что вы собираетесь использовать эту

751
00:33:08,120 --> 00:33:09,590
функцию преимущества, чтобы вычислить ее здесь,

752
00:33:09,590 --> 00:33:12,710
а затем вы собираетесь умножить ее

753
00:33:12,710 --> 00:33:15,050
на то, какова была вероятность

754
00:33:15,050 --> 00:33:17,540
действий с учетом состояния и тета-

755
00:33:17,540 --> 00:33:22,030
логарифмической производной от этого, а затем мы подключим

756
00:33:22,030 --> 00:33:24,800
что давайте превратим эту оценку

757
00:33:24,800 --> 00:33:27,950
градиента во что-то вроде стохастического

758
00:33:27,950 --> 00:33:35,280
градиентного спуска или Адама во что-то еще,

759
00:33:35,280 --> 00:33:46,020
так что это ванильный политический градиент, и

760
00:33:46,020 --> 00:33:47,400
то, что мы увидим до конца

761
00:33:47,400 --> 00:33:49,410
сегодняшнего дня, — это просто несколько различных

762
00:33:49,410 --> 00:33:51,690
небольших вариантов этого базового шаблона,

763
00:33:51,690 --> 00:33:53,730
поэтому я  я доберусь до вас через секунду, но я

764
00:33:53,730 --> 00:33:55,830
просто хочу подчеркнуть, что если вы, если

765
00:33:55,830 --> 00:33:57,750
вы, когда вы уходите, поняли,

766
00:33:57,750 --> 00:33:58,740
например, из того, что я хотел бы, чтобы вы

767
00:33:58,740 --> 00:34:00,990
поняли из основной идеи для Градиент политики,

768
00:34:00,990 --> 00:34:02,940
по сути, то, что на

769
00:34:02,940 --> 00:34:05,070
доске прямо сейчас  это то, что мы делаем

770
00:34:05,070 --> 00:34:07,950
, мы запускаем, мы берем одну политику, мы

771
00:34:07,950 --> 00:34:10,050
получаем кучу данных из нее, затем мы

772
00:34:10,050 --> 00:34:12,360
должны соответствовать чему-то вроде

773
00:34:12,360 --> 00:34:13,889
преимущества, будут разные способы

774
00:34:13,889 --> 00:34:15,210
вычислений, которые мы могли бы в конечном итоге сделать  запуская

775
00:34:15,210 --> 00:34:16,080
начальную загрузку,

776
00:34:16,080 --> 00:34:18,389
чтобы сделать какую-то телевизионную оценку, или мы можем

777
00:34:18,389 --> 00:34:20,668
просто напрямую использовать доходность, мы часто

778
00:34:20,668 --> 00:34:23,820
используем базовый уровень, который мы подгоняем с течением

779
00:34:23,820 --> 00:34:26,370
времени, а затем мы собираемся обновить

780
00:34:26,370 --> 00:34:29,159
политику и должны выбрать некоторый размер шага

781
00:34:29,159 --> 00:34:31,530
по отношению к градиенту  так что это

782
00:34:31,530 --> 00:34:33,179
своего рода самая важная вещь, которую я должен

783
00:34:33,179 --> 00:34:34,770
сказать, эй, есть этот базовый шаблон

784
00:34:34,770 --> 00:34:36,540
почти для всех алгоритмов градиента политики, я

785
00:34:36,540 --> 00:34:38,280
могу выбрать разные вещи, чтобы

786
00:34:38,280 --> 00:34:40,379
подключить сюда, и я могу выбрать разные

787
00:34:40,379 --> 00:34:43,050
способы, чтобы принять мои размеры шага, и это

788
00:34:43,050 --> 00:34:44,790
будет определять  целую кучу

789
00:34:44,790 --> 00:34:46,199
различных алгоритмов градиента политики,

790
00:34:46,199 --> 00:34:50,310
которые, как вы видите, мы должны использовать для

791
00:34:50,310 --> 00:34:52,500
представления предубеждений, которые, по нашему мнению, они

792
00:34:52,500 --> 00:34:56,070
создают, поэтому я спрашиваю вас, как

793
00:34:56,070 --> 00:34:58,350
мы представляем политику, чтобы мы могли принять

794
00:34:58,350 --> 00:34:59,610
ее градиент, который мы должны быть в состоянии принять

795
00:34:59,610 --> 00:35:02,700
это здесь, мы кратко говорили об этом в

796
00:35:02,700 --> 00:35:04,320
прошлый раз, но это также было на

797
00:35:04,320 --> 00:35:06,810
доске ближе к концу. Работа по Гауссу softmax

798
00:35:06,810 --> 00:35:08,910
есть и то, и другое, вы можете

799
00:35:08,910 --> 00:35:10,320
аналитически взять производную, и

800
00:35:10,320 --> 00:35:12,780
часто мы используем глубокую нейронную сеть.  работает или

801
00:35:12,780 --> 00:35:15,540
неглубокие глубокие нейронные сети да, я видел

802
00:35:15,540 --> 00:35:17,460
вопрос там, и сначала,

803
00:35:17,460 --> 00:35:19,130
пожалуйста,

804
00:35:19,130 --> 00:35:21,859
я был одет, если есть какие-либо проблемы с

805
00:35:21,859 --> 00:35:24,500
ними, такими как нестационарность,

806
00:35:24,500 --> 00:35:26,269
как базовая линия с нейромедиком, с этим есть

807
00:35:26,269 --> 00:35:31,160
проблемы с нестационарностью, поэтому

808
00:35:31,160 --> 00:35:34,910
я считаю, что нужно  скажем, вы спросили меня о

809
00:35:34,910 --> 00:35:37,099
базовой линии, так что, например, как мы сталкиваемся

810
00:35:37,099 --> 00:35:38,210
с нестационарными проблемами с этим

811
00:35:38,210 --> 00:35:39,920
эмпирически, что многие люди,

812
00:35:39,920 --> 00:35:44,690
включая меня, интересно, у нас

813
00:35:44,690 --> 00:35:46,369
есть все эти другие данные, поэтому, когда мы

814
00:35:46,369 --> 00:35:47,720
оцениваем градиент прямо сейчас,

815
00:35:47,720 --> 00:35:49,490
обычно  мы применяем политику, просто

816
00:35:49,490 --> 00:35:51,680
вы знаете четыре траектории D, а затем

817
00:35:51,680 --> 00:35:52,849
мы оцениваем градиент с этим,

818
00:35:52,849 --> 00:35:56,180
и могли бы мы, возможно, использовать другие данные для этого

819
00:35:56,180 --> 00:35:57,650
, но тогда это выходит за рамки

820
00:35:57,650 --> 00:35:58,880
политики, потому что тогда вы

821
00:35:58,880 --> 00:36:00,230
смешиваете данные, которые вы '  Я собрал четыре

822
00:36:00,230 --> 00:36:02,359
разных политики эмпирическим путем. Я думаю, что

823
00:36:02,359 --> 00:36:04,640
люди часто в конечном итоге используют только данные

824
00:36:04,640 --> 00:36:06,890
из текущего прогона, а затем вы, по

825
00:36:06,890 --> 00:36:09,619
сути, просто оцениваете V PI I с помощью

826
00:36:09,619 --> 00:36:11,150
этого, и вы не обязательно смешиваете

827
00:36:11,150 --> 00:36:14,450
данные для многих  другие политики Paraclete

828
00:36:14,450 --> 00:36:16,069
кажется, что часто бывает очень

829
00:36:16,069 --> 00:36:20,539
полезно быть в политике, и вы можете повторно ввести

830
00:36:20,539 --> 00:36:23,900
ее дисперсию, так что эмпирически часто

831
00:36:23,900 --> 00:36:25,670
лучше всего, я думаю, что жюри все еще не определилось,

832
00:36:25,670 --> 00:36:27,289
есть продолжающиеся исследования по этому вопросу, мы

833
00:36:27,289 --> 00:36:29,299
рассмотрели его Группа Сергея

834
00:36:29,299 --> 00:36:32,150
Ливьяна рассмотрела  это, но в большинстве случаев

835
00:36:32,150 --> 00:36:33,920
использование данных о политике имеет смысл, да, это

836
00:36:33,920 --> 00:36:35,630
другой вопрос, и главный пресс, пожалуйста, я

837
00:36:35,630 --> 00:36:38,059
просто хочу подтвердить, поэтому, когда вы говорите, что мы подходим к

838
00:36:38,059 --> 00:36:39,710
базовой линии, мы устанавливаем базовую линию,

839
00:36:39,710 --> 00:36:42,140
равную значению, которое минимизирует

840
00:36:42,140 --> 00:36:47,359
функцию Европа, если мы сделаем это  если мы

841
00:36:47,359 --> 00:36:49,130
только усредняем точки данных, которые

842
00:36:49,130 --> 00:36:50,599
у нас есть для этой текущей политики, когда мы

843
00:36:50,599 --> 00:36:53,029
делаем это, это, по

844
00:36:53,029 --> 00:36:54,289
сути, то же самое, что и когда мы

845
00:36:54,289 --> 00:36:56,750
проводили оценку политики Монте-Карло, так

846
00:36:56,750 --> 00:36:59,089
что это почти точно так же, как оценка политики Монте-Карло,

847
00:36:59,089 --> 00:37:02,450
где у нас есть  фиксированная политика,

848
00:37:02,450 --> 00:37:04,279
а затем у нас есть параметризованная

849
00:37:04,279 --> 00:37:07,190
функция для ее представления, а затем мы

850
00:37:07,190 --> 00:37:08,539
просто хотим подогнать эти параметры, чтобы мы

851
00:37:08,539 --> 00:37:12,160
могли лучше всего оценить политику,

852
00:37:16,820 --> 00:37:19,220
хорошо, так что я собираюсь немного б

853
00:37:19,220 --> 00:37:20,810
Это информация об аутодафе, вы можете

854
00:37:20,810 --> 00:37:23,000
проверить это на слайдах, и то, что

855
00:37:23,000 --> 00:37:27,020
мы собираемся пройти дальше, - это подумать

856
00:37:27,020 --> 00:37:29,720
об этом аспекте, как я уже говорил, а

857
00:37:29,720 --> 00:37:34,040
затем мы немного поговорим об этом, так что эта

858
00:37:34,040 --> 00:37:37,090
часть будет  быть там, где мы думаем о

859
00:37:37,090 --> 00:37:40,490
монотонном улучшении, потому что, когда у

860
00:37:40,490 --> 00:37:41,660
нас есть градиент, мы должны выяснить,

861
00:37:41,660 --> 00:37:44,290
как далеко мы продвинемся, и можем ли мы гарантировать, в

862
00:37:44,290 --> 00:37:46,280
зависимости от того, как далеко мы продвинемся, получим

863
00:37:46,280 --> 00:37:47,420
ли мы монотонное

864
00:37:47,420 --> 00:37:50,480
улучшение, и эта часть о

865
00:37:50,480 --> 00:37:51,950
в идеале дать лучшую оценку нашего

866
00:37:51,950 --> 00:37:54,740
градиента с меньшим количеством данных и

867
00:37:54,740 --> 00:37:57,200
уменьшить его дисперсию, поэтому они

868
00:37:57,200 --> 00:37:58,430
оба важны, они делают немного

869
00:37:58,430 --> 00:38:02,450
разные вещи, хорошо, так что давайте поговорим

870
00:38:02,450 --> 00:38:07,760
об этом, пожалуйста,

871
00:38:07,760 --> 00:38:14,210
спасибо, хорошо

872
00:38:14,210 --> 00:38:16,430
, как будто мы начали говорить об этом

873
00:38:16,430 --> 00:38:20,330
раньше  хорошо, давайте сначала поговорим

874
00:38:20,330 --> 00:38:22,070
о базовой линии, так как мы должны выбрать

875
00:38:22,070 --> 00:38:29,810
базовую линию. Одна вещь, которую мы можем сделать

876
00:38:29,810 --> 00:38:32,150
для базовой линии, - это просто понравиться тому,

877
00:38:32,150 --> 00:38:33,500
что мы видим там, что является

878
00:38:33,500 --> 00:38:36,110
эмпирической оценкой V PI, чтобы мы могли

879
00:38:36,110 --> 00:38:38,060
сказать в целом  мы хотим просто использовать

880
00:38:38,060 --> 00:38:42,770
V PI I в качестве базового уровня, что означает, что мы должны

881
00:38:42,770 --> 00:38:44,300
каким-то образом вычислить его, и способ, которым мы

882
00:38:44,300 --> 00:38:47,360
оцениваем, может быть получен из Монте-Карло

883
00:38:47,360 --> 00:38:53,210
или может быть из методов TD, поэтому то, что

884
00:38:53,210 --> 00:38:57,620
мы видели до сих пор, использует их как

885
00:38:57,620 --> 00:38:59,720
так что, я думаю, просто для ясности здесь

886
00:38:59,720 --> 00:39:01,040
есть пара разных мест, где мы, возможно,

887
00:39:01,040 --> 00:39:03,020
сможем переключаться между выполнением возвратов Монте-

888
00:39:03,020 --> 00:39:04,940
Карло и выполнением чего-то TD,

889
00:39:04,940 --> 00:39:08,480
например, одно здесь, а другое - наша

890
00:39:08,480 --> 00:39:11,690
базовая линия, хорошо, поэтому у нас есть базовая

891
00:39:11,690 --> 00:39:12,950
функция здесь  что мы как бы

892
00:39:12,950 --> 00:39:15,170
вычитаем, и у нас также есть простое число GT,

893
00:39:15,170 --> 00:39:20,690
и поэтому, если мы снова подумаем о нашем

894
00:39:20,690 --> 00:39:22,430
общем уравнении, то

895
00:39:22,430 --> 00:39:25,130
в этом случае у нас есть Delta Theta ya

896
00:39:25,130 --> 00:39:26,990
theta, это наше разрешение, это

897
00:39:26,990 --> 00:39:29,540
определяет параметры нашей политики  и

898
00:39:29,540 --> 00:39:30,530
мы сказали, что это

899
00:39:30,530 --> 00:39:34,220
I равно 1 по сумме m по I равно от 1

900
00:39:34,220 --> 00:39:38,690
до M некоторого вознаграждения, ну, я положу это

901
00:39:38,690 --> 00:39:43,460
внутрь суммы по T равно от 0 до t минус 1

902
00:39:43,460 --> 00:39:48,350
Я передумал,

903
00:39:48,350 --> 00:39:49,190
хорошо, я  мы поместим это здесь,

904
00:39:49,190 --> 00:39:50,450
потому что в конечном итоге

905
00:39:50,450 --> 00:39:51,950
это будет функция, которую мы можем использовать  e по-

906
00:39:51,950 --> 00:40:07,370
разному, так что это наше основное

907
00:40:07,370 --> 00:40:08,930
уравнение, с которым мы работали, мы

908
00:40:08,930 --> 00:40:10,640
сказали, что производная значения по

909
00:40:10,640 --> 00:40:12,520
отношению к параметрам нашей политики

910
00:40:12,520 --> 00:40:16,280
примерно равна сумме по m траекториям, которые

911
00:40:16,280 --> 00:40:18,200
мы выбрали для этих траекторий из

912
00:40:18,200 --> 00:40:21,020
времен этой политики.  общее вознаграждение, которое мы

913
00:40:21,020 --> 00:40:23,420
получили на этой траектории, умноженное на сумму

914
00:40:23,420 --> 00:40:26,030
по всем временным шагам

915
00:40:26,030 --> 00:40:29,390
производной политики относительно данного

916
00:40:29,390 --> 00:40:31,040
действия, которое мы предприняли в состоянии, в котором мы были в

917
00:40:31,040 --> 00:40:33,100
порядке, и мы сказали, что это было очень шумно,

918
00:40:33,100 --> 00:40:36,640
но я предвзят  и теперь мы можем подумать об

919
00:40:36,640 --> 00:40:41,420
изменении этого в качестве цели, так что здесь

920
00:40:41,420 --> 00:40:43,430
была беспристрастная оценка

921
00:40:43,430 --> 00:40:45,140
стоимости политики, и теперь мы можем подумать о

922
00:40:45,140 --> 00:40:47,690
замене другими вещами, все в порядке,

923
00:40:47,690 --> 00:40:51,020
чтобы мы могли представить, что здесь можно делать все виды

924
00:40:51,020 --> 00:40:53,780
вещей, которые мы могли бы мы могли бы  знаете ли

925
00:40:53,780 --> 00:41:01,340
вы методы TD или MC, если мы делаем это с

926
00:41:01,340 --> 00:41:03,140
функцией значения или если мы пытаемся

927
00:41:03,140 --> 00:41:05,360
явно вычислить функцию значения или

928
00:41:05,360 --> 00:41:08,300
или функцию значения действия состояния, тогда мы

929
00:41:08,300 --> 00:41:12,730
обычно называем это критиком, поэтому критик

930
00:41:13,000 --> 00:41:21,020
вычисляет B или Q, поэтому, когда мы говорим  аб  вне

931
00:41:21,020 --> 00:41:23,060
методов критики актера, когда у нас

932
00:41:23,060 --> 00:41:25,250
есть явное представление

933
00:41:25,250 --> 00:41:26,570
параметров политики, и у нас есть явное

934
00:41:26,570 --> 00:41:29,090
общее параметризованное

935
00:41:29,090 --> 00:41:31,790
представление значения или значения действия состояния, и

936
00:41:31,790 --> 00:41:34,010
если у нас это есть, то мы можем представить, как

937
00:41:34,010 --> 00:41:38,110
использовать это, чтобы изменить то, что наша цель

938
00:41:40,040 --> 00:41:42,650
я хочу  чтобы подчеркнуть, что наши методы критики

939
00:41:42,650 --> 00:41:46,100
объединяют эти две комбинированные политики плюс

940
00:41:46,100 --> 00:41:48,140
критику, и, вероятно, самый

941
00:41:48,140 --> 00:41:51,980
популярный из них - это три C, которые созданы мужчинами,

942
00:41:51,980 --> 00:41:58,930
и все это представлено в 2016 году.

943
00:41:58,930 --> 00:42:01,460
ICML был чрезвычайно популярен, это

944
00:42:01,460 --> 00:42:03,530
версия для глубоких нейронных сетей, но

945
00:42:03,530 --> 00:42:05,210
актер  Критические идеи сами

946
00:42:05,210 --> 00:42:07,610
по себе существуют намного дольше, чем это, но

947
00:42:07,610 --> 00:42:08,870
тройка C является одной из самых популярных

948
00:42:08,870 --> 00:42:11,740
версий этого 4d параллакса,

949
00:42:11,740 --> 00:42:15,290
хорошо, так как же нам сделать своего рода

950
00:42:15,290 --> 00:42:17,500
формулы градиента политики с функциями ценности,

951
00:42:17,500 --> 00:42:22,160
что вы могли бы сделать вместо этого здесь я

952
00:42:22,160 --> 00:42:25,640
поставлю  на этом сайте

953
00:42:25,640 --> 00:42:27,140
вы могли бы получить почти то же уравнение

954
00:42:27,140 --> 00:42:28,220
, что и раньше,

955
00:42:28,220 --> 00:42:30,910
поэтому управляемое уважение к функции ценности

956
00:42:30,910 --> 00:42:35,120
равно ожиданию с

957
00:42:35,120 --> 00:42:37,310
относительно траекторий, с которыми вы можете

958
00:42:37,310 --> 00:42:39,200
столкнуться, сумма по всем временным

959
00:42:39,200 --> 00:42:49,070
шагам на этой траектории, умноженная на

960
00:42:49,070 --> 00:42:50,750
производную по параметрам вашей политики,

961
00:42:50,750 --> 00:43:01,460
умноженная на Q от s T W минус B от s

962
00:43:01,460 --> 00:43:06,470
T, так что вместо того, чтобы иметь здесь свои оценки Монте-Карло,

963
00:43:06,470 --> 00:43:08,120
вы могли бы вставить  в вашей

964
00:43:08,120 --> 00:43:13,970
оценке функции Q и еще один

965
00:43:13,970 --> 00:43:17,210
способ представить это, если мы

966
00:43:17,210 --> 00:43:20,960
думаем, что это оценка стоимости, и

967
00:43:20,960 --> 00:43:23,090
это, по сути, наша функция преимущества

968
00:43:23,090 --> 00:43:26,000
снова, что это может быть R, поэтому у нас была

969
00:43:26,000 --> 00:43:29,030
функция преимущества здесь, вы определяете

970
00:43:29,030 --> 00:43:30,620
функцию преимущества  здесь, но это

971
00:43:30,620 --> 00:43:32,270
была функция результатов Монте-

972
00:43:32,270 --> 00:43:35,000
Карло для этого эпизода, это

973
00:43:35,000 --> 00:43:37,610
другая функция преимущества, которая

974
00:43:37,610 --> 00:43:40,460
является функцией Q, которую

975
00:43:40,460 --> 00:43:42,770
критик может поддерживать, - ваш базовый уровень,

976
00:43:42,770 --> 00:43:45,940
который является оценкой функции ценности,

977
00:43:45,940 --> 00:43:48,320
поэтому они выглядят очень похожими  но вы можете

978
00:43:48,320 --> 00:43:50,390
указать здесь разные варианты, и

979
00:43:50,390 --> 00:43:51,350
они будут иметь разные компромиссы,

980
00:43:51,350 --> 00:43:53,390
поэтому оценка доходности Монте-Карло

981
00:43:53,390 --> 00:43:54,980
является беспристрастной

982
00:43:54,980 --> 00:43:56,510
оценкой стоимости.  текущей

983
00:43:56,510 --> 00:43:57,110
политики,

984
00:43:57,110 --> 00:44:01,180
это будет предвзятым в целом, но с

985
00:44:01,180 --> 00:44:06,020
более низкой дисперсией,

986
00:44:06,020 --> 00:44:08,390
поэтому я также хочу подчеркнуть здесь, что,

987
00:44:08,390 --> 00:44:12,170
когда мы думаем о том, как получить эту

988
00:44:12,170 --> 00:44:16,490
оценку, о которой мы часто говорим, что

989
00:44:16,490 --> 00:44:17,750
критик собирается вычислить эту

990
00:44:17,750 --> 00:44:20,470
оценку, у него нет  быть только

991
00:44:20,470 --> 00:44:23,780
либо оценкой TD, либо оценкой Монте-

992
00:44:23,780 --> 00:44:25,400
Карло, но вы можете интерполировать

993
00:44:25,400 --> 00:44:27,950
между ними, часто называемой возвратом n шагов,

994
00:44:27,950 --> 00:44:32,360
так что это значит, так что давайте

995
00:44:32,360 --> 00:44:34,810
назовем это, давайте напишем это немного

996
00:44:34,810 --> 00:44:37,010
хорошо, я назову это здесь, так что давайте  но

997
00:44:37,010 --> 00:44:39,950
это шляпа, хорошо, просто чтобы отметить, что вы

998
00:44:39,950 --> 00:44:40,910
можете думать об этом, это просто

999
00:44:40,910 --> 00:44:43,040
функция, это будет оценка

1000
00:44:43,040 --> 00:44:46,460
вашей функции значения действия состояния, и поэтому

1001
00:44:46,460 --> 00:44:48,680
у нас может быть

1002
00:44:48,680 --> 00:44:55,910
оценка оценки значения из

1003
00:44:55,910 --> 00:44:58,760
временной шаг T вперед, который

1004
00:44:58,760 --> 00:45:01,130
равен фактическому, это фактический, который мы получили

1005
00:45:01,130 --> 00:45:03,430
на временном шаге I, поэтому я назову это

1006
00:45:03,430 --> 00:45:07,040
я назову этот вид я пришел 1,

1007
00:45:07,040 --> 00:45:09,320
и это будет тогда реальной

1008
00:45:09,320 --> 00:45:11,870
наградой вам  попал на временной шаг T в эпизоде

1009
00:45:11,870 --> 00:45:20,030
Я плюс гамма V из s T плюс 1, так что это

1010
00:45:20,030 --> 00:45:21,920
должно выглядеть почти точно так же, как оценки в стиле td0, о

1011
00:45:21,920 --> 00:45:25,250
которых мы говорили

1012
00:45:25,250 --> 00:45:28,250
ранее, так что это говорит о том, что я получил, я смотрю на

1013
00:45:28,250 --> 00:45:30,440
фактический немедленный 1 шаг вперед, который я получил,

1014
00:45:30,440 --> 00:45:33,620
а затем я загружаю я добавляю значение,

1015
00:45:33,620 --> 00:45:35,990
так что  это было бы так: я бы получил эту

1016
00:45:35,990 --> 00:45:38,240
функцию ценности для моего критика, и я бы подключил

1017
00:45:38,240 --> 00:45:39,890
ее, и тогда это было бы моей целью,

1018
00:45:39,890 --> 00:45:44,350
но затем я бы использовал в этом уравнении хорошо,

1019
00:45:44,350 --> 00:45:46,610
так что это будет одна вещь, которую вы

1020
00:45:46,610 --> 00:45:49,070
можете сделать, поэтому мы  видели это, и мы

1021
00:45:49,070 --> 00:45:51,770
видели многое из того, что я назову

1022
00:45:51,770 --> 00:45:56,060
версией бесконечности или версии Монте-Карло, и

1023
00:45:56,060 --> 00:46:00,230
это - вы суммируете все T Prime

1024
00:46:00,230 --> 00:46:02,780
вплоть до конца эпизода гаммы

1025
00:46:02,780 --> 00:46:06,770
до T Prime минус T

1026
00:46:06,770 --> 00:46:11,360
времена лучшие, так что это возвращение Монте-

1027
00:46:11,360 --> 00:46:12,950
Карло, где мы просто суммируем, мы

1028
00:46:12,950 --> 00:46:14,450
не делаем никакой начальной загрузки, и мы суммируем

1029
00:46:14,450 --> 00:46:16,369
все дороги и эпизоды, но, как

1030
00:46:16,369 --> 00:46:17,840
вы можете видеть здесь, должно быть вы

1031
00:46:17,840 --> 00:46:18,650
знаете, что, вероятно, есть какой-то способ

1032
00:46:18,650 --> 00:46:21,380
интерполировать между  эти два и

1033
00:46:21,380 --> 00:46:25,040
они часто известны как n возвратов шага, и поэтому,

1034
00:46:25,040 --> 00:46:27,350
например, вы могли бы d  о, вы могли бы

1035
00:46:27,350 --> 00:46:29,390
сказать, что я добавлю вознаграждение на временном

1036
00:46:29,390 --> 00:46:32,150
шаге I, и вознаграждение, которое я получил на временном шаге

1037
00:46:32,150 --> 00:46:38,920
2 T плюс 1, а затем я собираюсь выполнить начальную загрузку,

1038
00:46:43,119 --> 00:46:45,230
так что это была просто одна из

1039
00:46:45,230 --> 00:46:47,119
оценок, которые находятся между ними.  эти две

1040
00:46:47,119 --> 00:46:50,090
крайности: одна - вы делаете только один

1041
00:46:50,090 --> 00:46:51,770
шаг вознаграждения, другая - вы

1042
00:46:51,770 --> 00:46:53,030
суммируете все награды, а затем есть

1043
00:46:53,030 --> 00:46:54,530
целая куча интерполяций, которые вы можете

1044
00:46:54,530 --> 00:46:56,540
сделать между теми, почему вы хотите

1045
00:46:56,540 --> 00:46:58,640
сделать это хорошо, это обычно

1046
00:46:58,640 --> 00:47:01,190
будет  быть несколько предвзятым, низкая дисперсия,

1047
00:47:01,190 --> 00:47:03,110
это будет беспристрастно, но действительно

1048
00:47:03,110 --> 00:47:05,030
высокая дисперсия, нет причин

1049
00:47:05,030 --> 00:47:06,710
предполагать, что лучшее решение находится в

1050
00:47:06,710 --> 00:47:08,330
любой из этих двух крайностей, и поэтому вы

1051
00:47:08,330 --> 00:47:11,840
можете интерполировать между телевизионной оценкой

1052
00:47:11,840 --> 00:47:16,490
и оценкой Монте-Карло и всеми

1053
00:47:16,490 --> 00:47:19,040
этими  просто форма возвращает, что тогда вы

1054
00:47:19,040 --> 00:47:22,510
могли бы вычесть из базовой линии на два,

1055
00:47:22,510 --> 00:47:24,619
и все это, вероятно, будет

1056
00:47:24,619 --> 00:47:25,970
считаться гиперпараметром, который мы

1057
00:47:25,970 --> 00:47:27,650
могли бы выбрать через проверку, перекрестная

1058
00:47:27,650 --> 00:47:29,690
проверка заключается в том, что то, что люди делают

1059
00:47:29,690 --> 00:47:31,520
здесь, это слишком вычисление  ally

1060
00:47:31,520 --> 00:47:32,840
интенсивный, поэтому вам просто нужно выбрать

1061
00:47:32,840 --> 00:47:36,890
что-то машинное обучение, это будет

1062
00:47:36,890 --> 00:47:38,119
просто рассматриваться как своего рода гиперпараметр, который

1063
00:47:38,119 --> 00:47:39,500
вы знаете, вы можете превратить это

1064
00:47:39,500 --> 00:47:41,060
в N, и вы решите, например,

1065
00:47:41,060 --> 00:47:43,820
сколько шагов вы делаете, ну, люди делают,

1066
00:47:43,820 --> 00:47:45,080
и вопрос был в том, делать  вы делаете, люди делают

1067
00:47:45,080 --> 00:47:46,250
это, и обучение с подкреплением

1068
00:47:46,250 --> 00:47:48,590
считается слишком дорогим, вы, конечно,

1069
00:47:48,590 --> 00:47:50,720
могли бы, я думаю, это интересный

1070
00:47:50,720 --> 00:47:53,270
вопрос, я чувствую, что трюки, которые

1071
00:47:53,270 --> 00:47:55,580
люди делают в этом случае, я думаю, что я,

1072
00:47:55,580 --> 00:47:58,430
вероятно, вижу больше этого, но это больше варьируется,

1073
00:47:58,430 --> 00:48:00,410
когда tv0 делает  много

1074
00:48:00,410 --> 00:48:01,070
начальной загрузки,

1075
00:48:01,070 --> 00:48:02,240
но это, вероятно, зависит от вашего

1076
00:48:02,240 --> 00:48:04,250
домена приложения. Еще одна вещь, от которой

1077
00:48:04,250 --> 00:48:06,560
он, вероятно, будет зависеть, - это действительно ли ваши

1078
00:48:06,560 --> 00:48:09,410
домены отмечены или нет, так что в этом

1079
00:48:09,410 --> 00:48:11,000
случае это все еще работает, это

1080
00:48:11,000 --> 00:48:12,380
дает вам реальную оценку

1081
00:48:12,380 --> 00:48:13,820
возврата вашей политики даже  если вы

1082
00:48:13,820 --> 00:48:15,590
делаете отметку в этом случае, вы делаете

1083
00:48:15,590 --> 00:48:20,080
гораздо более сильное марковское предположение, поэтому

1084
00:48:20,080 --> 00:48:21,070
вы также можете делать

1085
00:48:21,070 --> 00:48:22,000
разные вещи в зависимости от вашей

1086
00:48:22,000 --> 00:48:24,220
области, а также от того, как e

1087
00:48:24,220 --> 00:48:29,110
собирать данные дорого, так что это дает нам

1088
00:48:29,110 --> 00:48:31,420
своего рода другой способ подключить что-

1089
00:48:31,420 --> 00:48:34,210
то к этому ванильному алгоритму градиента политики

1090
00:48:34,210 --> 00:48:35,860
, который я поместил туда, чтобы вы могли

1091
00:48:35,860 --> 00:48:38,310
подключать такого рода цели, а не

1092
00:48:38,310 --> 00:48:42,010
там, чтобы найти компромисс между предвзятостью и

1093
00:48:42,010 --> 00:48:44,410
дисперсией, когда  вы делаете эту

1094
00:48:44,410 --> 00:48:46,360
оценку градиента, так что

1095
00:48:46,360 --> 00:48:47,740
здесь это меняет наши

1096
00:48:47,740 --> 00:48:49,030
цели и то, как мы

1097
00:48:49,030 --> 00:48:52,750
вычисляем наш градиент, но затем следующее, о

1098
00:48:52,750 --> 00:48:54,910
чем я хочу поговорить, это та часть,

1099
00:48:54,910 --> 00:48:58,060
которая когда-то мы  мы на самом деле получили наш

1100
00:48:58,060 --> 00:49:00,130
градиент, однако мы решили его получить,

1101
00:49:00,130 --> 00:49:02,800
мы должны выяснить, как далеко

1102
00:49:02,800 --> 00:49:07,780
пройти по этому градиенту, так почему

1103
00:49:07,780 --> 00:49:12,670
это может быть важно, может быть

1104
00:49:12,670 --> 00:49:16,930
важно, потому что это просто локальное

1105
00:49:16,930 --> 00:49:18,640
приближение, которое вы даете локальному

1106
00:49:18,640 --> 00:49:29,080
оценка градиента, да, это

1107
00:49:29,080 --> 00:49:31,360
отличный вопрос, опять же зависит, так что

1108
00:49:31,360 --> 00:49:32,500
вы можете либо делать это часто

1109
00:49:32,500 --> 00:49:34,480
асинхронно, чтобы у вас были разные

1110
00:49:34,480 --> 00:49:36,160
потоки и разные сети для вашего

1111
00:49:36,160 --> 00:49:39,490
критика и для вашей политики и принципа

1112
00:49:39,490 --> 00:49:40,570
y  Вы могли бы просто обновлять свой критик

1113
00:49:40,570 --> 00:49:41,860
все время, как будто вы знаете, что можете

1114
00:49:41,860 --> 00:49:43,360
использовать dqn для этого и делать много-

1115
00:49:43,360 --> 00:49:47,020
много резервных копий. В общем, это зависит,

1116
00:49:47,020 --> 00:49:50,050
я думаю, вам нужно иметь расписание, да,

1117
00:49:50,050 --> 00:49:51,970
так часто вы можете делать что-то вроде 10

1118
00:49:51,970 --> 00:49:55,140
100  это действительно зависит от приложения,

1119
00:49:55,140 --> 00:49:57,850
но нет причин, по которым критику

1120
00:49:57,850 --> 00:49:59,260
нужно обновлять только по тому же

1121
00:49:59,260 --> 00:50:00,370
расписанию, по которому вы обновляете

1122
00:50:00,370 --> 00:50:02,500
политику, и выполнение асинхронного выполнения часто

1123
00:50:02,500 --> 00:50:07,120
имеет большой смысл, так что если мы

1124
00:50:07,120 --> 00:50:08,680
подумаем о том, что здесь происходит  вот

1125
00:50:08,680 --> 00:50:10,420
наша параметризованная политика, вот наше значение,

1126
00:50:10,420 --> 00:50:13,810
у нас есть какая-то сумасшедшая функция, а затем

1127
00:50:13,810 --> 00:50:18,730
мы вычисляем наш градиент, и этот

1128
00:50:18,730 --> 00:50:24,589
градиент локально довольно хорош,

1129
00:50:24,589 --> 00:50:27,420
так что здесь все выглядит линейно,

1130
00:50:27,420 --> 00:50:29,099
и все выглядит довольно хорошо, но,

1131
00:50:29,099 --> 00:50:30,900
конечно, по мере того, как мы продвигаемся дальше, как здесь

1132
00:50:30,900 --> 00:50:34,170
это будет плохо, например, если мы

1133
00:50:34,170 --> 00:50:35,670
попытаемся следовать градиенту слишком далеко, мы

1134
00:50:35,670 --> 00:50:36,930
получим оценку, которая сильно

1135
00:50:36,930 --> 00:50:40,819
отличается от функции реального значения,

1136
00:50:41,749 --> 00:50:44,279
поэтому, когда мы берем размеры шага в этом

1137
00:50:44,279 --> 00:50:45,660
случае это  в конечном итоге важно

1138
00:50:45,660 --> 00:50:47,279
учитывать такой факт, как то, насколько

1139
00:50:47,279 --> 00:50:49,220
далеко вы хотите, чтобы ваши размеры шага

1140
00:50:49,220 --> 00:51:02,160
позвольте мне просто вернуть это к нормальному, поэтому мы

1141
00:51:02,160 --> 00:51:03,900
хотим выяснить, как далеко мы должны зайти

1142
00:51:03,900 --> 00:51:07,339
в градиенте, и это важно сейчас,

1143
00:51:07,339 --> 00:51:10,200
вы можете  скажите хорошо, это всегда верно, так

1144
00:51:10,200 --> 00:51:12,119
как вам всегда нужно быть осторожным,

1145
00:51:12,119 --> 00:51:13,619
когда вы делаете градиентный спуск или

1146
00:51:13,619 --> 00:51:15,450
essent в любой задаче обучения с учителем,

1147
00:51:15,450 --> 00:51:16,950
когда используете стохастический

1148
00:51:16,950 --> 00:51:18,869
градиентный спуск, конечно, вы не

1149
00:51:18,869 --> 00:51:20,160
хотите заходить слишком далеко по размеру вашего шага,

1150
00:51:20,160 --> 00:51:23,039
потому что вы  может выйти за рамки, и вы

1151
00:51:23,039 --> 00:51:24,630
используете это линейное приближение, это

1152
00:51:24,630 --> 00:51:28,019
плохо, почему никто не

1153
00:51:28,019 --> 00:51:29,819
понимает, почему это может быть еще хуже

1154
00:51:29,819 --> 00:51:31,920
в случае обучения с подкреплением, мне

1155
00:51:31,920 --> 00:51:34,140
может быть еще важнее подумать

1156
00:51:34,140 --> 00:51:36,660
о размере шага, который он должен сделать  с тем,

1157
00:51:36,660 --> 00:51:46,289
откуда берутся данные, да,

1158
00:51:46,289 --> 00:51:54,269
это чашки DVD, и ваши

1159
00:51:54,269 --> 00:51:55,710
данные могут быть сгенерированы распределением iid,

1160
00:51:55,710 --> 00:51:57,779
не имеет значения, какой

1161
00:51:57,779 --> 00:51:59,489
выбор вы только что сделали для своего

1162
00:51:59,489 --> 00:52:01,650
стохастического градиента, отправленного в RL, который

1163
00:52:01,650 --> 00:52:03,450
определение следующей политики, которую мы используем

1164
00:52:03,450 --> 00:52:06,440
внутри нашей итерации для сбора данных,

1165
00:52:06,440 --> 00:52:08,670
чтобы вы не знали, если мы выберем

1166
00:52:08,670 --> 00:52:11,130
действительно плохую политику, если мы получим действительно очень плохую

1167
00:52:11,130 --> 00:52:13,200
политику, мы просто можем не получить данных

1168
00:52:13,200 --> 00:52:14,910
относительно фактического оптимума этой

1169
00:52:14,910 --> 00:52:17,249
функции  так что еще более важно как

1170
00:52:17,249 --> 00:52:20,130
бы тщательно подумать о том, куда

1171
00:52:20,130 --> 00:52:21,779
мы идем, и в идеале

1172
00:52:21,779 --> 00:52:23,999
надеяться получить монотонное улучшение, так

1173
00:52:23,999 --> 00:52:26,549
что это действительно очень

1174
00:52:26,549 --> 00:52:28,019
важно в случае обучения с подкреплением

1175
00:52:28,019 --> 00:52:29,579
думать о том, как мы делаем этот

1176
00:52:29,579 --> 00:52:33,749
размер шага  потому что это определяет

1177
00:52:33,749 --> 00:52:36,529
данные, которые мы собираем

1178
00:52:36,610 --> 00:52:46,180
pi, и, следовательно, данные в одной версии

1179
00:52:46,180 --> 00:52:47,890
одного из моих коллег говорят о

1180
00:52:47,890 --> 00:52:49,900
похожей проблеме.

1181
00:52:49,900 --> 00:52:51,460


1182
00:52:51,460 --> 00:52:52,870


1183
00:52:52,870 --> 00:52:54,820
ваша политика

1184
00:52:54,820 --> 00:52:56,530
просто действительно очень плохая вы делаете это

1185
00:52:56,530 --> 00:52:58,480
бесполезными данными, тогда вы не можете получить

1186
00:52:58,480 --> 00:53:00,460
хорошую оценку градиента, а

1187
00:53:00,460 --> 00:53:01,840
затем вы просто застряли, вы можете попасть

1188
00:53:01,840 --> 00:53:04,780
в действительно очень плохую Оптиму, хорошо, поэтому мы бы

1189
00:53:04,780 --> 00:53:06,780
хотелось бы тщательно обдумать эту часть,

1190
00:53:06,780 --> 00:53:10,270
так что одна вещь, которую мы могли бы сделать, это сделать

1191
00:53:10,270 --> 00:53:12,610
что-то вроде поиска по строке, поэтому мы

1192
00:53:12,610 --> 00:53:13,960
сейчас говорим о том, как

1193
00:53:13,960 --> 00:53:15,360
мы это делаем

1194
00:53:15,360 --> 00:53:27,280
, как делать размеры шагов, поэтому одна вещь, которую мы

1195
00:53:27,280 --> 00:53:28,780
могли бы сделать, это попытаться сделать  какой-то

1196
00:53:28,780 --> 00:53:40,170
поиск линии вдоль градиента, и это

1197
00:53:40,170 --> 00:53:43,030
нормально, но это немного дорого, поэтому

1198
00:53:43,030 --> 00:53:52,330
это просто, но это дорого, и он

1199
00:53:52,330 --> 00:53:56,050
имеет тенденцию игнорировать то, где линейное

1200
00:53:56,050 --> 00:53:59,470
приближение хорошо, поэтому мы хотели бы сделать

1201
00:53:59,470 --> 00:54:06,340
лучше, чем это, поэтому теперь мы  мы собираемся

1202
00:54:06,340 --> 00:54:07,750
вернуться к тому моменту, о котором я упомянул

1203
00:54:07,750 --> 00:54:08,890
в начале, и это то, что мы действительно

1204
00:54:08,890 --> 00:54:10,000
хотели бы сделать, когда мы

1205
00:54:10,000 --> 00:54:12,160
делаем это обновление, мы хотели бы

1206
00:54:12,160 --> 00:54:14,410
обеспечить монотонное улучшение, и поэтому

1207
00:54:14,410 --> 00:54:16,660
мы можем выбрать  наши размеры шага в некотором

1208
00:54:16,660 --> 00:54:18,670
роде или выберите, как далеко

1209
00:54:18,670 --> 00:54:20,800
идти по градиенту, чтобы добиться монотонного

1210
00:54:20,800 --> 00:54:22,960
улучшения, поэтому наша цель будет

1211
00:54:22,960 --> 00:54:26,350
заключаться в том, чтобы мы хотели, чтобы

1212
00:54:26,350 --> 00:54:29,200
PI для I плюс один был больше или

1213
00:54:29,200 --> 00:54:35,560
равен  к B PI, и мы надеемся

1214
00:54:35,560 --> 00:54:37,420
достичь этого, изменив размер

1215
00:54:37,420 --> 00:54:41,380
шага  размер, который вы принимаете правильно, поэтому давайте снова

1216
00:54:41,380 --> 00:54:43,000
подумаем о том, какова наша целевая функция,

1217
00:54:43,000 --> 00:54:45,970
поэтому мы получаем, что у нас есть наше

1218
00:54:45,970 --> 00:54:50,560
значение, значение наших параметров, поэтому B

1219
00:54:50,560 --> 00:54:53,650
тета равно ожидаемому значению в соответствии с

1220
00:54:53,650 --> 00:54:58,030
нашей политикой, которая определяется тета,

1221
00:54:58,030 --> 00:55:00,630
просто сумма по T равна  от 0 до бесконечности

1222
00:55:00,630 --> 00:55:08,980
gamma t r stat в соответствии с нашей политикой, хорошо,

1223
00:55:08,980 --> 00:55:12,310
и здесь мы просто смотрим на

1224
00:55:12,310 --> 00:55:14,080
ряд состояний, которые мы получаем в соответствии с нашей политикой

1225
00:55:14,080 --> 00:55:16,180
, это наше основное уравнение здесь с точки

1226
00:55:16,180 --> 00:55:17,740
зрения выражения значения

1227
00:55:17,740 --> 00:55:20,800
параметризованной политики и того, что мы

1228
00:55:20,800 --> 00:55:23,950
хотели бы  сделать здесь, мы хотели бы

1229
00:55:23,950 --> 00:55:26,920
получить новую политику, которая имеет лучшую ценность,

1230
00:55:26,920 --> 00:55:28,840
но проблема в том, что у нас есть образцы

1231
00:55:28,840 --> 00:55:32,020
из старой политики, поэтому, когда мы делаем это,

1232
00:55:32,020 --> 00:55:35,080
мы собираем политики с pi, а

1233
00:55:35,080 --> 00:55:36,730
затем пытаемся вычислить  каким

1234
00:55:36,730 --> 00:55:39,700
должно быть наше пи плюс 1, так что это будет

1235
00:55:39,700 --> 00:55:42,850
фундаментально включать, поэтому у нас есть доступ

1236
00:55:42,850 --> 00:55:45,910
к у нас есть доступ к траекториям,

1237
00:55:45,910 --> 00:55:51,880
которые взяты из PI тета, и теперь мы

1238
00:55:51,880 --> 00:55:57,610
хотим, чтобы мы предсказывали значение B a

1239
00:55:57,610 --> 00:55:58,590
PI тета.

1240
00:55:58,590 --> 00:56:02,980
Я буду  поставьте PI I I плюс 1, чтобы мы  как

1241
00:56:02,980 --> 00:56:05,500
бы теперь выяснить, каким будет новое значение

1242
00:56:05,500 --> 00:56:07,030
, если мы обновим эти молитвы,

1243
00:56:07,030 --> 00:56:08,560
обновим эти параметры каким-то образом и

1244
00:56:08,560 --> 00:56:12,040
возьмем как максимум, вы знаете, мы хотели бы

1245
00:56:12,040 --> 00:56:15,360
выяснить, какие новые параметры,

1246
00:56:15,990 --> 00:56:18,430
но это принципиально не политика

1247
00:56:18,430 --> 00:56:20,680
проблема, потому что у нас есть данные из нашей

1248
00:56:20,680 --> 00:56:22,150
последней политики, и мы хотим выяснить,

1249
00:56:22,150 --> 00:56:27,370
какая наша следующая политика должна быть в порядке, поэтому

1250
00:56:27,370 --> 00:56:30,100
что мы собираемся сделать, так это сначала

1251
00:56:30,100 --> 00:56:33,760
повторно выразить ценность нашей политики с

1252
00:56:33,760 --> 00:56:36,100
точки зрения преимущества ценность  нашей

1253
00:56:36,100 --> 00:56:37,840
новой политики с точки зрения преимущества

1254
00:56:37,840 --> 00:56:42,820
над нашей старой политикой, поэтому я собираюсь двигаться

1255
00:56:42,820 --> 00:56:46,560
вниз по среднему градиенту политики на данный момент,

1256
00:56:48,780 --> 00:56:52,359
хорошо, так что у нас есть V of

1257
00:56:52,359 --> 00:56:55,690
theta тильда, так что это может быть похоже на нашу

1258
00:56:55,690 --> 00:56:58,809
новую политику параметризации, это будет

1259
00:56:58,809 --> 00:57:00,540
равно значению нашей старой

1260
00:57:00,540 --> 00:57:03,130
параметризованной политики, поэтому все, что у нас было

1261
00:57:03,130 --> 00:57:07,420
раньше, плюс следующее

1262
00:57:07,420 --> 00:57:09,250
распределение по состояниям и действиям, которые

1263
00:57:09,250 --> 00:57:11,369
мы получим, если запустим нашу новую политику

1264
00:57:11,369 --> 00:57:14,170
нет, мы этого не знаем, но давайте я

1265
00:57:14,170 --> 00:57:15,339
проигнорирую это  за

1266
00:57:15,339 --> 00:57:18,839
секунду суммы по T равно zer  o до бесконечности

1267
00:57:18,839 --> 00:57:29,020
гаммы до T преимущество PI, так что

1268
00:57:29,020 --> 00:57:32,230
это просто обычно имеет место, это не

1269
00:57:32,230 --> 00:57:34,150
обязательно должно делать что-либо обязательно

1270
00:57:34,150 --> 00:57:36,010
с параметризацией, это просто говорит о том,

1271
00:57:36,010 --> 00:57:38,980
что значение любой политики, которая здесь

1272
00:57:38,980 --> 00:57:41,170
параметризуется тильдой PI, равно

1273
00:57:41,170 --> 00:57:43,569
значению  другая политика плюс сумма

1274
00:57:43,569 --> 00:57:45,099
по состояниям и действиям, которых вы достигли бы в

1275
00:57:45,099 --> 00:57:47,589
соответствии с вашей целевой политикой

1276
00:57:47,589 --> 00:57:49,510
преимущества, которое вы получаете от принятия этой новой

1277
00:57:49,510 --> 00:57:55,839
политики по сравнению со старой политикой, так что

1278
00:57:55,839 --> 00:57:58,270
это просто выражает то, как мы можем сказать, что

1279
00:57:58,270 --> 00:58:00,099
о том, как и ценность новой  политика

1280
00:58:00,099 --> 00:58:01,690
связана со значением старой политики,

1281
00:58:01,690 --> 00:58:03,520
она точно такая же, как и старая политика ценностей,

1282
00:58:03,520 --> 00:58:06,040
плюс преимущество, которое вы получите,

1283
00:58:06,040 --> 00:58:08,319
если запустите новую политику и посмотрите

1284
00:58:08,319 --> 00:58:10,299
на распределение действий состояния, с которым вы

1285
00:58:10,299 --> 00:58:21,640
столкнетесь да да, так что вы  делая это,

1286
00:58:21,640 --> 00:58:23,680
позвольте мне написать эти вопросы. Гудвин, позвольте

1287
00:58:23,680 --> 00:58:25,299
мне просто написать, что это ужасно,

1288
00:58:25,299 --> 00:58:29,319
хорошо, так что у нас есть V тета плюс сумма

1289
00:58:29,319 --> 00:58:32,109
по всем состояниям, и мы собираемся использовать

1290
00:58:32,109 --> 00:58:35,710
мю P тильду s, так что помните, что это было

1291
00:58:35,710 --> 00:58:38,290
стационарное распределение  мы используем это  s для

1292
00:58:38,290 --> 00:58:39,880
обозначения станции в распределении по

1293
00:58:39,880 --> 00:58:42,760
состояниям, которых мы достигли бы, если бы мы запустили

1294
00:58:42,760 --> 00:58:46,410
нашу новую политику, которая параметризует

1295
00:58:50,809 --> 00:58:57,679
функцию преимущества времени, хорошо, так

1296
00:58:57,679 --> 00:59:02,029
что здесь говорится, что это st и

1297
00:59:02,029 --> 00:59:07,640
80 находятся под нашей желаемой политикой, а

1298
00:59:07,640 --> 00:59:12,069
преимущество здесь  использует старую, так

1299
00:59:14,109 --> 00:59:17,569
что это долго, чтобы сравнить, так что же

1300
00:59:17,569 --> 00:59:24,849
это делает, позволяя нам сравнивать si s T 80

1301
00:59:24,849 --> 00:59:42,199
минус Q of s T с нашей старой политикой, и

1302
00:59:42,199 --> 00:59:47,359
это не действует, поэтому это позволяет нам сравнить,

1303
00:59:47,359 --> 00:59:49,159
насколько это лучше, если мы  примите как

1304
00:59:49,159 --> 00:59:53,419
наше новое действие, хорошо, но одна из

1305
00:59:53,419 --> 00:59:56,679
проблем в том, что мы этого не знаем,

1306
00:59:56,679 --> 00:59:59,099
да,

1307
00:59:59,099 --> 01:00:12,420
о, спасибо, о, нет, позволь мне

1308
01:00:12,420 --> 01:00:14,009
уточнить это, поэтому в этом случае то, что мы

1309
01:00:14,009 --> 01:00:15,779
делаем, это то, что мы принимаем ожидание

1310
01:00:15,779 --> 01:00:18,329
сверх  все временные шаги, и это говорит

1311
01:00:18,329 --> 01:00:20,549
о траекториях, к которым мы доберемся в

1312
01:00:20,549 --> 01:00:23,130
соответствии с нашей новой политикой, которую я сейчас

1313
01:00:23,130 --> 01:00:25,589
переформулировал и сказал, что у нас есть

1314
01:00:25,589 --> 01:00:27,930
стационарное распределение по состояниям, если

1315
01:00:27,930 --> 01:00:30,029
мы посмотрим, какова вероятность

1316
01:00:30,029 --> 01:00:32,640
достижения этих состояний, а затем мы  взвесьте

1317
01:00:32,640 --> 01:00:36,509
это преимуществом, поэтому мы пошли  от

1318
01:00:36,509 --> 01:00:40,710
усреднения по времени к усреднению по состоянию, которое

1319
01:00:40,710 --> 01:00:42,269
имеет смысл, поэтому мы можем либо думать о

1320
01:00:42,269 --> 01:00:44,880
нашей функции значения, усредняющей нашу

1321
01:00:44,880 --> 01:00:47,009
функцию значения по временным шагам, либо мы можем

1322
01:00:47,009 --> 01:00:48,690
думать, что здесь происходит усреднение по всем

1323
01:00:48,690 --> 01:00:50,789
состояниям и что для каждого состояния

1324
01:00:50,789 --> 01:00:52,410
является относительным значением, которое вы  получить,

1325
01:00:52,410 --> 01:00:53,880
следуя вашей новой политике по сравнению с вашей

1326
01:00:53,880 --> 01:00:59,309
старой политикой, о, извините, тогда спасибо,

1327
01:00:59,309 --> 01:01:07,559
что были наши опечатки, все в порядке, так что это

1328
01:01:07,559 --> 01:01:18,150
будет ниже, поэтому мы смотрим на

1329
01:01:18,150 --> 01:01:20,670
состояния, которые для каждого состояния, какова

1330
01:01:20,670 --> 01:01:22,559
вероятность, что мы достигнем этого состояния при

1331
01:01:22,559 --> 01:01:24,599
наших  новая политика, что является относительным

1332
01:01:24,599 --> 01:01:27,140
преимуществом,

1333
01:01:33,560 --> 01:01:46,340
то, на что вы указали, до

1334
01:01:46,340 --> 01:01:51,790
никогда здесь, это наш первоначальный плюс

1335
01:01:51,790 --> 01:01:59,360
шесть офицеров между высоким уровнем натрия натрия

1336
01:01:59,360 --> 01:02:02,780
и Тоби, я просто делал в этом году, чтобы

1337
01:02:02,780 --> 01:02:06,230
прояснить трубы.

1338
01:02:06,230 --> 01:02:08,660
это

1339
01:02:08,660 --> 01:02:18,140
политика, приватизированная тета тильдой, как

1340
01:02:18,140 --> 01:02:22,520
вы, хорошо, эпизод восьмой, поэтому мы не могли ни с

1341
01:02:22,520 --> 01:02:24,590
той стороны, ни с любой, я хотел просто

1342
01:02:24,590 --> 01:02:25,610
прояснить,

1343
01:02:25,610 --> 01:02:27,650
часто это обозначение идет туда и обратно

1344
01:02:27,650 --> 01:02:29,480
между вами, что вы  хочу, чтобы

1345
01:02:29,480 --> 01:02:31,250
политика была явной, давайте были просто

1346
01:02:31,250 --> 01:02:33,590
параметрами, я думаю, что здесь будет понятнее

1347
01:02:33,590 --> 01:02:36,560
иметь политику и параметры,

1348
01:02:36,560 --> 01:02:38,660
но помимо меня также используйте, вы можете просто

1349
01:02:38,660 --> 01:02:39,980
напрямую параметризовать функцию значения

1350
01:02:39,980 --> 01:02:42,410
с точки зрения данных, которые должны быть PI

1351
01:02:42,410 --> 01:02:47,200
тильда тета  но я собираюсь просто использовать

1352
01:02:47,200 --> 01:02:49,700
съесть что-нибудь из этого нормально

1353
01:02:49,700 --> 01:02:52,340
если кто-то запутался в том, что это такое я

1354
01:02:52,340 --> 01:02:53,540
имею в виду, если это проще, я могу просто пойти так,

1355
01:02:53,540 --> 01:02:53,750


1356
01:02:53,750 --> 01:02:57,050
я могу просто удалить все это хорошо, так

1357
01:02:57,050 --> 01:02:59,690
что это просто то, что я когда-либо говорил PI тильда

1358
01:02:59,690 --> 01:03:01,520
это  политика, которая

1359
01:03:01,520 --> 01:03:04,670
параметризована новой, это ваша новая политика, хорошо, и это

1360
01:03:04,670 --> 01:03:08,530
то, что я знаю об этом дольше,

1361
01:03:08,530 --> 01:03:10,150
поэтому у нас есть какие-либо вопросы о

1362
01:03:10,150 --> 01:03:16,030
санитарии, наконец, поэтому я получаю

1363
01:03:16,030 --> 01:03:17,380
немного вычислений без сна только

1364
01:03:17,380 --> 01:03:18,490
потому, что это немного отличается

1365
01:03:18,490 --> 01:03:22,470
от слайдов, и я  мне просто интересно,

1366
01:03:23,760 --> 01:03:26,620
так что в этом случае мы

1367
01:03:26,620 --> 01:03:29,170
суммируем возможные действия для данного состояния, или,

1368
01:03:29,170 --> 01:03:32,050
как отметили здесь люди, мы предполагаем, что

1369
01:03:32,050 --> 01:03:35,440
мы предпринимаем одно действие, используя

1370
01:03:35,440 --> 01:03:48,280
политику, которая у нас есть, хорошо,

1371
01:03:48,280 --> 01:03:53,590
скажем, B t  Гета тильда Я буду использовать то

1372
01:03:53,590 --> 01:03:56,890
же обозначение, что и на слайдах, оно

1373
01:03:56,890 --> 01:04:02,950
равно V тета плюс сумма по состояниям нашего

1374
01:04:02,950 --> 01:04:05,950
стационарного распределения по PI тильда

1375
01:04:05,950 --> 01:04:09,900
s, так что это распределение, которое мы получаем,

1376
01:04:09,900 --> 01:04:12,220
это дисконтированное взвешенное

1377
01:04:12,220 --> 01:04:23,050
распределение в соответствии с нашей целевой политикой и

1378
01:04:23,050 --> 01:04:41,020
там hi tilde sum над a так что это

1379
01:04:41,020 --> 01:04:42,820
взвешенная справедливость это взвешенное

1380
01:04:42,820 --> 01:04:44,440
распределение по состояниям мы перешли

1381
01:04:44,440 --> 01:04:46,270
от временной области к размышлениям

1382
01:04:46,270 --> 01:04:50,010
о распределении по состояниям раз

1383
01:04:50,010 --> 01:04:52,180
рассматривая все действия которые мы могли бы предпринять в

1384
01:04:52,180 --> 01:04:54,310
соответствии с нашей целевой политикой и относительным

1385
01:04:54,310 --> 01:04:57,490
преимуществом  каждого из них по сравнению с нашей

1386
01:04:57,490 --> 01:05:02,410
предыдущей политикой, и это должно быть

1387
01:05:02,410 --> 01:05:04,060
очень похоже на приглашение к обучению

1388
01:05:04,060 --> 01:05:06,520
в определенном смысле, так что мы

1389
01:05:06,520 --> 01:05:08,740
снова как бы думаем о том, вместо того, чтобы

1390
01:05:08,740 --> 01:05:10,330
думать о дополнительных вознаграждениях с течением времени,

1391
01:05:10,330 --> 01:05:11,710
мы думаем о том, что является

1392
01:05:11,710 --> 01:05:13,690
стационарным  распределение, которое мы могли бы получить в

1393
01:05:13,690 --> 01:05:16,000
соответствии с новой политикой, и как оно сравнивается

1394
01:05:16,000 --> 01:05:17,860
со стационарным распределением, которое у

1395
01:05:17,860 --> 01:05:20,890
нас было бы в соответствии с нашей старой политикой, и что

1396
01:05:20,890 --> 01:05:22,390
мы ищем  g до сих пор

1397
01:05:22,390 --> 01:05:24,190
мы смотрим на стационарное

1398
01:05:24,190 --> 01:05:26,589
распределение в рамках нашей целевой политики,

1399
01:05:26,589 --> 01:05:28,390
проблема в том, что мы этого не знаем, поэтому мы

1400
01:05:28,390 --> 01:05:30,640
не можем вычислить это, это просто

1401
01:05:30,640 --> 01:05:37,109
выражение, но это неизвестно, потому что

1402
01:05:37,109 --> 01:05:40,839
у нас нет выборок из  PI tilde

1403
01:05:40,839 --> 01:05:47,559
у нас есть только образцы из PI, поэтому мы не можем

1404
01:05:47,559 --> 01:05:49,839
вычислить это, зачем нам добавлять, просто чтобы вернуться

1405
01:05:49,839 --> 01:05:51,400
назад, почему мы пытаемся сделать что-либо из этого,

1406
01:05:51,400 --> 01:05:53,289
мы пытаемся сделать это, потому что, когда мы

1407
01:05:53,289 --> 01:05:57,970
делаем ванильный градиент политики, мы собираемся

1408
01:05:57,970 --> 01:06:00,369
мы пытаемся выяснить новую политику,

1409
01:06:00,369 --> 01:06:02,500
которая имеет значение, которое лучше, чем наша

1410
01:06:02,500 --> 01:06:05,170
старая политика, что мы сделали здесь, мы

1411
01:06:05,170 --> 01:06:07,660
попытались оценить производную от

1412
01:06:07,660 --> 01:06:10,720
текущей палы текущей политики, но

1413
01:06:10,720 --> 01:06:12,160
мы еще ничего не знаем о

1414
01:06:12,160 --> 01:06:14,920
ценности, как только мы  сделать этот шаг, и поэтому то, что

1415
01:06:14,920 --> 01:06:16,420
мы пытаемся сделать здесь, это сказать,

1416
01:06:16,420 --> 01:06:18,819
можем ли мы каким-то образом понять, какова

1417
01:06:18,819 --> 01:06:20,950
будет ценность новой политики, прежде чем мы ее

1418
01:06:20,950 --> 01:06:23,410
реализуем, и мы собираемся сделать это,

1419
01:06:23,410 --> 01:06:25,029
пытаясь связать ее с тем, что является нашей

1420
01:06:25,029 --> 01:06:28,119
значение предыдущей политики плюс некоторое

1421
01:06:28,119 --> 01:06:30,910
расстояние между старой политикой и  d

1422
01:06:30,910 --> 01:06:31,619
новая политика

1423
01:06:31,619 --> 01:06:34,000
идеально рассчитана с точки зрения вещей, которые мы

1424
01:06:34,000 --> 01:06:35,529
можем оценить, используя наши текущие

1425
01:06:35,529 --> 01:06:37,599
выборки, к этому мы и пытаемся подойти,

1426
01:06:37,599 --> 01:06:39,660


1427
01:06:40,099 --> 01:06:41,749
поэтому у нас есть это хорошее

1428
01:06:41,749 --> 01:06:45,160
выражение, но мы не можем его вычислить, поэтому

1429
01:06:45,160 --> 01:06:46,999
мы собираемся составить  новая целевая

1430
01:06:46,999 --> 01:06:51,049
функция, мы собираемся сделать это в

1431
01:06:51,049 --> 01:06:52,219
обратном порядке, потому что мы собираемся это сделать

1432
01:06:52,219 --> 01:06:53,359
, а затем мы собираемся показать, почему это

1433
01:06:53,359 --> 01:06:55,069
хорошо, так что мы

1434
01:06:55,069 --> 01:06:57,140
пытаемся сделать, мы хотели бы использовать что-то  вот

1435
01:06:57,140 --> 01:06:59,479
так, если бы у нас было это, то мы могли бы

1436
01:06:59,479 --> 01:07:01,339
сравнить ценность новой политики

1437
01:07:01,339 --> 01:07:03,380
со стоимостью старой политики, проблема

1438
01:07:03,380 --> 01:07:04,699
в том, что у нас нет этого, потому что у нас

1439
01:07:04,699 --> 01:07:05,959
нет того, и стационарное

1440
01:07:05,959 --> 01:07:09,979
распределение в соответствии с новой политикой, так

1441
01:07:09,979 --> 01:07:12,019
что мы  вместо этого мы

1442
01:07:12,019 --> 01:07:15,819
собираемся определить целевую функцию L pi,

1443
01:07:15,819 --> 01:07:18,499
которая выглядит следующим образом: это значение

1444
01:07:18,499 --> 01:07:22,039
вашего старого полиса плюс сумма по всему вашему

1445
01:07:22,039 --> 01:07:23,569
состоянию, стационарное распределение,

1446
01:07:23,569 --> 01:07:26,779
дисконтированное распределение вашего старого

1447
01:07:26,779 --> 01:07:30,979
полиса, вот где оно отличается, так что

1448
01:07:30,979 --> 01:07:35,089
это  старая ваша текущая политика в порядке

1449
01:07:35,089 --> 01:07:38,299
и  тогда остальная часть выражения

1450
01:07:38,299 --> 01:07:47,599
выглядит так же, теперь обратите внимание, что мы можем вычислить

1451
01:07:47,599 --> 01:07:50,599
это, хорошо, мы можем просто

1452
01:07:50,599 --> 01:07:52,249
усреднить все траектории, которые у нас есть

1453
01:07:52,249 --> 01:07:54,829
для текущего эпизода, мы можем оценить

1454
01:07:54,829 --> 01:07:56,779
наше стационарное распределение из наших

1455
01:07:56,779 --> 01:08:00,440
текущих данных, мы могли бы знать для новой

1456
01:08:00,440 --> 01:08:03,199
политики, что  его действие, поэтому, если кто-то

1457
01:08:03,199 --> 01:08:06,140
дает мне новый PI политики, я мог бы

1458
01:08:06,140 --> 01:08:07,969
оценить это, и я также мог бы

1459
01:08:07,969 --> 01:08:10,160
оценить преимущество в порядке, потому что это

1460
01:08:10,160 --> 01:08:13,009
преимущество определяется только с точки зрения моего

1461
01:08:13,009 --> 01:08:16,960
предыдущего PI, так что если у меня есть

1462
01:08:16,960 --> 01:08:19,698
представление функции значения действия состояния

1463
01:08:19,698 --> 01:08:22,130
для моей старой политики я мог бы

1464
01:08:22,130 --> 01:08:24,078
оценить это, так что теперь все это является

1465
01:08:24,078 --> 01:08:26,118
доступным значением, это может быть не очень

1466
01:08:26,118 --> 01:08:42,380
хорошо, но мы можем вычислить это, вы

1467
01:08:42,380 --> 01:08:44,118
можете, есть только некоторые новые параметры для

1468
01:08:44,118 --> 01:08:45,710
вычислений, поэтому наша политика всегда

1469
01:08:45,710 --> 01:08:47,689
параметризуется некоторым набором  параметры

1470
01:08:47,689 --> 01:08:49,099
вы можете либо думать о том, что это

1471
01:08:49,099 --> 01:08:50,448
просто новая политика, либо вы можете думать об

1472
01:08:50,448 --> 01:08:52,099
этом как о новых параметрах либо все в

1473
01:08:52,099 --> 01:08:53,538
порядке,

1474
01:08:53,538 --> 01:08:55,908
вы довольно хорошо объясняете, почему, если вам

1475
01:08:55,908 --> 01:08:59,839
дали на глаз  скажите мне почему вы не

1476
01:08:59,839 --> 01:09:06,288
сможете рассчитать кришна если вам

1477
01:09:06,288 --> 01:09:08,210
дадут пирог к новой политике почему вы

1478
01:09:08,210 --> 01:09:09,469
не сможете рассчитать новую это хороший вопрос

1479
01:09:09,469 --> 01:09:10,880
потому что у вас нет никаких данных из этого

1480
01:09:10,880 --> 01:09:13,269
там почти дают вам новую политику

1481
01:09:13,269 --> 01:09:15,828
там можно  есть способы приблизиться к этому,

1482
01:09:15,828 --> 01:09:17,448
но единственные данные, которые у вас есть прямо

1483
01:09:17,448 --> 01:09:21,229
сейчас, взяты из текущей старой политики от

1484
01:09:21,229 --> 01:09:23,509
PI, поэтому вы запускали это M раз, у вас

1485
01:09:23,509 --> 01:09:25,488
есть M траекторий, которые являются M

1486
01:09:25,488 --> 01:09:27,589
траекториями, собранными в соответствии с вашей старой

1487
01:09:27,589 --> 01:09:30,649
политикой pi хорошо, вы не  у меня нет данных

1488
01:09:30,649 --> 01:09:34,189
от tai tilde, и в целом, если i

1489
01:09:34,189 --> 01:09:36,618
тильда не совпадает с pi, вы получите

1490
01:09:36,618 --> 01:09:39,019
разные траектории, поэтому у вас

1491
01:09:39,019 --> 01:09:42,589
нет прямой оценки этого, которая имеет

1492
01:09:42,589 --> 01:09:43,908
смысл для всех, поэтому, если мы вернемся

1493
01:09:43,908 --> 01:09:45,979
к  ванильный градиент политики, что мы

1494
01:09:45,979 --> 01:09:49,819
сделали, у нас была политика pi I, мы ее использовали,

1495
01:09:49,819 --> 01:09:52,000
и мы получили траектории D из этого PI I,

1496
01:09:52,000 --> 01:09:54,739
мы могли бы использовать это для оценки того нового,

1497
01:09:54,739 --> 01:09:57,469
что просто дает нам данные политики о

1498
01:09:57,469 --> 01:09:59,360
том, какие состояния и действия мы

1499
01:09:59,360 --> 01:10:02,179
испытываем  когда мы следуем PI I, у

1500
01:10:02,179 --> 01:10:03,980
нас нет данных о P  Я плюс один, но

1501
01:10:03,980 --> 01:10:09,139
мы еще не провели оценку

1502
01:10:09,139 --> 01:10:10,670
стационарного распределения для старой

1503
01:10:10,670 --> 01:10:14,539
политики, вы в основном смотрите на все

1504
01:10:14,539 --> 01:10:16,159
данные, которые у вас есть, как и на все

1505
01:10:16,159 --> 01:10:18,079
траектории, и видите, в основном, какую

1506
01:10:18,079 --> 01:10:19,369
часть времени вы тратите на это

1507
01:10:19,369 --> 01:10:25,969
одно состояние, которое вы  перейти от просто необработанных данных

1508
01:10:25,969 --> 01:10:29,030
этих 2d траекторий к MU, вы можете

1509
01:10:29,030 --> 01:10:30,860
просто посчитать, знаете ли, я имею в виду, в общем, если

1510
01:10:30,860 --> 01:10:31,940
вы находитесь в действительно высоких измерениях, вы

1511
01:10:31,940 --> 01:10:33,170
хотите сделать что-то более плавное, чем то, что

1512
01:10:33,170 --> 01:10:34,550
вы хотите аппроксимировать функцию плотности,

1513
01:10:34,550 --> 01:10:36,980
но, по сути, вы можете просто

1514
01:10:36,980 --> 01:10:39,289
прямо вам  знать тип, чтобы вы могли

1515
01:10:39,289 --> 01:10:40,519
просто посчитать их, например, сколько раз

1516
01:10:40,519 --> 01:10:41,690
я дохожу до этой стадии и предпринимаю это

1517
01:10:41,690 --> 01:10:42,980
действие, и тогда это даст вам

1518
01:10:42,980 --> 01:10:46,340
прямую оценку Мааса в целом,

1519
01:10:46,340 --> 01:10:47,389
вам понадобится какая-то параметрическая

1520
01:10:47,389 --> 01:10:49,610
функция в больших измерениях, но  вы

1521
01:10:49,610 --> 01:10:51,260
не могли понять, что с помощью вы могли

1522
01:10:51,260 --> 01:10:53,090
представить, что это само по себе приватизировано, и

1523
01:10:53,090 --> 01:10:54,889
вы можете понять, что использование ваших существующих

1524
01:10:54,889 --> 01:10:58,670
данных о политике интуитивно делает эту работу,

1525
01:10:58,670 --> 01:11:00,889
потому что мы предполагали, что

1526
01:11:00,889 --> 01:11:02,690
распределение штатов может '  не менять слишком много словесных

1527
01:11:02,690 --> 01:11:04,199
политик Мне

1528
01:11:04,199 --> 01:11:05,969
нравится вопрос Ли, почему эта работа

1529
01:11:05,969 --> 01:11:07,440
Я не сказал вам, почему это работает, я

1530
01:11:07,440 --> 01:11:09,120
только что сказал, что это то, что мы могли бы сделать,

1531
01:11:09,120 --> 01:11:11,400
и что это вычислимо, и я еще не

1532
01:11:11,400 --> 01:11:13,410
сказал вам, почему это  хорошая вещь

1533
01:11:13,410 --> 01:11:17,070
, но мы собираемся показать, что

1534
01:11:17,070 --> 01:11:18,300
это позволит нам добраться до чего-то,

1535
01:11:18,300 --> 01:11:20,489
что является нижней границей, а затем мы можем

1536
01:11:20,489 --> 01:11:23,040
улучшить эти нижние границы, хорошо, так

1537
01:11:23,040 --> 01:11:25,290
что просто быстро заметьте,

1538
01:11:25,290 --> 01:11:30,890
что если вы сделаете это  если вы выполняете L PI для Pi,

1539
01:11:30,890 --> 01:11:33,060
так что это именно то, что представляет собой эта целевая

1540
01:11:33,060 --> 01:11:35,010
функция, если вы подключаете старую политику,

1541
01:11:35,010 --> 01:11:43,140
это просто равно V beta, поэтому, если

1542
01:11:43,140 --> 01:11:46,230
вы оцениваете эту функцию в рамках той

1543
01:11:46,230 --> 01:11:51,530
же политики, она просто дает вам значение,

1544
01:11:52,699 --> 01:11:54,060
все в порядке,

1545
01:11:54,060 --> 01:11:57,300
так что консервативно  Вкратце, нам

1546
01:11:57,300 --> 01:12:00,110
придется продолжить это позже, но

1547
01:12:00,110 --> 01:12:02,640
чтобы мы могли использовать это, чтобы сделать то, что известно как

1548
01:12:02,640 --> 01:12:04,850
итерация

1549
01:12:04,850 --> 01:12:13,500
консервативной политики, итерация консервативной политики, и

1550
01:12:13,500 --> 01:12:15,239
интуиция здесь такова: давайте сначала

1551
01:12:15,239 --> 01:12:18,060
начнем со смешанной смешанной политики, так

1552
01:12:18,060 --> 01:12:19,980
что представьте, что  у вас новая политика w

1553
01:12:19,980 --> 01:12:24,330
это смесь старой политики и

1554
01:12:24,330 --> 01:12:25,710
чего-то другого, поэтому у вас есть 1 минус

1555
01:12:25,710 --> 01:12:30,840
альфа в разы ваша старая политика плюс

1556
01:12:30,840 --> 01:12:35,239
альфа раз в какую-то новую политику PI Prime хорошо,

1557
01:12:35,239 --> 01:12:37,380
так что это просто означает, что вы берете какую-то

1558
01:12:37,380 --> 01:12:39,390
старую текущую существующую политику и

1559
01:12:39,390 --> 01:12:42,690
смешиваете что-то  иначе хорошо, тогда в этом случае

1560
01:12:42,690 --> 01:12:45,330
вы можете гарантировать, что значение вашей

1561
01:12:45,330 --> 01:12:47,699
новой политики больше или равно тому,

1562
01:12:47,699 --> 01:12:49,679
если вы возьмете эту целевую функцию

1563
01:12:49,679 --> 01:12:52,770
здесь и оцените ее с помощью своей новой

1564
01:12:52,770 --> 01:12:56,760
политики, поэтому вы берете свою новую политику, которую вы

1565
01:12:56,760 --> 01:12:58,590
оцениваете, к своей старой  политика, которую вы подключаете

1566
01:12:58,590 --> 01:13:00,210
, которую можно вычислить, потому что у вас

1567
01:13:00,210 --> 01:13:03,210
есть данные из вашей старой политики минус 2

1568
01:13:03,210 --> 01:13:06,870
эпсилон гаммы 1 минус гамма в квадрате

1569
01:13:06,870 --> 01:13:11,790
альфа-квадрата, чтобы вы могли установить нижнюю

1570
01:13:11,790 --> 01:13:14,280
границу значения вашей новой политики с точки зрения

1571
01:13:14,280 --> 01:13:16,080
какой бы ни была эта целевая функция, когда

1572
01:13:16,080 --> 01:13:17,550
вы ее вычисляете

1573
01:13:17,550 --> 01:13:23,430
- это  выражение Я просто хочу закончить

1574
01:13:23,430 --> 01:13:25,260
двумя другими мыслями, которые еще раз отмечают,

1575
01:13:25,260 --> 01:13:29,580
что если вы подключите альфа,

1576
01:13:29,580 --> 01:13:36,390
равно 0, это означает, что PI nu такой же,

1577
01:13:36,390 --> 01:13:41,460
как сложенный, и это идет к 0, что означает,

1578
01:13:41,460 --> 01:13:43,200
что и поскольку w  мы знаем, что это

1579
01:13:43,200 --> 01:13:45,330
равносильно тому, что просто говорит о том, что ваша

1580
01:13:45,330 --> 01:13:46,890
новая политика должна быть больше или

1581
01:13:46,890 --> 01:13:48,750
равна вашей старой политике, и, поскольку

1582
01:13:48,750 --> 01:13:50,100
все те же самые политики одинаковы,

1583
01:13:50,100 --> 01:13:55,050
это жестко, хорошо, поэтому мы

1584
01:13:55,050 --> 01:13:56,760
немного отличаемся от того, что мы  ожидается

1585
01:13:56,760 --> 01:13:59,220
из-за технических проблем с

1586
01:13:59,220 --> 01:14:01,740
PDF, поэтому я просто закончу здесь тем,

1587
01:14:01,740 --> 01:14:03,810
что следующие шаги будут идти от этого,

1588
01:14:03,810 --> 01:14:05,910
чтобы показать, что мы можем использовать это, чтобы по существу

1589
01:14:05,910 --> 01:14:07,920
установить нижнюю границу новой функции значения,

1590
01:14:07,920 --> 01:14:10,470
и мы можем показать в основном, что

1591
01:14:10,470 --> 01:14:13,140
если мы улучшим нижние границы,

1592
01:14:13,140 --> 01:14:15,000
которые были гарантированы, что фактическая

1593
01:14:15,000 --> 01:14:16,770
функция ценности монотонно

1594
01:14:16,770 --> 01:14:20,460
улучшается, поэтому мы пройдем через это, я

1595
01:14:20,460 --> 01:14:22,020
еще не решил, пройдем ли мы

1596
01:14:22,020 --> 01:14:23,460
это в понедельник, потому что

1597
01:14:23,460 --> 01:14:25,200
это промежуточный обзор, или мы подождем

1598
01:14:25,200 --> 01:14:27,780
что до следующей недели после

1599
01:14:27,780 --> 01:14:30,570
промежуточного семестра домашнее задание по градиенту политики

1600
01:14:30,570 --> 01:14:31,860
не будет опубликовано до окончания

1601
01:14:31,860 --> 01:14:33,780
промежуточного семестра, поэтому у нас есть немного больше времени для

1602
01:14:33,780 --> 01:14:36,420
этого, и я также пройдусь по

1603
01:14:36,420 --> 01:14:38,040
основным выводам с градиентом политики.

1604
01:14:38,040 --> 01:14:42,200
ff когда мы завершим эту часть Спасибо

