1
00:00:04,560 --> 00:00:06,240
хорошо, мы начнем,

2
00:00:06,240 --> 00:00:09,300
это последняя лекция в семестре, я всего

3
00:00:09,300 --> 00:00:10,980
лишь несколько вещей по логистике, когда мы

4
00:00:10,980 --> 00:00:13,139
приступим к началу, так что просто

5
00:00:13,139 --> 00:00:14,630
дружеское напоминание о

6
00:00:14,630 --> 00:00:16,610
написании проекта должно быть 20-го числа в

7
00:00:16,610 --> 00:00:18,890
23:59.  нет поздних дней, а

8
00:00:18,890 --> 00:00:21,350
затем постерные презентации

9
00:00:21,350 --> 00:00:24,920
состоятся в пятницу в 8:30 утра. вам также необходимо отправить

10
00:00:24,920 --> 00:00:26,840
свой постер, и он должен быть

11
00:00:26,840 --> 00:00:28,730
представлен онлайн в рамках оценки к тому

12
00:00:28,730 --> 00:00:31,400
же времени, когда мы откроем представление для

13
00:00:31,400 --> 00:00:33,829
этого в  заранее, и также нет поздних

14
00:00:33,829 --> 00:00:35,989
дней для этого, вы должны были получить

15
00:00:35,989 --> 00:00:37,579
электронное письмо с некоторыми подробностями о

16
00:00:37,579 --> 00:00:39,380
постерной сессии. любые вопросы обращайтесь

17
00:00:39,380 --> 00:00:42,880
к нам, поэтому у нас есть какие-либо вопросы прямо сейчас,

18
00:00:42,880 --> 00:00:44,860
это последняя неделя рабочих часов, у нас

19
00:00:44,860 --> 00:00:46,870
не будет рабочих часов на следующей  неделя финальная

20
00:00:46,870 --> 00:00:49,630
неделя для большинства людей, но вы можете

21
00:00:49,630 --> 00:00:51,309
связаться с нами на площади или, если у вас есть дополнительные

22
00:00:51,309 --> 00:00:52,900
вопросы, вы знаете, мы будем рады найти

23
00:00:52,900 --> 00:00:58,390
время, хорошо, хорошо, так что то, что мы собираемся

24
00:00:58,390 --> 00:01:00,460
сделать сегодня, это последний раз, конечно,

25
00:01:00,460 --> 00:01:03,760
просто  викторину, и мы собираемся

26
00:01:03,760 --> 00:01:05,019
разослать ее, наша цель - разослать оценки

27
00:01:05,019 --> 00:01:06,790
всем, кто прошел ее в понедельник, чтобы отправить

28
00:01:06,790 --> 00:01:08,020
их сегодня, мы почти закончили их оценивать,

29
00:01:08,020 --> 00:01:10,960
и для этого есть несколько

30
00:01:10,960 --> 00:01:12,759
человек, которые все еще опаздывают, так что

31
00:01:12,759 --> 00:01:15,280
хотя мы должны оценить scpd, но

32
00:01:15,280 --> 00:01:16,270
когда-либо  кто-нибудь еще должен получить свои

33
00:01:16,270 --> 00:01:18,160
баллы за викторину, кто сдавал ее в понедельник, должен получить

34
00:01:18,160 --> 00:01:19,720
ее сегодня, а

35
00:01:19,720 --> 00:01:20,890
сегодня мы собираемся немного поговорить

36
00:01:20,890 --> 00:01:22,149
о поиске по дереву Монте-Карло,

37
00:01:22,149 --> 00:01:24,220
а также обсудить их и, конечно,

38
00:01:24,220 --> 00:01:27,880
все такое.  почему поиск по дереву Монте-Карло хм,

39
00:01:27,880 --> 00:01:31,539
кто слышал, слышал об alphago, хорошо, да

40
00:01:31,539 --> 00:01:33,369
, я имею в виду, что alphago, как вы можете утверждать, является одним

41
00:01:33,369 --> 00:01:35,710
из основных достижений ИИ за последние

42
00:01:35,710 --> 00:01:39,220
10-20 лет, и это

43
00:01:39,220 --> 00:01:40,929
действительно было впечатляющее достижение, которое

44
00:01:40,929 --> 00:01:42,130
было достигнуто намного быстрее  чем

45
00:01:42,130 --> 00:01:45,580
ожидалось, да, победить людей в

46
00:01:45,580 --> 00:01:47,500
настольной игре, которая считается

47
00:01:47,500 --> 00:01:50,409
чрезвычайно сложной игрой, поэтому

48
00:01:50,409 --> 00:01:52,210
поиск по дереву Монте-Карло был важной частью, как вы

49
00:01:52,210 --> 00:01:54,100
знаете, для достижения успеха плюс множество

50
00:01:54,100 --> 00:01:55,810
других дополнительных вещей, но это один

51
00:01:55,810 --> 00:01:56,950
из аспектов, которые  мы еще не

52
00:01:56,950 --> 00:01:58,780
очень много говорили в классе, поэтому я

53
00:01:58,780 --> 00:02:00,009
думаю, что мы говорим о поиске по дереву Монте-Карло,

54
00:02:00,009 --> 00:02:01,329
так что вы знакомы с

55
00:02:01,329 --> 00:02:02,950
некоторыми идеями, лежащими в основе этого, и поэтому

56
00:02:02,950 --> 00:02:05,590
некоторые идеи, лежащие в основе alphago,

57
00:02:05,590 --> 00:02:08,289
полезно знать.  а также потому, что

58
00:02:08,289 --> 00:02:10,149
когда мы начинаем думать о

59
00:02:10,149 --> 00:02:11,470
поиске по дереву Монте-Карло, это способ для нас думать

60
00:02:11,470 --> 00:02:13,299
об обучении с подкреплением на основе моделей,

61
00:02:13,299 --> 00:02:15,670
которое является очень мощным инструментом, о котором

62
00:02:15,670 --> 00:02:17,739
мы не говорили так много отчасти

63
00:02:17,739 --> 00:02:19,870
потому, что мы не  видел такой же успех

64
00:02:19,870 --> 00:02:22,840
в случае глубокого обучения с моделями,

65
00:02:22,840 --> 00:02:24,519
и я рад поговорить завтра о

66
00:02:24,519 --> 00:02:26,890
том, что вы сделали сегодня или в автономном режиме, но я

67
00:02:26,890 --> 00:02:28,269
думаю, что в будущем это, вероятно,

68
00:02:28,269 --> 00:02:29,709
будет действительно продуктивным направлением

69
00:02:29,709 --> 00:02:32,170
исследований, и мы можем поговорить о том, почему это

70
00:02:32,170 --> 00:02:34,180
может  быть особенно полезным в альфе в

71
00:02:34,180 --> 00:02:38,140
альфаго, поэтому сначала

72
00:02:38,140 --> 00:02:39,220
мы собираемся немного поговорить

73
00:02:39,220 --> 00:02:40,570
о своего рода

74
00:02:40,570 --> 00:02:41,890
обучении с подкреплением на основе модели, а затем мы

75
00:02:41,890 --> 00:02:43,810
поговорим о поиске на основе симуляции, основанном на симуляции

76
00:02:43,810 --> 00:02:45,880
, где Монте  Поиск по дереву-Карло

77
00:02:45,880 --> 00:02:47,680
приходит Эшли только потому, что

78
00:02:47,680 --> 00:02:48,970
все берут разные классы, и мне

79
00:02:48,970 --> 00:02:50,949
любопытно, кто здесь занимался поиском по дереву Монте-Карло,

80
00:02:50,949 --> 00:02:53,880
вы знаете, в другом классе,

81
00:02:53,880 --> 00:02:58,350
ладно, только в каком классе это было,

82
00:02:58,680 --> 00:03:11,650
да, да, что, как правило, О, ген

83
00:03:11,650 --> 00:03:12,730
Было бы хорошо, если бы вы пришли с игрой ral, чтобы

84
00:03:12,730 --> 00:03:16,390
принести ее, хорошо, о, а также просто подумайте,

85
00:03:16,390 --> 00:03:17,680
что людям это интересно, в конце

86
00:03:17,680 --> 00:03:18,790
я также упомяну некоторые другие классы,

87
00:03:18,790 --> 00:03:19,540
где вы можете узнать больше об

88
00:03:19,540 --> 00:03:20,650
обучении с подкреплением,

89
00:03:20,650 --> 00:03:22,690
хорошо, так что обучение с подкреплением на основе мобильных устройств

90
00:03:22,690 --> 00:03:24,970
большую часть  то, что мы говорили об

91
00:03:24,970 --> 00:03:26,620
этом термине, хотя и не все, но большая

92
00:03:26,620 --> 00:03:27,879
часть того, что мы говорили об этом термине,

93
00:03:27,879 --> 00:03:29,049
особенно когда мы говорим об

94
00:03:29,049 --> 00:03:30,579
обучении, что означает, что мы не знаем,

95
00:03:30,579 --> 00:03:32,530
как устроен мир, это то, о чем мы

96
00:03:32,530 --> 00:03:34,420
думаем  либо изучение политики, либо

97
00:03:34,420 --> 00:03:36,430
функции ценности, либо и того, и другого непосредственно из

98
00:03:36,430 --> 00:03:38,500
данных, и то, о чем мы

99
00:03:38,500 --> 00:03:40,150
сегодня поговорим, касается изучения

100
00:03:40,150 --> 00:03:42,400
конкретной модели, поэтому просто

101
00:03:42,400 --> 00:03:44,260
напомним себе, что прошло немного времени,

102
00:03:44,260 --> 00:03:45,549
но мы будем говорить о

103
00:03:45,549 --> 00:03:50,799
изучение модели перехода и / или вознаграждения,

104
00:03:50,799 --> 00:03:55,299
и мы немного об этом говорили,

105
00:03:55,299 --> 00:03:58,060
может быть, я не знаю числа несколько

106
00:03:58,060 --> 00:04:00,370
недель назад, я также придумал исследование,

107
00:04:00,370 --> 00:04:02,470
но как только у вас есть модель, вы можете использовать ее

108
00:04:02,470 --> 00:04:04,540
планирование и просто обновить

109
00:04:04,540 --> 00:04:06,370
планирование наших воспоминаний — это когда мы берем

110
00:04:06,370 --> 00:04:08,680
известную модель мира, а затем используем

111
00:04:08,680 --> 00:04:10,930
итерацию значения, или итерацию политики, или

112
00:04:10,930 --> 00:04:13,989
динамическое программирование в целом, чтобы попытаться

113
00:04:13,989 --> 00:04:18,269
вычислить политику для этих заданных моделей,

114
00:04:18,418 --> 00:04:20,470
в отличие от того, о чем мы, конечно,

115
00:04:20,470 --> 00:04:22,419
много говорили.  свободное от модели RL, где

116
00:04:22,419 --> 00:04:24,190
нет модели, мы просто напрямую изучаем

117
00:04:24,190 --> 00:04:26,800
функцию ценности из опыта, и теперь

118
00:04:26,800 --> 00:04:28,690
мы собираемся изучить модель из

119
00:04:28,690 --> 00:04:31,599
опыта, а затем спланировать, используя ее,

120
00:04:31,599 --> 00:04:33,160
теперь планирование, которое мы делаем в дополнение к

121
00:04:33,160 --> 00:04:35,020
своего рода подходам, которые известны

122
00:04:35,020 --> 00:04:37,380
из классических  решение, такое как динамическое

123
00:04:37,380 --> 00:04:40,090
программирование, также может быть любым из других

124
00:04:40,090 --> 00:04:41,740
методов, о которых мы говорили до

125
00:04:41,740 --> 00:04:43,750
сих пор в классе, поэтому вы знаете, как только у нас

126
00:04:43,750 --> 00:04:46,560
это будет, это отключение в качестве симулятора,

127
00:04:46,560 --> 00:04:49,630
и поэтому, как только вы это сделаете, вы можете сделать

128
00:04:49,630 --> 00:04:54,970
RL без модели, используя это  симулятор, или

129
00:04:54,970 --> 00:04:57,190
вы можете выполнить поиск по политике или что

130
00:04:57,190 --> 00:04:58,840
-то еще, что вы хотели бы сделать, учитывая, что у вас

131
00:04:58,840 --> 00:05:01,360
есть модель мира, в основном просто

132
00:05:01,360 --> 00:05:03,039
действует как симулятор, вы можете использовать его для

133
00:05:03,039 --> 00:05:05,500
получения опыта, а также делать что-то

134
00:05:05,500 --> 00:05:09,260
как динамическое программирование,

135
00:05:09,260 --> 00:05:11,000
вы можете выполнять поиск по всем этим вещам, поэтому,

136
00:05:11,000 --> 00:05:12,320
когда у вас есть симулятор для мира

137
00:05:12,320 --> 00:05:14,390
, это здорово, недостатком, конечно, может

138
00:05:14,390 --> 00:05:15,890
быть, если этот симулятор не очень хорош,

139
00:05:15,890 --> 00:05:17,570
что он делает с точки зрения

140
00:05:17,570 --> 00:05:21,530
полученных оценок, хорошо, так что просто

141
00:05:21,530 --> 00:05:24,350
подумайте об этом еще раз, у нас есть наш мир, он

142
00:05:24,350 --> 00:05:26,420
генерирует действия, вознаграждения и состояния,

143
00:05:26,420 --> 00:05:29,270
и теперь мы собираемся подумать о том,

144
00:05:29,270 --> 00:05:31,310
чтобы явно попытаться смоделировать их,

145
00:05:31,310 --> 00:05:34,910
поэтому во многих случаях вы можете знать, что

146
00:05:34,910 --> 00:05:37,400
функция вознаграждения не всегда была много

147
00:05:37,400 --> 00:05:38,780
практических применений  вы будете знать

148
00:05:38,780 --> 00:05:40,280
функцию вознаграждения, поэтому, если вы

149
00:05:40,280 --> 00:05:41,780
разрабатываете систему, основанную на обучении с подкреплением

150
00:05:41,780 --> 00:05:43,730
, для чего-то вроде обслуживания клиентов,

151
00:05:43,730 --> 00:05:45,650
вы, вероятно, имеете

152
00:05:45,650 --> 00:05:48,530
в виду функцию вознаграждения, такую как участие, покуп 

153
00:05:48,530 --> 00:05:50,870
и или подобные вещи, у вас может быть н

154
00:05:50,870 --> 00:05:51,980
очень хорошая модел 

155
00:05:51,980 --> 00:05:54,860
клиент, так что есть много практических

156
00:05:54,860 --> 00:05:56,720
примеров, когда вам нужно изучить

157
00:05:56,720 --> 00:05:58,370
модель динамики явно или неявно,

158
00:05:58,370 --> 00:06:00,680
но сама функция вознаграждения

159
00:06:00,680 --> 00:06:07,250
может быть хорошо известна, так как

160
00:06:07,250 --> 00:06:08,570
думаем ли мы об этом с точки зрения

161
00:06:08,570 --> 00:06:12,140
цикла, мы думаем о наличии некоторого

162
00:06:12,140 --> 00:06:14,030
опыта, поэтому это могут быть такие вещи, как

163
00:06:14,030 --> 00:06:16,820
вы знаете состояние, действие, награда, следующие кортежи состояния,

164
00:06:16,820 --> 00:06:19,190
которые мы затем вводим в модель,

165
00:06:19,190 --> 00:06:21,140
и это будет выводить либо

166
00:06:21,140 --> 00:06:23,990
вознаграждение, либо модель перехода  мы

167
00:06:23,990 --> 00:06:26,360
планируем с помощью того, что может быть динамическим

168
00:06:26,360 --> 00:06:30,170
программированием, или изучением сигналов, или

169
00:06:30,170 --> 00:06:31,610
многими другими методами, которые мы видели здесь,

170
00:06:31,610 --> 00:06:34,490
поиск политики, а затем это должно дать

171
00:06:34,490 --> 00:06:36,050
нам способ выбрать действие, чтобы

172
00:06:36,050 --> 00:06:38,630
оно дало нам действие, которое мы можем  затем

173
00:06:38,630 --> 00:06:41,600
используйте здесь, нам не

174
00:06:41,600 --> 00:06:42,980
обязательно вычислять функцию полного значения,

175
00:06:42,980 --> 00:06:45,170
все, что нам нужно знать, это то,

176
00:06:45,170 --> 00:06:47,180
какое следующее действие нужно предпринять, мы собираемся

177
00:06:47,180 --> 00:06:48,530
использовать это, когда доберемся до поиска по дереву Монте-Карло,

178
00:06:48,530 --> 00:06:49,970
который у нас не обязательно

179
00:06:49,970 --> 00:06:51,860
есть  чтобы вычислить функцию полного значения

180
00:06:51,860 --> 00:06:53,420
для мира, и нам не нужно иметь

181
00:06:53,420 --> 00:06:55,760
полную политику, все, что нам нужно знать, это

182
00:06:55,760 --> 00:06:58,400
то, что мы должны делать для этого конкретного

183
00:06:58,400 --> 00:07:06,080
действия дальше, поэтому некоторые из

184
00:07:06,080 --> 00:07:08,840
преимуществ этого заключаются в том, что у нас есть много

185
00:07:08,840 --> 00:07:10,610
контролируемых методов обучения  в том числе  g

186
00:07:10,610 --> 00:07:12,680
из глубокого глубокого обучения, которое мы можем использовать

187
00:07:12,680 --> 00:07:15,560
для изучения моделей, некоторые из них лучше

188
00:07:15,560 --> 00:07:18,350
или хуже супер подходят, поэтому наша динамика перехода,

189
00:07:18,350 --> 00:07:19,700
как правило, будет думать

190
00:07:19,700 --> 00:07:21,650
о стохастике, поэтому нам понадобится метод обучения с учителем,

191
00:07:21,650 --> 00:07:22,729


192
00:07:22,729 --> 00:07:25,279
который может предсказывать распределения для

193
00:07:25,279 --> 00:07:26,870
моделей вознаграждения, которые мы  часто можно рассматривать их как

194
00:07:26,870 --> 00:07:29,860
скаляры, поэтому мы можем использовать очень классические

195
00:07:29,860 --> 00:07:32,960
подходы, основанные на регрессии, а

196
00:07:32,960 --> 00:07:34,219
другая приятная вещь в сравнении модели с

197
00:07:34,219 --> 00:07:35,599
обучением с подкреплением похожа на то, о чем мы

198
00:07:35,599 --> 00:07:38,180
говорили для исследования, что у нас

199
00:07:38,180 --> 00:07:40,009
часто могут быть явные модели для нашей

200
00:07:40,009 --> 00:07:42,259
неопределенности в отношении того, насколько хороши наши  моделей,

201
00:07:42,259 --> 00:07:44,779
и как только у нас появляется неопределенность в отношении наших

202
00:07:44,779 --> 00:07:46,219
моделей мира, мы можем использовать это для

203
00:07:46,219 --> 00:07:48,349
распространения неопределенности в отношении

204
00:07:48,349 --> 00:07:51,589
решений, которые мы принимаем, так что в случае с бандитами

205
00:07:51,589 --> 00:07:53,210
это было довольно прямолинейно, потому что в

206
00:07:53,210 --> 00:07:56,449
случае с бандитами, то есть для бандитов, у нас была

207
00:07:56,449 --> 00:08:01,389
неопределенность вознаграждения за  рука, и

208
00:08:01,389 --> 00:08:03,620
это просто напрямую отражало нашу

209
00:08:03,620 --> 00:08:05,120
неопределенность в отношении значения, потому что это

210
00:08:05,120 --> 00:08:07,339
был только один временной шаг в

211
00:08:07,339 --> 00:08:09,169
случае MDP, который

212
00:08:09,169 --> 00:08:11,539
мы могли представить.  Неопределенность

213
00:08:11,539 --> 00:08:14,210
в отношении вознаграждения и динамической модели

214
00:08:14,210 --> 00:08:16,430
информирует о такого рода бонусах, а

215
00:08:16,430 --> 00:08:18,169
затем распространяет эту информацию во время

216
00:08:18,169 --> 00:08:20,300
планирования, и это снова позволяет нам

217
00:08:20,300 --> 00:08:22,669
задуматься о том, насколько хорошо мы

218
00:08:22,669 --> 00:08:24,139
знаем ценность различных состояний и

219
00:08:24,139 --> 00:08:26,629
действий и что это может быть.  как

220
00:08:26,629 --> 00:08:28,360
должно быть оптимистично,

221
00:08:28,360 --> 00:08:31,099
теперь недостатком является то, что вы знаете, что сначала

222
00:08:31,099 --> 00:08:32,059
мы собираемся изучить модель, а затем

223
00:08:32,059 --> 00:08:33,019
мы собираемся построить функцию значения,

224
00:08:33,019 --> 00:08:34,818
и там может быть два источника

225
00:08:34,818 --> 00:08:38,809
ошибки аппроксимации, потому что

226
00:08:38,809 --> 00:08:41,089
мы собираемся получить  приблизительную модель, а

227
00:08:41,089 --> 00:08:42,289
затем мы собираемся выполнить приблизительное

228
00:08:42,289 --> 00:08:44,540
планирование в целом для больших пространств состояний,

229
00:08:44,540 --> 00:08:46,730
и поэтому мы можем получить

230
00:08:46,730 --> 00:08:50,029
ошибки компаундирования в этом случае. Теперь еще одно место

231
00:08:50,029 --> 00:08:51,470
, где мы видели ошибки компаундирования ранее

232
00:08:51,470 --> 00:08:52,670
в этом курсе, было, когда мы говорили об

233
00:08:52,670 --> 00:08:54,800
имитационном обучении, мы говорили  о том, если бы у

234
00:08:54,800 --> 00:08:56,899
вас была траектория, а затем

235
00:08:56,899 --> 00:08:58,490
вы попытались клонировать поведение и изучить

236
00:08:58,490 --> 00:09:01,190
сопоставления состояний с действиями, и как,

237
00:09:01,190 --> 00:09:02,930
если бы вы затем получили эту политику и следовали

238
00:09:02,930 --> 00:09:04,760
ей в  В реальном мире вы можете оказаться в

239
00:09:04,760 --> 00:09:05,959
частях пространства состояний, где у вас

240
00:09:05,959 --> 00:09:07,819
не так много данных, и у вас могут быть

241
00:09:07,819 --> 00:09:10,899
такие эскалирующие ошибки, потому что

242
00:09:10,899 --> 00:09:13,550
опять же это может усугубиться, когда вы попадете в

243
00:09:13,550 --> 00:09:14,600
части пространства состояний, где у вас не

244
00:09:14,600 --> 00:09:16,010
так много данных.  данные, то вы экстраполируете,

245
00:09:16,010 --> 00:09:18,709
и все может пойти плохо, так что в

246
00:09:18,709 --> 00:09:20,389
этом случае, если вы строите модель и

247
00:09:20,389 --> 00:09:23,000
вычисляете политику, которая в конечном итоге дает вам

248
00:09:23,000 --> 00:09:24,680
две части мира, где у вас

249
00:09:24,680 --> 00:09:26,389
не очень много данных и где ваша

250
00:09:26,389 --> 00:09:29,329
оценка модели  плохо, тогда снова ваша

251
00:09:29,329 --> 00:09:31,130
результирующая функция ценности, и ваша политика

252
00:09:31,130 --> 00:09:35,600
может быть плохой, я думаю, я просто упомяну еще

253
00:09:35,600 --> 00:09:36,499
одно

254
00:09:36,499 --> 00:09:38,179
преимущество, которое я думаю об

255
00:09:38,179 --> 00:09:39,709
обучении с подкреплением на основе моделей, заключается в том, что оно

256
00:09:39,709 --> 00:09:41,869
также может быть очень мощным для переноса,

257
00:09:41,869 --> 00:09:44,209
поэтому, когда Челси был здесь и говорил

258
00:09:44,209 --> 00:09:45,829
Об обучении металла одно из приятных

259
00:09:45,829 --> 00:09:48,589
преимуществ RL на основе моделей заключается в том, что если

260
00:09:48,589 --> 00:09:50,299
вы изучаете динамическую модель мира,

261
00:09:50,299 --> 00:09:52,639
то, если кто-то изменит функцию вознаграждения

262
00:09:52,639 --> 00:09:56,029
в plis Utley, вы можете просто сделать

263
00:09:56,029 --> 00:09:58,189
передачу с нулевым выстрелом, потому что вы можете просто

264
00:09:58,189 --> 00:09:59,599
взять  ваша учебная модель динамики,

265
00:09:59,599 --> 00:10:01,669
а затем ваша словесная функция, вы можете просто

266
00:10:01,669 --> 00:10:03,889
вычислить новый план, например, если я

267
00:10:03,889 --> 00:10:05,359
робот, и я научился ориентироваться в

268
00:10:05,359 --> 00:10:07,279
этой комнате, и теперь я знаю, как

269
00:10:07,279 --> 00:10:08,689
вы знаете, что значит поворачивать и

270
00:10:08,689 --> 00:10:10,489
каково это идти вперед и т. д. и раньше

271
00:10:10,489 --> 00:10:11,869
я всегда пытался добраться до этого выхода,

272
00:10:11,869 --> 00:10:13,939
но теперь я знаю динамику, я знаю свою

273
00:10:13,939 --> 00:10:16,219
модель динамики в целом для этой комнаты,

274
00:10:16,219 --> 00:10:18,169
а потом кто-то говорит нет, нет, я не хочу, чтобы

275
00:10:18,169 --> 00:10:19,549
вы шли к этим выходам  это лучше,

276
00:10:19,549 --> 00:10:20,929
вы знаете одежду или что-то в этом роде, поэтому идите

277
00:10:20,929 --> 00:10:22,909
к другому выходу, и они говорят мне о

278
00:10:22,909 --> 00:10:24,739
функции вознаграждения, они говорят, что вы знаете пользователя

279
00:10:24,739 --> 00:10:26,599
плюс один для этого выхода сейчас, а не

280
00:10:26,599 --> 00:10:29,179
там, тогда я могу просто перепланировать с моей

281
00:10:29,179 --> 00:10:32,539
моделью динамики, чтобы я не  нужно больше

282
00:10:32,539 --> 00:10:34,399
опыта, я могу получить передачу с нулевым выстрелом,

283
00:10:34,399 --> 00:10:36,829
так что это может быть действительно полезно, это

284
00:10:36,829 --> 00:10:38,839
одна из других причин, по которой вы можете

285
00:10:38,839 --> 00:10:40,609
просто строить модели мира

286
00:10:40,609 --> 00:10:42,409
в целом, и есть некоторые интересные

287
00:10:42,409 --> 00:10:44,419
доказательства того, что когда люди играют в

288
00:10:44,419 --> 00:10:45,799
игры Atari, они, вероятно,

289
00:10:45,799 --> 00:10:48,019
систематически покупать  что

290
00:10:48,019 --> 00:10:49,819
происходит, когда я перемещаю айсберг рядом

291
00:10:49,819 --> 00:10:52,579
с белым медведем, и потому что тогда вы можете

292
00:10:52,579 --> 00:10:53,779
обобщить эти модели на другой

293
00:10:53,779 --> 00:10:57,439
опыт, хорошо, так как мы собираемся

294
00:10:57,439 --> 00:10:58,549
записать нашу модель в этом случае,

295
00:10:58,549 --> 00:11:00,019
мы снова просто вроде нашего нормального

296
00:11:00,019 --> 00:11:02,539
состояния  динамика перехода действия и

297
00:11:02,539 --> 00:11:05,059
вознаграждение, и мы собираемся предположить, что

298
00:11:05,059 --> 00:11:08,199
наша модель приблизительно представляет нашу

299
00:11:08,199 --> 00:11:11,779
модель перехода и нашу модель вознаграждения, поэтому

300
00:11:11,779 --> 00:11:13,879
мы принимаем здесь предположение Маркова,

301
00:11:13,879 --> 00:11:17,419
чтобы мы могли представить, что наша следующая дата

302
00:11:17,419 --> 00:11:19,039
- это просто предыдущие данные в действии

303
00:11:19,039 --> 00:11:21,229
и распределение  над этим, и у нас

304
00:11:21,229 --> 00:11:22,759
также будет это для

305
00:11:22,759 --> 00:11:26,959
вознаграждения, и мы обычно предполагаем, что

306
00:11:26,959 --> 00:11:28,429
вещи условно независимы, как то, что

307
00:11:28,429 --> 00:11:30,289
мы делали раньше, поэтому у нас просто есть

308
00:11:30,289 --> 00:11:31,879
конкретная модель динамики, она

309
00:11:31,879 --> 00:11:33,499
обусловлена состоянием, действием и во 

310
00:11:33,499 --> 00:11:34,969
награждением, которое  обусловлены

311
00:11:34,969 --> 00:11:40,129
предыдущим состоянием в действии, и поэтому, если мы

312
00:11:40,129 --> 00:11:41,719
хотим провести модельное обучение, у нас есть

313
00:11:41,719 --> 00:11:43,159
эта проблема обучения с

314
00:11:43,159 --> 00:11:44,239
учителем, о которой мы говорили немного раньше.

315
00:11:44,239 --> 00:11:46,879
у вас есть состояние в действии, и вы

316
00:11:46,879 --> 00:11:48,399
хотите предсказать следующее состояние вашего вознаграждения,

317
00:11:48,399 --> 00:11:50,450
и поэтому у нас есть эта

318
00:11:50,450 --> 00:11:51,980
проблема регрессии в этой проблеме оценки плотности,

319
00:11:51,980 --> 00:11:54,890
тогда вы можете сделать это всеми

320
00:11:54,890 --> 00:11:58,700
возможными способами, вы можете я знаю, что это означает вполне

321
00:11:58,700 --> 00:12:00,460
или вы можете использовать разные формы  потерь,

322
00:12:00,460 --> 00:12:03,470
и на самом деле один из способов, которым мы

323
00:12:03,470 --> 00:12:05,330
недавно добились прогресса в

324
00:12:05,330 --> 00:12:06,830
обучении с подкреплением вне политики, заключается в использовании

325
00:12:06,830 --> 00:12:09,560
различных форм потерь, а затем

326
00:12:09,560 --> 00:12:11,420
стандартных видов потерь максимальной вероятности,

327
00:12:11,420 --> 00:12:13,880
но в целом здесь мы будем

328
00:12:13,880 --> 00:12:16,130
говорить о потерях максимальной вероятности, чтобы

329
00:12:16,130 --> 00:12:17,870
мы могли  просто сделайте это и, конечно,

330
00:12:17,870 --> 00:12:19,250
в табличном случае это просто

331
00:12:19,250 --> 00:12:22,250
подсчет, поэтому, если у вас просто есть дискретный

332
00:12:22,250 --> 00:12:24,350
набор состояний и действий, вы можете просто

333
00:12:24,350 --> 00:12:26,360
подсчитать, сколько раз я начинал в этом

334
00:12:26,360 --> 00:12:28,130
состоянии в действии и переходил в состояние один по

335
00:12:28,130 --> 00:12:29,870
сравнению с тем, как  много раз сегодня начинайте в

336
00:12:29,870 --> 00:12:32,120
этом состоянии, и действие переходит в состояние два, поэтому

337
00:12:32,120 --> 00:12:33,110
вы просто подсчитываете их, а затем

338
00:12:33,110 --> 00:12:38,510
нормализуете, и в целом существует огромное

339
00:12:38,510 --> 00:12:39,800
количество различных способов, которыми вы можете

340
00:12:39,800 --> 00:12:42,590
представить это, и я думаю, что один из них

341
00:12:42,590 --> 00:12:43,460
Те, которые я думаю, особенно

342
00:12:43,460 --> 00:12:46,040
интересны, это байесовские, а не байесовские

343
00:12:46,040 --> 00:12:47,660
глубокие нейронные сети, их было довольно

344
00:12:47,660 --> 00:12:50,210
сложно настроить до сих пор, так что другой процесс, который

345
00:12:50,210 --> 00:12:54,890
вы знаете, байесовские D-нейронные сети,

346
00:12:54,890 --> 00:12:56,810
ммм, я думаю, одна из причин, по которой они

347
00:12:56,810 --> 00:12:58,130
могут быть действительно мощными, поскольку они

348
00:12:58,130 --> 00:13:00,560
могут  представляют неопределенность, но до

349
00:13:00,560 --> 00:13:01,760
сих пор их было довольно сложно обучить,

350
00:13:01,760 --> 00:13:03,740
но я думаю, что вы знаете

351
00:13:03,740 --> 00:13:05,120
много действительно есть несколько очень простых

352
00:13:05,120 --> 00:13:06,740
моделей, которые мы можем использовать, а также некоторые действительно

353
00:13:06,740 --> 00:13:08,720
богатые функции, аппроксимированные для этих

354
00:13:08,720 --> 00:13:13,190
моделей, хорошо, так что если мы в  в

355
00:13:13,190 --> 00:13:15,440
случае поиска по таблице мы просто усредняем количество,

356
00:13:15,440 --> 00:13:17,510
поэтому мы просто подсчитываем, как я сказал, это

357
00:13:17,510 --> 00:13:19,850
действие в следующем состоянии кортежи следующего состояния делят

358
00:13:19,850 --> 00:13:22,610
на количество раз, которое мы выполняем в этом

359
00:13:22,610 --> 00:13:25,040
действии в этом состоянии, и мы аналогичным образом

360
00:13:25,040 --> 00:13:27,530
просто усредняем все награды, так что это

361
00:13:27,530 --> 00:13:31,160
должно  быть сценой вознаграждения за то время

362
00:13:31,160 --> 00:13:33,290
, когда мы были в этом состоянии, предприняли это

363
00:13:33,290 --> 00:13:35,060
действие и какова была награда, которую мы получили на

364
00:13:35,060 --> 00:13:41,510
этом временном шаге, поэтому давайте подумаем о

365
00:13:41,510 --> 00:13:43,610
примере того, как это выглядит здесь

366
00:13:43,610 --> 00:13:45,950
так долго  назад мы представили этот пример ABA,

367
00:13:45,950 --> 00:13:48,770
где у нас есть состояние, которое переходит

368
00:13:48,770 --> 00:13:51,590
в состояние a, которое переходит к действию, и в

369
00:13:51,590 --> 00:13:53,510
состояние B, а затем после этого оно либо

370
00:13:53,510 --> 00:13:55,400
переходит в конечное состояние, в котором я получил

371
00:13:55,400 --> 00:13:59,480
вознаграждение, равное единице с вероятностью 75%, либо оно

372
00:13:59,480 --> 00:14:01,220
переходит в  конечное состояние, в котором он получает

373
00:14:01,220 --> 00:14:04,070
вознаграждение, равное нулю с вероятностью 25%,

374
00:14:04,070 --> 00:14:06,230
и представьте, что мы испытали

375
00:14:06,230 --> 00:14:07,639
что-то в этом мире, поэтому здесь нет никаких

376
00:14:07,639 --> 00:14:09,259
действий, вы знаете, что есть одно

377
00:14:09,259 --> 00:14:12,350
действие, это действительно марковский процесс вознаграждения,

378
00:14:12,350 --> 00:14:15,220
а не процесс принятия решения,

379
00:14:15,220 --> 00:14:17,959
но мы можем  получить его наблюдения, так что,

380
00:14:17,959 --> 00:14:20,149
скажем, мы начали в состоянии А, а затем мы

381
00:14:20,149 --> 00:14:21,740
получили нулевое вознаграждение и перешли к Б и

382
00:14:21,740 --> 00:14:23,930
получили ноль, а затем у нас был целый

383
00:14:23,930 --> 00:14:26,540
набор раз, у нас есть шесть раз, когда мы

384
00:14:26,540 --> 00:14:28,880
начали Б, у меня есть  вознаграждение равно 1, а

385
00:14:28,880 --> 00:14:31,519
затем мы запустили его в состоянии B и

386
00:14:31,519 --> 00:14:33,860
получили вознаграждение 0, и теперь мы можем

387
00:14:33,860 --> 00:14:36,500
построить модель поиска по таблице из этого

388
00:14:36,500 --> 00:14:40,310
и просто освежить наши воспоминания, поэтому мы

389
00:14:40,310 --> 00:14:42,050
говорили о том факте, что если вы выполняете

390
00:14:42,050 --> 00:14:43,579
обучение временной разнице в этом

391
00:14:43,579 --> 00:14:45,550
проблема с табличным представлением  Это

392
00:14:45,550 --> 00:14:48,410
означает, что одна строка для каждого состояния, так что это

393
00:14:48,410 --> 00:14:51,589
всего лишь два состояния a и B, но если вы выполняете

394
00:14:51,589 --> 00:14:53,389
бесконечное воспроизведение этого набора

395
00:14:53,389 --> 00:14:55,699
опыта, то это эквивалентно тому, если бы

396
00:14:55,699 --> 00:14:59,870
вы взяли эти данные и оценили или

397
00:14:59,870 --> 00:15:02,420
марковская модель процесса принятия решений с ними,

398
00:15:02,420 --> 00:15:04,790
а затем выполнили планирование с этим  чтобы

399
00:15:04,790 --> 00:15:08,089
оценить оптимальную политику или

400
00:15:08,089 --> 00:15:09,920
политику, которую вы используете для сбора

401
00:15:09,920 --> 00:15:13,069
данных в этом случае, так что это была

402
00:15:13,069 --> 00:15:14,810
интересная эквивалентность, что TD

403
00:15:14,810 --> 00:15:17,000
получает точно такое же решение, как

404
00:15:17,000 --> 00:15:19,250
если бы вы вычислили то, что часто называют

405
00:15:19,250 --> 00:15:21,380
моделью эквивалентности достоверности, потому что

406
00:15:21,380 --> 00:15:24,380
вы берете  ваши данные, которые вы оцениваете, вы

407
00:15:24,380 --> 00:15:26,959
берете эмпирическое среднее этих данных, чтобы

408
00:15:26,959 --> 00:15:28,370
вы могли сказать, если бы это были все данные

409
00:15:28,370 --> 00:15:29,569
в мире, какой была бы модель,

410
00:15:29,569 --> 00:15:31,550
которая, как вы знаете, могла бы быть

411
00:15:31,550 --> 00:15:33,350
связана с оценкой максимального правдоподобия,

412
00:15:33,350 --> 00:15:36,649
а затем вы планируете так  TD делает

413
00:15:36,649 --> 00:15:38,389
это предположение, давайте просто быстро

414
00:15:38,389 --> 00:15:40,730
проверим память, сходятся ли методы Монте-Карло

415
00:15:40,730 --> 00:15:42,529
к одному и тому же решению на этих

416
00:15:42,529 --> 00:15:49,819
данных, поэтому, возможно, уделите минутку

417
00:15:49,819 --> 00:15:51,649
кому-нибудь рядом с вами и  решить

418
00:15:51,649 --> 00:15:54,310
, делают они это или нет,

419
00:15:57,090 --> 00:16:00,320
и почему, почему нет,

420
00:16:11,880 --> 00:16:15,480
да, вопрос, как Анна как опера,

421
00:16:15,480 --> 00:16:19,589
думаю, хорошо, я думаю, что методы Монте-Карло

422
00:16:19,589 --> 00:16:22,259
сойдутся к решению,

423
00:16:22,259 --> 00:16:25,610
будет минимальная MSE, предполагается, что у нее есть li,

424
00:16:25,610 --> 00:16:26,910
все в порядке,

425
00:16:26,910 --> 00:16:29,579
правильные методы Монте-Карло не

426
00:16:29,579 --> 00:16:32,519
делают предположения  из марковских, поэтому

427
00:16:32,519 --> 00:16:35,639
они подходят в случаях, когда

428
00:16:35,639 --> 00:16:37,889
домен не является марковским, поэтому в этом случае

429
00:16:37,889 --> 00:16:39,810
они будут сходиться к ним во

430
00:16:39,810 --> 00:16:41,880
всех случаях для этой оценки политики,

431
00:16:41,880 --> 00:16:42,870
они будут сходиться к минимальной

432
00:16:42,870 --> 00:16:45,000
среднеквадратической ошибке, да, вопрос,

433
00:16:45,000 --> 00:16:48,660
использующий это злоупотребление, сходятся  для

434
00:16:48,660 --> 00:16:50,190
видеопиратства, что, если вы используете другой

435
00:16:50,190 --> 00:16:53,100
лот, это то, что это

436
00:16:53,100 --> 00:16:57,959
сойдется на минимальном MSE, а не на MLE, если

437
00:16:57,959 --> 00:16:59,490
вы используете другого босса, мы не

438
00:16:59,490 --> 00:17:02,069
вырезали вас, чтобы увидеть, да, давайте посмотрим, как вы используете

439
00:17:02,069 --> 00:17:04,829
как пума или  Методы Монте-Карло

440
00:17:04,829 --> 00:17:06,630
преобразуются прямее, я имею в виду, в зависимости

441
00:17:06,630 --> 00:17:08,159
от потерь или если вы упорядочили, это

442
00:17:08,159 --> 00:17:10,380
отличный вопрос, если вы упорядочиваете гм, он

443
00:17:10,380 --> 00:17:12,030
может сходиться к разным решениям,

444
00:17:12,030 --> 00:17:13,409
минимальная среднеквадратическая ошибка в зависимости от

445
00:17:13,409 --> 00:17:14,880
хо  w вы обычно смотрите на те потери, которые вы используете,

446
00:17:14,880 --> 00:17:16,949
но в целом они не будут сходиться к

447
00:17:16,949 --> 00:17:19,500
тому же, как если бы вы получили

448
00:17:19,500 --> 00:17:21,539
модель оценки максимального правдоподобия, а затем выполнили

449
00:17:21,539 --> 00:17:23,640
планирование с ее помощью или оценку политики,

450
00:17:23,640 --> 00:17:26,159
и ключевое отличие состоит в том, что Монте-

451
00:17:26,159 --> 00:17:28,439
Карло не делал марковское предположение  так

452
00:17:28,439 --> 00:17:35,669
что он не предполагает Маркова, и поэтому, в

453
00:17:35,669 --> 00:17:38,940
частности, в этом случае я могу

454
00:17:38,940 --> 00:17:41,070
предположить, какое значение a будет

455
00:17:41,070 --> 00:17:44,720
при оценке Монте-Карло,

456
00:17:47,640 --> 00:17:51,700
есть только одна выборка, да,

457
00:17:51,700 --> 00:17:53,740
да, так что здесь только четыре Монте-Карло,

458
00:17:53,740 --> 00:17:56,590
мы'  скажем, я смотрю только на полные

459
00:17:56,590 --> 00:17:57,880
возвраты, которые начались с этого

460
00:17:57,880 --> 00:17:59,679
конкретного состояния, и нет никакой

461
00:17:59,679 --> 00:18:02,920
начальной загрузки, поэтому единственный раз, когда мы видели a,

462
00:18:02,920 --> 00:18:07,059
был когда возврат из a был нулевым, но

463
00:18:07,059 --> 00:18:08,530
вы знаете, если система действительно Маркофф

464
00:18:08,530 --> 00:18:09,640
, это не очень хорошее решение, потому что

465
00:18:09,640 --> 00:18:11,260
у нас есть все эти другие доказательства того, что B

466
00:18:11,260 --> 00:18:13,090
на самом деле обычно имеет более высокое значение,

467
00:18:13,090 --> 00:18:14,799
и мы не можем воспользоваться этим, в

468
00:18:14,799 --> 00:18:15,730
то

469
00:18:15,730 --> 00:18:18,910
время как PD делает так, что TB может хорошо сказать, что я

470
00:18:18,910 --> 00:18:20,710
знаю, что V из a был там в этот раз,

471
00:18:20,710 --> 00:18:23,710
но в g  В общем, мы думаем, что V для а

472
00:18:23,710 --> 00:18:27,250
равно вознаграждению за Rho метр плюс в

473
00:18:27,250 --> 00:18:28,660
этом случае нет дисконтирования, поэтому

474
00:18:28,660 --> 00:18:31,360
значение B, и у меня есть все другие

475
00:18:31,360 --> 00:18:34,210
другие доказательства того, что значение B в

476
00:18:34,210 --> 00:18:36,960
этом случае на самом деле точно равно 0,75,

477
00:18:36,960 --> 00:18:39,460
потому что у нас есть  шесть примеров того, что это

478
00:18:39,460 --> 00:18:42,580
один и два примера, что это ноль, поэтому

479
00:18:42,580 --> 00:18:45,850
мы получили бы, что V of B равно 0,75,

480
00:18:45,850 --> 00:18:50,230
и и Монте-Карло, и телевидение согласятся

481
00:18:50,230 --> 00:18:53,890
с этим, потому что, если вы посмотрите каждый

482
00:18:53,890 --> 00:18:56,410
раз, когда вы начинаете, и будет 75 процентов или

483
00:18:56,410 --> 00:18:58,150
вы  знаю некоторых из вас, в 1% случаев

484
00:18:58,150 --> 00:18:59,440
вы получаете единицу, в остальное время вы

485
00:18:59,440 --> 00:19:01,660
получаете ноль, поэтому значение этого числа равно

486
00:19:01,660 --> 00:19:07,929
0,75, поэтому оценка по телевидению также будет означать, что V

487
00:19:07,929 --> 00:19:14,770
of a равно 0,75 оценка по телевидению, поэтому

488
00:19:14,770 --> 00:19:16,270
одна из  причины, по которым это появляется здесь,

489
00:19:16,270 --> 00:19:19,150
и обратите внимание, что это не из-за

490
00:19:19,150 --> 00:19:21,220
своего рода конечного числа резервных копий, о,

491
00:19:21,220 --> 00:19:23,290
извините, я буду осторожен с конечным объемом

492
00:19:23,290 --> 00:19:26,080
использования данных, так что это говорит о том, что если вы как

493
00:19:26,080 --> 00:19:28,210
бы запускаете это через телевизор  много-много

494
00:19:28,210 --> 00:19:30,309
раз, и оценка Монте-Карло

495
00:19:30,309 --> 00:19:31,750
также получает доступ ко всем данным

496
00:19:31,750 --> 00:19:33,340
это просто говорит, что это все данные, которые

497
00:19:33,340 --> 00:19:36,250
есть, поэтому альтернативой будет, если

498
00:19:36,250 --> 00:19:38,320
вы возьмете эти данные и построите модель,

499
00:19:38,320 --> 00:19:41,169
так что теперь у нас есть модель, которая говорит, что

500
00:19:41,169 --> 00:19:43,270
вероятность того, что вы

501
00:19:43,270 --> 00:19:46,540
начнете, равна 1, вы всегда  идите от него

502
00:19:46,540 --> 00:19:48,820
от А к Б на самом деле вы

503
00:19:48,820 --> 00:19:50,860
видели это только один раз, но один раз, когда вы

504
00:19:50,860 --> 00:19:54,460
это увидели, вы отправились к Б, и мы можем использовать это, чтобы

505
00:19:54,460 --> 00:19:59,500
попытаться получить смоделированные данные, так что позвольте мне просто

506
00:19:59,500 --> 00:20:00,700
хорошо, я пройду пару

507
00:20:00,700 --> 00:20:02,770
или, таким образом, идея в этом случае состоит в том, что когда у

508
00:20:02,770 --> 00:20:04,840
вас есть симулятор, вы можете использовать его

509
00:20:04,840 --> 00:20:07,300
для моделирования образцов, а затем вы можете

510
00:20:07,300 --> 00:20:10,270
планировать использование этих смоделированных данных сейчас

511
00:20:10,270 --> 00:20:11,830
изначально, что может звучать так, как будто

512
00:20:11,830 --> 00:20:13,750
вы сделали это, потому что у вас были ваши

513
00:20:13,750 --> 00:20:15,070
предыдущие данные, возможно, вы могли бы

514
00:20:15,070 --> 00:20:17,590
вы знаете, что использовали подход, основанный на модели, не основанной на модели,

515
00:20:17,590 --> 00:20:19,570
например, зачем вам

516
00:20:19,570 --> 00:20:22,450
сначала строить модель, а затем генерировать

517
00:20:22,450 --> 00:20:24,550
данные из нее, но мы

518
00:20:24,550 --> 00:20:27,130
прямо сейчас увидим пример из такого рода примера B,

519
00:20:27,130 --> 00:20:29,760
почему это может быть полезно, поэтому

520
00:20:29,760 --> 00:20:31,930
вы  что мы можем сделать, мы можем получить это,

521
00:20:31,930 --> 00:20:33,850
мы можем получить максимальный лайк  оценка достоверности

522
00:20:33,850 --> 00:20:36,310
модели или другие оценки, которые

523
00:20:36,310 --> 00:20:37,180
вы, возможно, захотите использовать, а затем вы можете сделать

524
00:20:37,180 --> 00:20:40,330
выборку из нее, поэтому в этом примере, который у нас

525
00:20:40,330 --> 00:20:44,950
только что был, наша предполагаемая

526
00:20:44,950 --> 00:20:46,960
модель перехода состоит в том, что всякий раз, когда мы запускаем a, мы переходим к

527
00:20:46,960 --> 00:20:52,030
B, поэтому, когда я нахожусь в I  могу сделать выборку, и я

528
00:20:52,030 --> 00:20:53,620
пойду к B, и это сгенерирует мне

529
00:20:53,620 --> 00:20:57,850
фальшивую точку данных, и я мог бы сделать это

530
00:20:57,850 --> 00:20:59,410
много раз, мы получаем много фальшивых

531
00:20:59,410 --> 00:20:59,770
данных,

532
00:20:59,770 --> 00:21:01,870
теперь эти фальшивые данные могут или не могут

533
00:21:01,870 --> 00:21:03,370
выглядеть так, как в реальном мире, это зависит от

534
00:21:03,370 --> 00:21:05,500
того, как  моя модель хороша, но это, безусловно,

535
00:21:05,500 --> 00:21:07,630
данные, с которыми я могу тренироваться, и мы увидим каждую

536
00:21:07,630 --> 00:21:09,760
минуту, почему это полезно,

537
00:21:09,760 --> 00:21:12,820
хорошо, так что, если мы вернемся сюда,

538
00:21:12,820 --> 00:21:16,300
это реальный опыт слева, поэтому

539
00:21:16,300 --> 00:21:17,680
слева у нас было все  этот реальный

540
00:21:17,680 --> 00:21:19,870
опыт, а затем то, что мы сделали, мы

541
00:21:19,870 --> 00:21:23,830
построили модель из этого, а затем мы

542
00:21:23,830 --> 00:21:25,510
могли взять из нее образцы, чтобы мы могли получить

543
00:21:25,510 --> 00:21:27,100
опыт, который очень похож

544
00:21:27,100 --> 00:21:29,290
на данные, которые мы на самом деле видели, но мы

545
00:21:29,290 --> 00:21:36,310
также могли бы иметь такой опыт сейчас,

546
00:21:36,310 --> 00:21:37,600
почему  могли бы мы иметь это, потому что теперь у

547
00:21:37,600 --> 00:21:39,280
нас есть симулятор и мы  в нашей

548
00:21:39,280 --> 00:21:41,980
симуляции в нашей модели мы видели случаи,

549
00:21:41,980 --> 00:21:45,280
когда мы начинали с а и шли к Б,

550
00:21:45,280 --> 00:21:48,850
и в нашей модели были и другие

551
00:21:48,850 --> 00:21:50,230
случаи, когда мы начинали с Б, и у

552
00:21:50,230 --> 00:21:52,270
нас был один, так что, по сути, мы можем как бы

553
00:21:52,270 --> 00:21:54,130
связать этот опыт вместе и

554
00:21:54,130 --> 00:21:55,420
смоделировать то, что мы никогда не

555
00:21:55,420 --> 00:21:57,400
наблюдали в реальном мире, и мы

556
00:21:57,400 --> 00:21:58,660
используем здесь тот факт, что это

557
00:21:58,660 --> 00:22:03,130
Марков, поэтому, если домен на самом деле не

558
00:22:03,130 --> 00:22:04,660
Марков, мы могли бы в конечном итоге получить данные, которые

559
00:22:04,660 --> 00:22:06,490
выглядят совсем иначе, чем вы

560
00:22:06,490 --> 00:22:08,590
могли бы  когда-либо попасть в реальный мир, но если

561
00:22:08,590 --> 00:22:12,280
это Марков, то и это все еще может быть

562
00:22:12,280 --> 00:22:13,840
приблизительной моделью, потому что у нас был только

563
00:22:13,840 --> 00:22:14,380
предел

564
00:22:14,380 --> 00:22:16,720
из модели тренера данных, но теперь мы можем

565
00:22:16,720 --> 00:22:19,060
начать видеть сочетания состояний и

566
00:22:19,060 --> 00:22:21,280
действий, но мы, возможно, никогда не видели в наших

567
00:22:21,280 --> 00:22:27,550
данных  модель, поскольку мы хорошо сэмплируем, хорошо, не могли бы

568
00:22:27,550 --> 00:22:28,750
вы обновить свою мать, просто вы

569
00:22:28,750 --> 00:22:31,240
могли бы, но сейчас мы просто выбираем образцы

570
00:22:31,240 --> 00:22:33,520
из наших моделей, так что это не

571
00:22:33,520 --> 00:22:35,830
реальный опыт, поэтому это может привести

572
00:22:35,830 --> 00:22:37,750
к предвзятости подтверждения, потому что это похоже на то, что

573
00:22:37,750 --> 00:22:39,190
ваша модель дает вам  г  ata, и если вы

574
00:22:39,190 --> 00:22:41,110
относитесь к ним как к реальным данным и

575
00:22:41,110 --> 00:22:43,390
возвращаете их обратно в свою модель, они не из

576
00:22:43,390 --> 00:22:45,100
реального мира, так что вы можете в конечном итоге

577
00:22:45,100 --> 00:22:49,030
быть слишком уверены в I, потому

578
00:22:49,030 --> 00:22:50,140
что вы генерируете поддельные данные, а затем

579
00:22:50,140 --> 00:22:53,800
договор заключается в том, реальны ли они в нашей  примерный

580
00:22:53,800 --> 00:22:55,840
опыт, и это похоже на то,

581
00:22:55,840 --> 00:22:57,160
сколько тренировок вы думали, что

582
00:22:57,160 --> 00:23:00,010
модель здания в порядке, так как

583
00:23:00,010 --> 00:23:01,810
бы мы узнали, насколько компетентными должны быть, и в

584
00:23:01,810 --> 00:23:03,130
целом это проблема ваших моделей,

585
00:23:03,130 --> 00:23:05,020
которые иногда будут довольно плохими, если у вас

586
00:23:05,020 --> 00:23:06,550
есть ограниченное количество  данных, поэтому некоторые

587
00:23:06,550 --> 00:23:07,690
из методов, о которых мы говорили для

588
00:23:07,690 --> 00:23:09,250
исследования, где мы могли бы управлять

589
00:23:09,250 --> 00:23:10,900
этими доверительными интервалами относительно того, насколько

590
00:23:10,900 --> 00:23:12,550
хороши бутылки, они также живут здесь,

591
00:23:12,550 --> 00:23:15,100
поэтому, если у вас есть только немного

592
00:23:15,100 --> 00:23:16,630
данных, вы можете использовать такие вещи, как прыжок, чтобы

593
00:23:16,630 --> 00:23:19,150
скажите, да, конечно, я об этой модели вознаграждения,

594
00:23:19,150 --> 00:23:22,240
например, для большинства из нас мы не

595
00:23:22,240 --> 00:23:23,440
будем говорить об этом так много, но

596
00:23:23,440 --> 00:23:25,030
вы можете использовать эту информацию, чтобы попытаться

597
00:23:25,030 --> 00:23:27,460
количественно определить, насколько неуверенными вы должны быть и

598
00:23:27,460 --> 00:23:29,400
как эта ошибка  распространять

599
00:23:29,400 --> 00:23:31,420
да,

600
00:23:31,420 --> 00:23:34,180
так что я думаю, я пытаюсь

601
00:23:34,180 --> 00:23:36,430
концептуально подумать о следующем шаге

602
00:23:36,430 --> 00:23:38,230
, что мы строим эту модель,

603
00:23:38,230 --> 00:23:40,480
мы собираемся использовать метод, чтобы изучить какую-

604
00:23:40,480 --> 00:23:43,180
то политику или что-то вроде

605
00:23:43,180 --> 00:23:46,390
способа действовать в  способ работы, если у нас

606
00:23:46,390 --> 00:23:48,520
есть модель, вы не можете просто использовать модель,

607
00:23:48,520 --> 00:23:50,230
когда вы действуете, и просто в основном

608
00:23:50,230 --> 00:23:52,180
запускать нашу ставку через модель и получать,

609
00:23:52,180 --> 00:23:54,670
возможно, как распределение, и просто

610
00:23:54,670 --> 00:23:57,490
предпринимать максимальные действия и действия, которые

611
00:23:57,490 --> 00:24:02,110
максимизируют наши больше  так что, я думаю, когда у

612
00:24:02,110 --> 00:24:03,460
вас есть модель, вы можете использовать ее

613
00:24:03,460 --> 00:24:05,560
множеством разных способов для планирования, например

614
00:24:05,560 --> 00:24:07,420
, вы можете сделать это, если это небольшой случай,

615
00:24:07,420 --> 00:24:10,390
как здесь, это таблица, поэтому вы можете использовать

616
00:24:10,390 --> 00:24:13,000
итерацию значения и решить это точно

617
00:24:13,000 --> 00:24:16,150
, нет причин  симулировать данные, но

618
00:24:16,150 --> 00:24:17,710
когда вы начинаете думать о том, чтобы делать, как

619
00:24:17,710 --> 00:24:19,510
Atari, или другие действительно многомерные

620
00:24:19,510 --> 00:24:21,580
задачи, одна только проблема планирования является

621
00:24:21,580 --> 00:24:23,590
очень дорогой, и поэтому вы все еще можете использовать

622
00:24:23,590 --> 00:24:25,480
методы без моделей для вашего

623
00:24:25,480 --> 00:24:28,210
планирования с вашими симулированными данными

624
00:24:28,210 --> 00:24:29,470
и одна из причин, по которой вы  может захотеть

625
00:24:29,470 --> 00:24:32,320
сделать это, потому что мы говорили о

626
00:24:32,320 --> 00:24:33,759
разных способах обучения Q, чтобы быть более

627
00:24:33,759 --> 00:24:35,289
эффективным семплам, например, у вас есть буфер воспроизведения,

628
00:24:35,289 --> 00:24:36,580
и вы можете сделать это звуковым

629
00:24:36,580 --> 00:24:39,129
повтором, но другой альтернативой является то,

630
00:24:39,129 --> 00:24:40,570
что вы просто генерируете много данных из своего

631
00:24:40,570 --> 00:24:42,220
смоделированная модель, а затем вы воспроизводите

632
00:24:42,220 --> 00:24:44,559
ее тонну раз, и

633
00:24:44,559 --> 00:24:46,840
это еще один способ извлечь больше пользы

634
00:24:46,840 --> 00:24:52,480
из ваших данных, да, спросите у микрофона, если

635
00:24:52,480 --> 00:24:54,100
вы не хотите делать рыночные

636
00:24:54,100 --> 00:24:57,450
предположения, можете ли вы по-прежнему делать то же самое, но с

637
00:24:57,450 --> 00:25:02,919
условием  о прошлом рано, да, что, если

638
00:25:02,919 --> 00:25:03,700
вы не хотите делать предположение Маркова,

639
00:25:03,700 --> 00:25:05,470
да, и можете ли вы

640
00:25:05,470 --> 00:25:07,330
обусловить прошлое, вы абсолютно можете, это

641
00:25:07,330 --> 00:25:08,529
означает, что вы будете строить модели, которые

642
00:25:08,529 --> 00:25:10,450
полностью зависят от истории, проблема

643
00:25:10,450 --> 00:25:11,409
с этим в том, что вы не  у вас очень много

644
00:25:11,409 --> 00:25:14,169
данных, поэтому вам нужно, если вы хотите, чтобы

645
00:25:14,169 --> 00:25:15,700
условие для всей истории было, по

646
00:25:15,700 --> 00:25:17,200
сути, вашим состоянием, у вас всегда все в

647
00:25:17,200 --> 00:25:18,730
порядке с точки зрения предположения Маркова,

648
00:25:18,730 --> 00:25:20,559
но у вас будет очень очень

649
00:25:20,559 --> 00:25:22,029
мало данных для оценки моделей перехода в год.

650
00:25:22,029 --> 00:25:23,769
особенно по мере того, как горизонт расширяется,

651
00:25:23,769 --> 00:25:26,049
так что это часто компромисс, например, хотите ли вы

652
00:25:26,049 --> 00:25:27,639
иметь лучшие модели, что зависит

653
00:25:27,639 --> 00:25:28,869
от вашей предметной области, может быть, это действительно марковские,

654
00:25:28,869 --> 00:25:30,700
если это не совсем марковские, вы хотите

655
00:25:30,700 --> 00:25:33,389
лучшие модели с очень небольшим количеством данных, так что в

656
00:25:33,389 --> 00:25:35,769
целом такого рода  доходит до

657
00:25:35,769 --> 00:25:37,389
ошибки аппроксимации функции по сравнению с

658
00:25:37,389 --> 00:25:39,549
ошибкой оценки выборки, у вас может быть

659
00:25:39,549 --> 00:25:40,480
ошибка из-за того, что у

660
00:25:40,480 --> 00:25:41,980
вас мало данных, или у вас может быть ошибка из-

661
00:25:41,980 --> 00:25:42,700
за того, что аппроксимация вашей функции

662
00:25:42,700 --> 00:25:45,519
неверна, и часто

663
00:25:45,519 --> 00:25:46,659
вы хотите  на компромисс между этими

664
00:25:46,659 --> 00:25:49,210
двумя, так что этот пример, который вы знаете, вы можете в

665
00:25:49,210 --> 00:25:50,860
конечном итоге получить этот выборочный опыт,

666
00:25:50,860 --> 00:25:52,509
который выглядит иначе, чем все, что

667
00:25:52,509 --> 00:25:55,840
вы видели в реальности, а затем, в

668
00:25:55,840 --> 00:25:58,840
этом случае, если вы сейчас запустите Монте-Карло

669
00:25:58,840 --> 00:26:01,899
на новых данных, вы можете  вы можете получить

670
00:26:01,899 --> 00:26:03,159
что-то очень похожее, если

671
00:26:03,159 --> 00:26:07,200
вы выполнили TD на исходных данных, поэтому в

672
00:26:07,200 --> 00:26:09,460
основном вместо того, чтобы брать наш реальный

673
00:26:09,460 --> 00:26:12,820
опыт, а затем проводить Монте-Карло,

674
00:26:12,820 --> 00:26:15,070
используя его для оценки политики,

675
00:26:15,070 --> 00:26:17,379
альтернативой является сказать, что мы действительно  подумайте,

676
00:26:17,379 --> 00:26:18,669
что это система Маркова, давайте

677
00:26:18,669 --> 00:26:20,499
смоделируем кучу данных, а затем вы

678
00:26:20,499 --> 00:26:22,149
можете запустить обучение Монте-Карло на этом

679
00:26:22,149 --> 00:26:24,580
или обучение TD на нем, и вы получите,

680
00:26:24,580 --> 00:26:28,240
вероятно, тот же ответ, так что это вы

681
00:26:28,240 --> 00:26:29,799
знаете, в отличие от того, что магия Харлоу

682
00:26:29,799 --> 00:26:31,480
сошлась бы  до которого было

683
00:26:31,480 --> 00:26:33,549
V of a равно 0, а B of B

684
00:26:33,549 --> 00:26:36,999
равно 0,75 теперь снова вы можете сказать хорошо, но

685
00:26:36,999 --> 00:26:38,740
действительно ли я хочу сделать это, как если бы я если бы

686
00:26:38,740 --> 00:26:39,970
я действительно не думал, что система была

687
00:26:39,970 --> 00:26:42,190
марковской, я бы не стал  Я также не проводил

688
00:26:42,190 --> 00:26:46,270
Монте-Карло с моими поддельными данными, но я

689
00:26:46,270 --> 00:26:49,240
думаю, что это иллюстрирует то, что вы не можете

690
00:26:49,240 --> 00:26:50,950
сделать, когда у вас есть выборка, и просто

691
00:26:50,950 --> 00:26:52,420
показывает, что вы можете делать

692
00:26:52,420 --> 00:26:55,450
всевозможные выборы, так что, может быть, вы хотите

693
00:26:55,450 --> 00:26:56,950
иметь что-то вроде двух-  шаг марковского процесса

694
00:26:56,950 --> 00:26:58,330
или вы хотите сделать

695
00:26:58,330 --> 00:26:59,890
разные предположения в своей модели, а

696
00:26:59,890 --> 00:27:01,630
затем, после этого, вы хотите сделать много

697
00:27:01,630 --> 00:27:03,550
планирования с ним, чтобы вы

698
00:27:03,550 --> 00:27:05,440
могли сначала взять свои данные, вычислить модель,

699
00:27:05,440 --> 00:27:08,140
а затем вы можете решить, как вы'

700
00:27:08,140 --> 00:27:10,450
собираюсь использовать это, чтобы попытаться сделать планирование и

701
00:27:10,450 --> 00:27:11,620


702
00:27:11,620 --> 00:27:14,770
вскоре мы увидим конкретный способ сделать это, поскольку вы, ребята, только что спрашивали

703
00:27:14,770 --> 00:27:18,010
меня о том, что если у нас плохая модель, то

704
00:27:18,010 --> 00:27:20,650
мы собираемся вычислить неоптимальную политику

705
00:27:20,650 --> 00:27:22,480
в целом, вы знаете, что нам может

706
00:27:22,480 --> 00:27:25,060
невероятно повезти, потому что в конечном итоге для

707
00:27:25,060 --> 00:27:27,490
решений мы только  нужно решить,

708
00:27:27,490 --> 00:27:32,230
знаете ли вы, что B of s a 1 больше, чем V of

709
00:27:32,230 --> 00:27:34,360
s a 2, поэтому в конечном итоге мы будем принимать

710
00:27:34,360 --> 00:27:36,580
решения о попарном сравнении,

711
00:27:36,580 --> 00:27:39,130
так что у вас может быть действительно

712
00:27:39,130 --> 00:27:40,600
плохая модель, но в итоге вы получите хорошую

713
00:27:40,600 --> 00:27:43,630
политику, но в целом, если  ваши модели плохие,

714
00:27:43,630 --> 00:27:45,250
и вы планируете в целом, ваша

715
00:27:45,250 --> 00:27:47,490
политика также будет неоптимальной,

716
00:27:47,490 --> 00:27:52,030
и поэтому один из подходов, если модель

717
00:27:52,030 --> 00:27:56,020
неверна, состоит в том, чтобы проводить обучение с подкреплением без модели

718
00:27:56,020 --> 00:27:58,900
на исходных данных, чтобы

719
00:27:58,900 --> 00:28:02,110
не выполнять планирование на основе модели, неясно,

720
00:28:02,110 --> 00:28:04,630
что всегда  решает проблему, поэтому это

721
00:28:04,630 --> 00:28:07,360
зависит от того, почему ваша модель неверна, если ваша

722
00:28:07,360 --> 00:28:08,950
модель неверна, потому что вы выбрали

723
00:28:08,950 --> 00:28:11,170
неправильный параметрический класс или потому, что

724
00:28:11,170 --> 00:28:13,390
система не является марковской, они выполняют Q-

725
00:28:13,390 --> 00:28:14,500
обучение, которое не решит вашу

726
00:28:14,500 --> 00:28:16,360
проблему, потому что Q ле  Arning также предполагает,

727
00:28:16,360 --> 00:28:19,120
что мир является марковским, поэтому модель свободна, вы

728
00:28:19,120 --> 00:28:20,680
знаете, что это зависит от того, почему вы знаете, почему

729
00:28:20,680 --> 00:28:24,430
это неправильно, зависит от того, почему

730
00:28:24,430 --> 00:28:30,430
помогает ли это другому, чтобы

731
00:28:30,430 --> 00:28:32,110
явно рассуждать о неопределенности вашей модели,

732
00:28:32,110 --> 00:28:34,630
и это снова возвращается к разведке и

733
00:28:34,630 --> 00:28:35,500
эксплуатации.

734
00:28:35,500 --> 00:28:37,450
это имеет дело только с

735
00:28:37,450 --> 00:28:40,030
определенной формой неправильности, оно связано

736
00:28:40,030 --> 00:28:41,110
с тем фактом, что у вас может быть

737
00:28:41,110 --> 00:28:43,630
ошибка оценки выборки, но по-прежнему

738
00:28:43,630 --> 00:28:45,100


739
00:28:45,100 --> 00:28:48,430
делается основное предположение о том, что ваш класс модели правильный, например, если

740
00:28:48,430 --> 00:28:50,590
вы моделируете мир как

741
00:28:50,590 --> 00:28:53,080
полиномиальное распределение и  вам нужно

742
00:28:53,080 --> 00:28:54,700
очень много данных, тогда ваши предыдущие метрические

743
00:28:54,700 --> 00:28:56,140
оценки будут ошибочными,

744
00:28:56,140 --> 00:28:57,370
но если мир действительно не

745
00:28:57,370 --> 00:29:02,350
полиномиальный, то все это скорее так,

746
00:29:02,350 --> 00:29:03,340
поэтому всегда полезно знать, какие

747
00:29:03,340 --> 00:29:04,870
предположения мы делаем в наших

748
00:29:04,870 --> 00:29:06,370
алгоритмах, а затем какие

749
00:29:06,370 --> 00:29:07,270
формы  неопределенность, которую

750
00:29:07,270 --> 00:29:11,110
мы учитываем сейчас, я думаю, я

751
00:29:11,110 --> 00:29:12,429
просто скажу еще одну вещь, которая

752
00:29:12,429 --> 00:29:13,809
немного тонкая, что я нахожу очень

753
00:29:13,809 --> 00:29:16,150
интересной, а именно, если у вас

754
00:29:16,150 --> 00:29:20,049
действительно хороший  модель, это я обычно говорю,

755
00:29:20,049 --> 00:29:21,820
или если у вас есть идеальная модель и

756
00:29:21,820 --> 00:29:23,559
идеальная оценка параметров,

757
00:29:23,559 --> 00:29:25,809
которых достаточно для принятия правильных решений, если

758
00:29:25,809 --> 00:29:27,850
вы пытаетесь обучить свою модель, и у

759
00:29:27,850 --> 00:29:29,890
вас есть ограниченный объем данных или

760
00:29:29,890 --> 00:29:31,540
ограниченный вид выразительности вашей

761
00:29:31,540 --> 00:29:34,450
модели  тогда модель, которая имеет более высокую

762
00:29:34,450 --> 00:29:36,820
точность прогнозирования, может на самом деле быть хуже,

763
00:29:36,820 --> 00:29:40,150
когда вы используете ее для принятия решений,

764
00:29:40,150 --> 00:29:41,950
и интуиция, о которой мне нравится думать, заключается в том, что

765
00:29:41,950 --> 00:29:43,299
мы обнаружили это несколько лет назад,

766
00:29:43,299 --> 00:29:45,250
это открыли другие - мы

767
00:29:45,250 --> 00:29:46,390
думали об этом для разумного человека.

768
00:29:46,390 --> 00:29:49,240
система обучения задача состоит в том,

769
00:29:49,240 --> 00:29:50,470
давайте представим, что у вас есть

770
00:29:50,470 --> 00:29:52,630
действительно сложное пространство состояний, скажем,

771
00:29:52,630 --> 00:29:54,760
вы пытаетесь смоделировать, как выглядит кухня,

772
00:29:54,760 --> 00:29:56,470
когда кто-то готовит чай, и

773
00:29:56,470 --> 00:29:57,970
есть все виды функций, которые вы знаете,

774
00:29:57,970 --> 00:29:59,650
например, есть пар, может быть, на

775
00:29:59,650 --> 00:30:01,809
улице закат.  а еще есть

776
00:30:01,809 --> 00:30:03,940
температура воды, а для

777
00:30:03,940 --> 00:30:05,890
заваривания чая нужна температура воды выше

778
00:30:05,890 --> 00:30:07,570
100 градусов и на самом деле это единственная

779
00:30:07,570 --> 00:30:09,460
особенность, на которую нужно обратить внимание

780
00:30:09,460 --> 00:30:11,740
Чтобы успешно заваривать чай, но если

781
00:30:11,740 --> 00:30:14,410
вы пытаетесь просто построить

782
00:30:14,410 --> 00:30:16,030
модель мира, вы пытаетесь смоделировать

783
00:30:16,030 --> 00:30:17,260
закат, вы пытаетесь смоделировать пар и

784
00:30:17,260 --> 00:30:19,660
т. д., и может быть огромное количество

785
00:30:19,660 --> 00:30:21,190
функций, которые  вы пытаетесь зафиксировать

786
00:30:21,190 --> 00:30:23,140
в своем роде, как вы знаете, возможно, немного

787
00:30:23,140 --> 00:30:25,600
бедную нейронную сеть, и поэтому, если

788
00:30:25,600 --> 00:30:27,429
вы просто попытаетесь подобрать наилучшую

789
00:30:27,429 --> 00:30:29,830
модель оценки максимального правдоподобия, это может

790
00:30:29,830 --> 00:30:31,270
быть не та, которая захватывает функции,

791
00:30:31,270 --> 00:30:34,900
которые вам нужны для принятия решений и, следовательно,

792
00:30:34,900 --> 00:30:36,460
моделей  которые выглядят лучше с точки зрения

793
00:30:36,460 --> 00:30:38,110
точности прогнозирования, не всегда могут быть

794
00:30:38,110 --> 00:30:40,809
лучше с точки зрения принятия решений, с

795
00:30:40,809 --> 00:30:42,040
чем мы столкнулись несколько

796
00:30:42,040 --> 00:30:43,600
лет назад, и я думаю, что это просто

797
00:30:43,600 --> 00:30:45,429
иллюстрирует, почему модели, которые нам нужно

798
00:30:45,429 --> 00:30:46,690
построить, когда мы хотим принимать решения

799
00:30:46,690 --> 00:30:48,520
, не  обязательно те же модели, которые нам

800
00:30:48,520 --> 00:30:51,370
нужны для точности прогнозирования, поэтому

801
00:30:51,370 --> 00:30:52,990
важно, чтобы мы могли знать, какие

802
00:30:52,990 --> 00:30:54,490
из ваших функций вас интересуют с

803
00:30:54,490 --> 00:30:59,320
точки зрения полезности и ценности, хорошо, поэтому давайте

804
00:30:59,320 --> 00:31:00,549
немного поговорим о моделировании.

805
00:31:00,549 --> 00:31:02,860
Арх, кто здесь раньше видел поиск по

806
00:31:02,860 --> 00:31:05,500
словам, и один из их классов, хорошо,

807
00:31:05,500 --> 00:31:06,970
количество людей, но не все, и

808
00:31:06,970 --> 00:31:09,640
так далее алгоритмы поиска,

809
00:31:09,640 --> 00:31:10,600
о которых мы собираемся поговорить сейчас, это

810
00:31:10,600 --> 00:31:12,309
разные способы вместо того, чтобы делать два

811
00:31:12,309 --> 00:31:14,559
обучения на наших смоделированных данных, хорошо,

812
00:31:14,559 --> 00:31:16,059
у нас есть  модель, как еще мы

813
00:31:16,059 --> 00:31:18,070
можем использовать ее, чтобы пытаться принимать решения, один из

814
00:31:18,070 --> 00:31:19,929
способов - это поиск вперед, так как же

815
00:31:19,929 --> 00:31:22,120
работает поиск вперед? Идея поиска вперед

816
00:31:22,120 --> 00:31:24,130
заключается в том, что мы собираемся подумать обо

817
00:31:24,130 --> 00:31:26,679
всех действиях, которые мы могли

818
00:31:26,679 --> 00:31:28,540
бы  просто есть два действия, которые вы

819
00:31:28,540 --> 00:31:30,250
хотите наткнуть на вас, а затем мы

820
00:31:30,250 --> 00:31:31,840
подумаем обо всех возможных следующих состояниях, в которые

821
00:31:31,840 --> 00:31:33,760
мы могли бы попасть, так что скажем, это

822
00:31:33,760 --> 00:31:35,860
довольно маленький мир, поэтому у нас есть только s1

823
00:31:35,860 --> 00:31:42,460
и s2, так что в этом текущем состоянии я мог бы

824
00:31:42,460 --> 00:31:44,740
либо принять  действие 1 или действие - и

825
00:31:44,740 --> 00:31:46,030
после того, как я предприму эти действия,

826
00:31:46,030 --> 00:31:47,500
я могу либо перейти в состояние 1, либо в

827
00:31:47,500 --> 00:31:49,660
состояние 2, а затем, после того, как я доберусь до

828
00:31:49,660 --> 00:31:52,120
любого состояния, в которое я попаду, я снова могу

829
00:31:52,120 --> 00:31:55,419
принять решение 1 или 2, потому

830
00:31:55,419 --> 00:31:58,630
что это мое пространство для действий  здесь и

831
00:31:58,630 --> 00:31:59,919
потом  после того, как я предприму это действие,

832
00:31:59,919 --> 00:32:01,990
я снова могу перейти или, может быть,

833
00:32:01,990 --> 00:32:03,340
иногда я завершаю работу, так что это

834
00:32:03,340 --> 00:32:08,740
конечное состояние, может быть, мой робот падает

835
00:32:08,740 --> 00:32:10,419
или падает или что-то в этом роде, или,

836
00:32:10,419 --> 00:32:14,710
может быть, еще я перехожу в другое состояние, и я

837
00:32:14,710 --> 00:32:16,000
могу думать о чем-то вроде этих

838
00:32:16,000 --> 00:32:18,790
ветвлений  набор фьючерсов, и я могу

839
00:32:18,790 --> 00:32:20,710
раскатывать их столько, сколько захочу, скажем,

840
00:32:20,710 --> 00:32:22,750
я хочу подумать о следующих H шагах,

841
00:32:22,750 --> 00:32:26,770
например, а затем я останавливаюсь, и как только я это

842
00:32:26,770 --> 00:32:28,809
получу, я могу использовать эту информацию

843
00:32:28,809 --> 00:32:31,660
и мое вознаграждение, пусть  я просто

844
00:32:31,660 --> 00:32:34,030
скажу еще одну вещь, которая заключается в том, что когда я делаю что-

845
00:32:34,030 --> 00:32:36,850
то вроде смоделированных фьючерсов, я

846
00:32:36,850 --> 00:32:38,470
могу думать о том, какую награду я

847
00:32:38,470 --> 00:32:40,570
получу в этих разных фьючерсах,

848
00:32:40,570 --> 00:32:42,340
потому что прямо сейчас я предполагаю, что у меня есть

849
00:32:42,340 --> 00:32:47,320
модель, поэтому мне дана модель, поэтому я

850
00:32:47,320 --> 00:32:49,179
Я могу подумать о том, если бы я принял это состояние за Т

851
00:32:49,179 --> 00:32:51,820
и предпринял бы какое-либо действие, какую награду я

852
00:32:51,820 --> 00:32:55,510
бы получил, а затем здесь, внизу, я могу подумать о том,

853
00:32:55,510 --> 00:32:57,580
если бы я получил, какую награду я получил бы S 2

854
00:32:57,580 --> 00:33:00,130
a 2, чтобы я мог подумать о создании

855
00:33:00,130 --> 00:33:02,049
различных вариантов будущего.  а потом

856
00:33:02,049 --> 00:33:04,600
подведение итогов или получение серии  s

857
00:33:04,600 --> 00:33:06,280
вознаграждения по любому из этих различных

858
00:33:06,280 --> 00:33:08,890
путей, а затем, чтобы

859
00:33:08,890 --> 00:33:10,870
выяснить ценность этих разного рода

860
00:33:10,870 --> 00:33:12,820
действий или лучшее действие, я должен предпринять

861
00:33:12,820 --> 00:33:17,020
то, что я могу сделать, это я могу взять максимум над

862
00:33:17,020 --> 00:33:19,809
действиями, и я могу принять ожидание

863
00:33:19,809 --> 00:33:22,350
над действиями.  Состояния,

864
00:33:22,350 --> 00:33:23,490
и я всегда знаю, как принять это

865
00:33:23,490 --> 00:33:24,990
ожидание, потому что я предполагаю, что у меня

866
00:33:24,990 --> 00:33:28,950
есть модель, поэтому я всегда могу подумать о том, какова

867
00:33:28,950 --> 00:33:30,299
будет вероятность того, что я попаду

868
00:33:30,299 --> 00:33:33,149
в это конкретное состояние, учитывая действия моего родителя

869
00:33:33,149 --> 00:33:38,490
и состояние, из которого я выхожу.

870
00:33:38,490 --> 00:33:40,320
что происходит в этом случае, так это то, что я

871
00:33:40,320 --> 00:33:41,850
развертываю все эти потенциальные функции

872
00:33:41,850 --> 00:33:44,669
до определенной глубины в случае го

873
00:33:44,669 --> 00:33:46,080
или чего-то подобного, это будет до тех пор, пока

874
00:33:46,080 --> 00:33:47,610
вы не выиграете игру или не проиграете, а

875
00:33:47,610 --> 00:33:50,009
затем я хочу сделать резервную копию, чтобы вы могли

876
00:33:50,009 --> 00:33:51,960
думайте об этом как о не очень

877
00:33:51,960 --> 00:33:53,600
эффективной форме динамического программирования,

878
00:33:53,600 --> 00:33:55,740
потому что почему это не так эффективно,

879
00:33:55,740 --> 00:33:58,049
потому что здесь может быть много состояний

880
00:33:58,049 --> 00:34:01,799
, которые идентичны, и я не

881
00:34:01,799 --> 00:34:02,159


882
00:34:02,159 --> 00:34:03,929
делаю их псевдонимами или я не лечу

883
00:34:03,929 --> 00:34:05,519
они идентичны я говорю я  я собираюсь

884
00:34:05,519 --> 00:34:07,230
отдельно подумать о каждом из этих

885
00:34:07,230 --> 00:34:08,909
состояний, которых я достигну, какой будет

886
00:34:08,909 --> 00:34:10,319
будущая награда, которую я получу из этого

887
00:34:10,319 --> 00:34:11,819
состояния при различных последовательностях его

888
00:34:11,819 --> 00:34:14,699
действий и результирующих состояний, а затем, если

889
00:34:14,699 --> 00:34:16,469
я хочу выяснить, как действовать, я ухожу

890
00:34:16,469 --> 00:34:20,760
из своих листьев  и я беру максимум за все

891
00:34:20,760 --> 00:34:25,319
это, так что, скажем, в этом случае я просто

892
00:34:25,319 --> 00:34:28,500
делаю это как простой маленький,

893
00:34:28,500 --> 00:34:32,489
это a1 a2 теперь скажем, в этот момент я

894
00:34:32,489 --> 00:34:39,810
заканчиваю, поэтому я получил R из sa1 sa-2, поэтому в

895
00:34:39,810 --> 00:34:40,980
любое время я  у меня есть структура, которая выглядит

896
00:34:40,980 --> 00:34:43,560
так, что я делаю, я беру максимум,

897
00:34:43,560 --> 00:34:46,859
и вознаграждение здесь равно тому, какое из

898
00:34:46,859 --> 00:34:48,899
них было больше, давайте представим, что это

899
00:34:48,899 --> 00:34:52,409
было дерево, которое было больше, поэтому, если я

900
00:34:52,409 --> 00:34:54,329
хочу вычислить, я в основном выкатываю все

901
00:34:54,329 --> 00:34:57,180
это  вычисления, такие как получение

902
00:34:57,180 --> 00:34:59,250
образца вознаграждения и следующего состояния, когда я прохожу

903
00:34:59,250 --> 00:35:01,740
весь путь, а затем, чтобы получить

904
00:35:01,740 --> 00:35:05,190
значение в корне всякий раз, когда я вижу два

905
00:35:05,190 --> 00:35:07,589
до как ряд узлов действия, я

906
00:35:07,589 --> 00:35:09,420
беру максимум по всем из них, которые  точно так же,

907
00:35:09,420 --> 00:35:10,950
как в нашем посыльном резервном копировании, мы

908
00:35:10,950 --> 00:35:13,710
берем максимум за действие  это позволяет нам

909
00:35:13,710 --> 00:35:16,319
получать наилучшие награды в будущем, а затем

910
00:35:16,319 --> 00:35:18,599
всякий раз, когда я получу два состояния, я сделаю

911
00:35:18,599 --> 00:35:22,109
еще одно здесь, поэтому скажем, теперь у меня есть

912
00:35:22,109 --> 00:35:24,839
два состояния s1 и s2, и одно из них имеет

913
00:35:24,839 --> 00:35:28,530
это значение s1, а это имеет значение s2,

914
00:35:28,530 --> 00:35:31,770
и я  хочу выяснить для этого действия,

915
00:35:31,770 --> 00:35:33,720
но каково мое новое значение, тогда оно

916
00:35:33,720 --> 00:35:35,880
будет равно вероятности,

917
00:35:35,880 --> 00:35:39,360
наилучшей из данных, скажем, я пришел из s 0 s

918
00:35:39,360 --> 00:35:43,830
0 a1, умноженный на B из s 1, плюс вероятность

919
00:35:43,830 --> 00:35:50,400
s 2 s равна 0 a1  умножить на V из s это

920
00:35:50,400 --> 00:35:52,920
точно так же, как когда мы делаем резервную

921
00:35:52,920 --> 00:35:54,750
копию посыльного, мы думаем обо всех следующих

922
00:35:54,750 --> 00:35:56,310
датах, к которым я мог бы добраться при текущем

923
00:35:56,310 --> 00:35:58,350
действии, и текущее состояние, умноженное на

924
00:35:58,350 --> 00:36:02,610
значение каждого из тех, которые имеют смысл, поэтому мы

925
00:36:02,610 --> 00:36:04,080
строим это дерево.  а затем

926
00:36:04,080 --> 00:36:06,870
, чтобы превзойти значение, мы выполняем одну из

927
00:36:06,870 --> 00:36:09,180
двух операций: либо мы берем

928
00:36:09,180 --> 00:36:12,990
максимум над действиями, если это заметки о действиях,

929
00:36:12,990 --> 00:36:16,050
либо мы берем ожидание, так что

930
00:36:16,050 --> 00:36:21,540
они называются ожидающими максимальные деревья, которые некоторые

931
00:36:21,540 --> 00:36:22,670
из вас, ребята, могли видеть  эти раньше

932
00:36:22,670 --> 00:36:25,620
в ИИ иногда люди часто говорят о

933
00:36:25,620 --> 00:36:28,020
минимаксных деревьях, так что если  вы играете в

934
00:36:28,020 --> 00:36:30,510
теорию игр, где другой агент

935
00:36:30,510 --> 00:36:31,830
пытается минимизировать вашу ценность, а вы

936
00:36:31,830 --> 00:36:32,610
максимизируете ее,

937
00:36:32,610 --> 00:36:34,500
это очень похоже, за исключением того, что мы

938
00:36:34,500 --> 00:36:36,570
делаем ожидание для следующих состояний,

939
00:36:36,570 --> 00:36:40,680
а затем максимизируем действия, и это

940
00:36:40,680 --> 00:36:42,480
точно так же, как динамическая программа, но  более

941
00:36:42,480 --> 00:36:45,540
неэффективно, но мы увидим, почему мы

942
00:36:45,540 --> 00:36:46,770
хотели бы сделать это, через секунду

943
00:36:46,770 --> 00:36:51,000
так много вопросов об этом, хорошо,

944
00:36:51,000 --> 00:36:52,560
так что это все, и способ, которым мы это делаем,

945
00:36:52,560 --> 00:36:53,910
заключается в том, что у нас должна быть модель,

946
00:36:53,910 --> 00:36:55,620
потому что, если мы не  у нас есть модель прямо

947
00:36:55,620 --> 00:36:58,560
сейчас, мы не можем вычислить это максимально

948
00:36:58,560 --> 00:37:01,170
точное ожидание, потому что мы используем это,

949
00:37:01,170 --> 00:37:02,910
мы знаем, что мы расширяем только два

950
00:37:02,910 --> 00:37:05,730
состояния здесь и где мы, чтобы

951
00:37:05,730 --> 00:37:07,500
выяснить, какой вес мы хотим

952
00:37:07,500 --> 00:37:08,910
придать каждому  из этих двух состояний нам

953
00:37:08,910 --> 00:37:10,470
нужно знать вероятность достижения

954
00:37:10,470 --> 00:37:13,200
каждого из них в порядке, поэтому здесь мы

955
00:37:13,200 --> 00:37:14,580
используем модель здесь, и мы используем

956
00:37:14,580 --> 00:37:18,240
модель, чтобы получить вознаграждение, поэтому

957
00:37:18,240 --> 00:37:21,330
поиск на основе моделирования аналогичен, за исключением того, что мы

958
00:37:21,330 --> 00:37:22,650
просто  будем моделировать с помощью модели,

959
00:37:22,650 --> 00:37:24,510
которую мы не собираемся  вычислить все эти

960
00:37:24,510 --> 00:37:27,990
виды экспоненциально растущего числа

961
00:37:27,990 --> 00:37:29,820
фьючерсов, вместо этого мы просто скажем, что

962
00:37:29,820 --> 00:37:32,850
я начну здесь, и у меня есть модель, и

963
00:37:32,850 --> 00:37:35,460
у каждого из меня есть здесь какая-то политика, но

964
00:37:35,460 --> 00:37:37,500
скажем, у меня есть политика PI, а затем я просто

965
00:37:37,500 --> 00:37:39,540
использую это  поэтому я смотрю на свою политику для

966
00:37:39,540 --> 00:37:40,800
текущего состояния, и она говорит мне что-то

967
00:37:40,800 --> 00:37:44,670
делать, поэтому я выполнил это действие, а затем

968
00:37:44,670 --> 00:37:47,160
захожу в свою модель и пробую S

969
00:37:47,160 --> 00:37:49,230
Prime,

970
00:37:49,230 --> 00:37:51,030
поэтому я смотрю на свою модель и говорю, что

971
00:37:51,030 --> 00:37:54,119
будет следующим состоянием  учитывая, что я был

972
00:37:54,119 --> 00:37:55,500
в этом конкретном состоянии и предпринял это

973
00:37:55,500 --> 00:37:57,210
действие, и я просто смоделировал одно следующее

974
00:37:57,210 --> 00:37:58,430
состояние,

975
00:37:58,430 --> 00:38:00,359
это точно так же, как мы могли

976
00:38:00,359 --> 00:38:02,369
смоделировать данные из наших моделей раньше, поэтому

977
00:38:02,369 --> 00:38:04,080
скажем, что это привело меня сюда, которое было

978
00:38:04,080 --> 00:38:06,720
состоянием s 1, а затем я смотрю  снова я

979
00:38:06,720 --> 00:38:08,340
смотрю в свою политику, и я говорю, что

980
00:38:08,340 --> 00:38:11,130
такое политика для s 1, я бы сказал, что это 2,

981
00:38:11,130 --> 00:38:13,140
а затем я сяду, затем я следую за

982
00:38:13,140 --> 00:38:15,270
ней сюда, они просто моделируют

983
00:38:15,270 --> 00:38:18,720
траекторию, просто следуя моей политике,

984
00:38:18,720 --> 00:38:20,369
имитируя ее  пока я иду, пока он не

985
00:38:20,369 --> 00:38:23,190
закончится, и это дает мне 1 возврат того,

986
00:38:23,190 --> 00:38:30,900
насколько хорошо  эта политика заключается в том, что в таких

987
00:38:30,900 --> 00:38:32,670
случаях мы можем просто смоделировать полные

988
00:38:32,670 --> 00:38:35,369
траектории с помощью модели, и как только они у

989
00:38:35,369 --> 00:38:37,140
нас будут, вы можете сделать что-то вроде

990
00:38:37,140 --> 00:38:39,420
RL без модели над этими смоделированными

991
00:38:39,420 --> 00:38:41,100
траекториями, которые могут быть либо Монте-

992
00:38:41,100 --> 00:38:43,320
Карло, либо это может быть что-то вроде

993
00:38:43,320 --> 00:38:49,410
обучения на телевидении, поэтому  если мы думаем об этом как о чем-то

994
00:38:49,410 --> 00:38:51,060
похожем на то, чтобы выполнить эту

995
00:38:51,060 --> 00:38:52,920
симуляцию, нам нужна какая-то политика, у

996
00:38:52,920 --> 00:38:54,510
вас должен быть какой-то способ выбирать

997
00:38:54,510 --> 00:38:56,760
действия в нашем симулируемом мире,

998
00:38:56,760 --> 00:38:58,080
когда мы думаем о том, чтобы быть в состоянии

999
00:38:58,080 --> 00:38:59,609
и предпринимать действия, как  знаем ли мы, какое

1000
00:38:59,609 --> 00:39:01,109
действие предпринять, мы следуем нашей текущей

1001
00:39:01,109 --> 00:39:04,740
политике моделирования, поэтому, скажем, мы

1002
00:39:04,740 --> 00:39:06,600
хотели сделать один шаг улучшения политики,

1003
00:39:06,600 --> 00:39:09,060
чтобы у вас была политика, у вас

1004
00:39:09,060 --> 00:39:11,730
была ваша модель, а затем вы начинаете

1005
00:39:11,730 --> 00:39:13,230
в состоянии и для каждого из возможных

1006
00:39:13,230 --> 00:39:15,530
действий  вы моделируете траектории, так

1007
00:39:15,530 --> 00:39:19,910
что это похоже на развертывание Монте-Карло,

1008
00:39:20,810 --> 00:39:24,210
поэтому я запустил свое состояние, так что,

1009
00:39:24,210 --> 00:39:26,310
скажем, я действительно в состоянии st, и мне

1010
00:39:26,310 --> 00:39:28,109
нужно выяснить, что делать дальше, поэтому я

1011
00:39:28,109 --> 00:39:30,119
начал  t состояние st, а затем в моей

1012
00:39:30,119 --> 00:39:31,530
голове, прежде чем я предприму действие в реальном

1013
00:39:31,530 --> 00:39:33,270
мире, я думаю обо всех действиях, которые я

1014
00:39:33,270 --> 00:39:34,800
мог бы предпринять, а затем я просто выполняю развертывание

1015
00:39:34,800 --> 00:39:36,600
каждого из них в соответствии с политикой поведения

1016
00:39:36,600 --> 00:39:39,359
PI, затем я выбираю максимальное из них,

1017
00:39:39,359 --> 00:39:42,960
поэтому я  Я действительно в состоянии st, а затем в моем

1018
00:39:42,960 --> 00:39:44,850
мозгу я думаю о том, чтобы сделать 1, а затем я

1019
00:39:44,850 --> 00:39:46,920
делаю много развертываний из этого в соответствии с моей

1020
00:39:46,920 --> 00:39:49,830
политикой PI, а затем я делаю 2 и делаю

1021
00:39:49,830 --> 00:39:53,010
много развертываний. Мне нравится, что 3 это все

1022
00:39:53,010 --> 00:39:56,010
в  мою голову, и это в основном дает мне, что

1023
00:39:56,010 --> 00:40:00,420
вы знаете оценку Q sta-1

1024
00:40:00,420 --> 00:40:03,500
под числом пи,

1025
00:40:04,130 --> 00:40:06,720
поэтому, если я должен был предпринять это действие, то

1026
00:40:06,720 --> 00:40:08,160
последующее действие, которое принесет мое

1027
00:40:08,160 --> 00:40:09,660
расчетное кубическое действие, и я делаю это для

1028
00:40:09,660 --> 00:40:10,980
каждого из действий, а затем я  может

1029
00:40:10,980 --> 00:40:13,829
принять максимум, так что это похоже на выполнение одного

1030
00:40:13,829 --> 00:40:15,270
набора улучшений политики, потому

1031
00:40:15,270 --> 00:40:16,680
что это будет зависеть от того, какая у меня

1032
00:40:16,680 --> 00:40:20,460
политика симуляции, которая имеет смысл, поэтому

1033
00:40:20,460 --> 00:40:22,829
есть какая-то существующая политика симуляции.

1034
00:40:22,829 --> 00:40:24,450
Я не сказал вам, как мы ее получаем, а затем

1035
00:40:24,450 --> 00:40:28,220
мы используем  это для имитации нашего опыта,

1036
00:40:28,220 --> 00:40:30,630
хорошо, поэтому вопрос в том, можем ли

1037
00:40:30,630 --> 00:40:32,220
мы на самом деле сделать  лучше, чем один

1038
00:40:32,220 --> 00:40:34,109
шаг улучшения политики, кажется, как

1039
00:40:34,109 --> 00:40:36,180
мы можем получить эти политики моделирования, например,

1040
00:40:36,180 --> 00:40:38,010
хорошо, если бы у нас была политика моделирования, это

1041
00:40:38,010 --> 00:40:39,809
было бы хорошо, мы могли бы сделать этот один шаг, но

1042
00:40:39,809 --> 00:40:41,279
как мы могли бы сделать это в более общих

1043
00:40:41,279 --> 00:40:45,359
условиях, ну, идея в том, что если  у вас

1044
00:40:45,359 --> 00:40:46,770
есть эта модель, вы могли бы фактически

1045
00:40:46,770 --> 00:40:48,990
вычислить оптимальные значения, выполнив это

1046
00:40:48,990 --> 00:40:51,630
ожидание максимального дерева, как будто я был в

1047
00:40:51,630 --> 00:40:53,880
состоянии st, и вместо того, чтобы просто думать

1048
00:40:53,880 --> 00:40:57,299
об этом, помните, что в

1049
00:40:57,299 --> 00:40:58,799
поиске на основе моделирования мы просто будем следовать одной

1050
00:40:58,799 --> 00:41:01,170
траектории, но в  ожидая максимальное

1051
00:41:01,170 --> 00:41:02,640
дерево, мы можем хорошо подумать, что, если бы я

1052
00:41:02,640 --> 00:41:06,329
сделал 1 или 2, и после этого я перешел бы

1053
00:41:06,329 --> 00:41:09,720
к s1 или s2, а затем какое действие

1054
00:41:09,720 --> 00:41:13,859
я должен там сделать, и я могу думать о том, чтобы в основном

1055
00:41:13,859 --> 00:41:16,069
попытаться вычислить оптимальную функцию Q

1056
00:41:16,069 --> 00:41:18,569
при моем  приблизительная модель для

1057
00:41:18,569 --> 00:41:21,599
текущего состояния, хорошо, проблема в том

1058
00:41:21,599 --> 00:41:25,260
, что это дерево становится очень большим, поэтому в

1059
00:41:25,260 --> 00:41:28,289
целом размер дерева будет

1060
00:41:28,289 --> 00:41:32,359
масштабироваться, по крайней мере, с s раз a до H,

1061
00:41:32,359 --> 00:41:35,670
если H - это горизонт, потому что каждый шаг,

1062
00:41:35,670 --> 00:41:37,470
вот почему это  н  не столь эффективна

1063
00:41:37,470 --> 00:41:39,510
идея динамического программирования, что на каждом шаге

1064
00:41:39,510 --> 00:41:40,559
вы будете думать обо всех

1065
00:41:40,559 --> 00:41:42,119
возможных следующих состояниях, а затем обо всех

1066
00:41:42,119 --> 00:41:44,099
возможных следующих действиях, и поэтому это

1067
00:41:44,099 --> 00:41:45,329
дерево экспоненциально растет с

1068
00:41:45,329 --> 00:41:47,010
горизонтом, и если вы думаете о чем-то

1069
00:41:47,010 --> 00:41:49,589
вроде alphago, которые играют  вы знаете, что

1070
00:41:49,589 --> 00:41:51,059
за несколько временных шагов, прежде чем

1071
00:41:51,059 --> 00:41:53,609
кто-то выиграет или проиграет, это H может быть

1072
00:41:53,609 --> 00:41:56,849
где-то между 50 и 200, поэтому, если у вас

1073
00:41:56,849 --> 00:41:58,529
есть что-то большее, чем чрезвычайно

1074
00:41:58,529 --> 00:42:00,960
маленькая база состояний, такая как 1, тогда это

1075
00:42:00,960 --> 00:42:05,160
не будет неосуществимо,

1076
00:42:05,160 --> 00:42:06,960
поэтому идея будет  soar поиск по дереву Монте-Карло

1077
00:42:06,960 --> 00:42:08,609
- это нормально, мы хотели бы добиться большего успеха

1078
00:42:08,609 --> 00:42:10,680
, в любом случае нам нужна какая-то

1079
00:42:10,680 --> 00:42:12,599
политика моделирования, если мы вообще собираемся это делать,

1080
00:42:12,599 --> 00:42:14,099
и мы не можем быть настолько

1081
00:42:14,099 --> 00:42:16,140
вычислительно неразрешимыми, как глупый

1082
00:42:16,140 --> 00:42:18,090
назад  t max, так как же нам сделать что-то среднее,

1083
00:42:18,090 --> 00:42:22,230
так что идея поиска по дереву Монте-Карло

1084
00:42:22,230 --> 00:42:23,910
состоит в том, чтобы попытаться получить

1085
00:42:23,910 --> 00:42:25,500
лучшее из обоих миров, где то, что мы

1086
00:42:25,500 --> 00:42:27,210
действительно хотели бы, - это дерево ожидаемого Emax, в

1087
00:42:27,210 --> 00:42:28,590
котором мы думаем обо всех возможных вариантах

1088
00:42:28,590 --> 00:42:31,830
будущего и  взять максимум над ними, но

1089
00:42:31,830 --> 00:42:33,090
вместо этого нам нужно сделать это

1090
00:42:33,090 --> 00:42:34,770
немного более податливым с точки зрения вычислений способом,

1091
00:42:34,770 --> 00:42:36,960
и почему это может быть возможно,

1092
00:42:36,960 --> 00:42:39,240
давайте подумаем об этом, давайте, если у нас

1093
00:42:39,240 --> 00:42:41,040
есть наше начальное начальное состояние,

1094
00:42:41,040 --> 00:42:44,910
скажем, это наше общее дерево, оно будет

1095
00:42:44,910 --> 00:42:46,590
все это  ups, некоторые из этих потенциальных

1096
00:42:46,590 --> 00:42:48,360
способов действия могут быть действительно очень

1097
00:42:48,360 --> 00:42:51,060
плохими, поэтому некоторые из них могут быть ясны

1098
00:42:51,060 --> 00:42:53,430
очень рано, например, с очень небольшим

1099
00:42:53,430 --> 00:42:56,430
количеством данных или очень небольшим количеством

1100
00:42:56,430 --> 00:42:58,770
развертываний, что на самом деле это способы, которыми вы

1101
00:42:58,770 --> 00:43:00,240
никогда не захотите играть.  потому

1102
00:43:00,240 --> 00:43:02,250
что вы немедленно проиграете, и

1103
00:43:02,250 --> 00:43:03,480
тогда вам не нужно

1104
00:43:03,480 --> 00:43:05,190
продолжать тратить много

1105
00:43:05,190 --> 00:43:07,230
вычислительных усилий на конкретизацию этого

1106
00:43:07,230 --> 00:43:08,760
дерева, когда что-то другое могло бы выглядеть намного

1107
00:43:08,760 --> 00:43:11,430
лучше, так что это своего рода интуиция.

1108
00:43:11,430 --> 00:43:13,260
Что

1109
00:43:13,260 --> 00:43:15,780
мы собираемся сделать, так это построить частичное

1110
00:43:15,780 --> 00:43:18,810
дерево поиска, поэтому мы начнем с

1111
00:43:18,810 --> 00:43:20,910
текущего состояния и сможем попробовать действия

1112
00:43:20,910 --> 00:43:22,890
в следующем состоянии, как в

1113
00:43:22,890 --> 00:43:25,170
поиске на основе симуляции, так что, может быть, мы сначала сэмулируем  ple a

1114
00:43:25,170 --> 00:43:28,560
1, а затем мы снова сэмплируем s1, а затем

1115
00:43:28,560 --> 00:43:31,050
сэмплируем 2, поэтому мы начинаем, когда мы

1116
00:43:31,050 --> 00:43:32,970
вроде как самый первый раунд, он выглядит

1117
00:43:32,970 --> 00:43:35,130
точно так же, как поиск на основе моделирования,

1118
00:43:35,130 --> 00:43:36,300
но идея состоит в том, что затем мы можем делать это

1119
00:43:36,300 --> 00:43:38,310
несколько раз и медленно заполнять

1120
00:43:38,310 --> 00:43:40,230
дерево, так что, может быть, в следующий раз, когда мы

1121
00:43:40,230 --> 00:43:43,790
сэмплируем 2, а затем, возможно, мы сэмплируем s 2,

1122
00:43:43,790 --> 00:43:46,800
а затем сэмплируем 1, и поэтому вы можете подумать

1123
00:43:46,800 --> 00:43:49,080
о медленном заполнении этого максимального дерева ожидания,

1124
00:43:49,080 --> 00:43:52,920
и в пределе вы

1125
00:43:52,920 --> 00:43:54,360
заполните все максимальное дерево ожидания

1126
00:43:54,360 --> 00:43:55,590
просто на практике вы почти

1127
00:43:55,590 --> 00:43:57,300
никогда этого не сделаете, потому что это

1128
00:43:57,300 --> 00:44:02,790
сложно вычислить, поэтому мы собираемся сделать

1129
00:44:02,790 --> 00:44:03,900
это, и мы сделаем это для некоторого

1130
00:44:03,900 --> 00:44:06,030
количества эпизодов

1131
00:44:06,030 --> 00:44:07,740
симуляции, о каждом эпизоде симуляции можно думать, когда вы 

1132
00:44:07,740 --> 00:44:09,450
ачинаете с корня  это

1133
00:44:09,450 --> 00:44:11,790
текущее состояние корневого узла, в котором вы находитесь в начале, а

1134
00:44:11,790 --> 00:44:13,950
затем вы разворачиваетесь, пока не достигнете

1135
00:44:13,950 --> 00:44:16,740
конечного состояния или возраста горизонта, а затем

1136
00:44:16,740 --> 00:44:18,150
вы возвращаетесь в начальное состояние и

1137
00:44:18,150 --> 00:44:21,000
снова делаете другую траекторию, и когда

1138
00:44:21,000 --> 00:44:22,710
вы закончите со всем  из этого вы можете

1139
00:44:22,710 --> 00:44:24,150
сделать с  То же самое, что вы могли бы сделать и ожидать

1140
00:44:24,150 --> 00:44:26,310
Emax, в том, что вы всегда будете

1141
00:44:26,310 --> 00:44:29,180
брать максимальное количество действий, а обратная связь X

1142
00:44:29,180 --> 00:44:34,550
преувеличивает, но вы

1143
00:44:34,550 --> 00:44:36,170
заполните только часть дерева, поэтому

1144
00:44:36,170 --> 00:44:42,200
часть дерева может отсутствовать, поэтому для того, чтобы

1145
00:44:42,200 --> 00:44:44,750
сделайте это, есть два ключевых аспекта: один — это

1146
00:44:44,750 --> 00:44:47,119
то, что вы делаете в частях дерева, у нас

1147
00:44:47,119 --> 00:44:48,950
уже есть некоторые данные, например, если вы

1148
00:44:48,950 --> 00:44:50,869
уже пробовали оба действия в

1149
00:44:50,869 --> 00:44:52,550
состоянии, какое действие вы должны выбрать снова,

1150
00:44:52,550 --> 00:44:55,400
а затем что вы должны делать, когда вы

1151
00:44:55,400 --> 00:44:56,869
достигнете, например  узел, на котором больше

1152
00:44:56,869 --> 00:44:58,819
ничего нет или как будто

1153
00:44:58,819 --> 00:45:00,890
до сих пор пробовали только одну вещь, поэтому это часто

1154
00:45:00,890 --> 00:45:02,329
называют политикой дерева в политике

1155
00:45:02,329 --> 00:45:05,210
развертывания, для которой политика развертывания предназначена,

1156
00:45:05,210 --> 00:45:07,880
когда вы попадаете на узел, где, как вы

1157
00:45:07,880 --> 00:45:08,990
знаете, вы только пробовали  что-то одно или

1158
00:45:08,990 --> 00:45:10,099
больше нет данных, с которыми вы никогда

1159
00:45:10,099 --> 00:45:12,079
не были раньше, поэтому, например,

1160
00:45:12,079 --> 00:45:13,609
вы можете попробовать состояние, которого вы никогда не

1161
00:45:13,609 --> 00:45:15,349
достигали раньше, и теперь это новый

1162
00:45:15,349 --> 00:45:17,300
узел, и с этого момента вы выполняете политику развертывания,

1163
00:45:17,300 --> 00:45:19,250
которая покажет пример  из этого в

1164
00:45:19,250 --> 00:45:22,790
секунду, а затем й  Идея в том, что когда мы

1165
00:45:22,790 --> 00:45:24,020
думаем о вычислении функции Q,

1166
00:45:24,020 --> 00:45:26,180
мы просто собираемся усреднить все

1167
00:45:26,180 --> 00:45:28,040
вознаграждения, полученные от этого узла и

1168
00:45:28,040 --> 00:45:32,210
далее, это должно показаться немного

1169
00:45:32,210 --> 00:45:32,569
странным,

1170
00:45:32,569 --> 00:45:34,130
потому что мы больше не говорим о максимумах

1171
00:45:34,130 --> 00:45:36,460
, мы не говорим  о том, чтобы

1172
00:45:36,460 --> 00:45:38,420
рассматривать явно как

1173
00:45:38,420 --> 00:45:40,190
ожидание по состояниям в нашем

1174
00:45:40,190 --> 00:45:43,180
формальным образом, мы просто собираемся усреднить это,

1175
00:45:43,180 --> 00:45:46,960
причина, по которой это нормально, заключается в том, что

1176
00:45:46,960 --> 00:45:49,910
мы собираемся сортировать действия таким

1177
00:45:49,910 --> 00:45:52,010
образом, чтобы со временем мы собирались

1178
00:45:52,010 --> 00:45:53,480
примерные действия, которые выглядят намного

1179
00:45:53,480 --> 00:45:56,480
лучше, и поэтому мы ожидаем, что в конечном

1180
00:45:56,480 --> 00:45:58,609
итоге распределение данных будет

1181
00:45:58,609 --> 00:46:04,069
сходиться к истинному. Q — это разница

1182
00:46:04,069 --> 00:46:05,359
между этим и симуляцией до

1183
00:46:05,359 --> 00:46:07,760
того, как это будет другой вид усреднения и

1184
00:46:07,760 --> 00:46:09,589
движущихся частей, потому что раньше казалось, что

1185
00:46:09,589 --> 00:46:12,020
мы также делаем  кучу развертываний, а

1186
00:46:12,020 --> 00:46:14,059
затем напомнить им, чтобы эта часть

1187
00:46:14,059 --> 00:46:19,400
осталась прежней, да, мы все еще собираемся

1188
00:46:19,400 --> 00:46:21,290
провести кучу симуляций, поэтому

1189
00:46:21,290 --> 00:46:22,579
мы собираемся их усреднить,

1190
00:46:22,579 --> 00:46:24,079
вопрос в том, какова наша политика.

1191
00:46:24,079 --> 00:46:26,720
использование для выполнения развертываний, как

1192
00:46:26,720 --> 00:46:28,400
правило, будет меняться для каждого

1193
00:46:28,400 --> 00:46:29,960
развертывания, как он сказал, я был идентичен

1194
00:46:29,960 --> 00:46:31,880
во всех развертываниях, а затем

1195
00:46:31,880 --> 00:46:32,960
способ их усреднения также

1196
00:46:32,960 --> 00:46:36,410
отличается, и на самом деле ключевая часть, я

1197
00:46:36,410 --> 00:46:39,200
думаю, заключается в том, что вместо этого  использования, как

1198
00:46:39,200 --> 00:46:43,910
я сказал для простого Монте-Карлоса,

1199
00:46:43,910 --> 00:46:45,769
который предполагает, что вы устанавливаете политику и

1200
00:46:45,769 --> 00:46:47,329
получаете целую кучу аутов Баррелла из

1201
00:46:47,329 --> 00:46:49,130
этой политики, просто начиная с разных

1202
00:46:49,130 --> 00:46:50,900
начальных действий, но затем всегда

1203
00:46:50,900 --> 00:46:52,819
следуя им, когда вы проводите исследование Монте-Карлоса,

1204
00:46:52,819 --> 00:46:55,309
а также делаете ради  как

1205
00:46:55,309 --> 00:46:57,259
правило, политика будет отличаться

1206
00:46:57,259 --> 00:46:59,509
для каждого из развертываний K, и это сделано

1207
00:46:59,509 --> 00:47:00,829
специально, чтобы вы могли надеяться

1208
00:47:00,829 --> 00:47:02,559
на лучшую политику,

1209
00:47:02,559 --> 00:47:05,209
хорошо, так что еще раз просто и просто чтобы

1210
00:47:05,209 --> 00:47:06,469
вернуться еще раз, что вы знаете, что

1211
00:47:06,469 --> 00:47:08,539
здесь происходит весь цикл  так что

1212
00:47:08,539 --> 00:47:09,920
в этом случае происходит так, как будто у вас есть

1213
00:47:09,920 --> 00:47:13,670
ваш агент, вот наш робот, и он

1214
00:47:13,670 --> 00:47:15,229
пытается выяснить, какое действие предпринять,

1215
00:47:15,229 --> 00:47:17,989
а затем реальный мир дает ответ на s

1216
00:47:17,989 --> 00:47:19,219
Prime и R Prime,

1217
00:47:19,219 --> 00:47:20,989
а затем то, что мы  говорить о том, что прямо

1218
00:47:20,989 --> 00:47:23,089
сейчас, это все, что ему нужно сделать в своей

1219
00:47:23,089 --> 00:47:27,109
голове, как все эти развертывания, чтобы

1220
00:47:27,109 --> 00:47:31,459
решить, какое следующее действие предпринять, так что он

1221
00:47:31,459 --> 00:47:32,660
собирается сделать целую кучу планирования,

1222
00:47:32,660 --> 00:47:34,729
прежде чем он предпримет следующее действие, в общем,

1223
00:47:34,729 --> 00:47:36,229
он может затем бросить все это дерево  прочь,

1224
00:47:36,229 --> 00:47:38,059
а затем мир собирается дать это,

1225
00:47:38,059 --> 00:47:39,469
и вы объявили новую награду, и это

1226
00:47:39,469 --> 00:47:40,279
облажался, и снова проделать весь этот процесс

1227
00:47:40,279 --> 00:47:43,249
вместе, так что ключевой момент в том, что

1228
00:47:43,249 --> 00:47:44,989
нам нужно решить, какие действия предпринять

1229
00:47:44,989 --> 00:47:50,170
дальше, и мы хотим сделать это таким образом  что

1230
00:47:50,170 --> 00:47:52,489
мы собираемся получить наилучшее ожидаемое значение,

1231
00:47:52,489 --> 00:47:55,609
учитывая информацию, которую мы имеем до сих пор,

1232
00:47:55,609 --> 00:47:57,619
в общем, в поиске по дереву Монте-Карло у

1233
00:47:57,619 --> 00:48:00,109
вас также может быть еще один шаг здесь,

1234
00:48:00,109 --> 00:48:05,239
где вы можете вычислить модель Амину, поэтому,

1235
00:48:05,239 --> 00:48:06,920
если вы делаете это онлайн, вы можете

1236
00:48:06,920 --> 00:48:09,349
взять  самые последние данные переобучают вашу

1237
00:48:09,349 --> 00:48:11,630
модель, учитывая, что модель повторно запускает поиск по дереву Монте-Карло,

1238
00:48:11,630 --> 00:48:13,459
и теперь решите, что вы

1239
00:48:13,459 --> 00:48:18,769
собираетесь делать на следующем временном шаге,

1240
00:48:18,769 --> 00:48:20,359
так что ключевым моментом является действительно эта политика дерева,

1241
00:48:20,359 --> 00:48:22,219
и развертывание обоих из них имеет

1242
00:48:22,219 --> 00:48:24,410
значение  Развертывание часто выполняется

1243
00:48:24,410 --> 00:48:25,969
случайным образом, по крайней мере, в самой базовой

1244
00:48:25,969 --> 00:48:27,559
ванильной версии для него есть множество

1245
00:48:27,559 --> 00:48:29,599
расширений, для этого ключевой

1246
00:48:29,599 --> 00:48:34,789
частью является политика дерева, поэтому один из

1247
00:48:34,789 --> 00:48:36,559
действительно распространенных способов сделать это называется

1248
00:48:36,559 --> 00:48:38,779
поиском по верхнему доверительному дереву, и это

1249
00:48:38,779 --> 00:48:40,459
относится к  то, о чем мы говорили в

1250
00:48:40,459 --> 00:48:42,469
течение последних нескольких недель с исследованием,

1251
00:48:42,469 --> 00:48:45,109
так что идея состоит в том, что когда мы

1252
00:48:45,109 --> 00:48:48,890
разворачиваемся, скажем, мы находимся в st, и

1253
00:48:48,890 --> 00:48:50,749
мы используем наши смоделированные модели, чтобы

1254
00:48:50,749 --> 00:48:53,059
подумать о следующих действиях и состояниях, которые

1255
00:48:53,059 --> 00:48:55,860
мы могли бы  быть в

1256
00:48:55,860 --> 00:49:00,270
этом, скажем, я дошел до состояния 1, и в

1257
00:49:00,270 --> 00:49:01,740
этот момент я хотел, скажем, я

1258
00:49:01,740 --> 00:49:04,380
взял 1 и 2 в прошлом, и я

1259
00:49:04,380 --> 00:49:05,670
закончил с вы знаете, я сделал много

1260
00:49:05,670 --> 00:49:07,260
развертываний из этих и  количество

1261
00:49:07,260 --> 00:49:09,360
развертываний отсюда, и, скажем, 3 раза,

1262
00:49:09,360 --> 00:49:11,370
я получил, скажем, я выиграл игру, поэтому

1263
00:49:11,370 --> 00:49:16,680
три, и я получил 1 1 и 1 0, хорошо, так что ключ

1264
00:49:16,680 --> 00:49:18,990
в том, какие действия я должен предпринять в следующий

1265
00:49:18,990 --> 00:49:21,060
раз, когда я столкнусь с s1, когда я делаю  мое

1266
00:49:21,060 --> 00:49:23,910
развертывание, и идея состоит в том, чтобы быть оптимистичным

1267
00:49:23,910 --> 00:49:26,160
в отношении данных, которые у вас есть до сих пор, по

1268
00:49:26,160 --> 00:49:28,200
существу  мы будем относиться к этому

1269
00:49:28,200 --> 00:49:32,910
как к бандиту, думаем о каждой точке принятия решения

1270
00:49:32,910 --> 00:49:35,010
как о своем собственном бандите, как о своем собственном независимом

1271
00:49:35,010 --> 00:49:36,990
бандите, и хорошо скажем, если я предпринял

1272
00:49:36,990 --> 00:49:38,720
все действия, которые мог, для моего текущего состояния,

1273
00:49:38,720 --> 00:49:41,340
какова моя средняя награда, которую я получил от

1274
00:49:41,340 --> 00:49:43,500
каждое из этих действий в любом развертывании,

1275
00:49:43,500 --> 00:49:45,330
которое я предпринял из этого конкретного

1276
00:49:45,330 --> 00:49:48,180
узла на графике, и действие, и

1277
00:49:48,180 --> 00:49:51,060
сколько раз я его выполнял, чтобы вы могли

1278
00:49:51,060 --> 00:49:55,530
получить эмпирическое среднее значение для этого состояния 1

1279
00:49:55,530 --> 00:49:59,760
на графике 1 плюс скидка

1280
00:49:59,760 --> 00:50:01,650
фактор, который часто выглядит как

1281
00:50:01,650 --> 00:50:04,170
количество раз, когда вы были в этом конкретном

1282
00:50:04,170 --> 00:50:07,440
узле, хорошо, это действительно узел на

1283
00:50:07,440 --> 00:50:14,970
графике, это также для этого узла, поэтому мы

1284
00:50:14,970 --> 00:50:16,620
думаем о том, что каждый раз, когда я был

1285
00:50:16,620 --> 00:50:18,300
в этом узле, что и что я взял  это

1286
00:50:18,300 --> 00:50:19,410
конкретное действие, каков средний

1287
00:50:19,410 --> 00:50:21,210
Уорд, который я получил, плюс сколько раз

1288
00:50:21,210 --> 00:50:22,410
я это делал, и это просто позволяет вам

1289
00:50:22,410 --> 00:50:25,080
снова использовать оптимизм, это хорошо говорит,

1290
00:50:25,080 --> 00:50:26,640
когда я достиг разных частей

1291
00:50:26,640 --> 00:50:28,590
графика, прежде чем использовать мою смоделированную модель,

1292
00:50:28,590 --> 00:50:30,900
как все выглядит  хорошо, я собираюсь сосредоточиться на том,

1293
00:50:30,900 --> 00:50:32,580
чтобы убедиться, что  это та часть

1294
00:50:32,580 --> 00:50:34,260
дерева, которую я очищаю больше, потому

1295
00:50:34,260 --> 00:50:35,340
что это та часть, где я думаю, что

1296
00:50:35,340 --> 00:50:37,560
получу более вероятные политики охвата, которые имеют

1297
00:50:37,560 --> 00:50:39,960
более высокую ценность, и поэтому, надеюсь, это

1298
00:50:39,960 --> 00:50:41,280
будет означать, что мне нужно меньше

1299
00:50:41,280 --> 00:50:42,960
вычислений, чтобы вычислить хорошую

1300
00:50:42,960 --> 00:50:46,740
политику  имеет ли это смысл, как если бы у

1301
00:50:46,740 --> 00:50:48,690
вас был Oracle, который мог бы сказать вам,

1302
00:50:48,690 --> 00:50:50,670
какова оптимальная политика, тогда вам

1303
00:50:50,670 --> 00:50:52,170
нужно было бы заполнить только эту

1304
00:50:52,170 --> 00:50:54,960
часть дерева, и то, что мы здесь используем, это

1305
00:50:54,960 --> 00:50:56,280
то, что мы говорим хорошо, учитывая данные, которые мы  мы

1306
00:50:56,280 --> 00:50:58,620
видели до сих пор, можем ли мы, как бы, только вы знаете,

1307
00:50:58,620 --> 00:51:00,420
сосредоточиться на частях дерева, которые, кажется,

1308
00:51:00,420 --> 00:51:01,650
будут теми, которые,

1309
00:51:01,650 --> 00:51:03,840
когда мы берем наши максимальные действия,

1310
00:51:03,840 --> 00:51:05,750
будут теми, которые мы в конечном итоге

1311
00:51:05,750 --> 00:51:08,250
распространяем значения  резервное копирование в

1312
00:51:08,250 --> 00:51:10,400
корень в

1313
00:51:10,880 --> 00:51:13,770
порядке, поэтому мы поддерживаем высшую

1314
00:51:13,770 --> 00:51:15,120
компетенцию, обнаруженную по вознаграждению каждого

1315
00:51:15,120 --> 00:51:19,290
, используем то же самое

1316
00:51:19,290 --> 00:51:20,340
, что и раньше,

1317
00:51:20,340 --> 00:51:22,440
и мы обрабатываем каждый из узлов, поэтому

1318
00:51:22,440 --> 00:51:29,370
каждый узел состояния как отдельный  бандит а

1319
00:51:29,370 --> 00:51:31,560
так значит по сути что знаешь

1320
00:51:31,560 --> 00:51:33,390
в следующий раз, когда мы достигнем того же узла

1321
00:51:33,390 --> 00:51:34,770
в дереве, мы могли бы сделать что-то другое,

1322
00:51:34,770 --> 00:51:38,420
потому что счетчики изменятся,

1323
00:51:38,420 --> 00:51:40,440
может ли договор использоваться, похоже ли это на

1324
00:51:40,440 --> 00:51:43,440
телевизионный движок, если вы вознаграждаете за

1325
00:51:43,440 --> 00:51:45,990
проблему с бандитами,

1326
00:51:45,990 --> 00:51:48,990
значение статоров, если  сделать пару действий состояния

1327
00:51:48,990 --> 00:51:51,630
или это награда только за этот

1328
00:51:51,630 --> 00:51:55,050
переход, это отличный вопрос, поэтому для

1329
00:51:55,050 --> 00:51:57,470
этого бандита мы будем рассматривать его как, по

1330
00:51:57,470 --> 00:52:00,360
сути, полный разворот из этого

1331
00:52:00,360 --> 00:52:02,340
узла, потому что это то, что мы усредняем,

1332
00:52:02,340 --> 00:52:04,560
и мы'  капитан делает подсчеты, это

1333
00:52:04,560 --> 00:52:06,060
не похоже на TD в том смысле, что мы

1334
00:52:06,060 --> 00:52:08,970
делаем это для каждого узла, поэтому, как я упоминал

1335
00:52:08,970 --> 00:52:11,340
ранее, вы знаете, что у вас может быть s1 a1

1336
00:52:11,340 --> 00:52:12,660
здесь, в этой части графика, и s1

1337
00:52:12,660 --> 00:52:14,310
a-1 появляется здесь, и мы'  мы не

1338
00:52:14,310 --> 00:52:15,990
объединяем их значения, мы рассматриваем

1339
00:52:15,990 --> 00:52:17,640
каждый узел так, как будто он полностью различен,

1340
00:52:17,640 --> 00:52:19,710
хотя часто модель, которую мы будем

1341
00:52:19,710 --> 00:52:22,290
использовать для моделирования, будет помечена, но

1342
00:52:22,290 --> 00:52:23,910
внутри обработки вы можете сделать это, в

1343
00:52:23,910 --> 00:52:26,250
основном, это становится намного

1344
00:52:26,250 --> 00:52:27,870
сложнее для  реализация, если

1345
00:52:27,870 --> 00:52:29,190
хотите  в основном рассматривать это как график,

1346
00:52:29,190 --> 00:52:32,580
а не как дерево, теперь я думаю, что

1347
00:52:32,580 --> 00:52:33,720
другой момент, который вы приводите, к которому

1348
00:52:33,720 --> 00:52:35,580
мы вернемся через секунду,

1349
00:52:35,580 --> 00:52:38,700
и это хорошая идея, это то,

1350
00:52:38,700 --> 00:52:40,440
каковы ограничения бандита  сеттинг, так что

1351
00:52:40,440 --> 00:52:42,660
мы вернемся к ним через секунду,

1352
00:52:42,660 --> 00:52:43,920
хорошо, так что давайте поговорим об этом в

1353
00:52:43,920 --> 00:52:45,900
контексте го для тех из вас,

1354
00:52:45,900 --> 00:52:47,220
кто не играл в го или не слишком хорошо

1355
00:52:47,220 --> 00:52:49,200
с ним знаком, ему как минимум 2500 лет,

1356
00:52:49,200 --> 00:52:50,940
он считается  классическая сложнейшая

1357
00:52:50,940 --> 00:52:53,160
настольная игра, и она была известна как

1358
00:52:53,160 --> 00:52:54,930
грандиозная задача в области ИИ в течение очень

1359
00:52:54,930 --> 00:52:58,860
долгого периода времени, просто чтобы напомнить

1360
00:52:58,860 --> 00:53:01,620
себе, что это не связано с

1361
00:53:01,620 --> 00:53:02,940
принятием решений в случае, когда

1362
00:53:02,940 --> 00:53:04,500
динамика и модель вознаграждения неизвестны,

1363
00:53:04,500 --> 00:53:06,750
но правила игры  известны,

1364
00:53:06,750 --> 00:53:08,220
структура вознаграждения известна, но это

1365
00:53:08,220 --> 00:53:11,490
невероятно большое пространство для поиска, поэтому, если мы

1366
00:53:11,490 --> 00:53:13,020
подумаем о комбинаторике, то

1367
00:53:13,020 --> 00:53:15,960
количество возможных досок, которые вы можете

1368
00:53:15,960 --> 00:53:21,930
увидеть, чрезвычайно велико, так

1369
00:53:21,930 --> 00:53:23,880
что вкратце есть два разных

1370
00:53:23,880 --> 00:53:25,770
типа камней, которые большинство людей, вероятно, знают.  это

1371
00:53:25,770 --> 00:53:28,110
я, и обычно в нее играют на доске 19 на 19,

1372
00:53:28,110 --> 00:53:29,640
хотя люди также думали

1373
00:53:29,640 --> 00:53:30,870
об этом, вы знаете, что некоторые люди играют на

1374
00:53:30,870 --> 00:53:33,270
меньших досках, и вы хотите

1375
00:53:33,270 --> 00:53:35,370
захватить как можно больше территории, и это конечная

1376
00:53:35,370 --> 00:53:37,800
игра, потому что есть конечное количество

1377
00:53:37,800 --> 00:53:40,500
мест для размещения камней  на доске, так

1378
00:53:40,500 --> 00:53:48,450
что это конечный горизонт, я собираюсь пройтись

1379
00:53:48,450 --> 00:53:49,500
по этой части вкратце,

1380
00:53:49,500 --> 00:53:50,880
есть разные способы записи, вы

1381
00:53:50,880 --> 00:53:52,800
можете записать функцию вознаграждения для

1382
00:53:52,800 --> 00:53:55,560
этой игры с точки зрения я, вы знаете

1383
00:53:55,560 --> 00:53:57,030
разные, вы можете делать разные

1384
00:53:57,030 --> 00:53:58,380
функции самый простой  просто

1385
00:53:58,380 --> 00:53:59,970
посмотреть, выигрывают ли белые или

1386
00:53:59,970 --> 00:54:01,860
черные в игре, и в этом случае

1387
00:54:01,860 --> 00:54:04,050
это очень разреженный сигнал вознаграждения, и вы

1388
00:54:04,050 --> 00:54:05,880
получаете вознаграждение только в самом конце, поэтому вам

1389
00:54:05,880 --> 00:54:07,050
просто нужно пройти весь путь и

1390
00:54:07,050 --> 00:54:09,770
посмотреть, какая игра какая  желание для кого-то,

1391
00:54:09,770 --> 00:54:12,120
и тогда ваша функция ценности, по

1392
00:54:12,120 --> 00:54:13,380
сути, является ожидаемой

1393
00:54:13,380 --> 00:54:15,360
вероятностью вашего выигрыша в

1394
00:54:15,360 --> 00:54:20,520
текущем состоянии, так как это работает, если

1395
00:54:20,520 --> 00:54:22,560
мы проводим оценку Монте-Карло, так что давайте

1396
00:54:22,560 --> 00:54:24,180
представим, что это ваша текущая доска и

1397
00:54:24,180 --> 00:54:28,530
y  У вас есть определенная политика, тогда вы

1398
00:54:28,530 --> 00:54:33,000
играете против стационарного противника, как

1399
00:54:33,000 --> 00:54:34,890
обычно предполагается, но затем в конце вы

1400
00:54:34,890 --> 00:54:36,660
видите свой результат, так что, возможно, вы выиграли дважды

1401
00:54:36,660 --> 00:54:39,870
и дважды проиграли, и тогда значение

1402
00:54:39,870 --> 00:54:43,400
для этого текущего начального состояния равно половине,

1403
00:54:45,110 --> 00:54:47,160
так как бы мы

1404
00:54:47,160 --> 00:54:48,990
в этом случае вы хотите назвать это исследованием, поэтому вы начинаете,

1405
00:54:48,990 --> 00:54:51,810
и у вас есть одно единственное начальное состояние, поэтому

1406
00:54:51,810 --> 00:54:53,130
на данный момент вы не моделировали какую-либо

1407
00:54:53,130 --> 00:54:55,530
часть дерева, поэтому мы никогда не предпринимали

1408
00:54:55,530 --> 00:54:58,470
никаких действий, поэтому вы просто выбираете случайным образом,

1409
00:54:58,470 --> 00:55:00,810
так что, возможно, вы  возьмите 1, а затем вы

1410
00:55:00,810 --> 00:55:02,580
следуете своей политике по умолчанию, и это

1411
00:55:02,580 --> 00:55:05,370
часто бывает случайным, хотя для таких вещей, как

1412
00:55:05,370 --> 00:55:06,900
alphago, вам часто нужны гораздо лучшие

1413
00:55:06,900 --> 00:55:09,810
политики, но вы можете просто использовать случайную

1414
00:55:09,810 --> 00:55:11,760
политику, а не просто выполнять случайные действия и

1415
00:55:11,760 --> 00:55:13,290
переходить к следующим состояниям, и вы делаете это до тех пор, пока не

1416
00:55:13,290 --> 00:55:15,000
конец, и вы видите, что вы либо выигрываете, либо

1417
00:55:15,000 --> 00:55:19,110
проигрываете сейчас, в этом случае это игра для двух игроков,

1418
00:55:19,110 --> 00:55:21,000
поэтому мы делаем минимаксное дерево вместо того, чтобы

1419
00:55:21,000 --> 00:55:24,180
ожидать Emacs, но основные идеи

1420
00:55:24,180 --> 00:55:27,510
точно такие же, так что это мой первый выпуск

1421
00:55:27,510 --> 00:55:29,580
, я собираюсь сделать много  эти выпуски

1422
00:55:29,580 --> 00:55:30,900
раньше  Я придумываю, как я на

1423
00:55:30,900 --> 00:55:33,810
самом деле размещу свою часть, так что в следующий

1424
00:55:33,810 --> 00:55:35,940
раз это будет мой второй разворот, так как

1425
00:55:35,940 --> 00:55:36,210
только

1426
00:55:36,210 --> 00:55:39,390
второй раз вылетел из головы, я говорю хорошо,

1427
00:55:39,390 --> 00:55:42,119
хорошо, в прошлый раз, когда вы знаете, я предпринял это

1428
00:55:42,119 --> 00:55:44,160
действие, так что теперь у меня есть политика по умолчанию

1429
00:55:44,160 --> 00:55:45,990
поэтому на этот раз я предприму другое

1430
00:55:45,990 --> 00:55:48,119
действие, как правило, вы хотите заполнить все,

1431
00:55:48,119 --> 00:55:50,609
попробуйте все действия хотя бы один раз из

1432
00:55:50,609 --> 00:55:53,430
текущей заметки, теперь конкретный порядок, в

1433
00:55:53,430 --> 00:55:54,780
котором вы пытаетесь выполнить действия, может иметь большое

1434
00:55:54,780 --> 00:55:56,700
значение, и раньше была

1435
00:55:56,700 --> 00:55:58,740
значительная экономия  приведя в действие

1436
00:55:58,740 --> 00:56:00,660
эвристику того, в каком порядке пробовать

1437
00:56:00,660 --> 00:56:02,550
действия прямо сейчас, давайте просто представим, что вам нужно

1438
00:56:02,550 --> 00:56:05,580
попробовать все действия одинаково, поэтому в этом

1439
00:56:05,580 --> 00:56:07,109
случае теперь вы выполняете другое действие, а

1440
00:56:07,109 --> 00:56:08,220
затем после этого вы никогда не пробовали

1441
00:56:08,220 --> 00:56:09,990
ничего из этого действия, так что вы просто

1442
00:56:09,990 --> 00:56:11,700
снова нарисовал рулон, просто на самом деле

1443
00:56:11,700 --> 00:56:15,960
случайно, хорошо, а затем вы повторяете это,

1444
00:56:15,960 --> 00:56:18,690
так что теперь, когда вы доберетесь до этого, скажем,

1445
00:56:18,690 --> 00:56:20,520
я пробовал это раньше, так что теперь, когда я доберусь

1446
00:56:20,520 --> 00:56:24,839
до этой заметки, я должен выбрать, я должен

1447
00:56:24,839 --> 00:56:28,980
сделать максимум, возможно, используя  мой UCT, поэтому я смотрю,

1448
00:56:28,980 --> 00:56:30,480
что было  Награда за это и

1449
00:56:30,480 --> 00:56:33,030
их слово за это, плюс вы знаете

1450
00:56:33,030 --> 00:56:36,570
кое-что о подсчетах, хорошо,

1451
00:56:36,570 --> 00:56:39,720
это мило, я делаю это яснее, и поэтому я выбираю то

1452
00:56:39,720 --> 00:56:41,220
действие, которое выглядело

1453
00:56:41,220 --> 00:56:42,540
лучше в развертываниях, которые я распечатал

1454
00:56:42,540 --> 00:56:44,400
до сих пор, а затем  Я собираюсь сосредоточиться на

1455
00:56:44,400 --> 00:56:47,310
расширении этой части дерева, а вы

1456
00:56:47,310 --> 00:56:48,720
продолжайте делать это, и вы будете медленно

1457
00:56:48,720 --> 00:56:51,330
строить дерево, и вы будете делать

1458
00:56:51,330 --> 00:56:52,770
это, пока не истечет ваш вычислительный бюджет,

1459
00:56:52,770 --> 00:56:54,990
а затем вы идете к нижней

1460
00:56:54,990 --> 00:56:56,700
части дерева, и вы  пройдите весь путь назад,

1461
00:56:56,700 --> 00:56:58,619
где для каждого из узлов действия

1462
00:56:58,619 --> 00:57:01,380
вы берете максимум в каждом из

1463
00:57:01,380 --> 00:57:02,550
узлов состояния, вы делаете шею

1464
00:57:02,550 --> 00:57:04,200
наблюдателя, вы делаете

1465
00:57:04,200 --> 00:57:11,609
минимаксный противник от моего имени, как

1466
00:57:11,609 --> 00:57:16,680
неподвижный неизвестный, хорошо, так что  одно из

1467
00:57:16,680 --> 00:57:19,740
других действительно важных открытий к тому, почему люди

1468
00:57:19,740 --> 00:57:22,230
ходят на работу, - это игра с самим собой, поэтому обычно

1469
00:57:22,230 --> 00:57:24,359
в этом случае вы используете текущего агента

1470
00:57:24,359 --> 00:57:29,160
в качестве противника, поэтому я принимаю любую

1471
00:57:29,160 --> 00:57:31,800
политику, которую я только что вычислил, для других

1472
00:57:31,800 --> 00:57:33,599
деталей представьте, что я сохранил

1473
00:57:33,599 --> 00:57:34,980
это дерево  так это уже  знает, что он

1474
00:57:34,980 --> 00:57:37,200
собирается делать, поэтому в каждый момент, на который я смотрел

1475
00:57:37,200 --> 00:57:39,270
, я бы попросил другого агента сказать мне,

1476
00:57:39,270 --> 00:57:41,630
какое действие он будет делать в этом состоянии,

1477
00:57:41,630 --> 00:57:44,940
но один из действительно, так что я думаю, что

1478
00:57:44,940 --> 00:57:46,920
игра с самим собой была невероятно важным пониманием

1479
00:57:46,920 --> 00:57:48,510
для этого и почему это так  важно,

1480
00:57:48,510 --> 00:57:49,490
потому что,

1481
00:57:49,490 --> 00:57:51,560
если я играю против гроссмейстера и ухожу, я не

1482
00:57:51,560 --> 00:57:53,960
получаю вознаграждения в течение очень длительного

1483
00:57:53,960 --> 00:57:56,180
периода времени, и

1484
00:57:56,180 --> 00:57:57,770
агенту невероятно сложно извлечь урок из этого, потому

1485
00:57:57,770 --> 00:57:59,960
что нет другого сигнала вознаграждения, и поэтому, по

1486
00:57:59,960 --> 00:58:01,160
сути, вы просто играете эти тонны

1487
00:58:01,160 --> 00:58:02,420
и  тонны и тонны игр, и

1488
00:58:02,420 --> 00:58:03,740
просто нет сигнала в течение очень

1489
00:58:03,740 --> 00:58:05,180
очень долгого времени, и поэтому вам нужен какой-

1490
00:58:05,180 --> 00:58:06,560
то сигнал, чтобы вы могли начать

1491
00:58:06,560 --> 00:58:07,850
загружаться и на самом деле получить хорошую

1492
00:58:07,850 --> 00:58:11,000
политику, если я сыграю против меня пять пять

1493
00:58:11,000 --> 00:58:12,380
минут назад, я  вероятно, я побью их

1494
00:58:12,380 --> 00:58:15,050
, или, по крайней мере, в половине случаев, может быть, я

1495
00:58:15,050 --> 00:58:17,930
побью их, и это позволяет, потому что у вас

1496
00:58:17,930 --> 00:58:19,880
могут быть два плохих игрока,

1497
00:58:19,880 --> 00:58:21,500
и один из них выиграет, а один из

1498
00:58:21,500 --> 00:58:22,520
них проиграет, и вы начнете получать

1499
00:58:22,520 --> 00:58:27,470
сигнал и так этот se  Идея игры

1500
00:58:27,470 --> 00:58:29,450
была чрезвычайно полезной в контексте таких

1501
00:58:29,450 --> 00:58:32,090
игр, как игры для двух игроков, потому что это

1502
00:58:32,090 --> 00:58:33,860
может означать, что вы можете начать получать некоторый

1503
00:58:33,860 --> 00:58:35,330
сигнал вознаграждения о том, какие вещи

1504
00:58:35,330 --> 00:58:37,040
успешны или нет, и тогда кажется,

1505
00:58:37,040 --> 00:58:39,800
что и то, и другое помогает вам

1506
00:58:39,800 --> 00:58:41,750
с  специальная задача со словами, и это дает

1507
00:58:41,750 --> 00:58:44,300
вам учебный план, потому что вы всегда

1508
00:58:44,300 --> 00:58:46,460
играете только в среде,

1509
00:58:46,460 --> 00:58:48,350
которая немного сложнее, чем, возможно,

1510
00:58:48,350 --> 00:58:50,450
то, что вы можете бросить вызов, и я на самом деле

1511
00:58:50,450 --> 00:58:53,119
думаю, что было бы действительно очень здорово, если бы

1512
00:58:53,119 --> 00:58:54,380
мы могли понять, как  перенести те же

1513
00:58:54,380 --> 00:58:56,810
идеи во многие другие области, например, если

1514
00:58:56,810 --> 00:58:58,250
есть другие способы, по сути, заставить

1515
00:58:58,250 --> 00:59:01,600
себя играть в таких вещах, как медицина,

1516
00:59:01,600 --> 00:59:03,590
отношения с клиентами или тому подобное,

1517
00:59:03,590 --> 00:59:05,180
это было бы действительно здорово, потому что

1518
00:59:05,180 --> 00:59:06,680
часто очень трудно получить такой

1519
00:59:06,680 --> 00:59:08,720
сигнал вознаграждения.  хочу, и это одна

1520
00:59:08,720 --> 00:59:10,730
из действительно приятных вещей здесь,

1521
00:59:10,730 --> 00:59:13,099
так что играйте хорошо, тогда мы застрянем, и какая-то

1522
00:59:13,099 --> 00:59:15,950
местная хема абсолютно да, но это только

1523
00:59:15,950 --> 00:59:19,700
как это нормально, вы всегда пытались

1524
00:59:19,700 --> 00:59:21,380
максимизировать, так что это немного б  это похоже на улучшение политики,

1525
00:59:21,380 --> 00:59:23,000
вы всегда пытаетесь сделать

1526
00:59:23,000 --> 00:59:24,230
немного лучше, вы все еще пытаетесь

1527
00:59:24,230 --> 00:59:26,750
выиграть, поэтому возможно, что вы можете застрять

1528
00:59:26,750 --> 00:59:28,609
в случае, когда вы оба просто

1529
00:59:28,609 --> 00:59:30,079
знаете, что выигрываете в половине случаев, но

1530
00:59:30,079 --> 00:59:31,010
тогда должно быть что-то  вы можете

1531
00:59:31,010 --> 00:59:33,170
эксплуатировать, и если есть что-то новое, что можно

1532
00:59:33,170 --> 00:59:34,520
использовать, если вы хорошо спланируете, вы

1533
00:59:34,520 --> 00:59:37,540
должны быть в состоянии идентифицировать это

1534
00:59:37,970 --> 00:59:39,619
, вы представляли, что будет просто

1535
00:59:39,619 --> 00:59:42,260
точка перехода, когда вы можете получить

1536
00:59:42,260 --> 00:59:44,359
дополнительную выгоду от перехода к

1537
00:59:44,359 --> 00:59:46,640
более опытному игроку, чтобы играть против

1538
00:59:46,640 --> 00:59:48,830
против  полезность

1539
00:59:48,830 --> 00:59:50,540
начинается медленно, и он в ней, но тогда

1540
00:59:50,540 --> 00:59:52,609
вы действительно можете научиться этому быстрее,

1541
00:59:52,609 --> 00:59:54,290
играя против кого-то более жесткого, да,

1542
00:59:54,290 --> 00:59:56,450
как вы знаете, вы также всегда

1543
00:59:56,450 --> 00:59:57,680
хотели бы делать, как продавать, играть

1544
00:59:57,680 --> 00:59:59,090
против вы знаете себя пять минут

1545
00:59:59,090 --> 01:00:00,680
назад или  может быть, в какой-то момент вам было

1546
01:00:00,680 --> 01:00:02,300
бы эффективнее пойти на кого-то

1547
01:00:02,300 --> 01:00:03,710
сильнее, я думаю, это отличный вопрос, я

1548
01:00:03,710 --> 01:00:05,420
думаю, что, вероятно, это тот случай, как,

1549
01:00:05,420 --> 01:00:07,790
вероятно, были бы случаи, когда вы

1550
01:00:07,790 --> 01:00:09,830
могли бы сделать  большие скачки в учебной программе, и

1551
01:00:09,830 --> 01:00:11,570
это может ускорить обучение, но я

1552
01:00:11,570 --> 01:00:13,490
думаю, что это сложное приятное место, если

1553
01:00:13,490 --> 01:00:14,540
вам все еще нужно иметь достаточно

1554
01:00:14,540 --> 01:00:16,390
сигнала вознаграждения, чтобы начать загрузку с

1555
01:00:16,390 --> 01:00:20,570
абсолютно любого правильного, чтобы вы знали

1556
01:00:20,570 --> 01:00:21,920
преимущества этого, это становится

1557
01:00:21,920 --> 01:00:23,480
очень избирательным лучшим первым поиском

1558
01:00:23,480 --> 01:00:25,280
потому что вы как бы строите

1559
01:00:25,280 --> 01:00:26,630
часть дерева, но вы строите

1560
01:00:26,630 --> 01:00:28,760
его очень специфическим образом, и цель состоит в

1561
01:00:28,760 --> 01:00:30,290
том, чтобы вы были намного более эффективными сэмплами,

1562
01:00:30,290 --> 01:00:32,540
чем при ожидании Emax и

1563
01:00:32,540 --> 01:00:34,340
создании всего дерева, но вы

1564
01:00:34,340 --> 01:00:35,840
собираетесь намного  лучше, чем делать только один

1565
01:00:35,840 --> 01:00:37,670
шаг улучшения политики с какой-то

1566
01:00:37,670 --> 01:00:41,770
фиксированной, как вы знаете, политикой, основанной на моделировании

1567
01:00:41,770 --> 01:00:44,750
, и вы также знаете, что парализовать в

1568
01:00:44,750 --> 01:00:46,640
любое время в любое время в том смысле, что,

1569
01:00:46,640 --> 01:00:48,440
если у вас есть одна минута или у вас есть

1570
01:00:48,440 --> 01:00:50,180
три часа, чтобы вычислить следующее действие,

1571
01:00:50,180 --> 01:00:52,130
и вы  знать, что три часа могут быть очень

1572
01:00:52,130 --> 01:00:53,599
реалистичными, если это что-то вроде того, что вы

1573
01:00:53,599 --> 01:00:55,970
знаете статью с рекомендациями клиентов

1574
01:00:55,970 --> 01:00:58,250
или вещь, которая будет иметь значение, или, может быть,

1575
01:00:58,250 --> 01:00:59,510
вы собираетесь принимать одно решение за  день,

1576
01:00:59,510 --> 01:01:00,920
и поэтому вы можете запустить его на ночь в течение

1577
01:01:00,920 --> 01:01:02,270
восьми часов, а затем вычислить это одно

1578
01:01:02,270 --> 01:01:05,570
решение, чтобы оно позволило вам воспользоваться

1579
01:01:05,570 --> 01:01:06,770
преимуществами вычислений, которые у вас есть,

1580
01:01:06,770 --> 01:01:08,630
но затем всегда давать ответ, независимо

1581
01:01:08,630 --> 01:01:10,070
от того, как быстро вам нужно это сделать,

1582
01:01:10,070 --> 01:01:14,480
потому что вы просто делаете меньше, чем мы  В противном случае

1583
01:01:14,480 --> 01:01:15,800
я пропущу это сейчас, я просто хочу

1584
01:01:15,800 --> 01:01:17,599
кратко упомянуть, и я думаю, что это был

1585
01:01:17,599 --> 01:01:20,359
вопрос, это немного странно, что мы можем

1586
01:01:20,359 --> 01:01:22,550
делать бандитов на каждом из узлов, и

1587
01:01:22,550 --> 01:01:24,109
интуитивно причина, по которой это немного

1588
01:01:24,109 --> 01:01:27,260
странно, заключается в том, что в  бандиты, почему мы проявляем

1589
01:01:27,260 --> 01:01:29,180
оптимизм в условиях неопределенности, мы делаем это,

1590
01:01:29,180 --> 01:01:31,010
потому что на самом деле

1591
01:01:31,010 --> 01:01:34,010
испытываем боль от принятия неверных решений, и поэтому

1592
01:01:34,010 --> 01:01:35,599
идея оптимизма и уверенности заключается в

1593
01:01:35,599 --> 01:01:36,980
том, что либо вы действительно получаете высокую

1594
01:01:36,980 --> 01:01:39,290
награду, либо узнаете что-то странное

1595
01:01:39,290 --> 01:01:40,760
о том, что делаете.  что для планирования является

1596
01:01:40,760 --> 01:01:43,280
то, что мы не страдаем, если принимаем плохие

1597
01:01:43,280 --> 01:01:45,770
решения в своей голове, по сути, мы

1598
01:01:45,770 --> 01:01:47,900
просто пытаемся выяснить, какие действия

1599
01:01:47,900 --> 01:01:50,119
я могу предпринять как можно быстрее с

1600
01:01:50,119 --> 01:01:51,830
точки зрения ценности

1601
01:01:51,830 --> 01:01:53,210
, чтобы я знал, что  правильное

1602
01:01:53,210 --> 01:01:55,430
действие выбирается по маршруту, и поэтому на самом деле не имеет

1603
01:01:55,430 --> 01:01:57,590
значения, моделирую ли я плохие

1604
01:01:57,590 --> 01:01:59,960
действия, если это позволяет мне принять лучшее

1605
01:01:59,960 --> 01:02:01,550
решение о маршруте, мы просто даем

1606
01:02:01,550 --> 01:02:03,050
очень быстрый пример того, где это может

1607
01:02:03,050 --> 01:02:05,900
быть иначе, поэтому, если у вас есть  что-то

1608
01:02:05,900 --> 01:02:11,240
вроде этого, скажем, это

1609
01:02:11,240 --> 01:02:15,440
потенциальное значение Q, ладно, это

1610
01:02:15,440 --> 01:02:17,330
значение a1, а это значение a2,

1611
01:02:17,330 --> 01:02:19,640
и это наша неопределенность. Хорошо, если

1612
01:02:19,640 --> 01:02:20,990
вы настроены оптимистично, вы всегда

1613
01:02:20,990 --> 01:02:22,880
будете выбирать это, потому что оно имеет более

1614
01:02:22,880 --> 01:02:24,860
высокое значение.  значение, но если вы хотите быть

1615
01:02:24,860 --> 01:02:27,800
действительно уверены, что 1 лучше, вы

1616
01:02:27,800 --> 01:02:29,720
должны выбрать а2, потому что, вероятно, когда вы

1617
01:02:29,720 --> 01:02:31,130
это сделаете, вы обновите свои

1618
01:02:31,130 --> 01:02:32,420
доверительные интервалы, и теперь вы

1619
01:02:32,420 --> 01:02:35,860
будете полностью уверены, что а1 лучше,

1620
01:02:35,860 --> 01:02:38,960
но этот подход победит  Я не делаю этого, потому

1621
01:02:38,960 --> 01:02:41,390
что это нет, я понесу

1622
01:02:41,390 --> 01:02:43,340
в своей голове цену за неправильное действие, поэтому

1623
01:02:43,340 --> 01:02:45,410
я приму 1, но если в конечном счете вам

1624
01:02:45,410 --> 01:02:46,670
просто нужно знать, что

1625
01:02:46,670 --> 01:02:48,980
нужно делать правильно, то иногда с точки зрения

1626
01:02:48,980 --> 01:02:50,810
вычисления, вы должны взять 2, потому что

1627
01:02:50,810 --> 01:02:52,460
теперь лет  ваши доверительные интервалы,

1628
01:02:52,460 --> 01:02:54,200
скорее всего, разделят вас, и вам не нужно больше выполнять какие-либо

1629
01:02:54,200 --> 01:02:57,260
вычисления, поэтому неясно,

1630
01:02:57,260 --> 01:02:59,900
что бандиты в каждом узле - это оптимально

1631
01:02:59,900 --> 01:03:02,740
, но это довольно эффективно,

1632
01:03:02,740 --> 01:03:05,420
так что это в основном все, что я

1633
01:03:05,420 --> 01:03:07,370
собираюсь сказать о переходе.  есть несколько действительно

1634
01:03:07,370 --> 01:03:09,650
красивых статей об этом,

1635
01:03:09,650 --> 01:03:12,470
включая новые недавние расширения, и у них есть

1636
01:03:12,470 --> 01:03:14,150
приложения к шахматам, а также вы

1637
01:03:14,150 --> 01:03:16,010
знаете ряд других игр, которые, я

1638
01:03:16,010 --> 01:03:17,510
думаю, действительно существуют, они потрясающие

1639
01:03:17,510 --> 01:03:18,830
результаты, поэтому я настоятельно рекомендую вам

1640
01:03:18,830 --> 01:03:20,570
взглянуть на некоторые из них.  документы, позвольте мне

1641
01:03:20,570 --> 01:03:22,100
кратко рассказать о том, как

1642
01:03:22,100 --> 01:03:23,900
вернуться к концу курса, потому что

1643
01:03:23,900 --> 01:03:26,720
это последняя лекция, хорошо, поэтому я

1644
01:03:26,720 --> 01:03:28,280
просто хотел освежить в памяти, как вы знаете,

1645
01:03:28,280 --> 01:03:30,230
каковы были цели курса, когда

1646
01:03:30,230 --> 01:03:32,120
мы заканчиваем, и некоторые из  у вас, ребята, была

1647
01:03:32,120 --> 01:03:35,060
возможность потренироваться в понедельник, но я

1648
01:03:35,060 --> 01:03:36,680
просто хотел сказать, что я думаю

1649
01:03:36,680 --> 01:03:38,120
о ключевых вещах, которые, я надеюсь,

1650
01:03:38,120 --> 01:03:40,010
вы усвоили из этого, так что я вроде того,

1651
01:03:40,010 --> 01:03:41,810
что является ключевыми особенностями RL  против

1652
01:03:41,810 --> 01:03:42,920
всего  Другим важным моментом,

1653
01:03:42,920 --> 01:03:45,950
как ИИ, так и обучением с учителем, и для

1654
01:03:45,950 --> 01:03:48,560
меня является то, что на самом деле эта проблема заключается в том, что

1655
01:03:48,560 --> 01:03:49,670
агенты отправляются собирать свои собственные

1656
01:03:49,670 --> 01:03:51,470
данные и принимать решения в мире, и

1657
01:03:51,470 --> 01:03:54,920
поэтому данные датчиков сильно

1658
01:03:54,920 --> 01:03:56,540
отличаются от предположения IID об обучении с учителем,

1659
01:03:56,540 --> 01:03:58,460
и это  также очень

1660
01:03:58,460 --> 01:04:00,650
отличается от планирования, потому что вы

1661
01:04:00,650 --> 01:04:02,600
полагаетесь на данные, которые вы получаете о

1662
01:04:02,600 --> 01:04:05,470
мире, чтобы принимать решения,

1663
01:04:05,820 --> 01:04:08,130
это, вероятно, вторая вещь,

1664
01:04:08,130 --> 01:04:09,720
вероятно, вещь, которая для многих из вас

1665
01:04:09,720 --> 01:04:11,160
может оказаться самой полезной.

1666
01:04:11,160 --> 01:04:12,780
выясните с учетом

1667
01:04:12,780 --> 01:04:15,000
проблемы, следует ли вам даже записать ее

1668
01:04:15,000 --> 01:04:16,620
как проблему RL и как ее

1669
01:04:16,620 --> 01:04:18,630
сформулировать, вы немного попрактиковались в этом

1670
01:04:18,630 --> 01:04:21,150
в понедельник, а также это

1671
01:04:21,150 --> 01:04:22,440
шанс много подумать об этом в некоторых

1672
01:04:22,440 --> 01:04:24,120
из ваших проектов, но я думаю  это

1673
01:04:24,120 --> 01:04:25,590
часто одна из действительно сложных частей, она

1674
01:04:25,590 --> 01:04:27,750
имеет огромное значение для того, насколько легко или

1675
01:04:27,750 --> 01:04:30,240
сложно решить проблему, и

1676
01:04:30,240 --> 01:04:31,770
часто неясно, что существует множество способов

1677
01:04:31,770 --> 01:04:33,420
записать пространство состояний описания.

1678
01:04:33,420 --> 01:04:35,760
пациент или описание студента или

1679
01:04:35,760 --> 01:04:37,920
описание клиента, и это в некотором

1680
01:04:37,920 --> 01:04:39,900
роде восходит к проблеме аппроксимации функции по

1681
01:04:39,900 --> 01:04:42,000
сравнению с эффективностью выборки. Я

1682
01:04:42,000 --> 01:04:44,100
лечу всех клиентов, скажем, может иметь

1683
01:04:44,100 --> 01:04:45,870
много данных, это, вероятно, довольно плохая

1684
01:04:45,870 --> 01:04:47,760
модель, поэтому есть много разных

1685
01:04:47,760 --> 01:04:49,320
сделок.  -offs, которые возникают в этих случаях,

1686
01:04:49,320 --> 01:04:51,900
и я уверен, что все вы, ребята, подумаете

1687
01:04:51,900 --> 01:04:53,190
об интересных захватывающих новых способах

1688
01:04:53,190 --> 01:04:55,530
решения этого, а затем других трех

1689
01:04:55,530 --> 01:04:57,150
вещей, где вы хорошо

1690
01:04:57,150 --> 01:04:58,680
знакомы с количеством распространенных

1691
01:04:58,680 --> 01:04:59,880
алгоритмов RL, которые вы, ребята,

1692
01:04:59,880 --> 01:05:02,190
реализовали многое, чтобы понять, как мы

1693
01:05:02,190 --> 01:05:04,560
должны даже решить, хорош ли алгоритм RL,

1694
01:05:04,560 --> 01:05:07,050
будь то эмпирические вычисления, которые

1695
01:05:07,050 --> 01:05:08,190
вы знаете с точки зрения его вычислительной

1696
01:05:08,190 --> 01:05:10,200
сложности или таких вещей, как количество данных, которые

1697
01:05:10,200 --> 01:05:12,380
он принимает, или его гарантии производительности,

1698
01:05:12,380 --> 01:05:15,030
и чтобы понять эту проблему исследования и

1699
01:05:15,030 --> 01:05:17,130
эксплуатации, которая на самом деле

1700
01:05:17,130 --> 01:05:19,080
совершенно уникален для RL, он не возникает,

1701
01:05:19,080 --> 01:05:21,540
и планирование не возникает в мл, и

1702
01:05:21,540 --> 01:05:23,310
снова это критический вопрос, например,

1703
01:05:23,310 --> 01:05:25,200
как вы собираете данные  быстро,

1704
01:05:25,200 --> 01:05:29,040
чтобы принимать правильные решения, если вы хотите

1705
01:05:29,040 --> 01:05:30,060
узнать больше об обучении с подкреплением,

1706
01:05:30,060 --> 01:05:31,290
есть куча других классов,

1707
01:05:31,290 --> 01:05:33,000
особенно микро Кака и усилие, есть

1708
01:05:33,000 --> 01:05:35,100
несколько действительно хороших, а также Бен Ван

1709
01:05:35,100 --> 01:05:36,630
Рой делает несколько хороших, особенно

1710
01:05:36,630 --> 01:05:37,890
глядя на некоторые из более теоретических

1711
01:05:37,890 --> 01:05:40,560
аспекты этого, а затем я делаю расширенный

1712
01:05:40,560 --> 01:05:42,240
обзор этого, где мы рассматриваем текущие темы,

1713
01:05:42,240 --> 01:05:45,630
и это класс, основанный на проектах, и

1714
01:05:45,630 --> 01:05:47,520
я просто, я думаю, я сделаю еще две вещи,

1715
01:05:47,520 --> 01:05:49,530
одна из которых, я думаю, вы знаете, что мы видим некоторые

1716
01:05:49,530 --> 01:05:51,660
действительно удивительные  результаты идут — это один из примеров,

1717
01:05:51,660 --> 01:05:54,090
и мы видим, что начинаем видеть некоторые

1718
01:05:54,090 --> 01:05:55,590
действительно захватывающие результаты в робототехнике, но

1719
01:05:55,590 --> 01:05:57,930
я думаю, что мы упускаем из виду, что у большинства из нас еще

1720
01:05:57,930 --> 01:06:00,030
нет RL на нашем телефоне таким же образом, как

1721
01:06:00,030 --> 01:06:01,530
у нас есть распознавание лиц на нашем телефоне,

1722
01:06:01,530 --> 01:06:03,720
и поэтому я  думаю, что потенциал

1723
01:06:03,720 --> 01:06:05,220
использования этих типов идей для многих

1724
01:06:05,220 --> 01:06:06,810
других типов приложений по-прежнему

1725
01:06:06,810 --> 01:06:09,180
огромен, и поэтому, если вы уйдете и сделаете что-

1726
01:06:09,180 --> 01:06:10,200
то из этого, я хотел бы услышать

1727
01:06:10,200 --> 01:06:12,780
об этом в моей лаборатории, мы много думаем об

1728
01:06:12,780 --> 01:06:15,030
этом  другие формы  приложений, и я

1729
01:06:15,030 --> 01:06:16,410
думаю, что еще одним действительно важным аспектом

1730
01:06:16,410 --> 01:06:18,510
этого является размышление о том, когда мы делаем этих

1731
01:06:18,510 --> 01:06:18,930


1732
01:06:18,930 --> 01:06:21,510
агентов RL, как мы делаем это безопасным,

1733
01:06:21,510 --> 01:06:23,220
честным и подотчетным образом, потому что,

1734
01:06:23,220 --> 01:06:24,510
как правило, эти системы будут

1735
01:06:24,510 --> 01:06:26,339
частью системы циклов

1736
01:06:26,339 --> 01:06:29,069
и  так что предоставление агентам возможности

1737
01:06:29,069 --> 01:06:31,760
раскрыть свои рассуждения и раскрыть

1738
01:06:31,760 --> 01:06:35,520
свои ограничения будет иметь решающее значение,

1739
01:06:35,520 --> 01:06:37,500
поэтому последнее, что действительно

1740
01:06:37,500 --> 01:06:39,000
полезно, чтобы вы, ребята, получали обратную связь, это

1741
01:06:39,000 --> 01:06:40,829
позволяет нам улучшить класс на

1742
01:06:40,829 --> 01:06:42,780
будущие годы либо убедиться, что мы

1743
01:06:42,780 --> 01:06:44,190
продолжаем  делать то, что вы нашли

1744
01:06:44,190 --> 01:06:45,780
полезным, или что мы прекратили делать то,

1745
01:06:45,780 --> 01:06:47,280
что вы не нашли полезным, поэтому я был бы

1746
01:06:47,280 --> 01:06:48,480
очень признателен, что мы могли бы потратить около

1747
01:06:48,480 --> 01:06:50,609
десяти минут, чтобы просмотреть оценки курса

1748
01:06:50,609 --> 01:06:53,730
и просто передать его, дайте нам знать,

1749
01:06:53,730 --> 01:06:55,680
что помогает вам учиться  что мы

1750
01:06:55,680 --> 01:06:59,180
могли бы сделать еще лучше в следующем году Спасибо

